<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AWS on dwmkerr.com</title><link>http://dwmkerr.com/tags/AWS/</link><description>Recent content in AWS on dwmkerr.com</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Dave Kerr</copyright><lastBuildDate>Tue, 11 Dec 2018 21:24:34 +0000</lastBuildDate><atom:link href="http://dwmkerr.com/tags/AWS/index.xml" rel="self" type="application/rss+xml"/><item><title>Dynamic and Configurable Availability Zones in Terraform</title><link>http://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</link><pubDate>Tue, 11 Dec 2018 21:24:34 +0000</pubDate><guid>http://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</guid><description>When building Terraform modules, it is a common requirement to want to allow the client to be able to choose which region resources are created in, and which availability zones are used.
I've seen a few ways of doing this, none of which felt entirely satisfactory. After a bit of experimentation I've come up with a solution which I think really works nicely. This solution avoids having to know in advance how many availability zones we'll support.</description></item><item><title>Integrating OpenShift and Splunk for Docker Container Logging</title><link>http://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</link><pubDate>Sun, 29 Oct 2017 07:15:04 +0000</pubDate><guid>http://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</guid><description>In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.
These techniques could easily be adapted for a standard Kubernetes installation as well!
The techniques used in this article are based on the Kubernetes Logging Cluster Administration Guide. I also found Jason Poon's article Kubernetes Logging with Splunk very helpful.
First, clone the Terraform AWS OpenShift repo:</description></item><item><title>Get up and running with OpenShift on AWS</title><link>http://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</link><pubDate>Thu, 02 Feb 2017 07:47:00 +0000</pubDate><guid>http://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</guid><description>OpenShift is Red Hat's platform-as-a-service offering for hosting and scaling applications. It's built on top of Google's popular Kubernetes system.
Getting up and running with OpenShift Online is straightforward, as it is a cloud hosted solution. Setting up your own cluster is a little more complex, but in this article I'll show you how to make it fairly painless.
The repo for this project is at: github.com/dwmkerr/terraform-aws-openshift.
Creating the Infrastructure OpenShift has some fairly specific requirements about what hardware it runs on1.</description></item><item><title>Creating a Resilient Consul Cluster for Docker Microservice Discovery with Terraform and AWS</title><link>http://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</link><pubDate>Mon, 09 Jan 2017 07:10:40 +0000</pubDate><guid>http://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</guid><description>In this article I'm going to show you how to create a resilient Consul cluster, using Terraform and AWS. We can use this cluster for microservice discovery and management. No prior knowledge of the technologies or patterns is required!
The final code is at github.com/dwmkerr/terraform-consul-cluster. Note that it has evolved somewhat since the time of writing, see the Appendices at the end of the article for details.
Consul, Terraform &amp;amp; AWS Consul is a technology which enables Service Discovery1, a pattern which allows services to locate each other via a central authority.</description></item><item><title>Run Amazon DynamoDB locally with Docker</title><link>http://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</link><pubDate>Thu, 27 Oct 2016 08:06:00 +0000</pubDate><guid>http://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</guid><description>tl;dr: Run DynamoDB locally using Docker:
docker run -d -p 8000:8000 dwmkerr/dynamodb Try it out by opening the shell, localhost:8000/shell:
That's all there is to it!
DynamoDB Amazon DynamoDB is a NoSQL database-as-a-service, which provides a flexible and convenient repository for your services.
Building applications which use DynamoDB is straightforward, there are APIs and clients for many languages and platforms.
One common requirement is to be able to run a local version of DynamoDB, for testing and development purposes.</description></item><item><title>Failures Connecting from Elastic Beanstalk servers to MongoDB on EC?</title><link>http://dwmkerr.com/failures-connecting-from-elastic-beanstalk-servers-to-mongodb-on-ec/</link><pubDate>Mon, 16 Mar 2015 10:34:04 +0000</pubDate><guid>http://dwmkerr.com/failures-connecting-from-elastic-beanstalk-servers-to-mongodb-on-ec/</guid><description>tl;dr?
Check your mongodb.conf bind_ip settings to make sure that you're not allowing connections only from localhost.
This may just end up being the first part of a wider troubleshooting guide, but this is one I've spent a few hours fixing, after assuming I was making terrible mistakes with my security groups.
If you find you cannot connect to your MongoDB server from an EB app server (or anything for that matter), before you spend ages checking your Elastic IP, VPC and Security Group config, don't forget that you may have simply used bind_ip in your config file.</description></item></channel></rss>