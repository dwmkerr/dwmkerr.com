<!doctype html><html prefix="og: http://ogp.me/ns#"><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Integrating OpenShift and Splunk for Docker Container Logging &#183; Dave Kerr</title><meta name=description content="In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.
These techniques could easily be adapted for a standard Kubernetes installation as well!
The techniques used in this article are based on the Kubernetes Logging Cluster Administration Guide. I also found Jason Poon's article Kubernetes Logging with Splunk very helpful.
First, clone the Terraform AWS OpenShift repo:"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=generator content="Hugo 0.61.0"><meta name=robots content="index,follow"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Integrating OpenShift and Splunk for Docker Container Logging"><meta property="og:description" content="In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.
These techniques could easily be adapted for a standard Kubernetes installation as well!
The techniques used in this article are based on the Kubernetes Logging Cluster Administration Guide. I also found Jason Poon's article Kubernetes Logging with Splunk very helpful.
First, clone the Terraform AWS OpenShift repo:"><meta property="og:type" content="article"><meta property="og:url" content="http://example.org/integrating-openshift-and-splunk-for-logging/"><link rel=stylesheet href=http://example.org/dist/styles.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic"><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css integrity=sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN crossorigin=anonymous></head><body><script type=application/javascript>var dnt=(navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack);var doNotTrack=(dnt=="1"||dnt=="yes");if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-41728580-1','auto');ga('set','anonymizeIp',true);ga('send','pageview');}</script><div id=wrapper><header class=site-header><div class=container><div class=site-title-wrapper><h1 class=site-title><a title=dwmkerr.com href=http://example.org/>dwmkerr.com</a></h1><a class=button-square href=http://example.org/index.xml><i class="fa fa-rss"></i></a><a class="button-square button-social hint--top" data-hint=Twitter title=Twitter href=https://twitter.com/dwmkerr rel=me><i class="fa fa-twitter"></i></a><a class="button-square button-social hint--top" data-hint=Github title=Github href=https://github.com/dwmkerr rel=me><i class="fa fa-github-alt"></i></a><a class="button-square button-social hint--top" data-hint="Stack Overflow" title="Stack Overflow" href=https://stackoverflow.com/users/1189164/dave-kerr rel=me><i class="fa fa-stack-overflow"></i></a><a class="button-square button-social hint--top" data-hint=LinkedIn title=LinkedIn href=https://www.linkedin.com/in/dwmkerr/ rel=me><i class="fa fa-linkedin"></i></a></div><ul class=site-nav><li class=site-nav-item><a title=Blog href=/>Blog</a></li><li class=site-nav-item><a title=Speaking href=/page/speaking/>Speaking</a></li><li class=site-nav-item><a title=About href=/page/about/>About</a></li></ul></div></header><div id=container><div class=container><article class=post-container itemscope itemtype=http://schema.org/BlogPosting><header class=post-header><h1 class=post-title itemprop="name headline">Integrating OpenShift and Splunk for Docker Container Logging</h1><p class="post-date post-line"><span>Published <time datetime=2017-10-29 itemprop=datePublished>Sun, Oct 29, 2017</time></span>
<span>by</span>
<span itemscope itemprop=author itemtype=https://schema.org/Person><span itemprop=name><a href=https://github.com/dwmkerr itemprop=url rel=author>Dave Kerr</a></span></span></p></header><div class="post-content clearfix" itemprop=articleBody><img class=post-featured-image src=/images/2017/10/counter-service-splunk-1.png><p>In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.</p><p>These techniques could easily be adapted for a standard Kubernetes installation as well!</p><p><img src=/images/2017/10/counter-service-splunk.png alt="Screenshot: Counter service splunk"></p><p>The techniques used in this article are based on the <a href=https://kubernetes.io/docs/concepts/cluster-administration/logging>Kubernetes Logging Cluster Administration Guide</a>. I also found Jason Poon's article <a href=http://jasonpoon.ca/2017/04/03/kubernetes-logging-with-splunk/>Kubernetes Logging with Splunk</a> very helpful.</p><p>First, clone the <a href=https://github.com/dwmkerr/terraform-aws-openshift>Terraform AWS OpenShift</a> repo:</p><pre><code>git clone git@github.com:dwmkerr/terraform-aws-openshift
</code></pre><p>This repo can be used to create a vanilla OpenShift cluster. I'm adding &lsquo;recipes&rsquo; to the project, which will allow you to mix in more features (but still keep the main codebase clean). For now, let's merge in the &lsquo;splunk&rsquo; recipe:</p><pre><code>cd terraform-aws-openshift
git pull origin recipes/splunk
</code></pre><p>Pulling this recipe in adds the extra config and scripts required to set up Splunk<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>.</p><p>Now we've got the code, we can get started!</p><h2 id=create-the-infrastructure>Create the Infrastructure</h2><p>To create the cluster, you'll need to install the <a href=https://aws.amazon.com/cli/>AWS CLI</a> and log in, and install <a href=https://www.terraform.io/downloads.html>Terraform</a>.</p><p>Before you continue, <strong>be aware</strong>: the machines on AWS we'll create are going to run to about $250 per month:</p><p><img src=/images/2017/10/aws-cost.png alt="AWS Cost Calculator"></p><p>Once you are logged in with the AWS CLI just run:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make infrastructure
</code></pre></div><p>You'll be asked to specify a region:</p><p><img src=/images/2017/10/region.png alt="Specify Region"></p><p>Any <a href=http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions>AWS region</a> will work fine, use <code>us-east-1</code> if you are not sure.</p><p>It'll take about 5 minutes for Terraform to build the required infrastructure, which looks like this:</p><p><img src=/images/2017/10/splunk-architecture.png alt="AWS Infrastructure"></p><p>Once it's done you'll see a message like this:</p><p><img src=/images/2017/10/apply-complete.png alt="Apply Complete"></p><p>The infrastructure is ready! A few of the most useful parameters are shown as output variables. If you log into AWS you'll see our new instances, as well as the VPC, network settings etc etc:</p><p><img src=/images/2017/10/aws.png alt=AWS></p><h2 id=installing-openshift>Installing OpenShift</h2><p>Installing OpenShift is easy:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make openshift
</code></pre></div><p>This command will take quite some time to run (sometimes up to 30 minutes). Once it is complete you'll see a message like this:</p><p><img src=/images/2017/10/openshift-complete.png alt="OpenShift Installation Complete"></p><p>You can now open the OpenShift console. Use the public address of the master node (which you can get with <code>$(terraform output master-url)</code>), or just run:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make browse-openshift
</code></pre></div><p>The default username and password is <code>admin</code> and <code>123</code>. You'll see we have a clean installation and are ready to create our first project:</p><p><img src=/images/2017/10/welcome-to-openshift.png alt="Welcome to OpenShift"></p><p>Close the console for now.</p><h2 id=installing-splunk>Installing Splunk</h2><p>You've probably figured out the pattern by now&mldr;</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make splunk
</code></pre></div><p>Once this command is complete, you can open the Splunk console with:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make browse-splunk
</code></pre></div><p>Again the username and password is <code>admin</code> and <code>123</code>. You can change the password on login, or leave it:</p><p><img src=/images/2017/10/splunk-home.png alt="Splunk Login"></p><p>You can close the Splunk console now, we'll come back to it shortly.</p><h2 id=demoing-splunk-and-openshift>Demoing Splunk and OpenShift</h2><p>To see Splunk and OpenShift in action, it helps to have some kind of processing going on in the cluster. You can create a very basic sample project which will spin up two nodes which just write a counter every second as a way to get something running:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>make sample
</code></pre></div><p>This will create a simple &lsquo;counter&rsquo; service:</p><p><img src=/images/2017/10/counter-service.png alt="Screenshot: The counter service"></p><p>We can see the logs in OpenShift:</p><p><img src=/images/2017/10/counter-service-logs.png alt="Screenshot: The counter service logs"></p><p>Almost immediately you'll be able to see the data in Splunk:</p><p><img src=/images/2017/10/counter-service-splunk-data-summary.png alt="Screenshot: The Splunk data explorer"></p><p>And because of the way the log files are named, we can even rip out the namespace, pod, container and id:</p><p><img src=/images/2017/10/counter-service-splunk.png alt="Screenshot: Counter service splunk"></p><p>That's it! You have OpenShift running, Splunk set up and automatically forwarding of all container logs. Enjoy!</p><h2 id=how-it-works>How It Works</h2><p>I've tried to keep the setup as simple as possible. Here's how it works.</p><h3 id=how-log-files-are-written>How Log Files Are Written</h3><p>The Docker Engine has a <a href=https://docs.docker.com/engine/admin/logging/overview/>log driver</a> which determines how container logs are handled<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. It defaults to the <code>json-file</code> driver, which means that logs are written as a json file to:</p><pre><code>/var/lib/docker/containers/{container-id}/{container-id}-json.log
</code></pre><p>Or visually:</p><p><img src=/images/2017/10/logging-docker-1.png alt="Diagram: How Docker writes log files"></p><p>Normally we wouldn't touch this file, in theory it is supposed to be used internally<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> and we would use <code>docker logs &lt;container-id></code>.</p><p>In theory, all we need to do is use a <a href=http://docs.splunk.com/Documentation/Forwarder/7.0.0/Forwarder/Abouttheuniversalforwarder>Splunk Forwarder</a> to send this file to our indexer. The only problem is that we only get the container ID from the file name, finding the right container ID for your container can be a pain. However, we are running on Kubernetes, which means the picture is a little different&mldr;</p><h3 id=how-log-files-are-written---on-kubernetes>How Log Files Are Written - on Kubernetes</h3><p>When running on Kubernetes, things are little different. On machines with <code>systemd</code>, the log driver for the docker engine is set to <code>journald</code> (see <a href=https://kubernetes.io/docs/concepts/cluster-administration/logging/>Kubernetes - Logging Architecture</a>.</p><p>It <em>is</em> possible to forward <code>journald</code> to Splunk, but only by streaming it to a file and then forwarding the file. Given that we need to use a file as an intermediate, it seems easier just to change the driver back to <code>json-file</code> and forward that.</p><p>So first, we configure the docker engine to use <code>json-file</code> (see <a href=https://github.com/dwmkerr/terraform-aws-openshift/blob/recipes/splunk/scripts/postinstall-master.sh>this file</a>):</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sed -i <span style=color:#e6db74>&#39;/OPTIONS=.*/c\OPTIONS=&#34;--selinux-enabled --insecure-registry 172.30.0.0/16 --log-driver=json-file --log-opt max-size=1M --log-opt max-file=3&#34;&#39;</span> /etc/sysconfig/docker
</code></pre></div><p>Here we just change the options to default to the <code>json-file</code> driver, with a max file size of 1MB (and maximum of three files, so we don't chew all the space on the host).</p><p>Now the cool thing about Kubernetes is that it creates symlinks to the log files, which have much more descriptive names:</p><p><img src=/images/2017/10/logging-k8s.png alt="Symlink diagram"></p><p>We still have the original container log, in the same location. But we also have a pod container log (which is a symlink to the container log) and another container log, which is a symlink to the pod container log.</p><p>This means we can read the container log, and extract some really useful information from the file name. The container log file name has the following format:</p><pre><code>/var/log/containers/{container-id}/{container-id}-json.log
</code></pre><h3 id=how-log-files-are-read>How Log Files Are Read</h3><p>Now that we are writing the log files to a well defined location, reading them is straightforward. The diagram below shows how we use a splunk-forwarder to complete the picture:</p><p><img src=/images/2017/10/how-logs-are-read.png alt="Diagram: How logs are read"></p><p>First, we create a DaemonSet, which ensures we run a specific pod on every node.</p><p>The DaemonSet runs with a new account which has the &lsquo;any id&rsquo; privilege, allowing it to run as root. We then mount the log folders into the container (which are owned by root, which is why our container needs these extra permissions to read the files).</p><p>The pod contains a splunk-forwarder container, which is configured to monitor the <code>/var/log/containers</code> folder. It also monitors the docker socket, allowing us to see docker events. The forwarder is also configured with the IP address of the Splunk Indexer.</p><h2 id=footnotes>Footnotes</h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>As a reference, you can also see the recipe pull request to see what changes from a &lsquo;vanilla&rsquo; installation to add Splunk: <a href=https://github.com/dwmkerr/terraform-aws-openshift/pull/16>Splunk Recipe Pull Request</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>It is useful to check the documentation on logging drivers for Docker. See <a href=https://docs.docker.com/engine/admin/logging/overview/#supported-logging-drivers>Configure Logging Drivers</a> and <a href=https://docs.docker.com/engine/extend/plugins_logging/>Docker Log Driver Plugins</a>. It is possible to create custom log drivers. However, at the time of writing only the journald and json-file log drivers will work with the integrated logging view in OpenShift. <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer class="post-footer clearfix"><p class=post-tags><span>Tagged:</span>
<a href=/tags/OpenShift/>OpenShift</a>,
<a href=/tags/Terraform/>Terraform</a>,
<a href=/tags/AWS/>AWS</a>,
<a href=/tags/CodeProject/>CodeProject</a>,
<a href=/tags/Splunk/>Splunk</a>,
<a href=/tags/Kubernetes/>Kubernetes</a></p><div class=share><a class=icon-twitter href="https://twitter.com/share?text=Integrating%20OpenShift%20and%20Splunk%20for%20Docker%20Container%20Logging&url=http%3a%2f%2fexample.org%2fintegrating-openshift-and-splunk-for-logging%2f" onclick="window.open(this.href,'twitter-share','width=550,height=235');return false;"><i class="fa fa-twitter"></i><span class=hidden>Twitter</span></a>
<a class=icon-facebook href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fexample.org%2fintegrating-openshift-and-splunk-for-logging%2f" onclick="window.open(this.href,'facebook-share','width=580,height=296');return false;"><i class="fa fa-facebook"></i><span class=hidden>Facebook</span></a></div></footer><div class=comments><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"dmwkerr"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></article></div></div></div><footer class=footer><div class=container><div class=site-title-wrapper><h1 class=site-title><a title=dwmkerr.com href=http://example.org/>dwmkerr.com</a></h1><a class="button-square button-jump-top js-jump-top" href=#><i class="fa fa-angle-up"></i></a></div><p class=footer-copyright><span>&copy; 2019 / Powered by <a href=https://gohugo.io/>Hugo</a></span></p><p class=footer-copyright><span><a href=https://github.com/roryg/ghostwriter>Ghostwriter theme</a> By <a href=http://jollygoodthemes.com>JollyGoodThemes</a></span>
<span>/ <a href=https://github.com/jbub/ghostwriter>Ported</a> to Hugo By <a href=https://github.com/jbub>jbub</a></span></p></div></footer><script src=http://example.org/js/jquery-1.11.3.min.js></script><script src=http://example.org/js/jquery.fitvids.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script><script src=http://example.org/js/scripts.js></script></body></html>