<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Devops on dwmkerr.com</title><link>https://dwmkerr.com/categories/devops/</link><description>Recent content in Devops on dwmkerr.com</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Copright &amp;copy; Dave Kerr</copyright><lastBuildDate>Wed, 01 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://dwmkerr.com/categories/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Modernising .NET projects for .NET Core and beyond!</title><link>https://dwmkerr.com/modernising-dotnet-projects/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/modernising-dotnet-projects/</guid><description>&lt;p>The world of .NET is going through a transformation. The .NET Framework is reaching end of life, &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">.NET Core&lt;/a> is an increasingly feature rich and robust platform to develop solutions which target Linux, MacOS, embedded devices, containers and more. There's also the .NET Standard.&lt;/p>
&lt;p>But what does this mean for .NET &lt;em>Framework&lt;/em> projects? In this article I'll describe how to modernise your .NET Framework projects for .NET Core, the .NET Standard and .NET 5, which is planned to be released this year. I'll also explain the high level differences between the platforms and what the consequences of upgrading are for consumers, developers and maintainers.&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#the-net-framework-net-core-and-the-future">The .NET Framework, .NET Core and the Future&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-challenge-modernisation-and-compatibility">The Challenge: Modernisation and Compatibility&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-modernisation-process---introducing-our-two-villains">The Modernisation Process - Introducing our two Villains&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#step-1---understand-the-domain">Step 1 - Understand the Domain&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-2---understand-the-goal---multi-platform-builds">Step 2 - Understand the Goal - Multi-Platform Builds&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-3---migrate-projects-leaf-wise">Step 3 - Migrate Projects &amp;ldquo;Leaf-wise&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-4---refactor-rinse-repeat">Step 4 - Refactor, Rinse, Repeat&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-5---update-your-builds">Step 5 - Update Your Builds&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-6---test-test-test">Step 6 - Test, Test, Test&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-7---document-compatibility">Step 7 - Document Compatibility&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-key-learnings">The Key Learnings&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h1 id="the-net-framework-net-core-and-the-future">The .NET Framework, .NET Core and the Future&lt;/h1>
&lt;p>There's a lot which has been written on this topic, but it can still be a little overwhelming to understand just how all of these things fit together.&lt;/p>
&lt;p>Here's a simple visual I've created to try and put things into context:&lt;/p>
&lt;p>&lt;img src="images/dotnet-timeline.png" alt="Diagram: .NET Timeline">&lt;/p>
&lt;p>I'm only going to cover the bare essentials - but there are links to further reading on each topic if you want to go deeper. This article is mainly going to be focused on the practicality and consequence of migration and re-targeting.&lt;/p>
&lt;p>First, the &lt;strong>.NET Framework&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>The .NET Framework was created in 2002 as set of unified tools and standards to allow developers on the Microsoft Platform to more quickly build solutions, provide interoperability between languages and more. &lt;a href="https://dotnet.microsoft.com/learn/dotnet/what-is-dotnet-framework">Read more about the .NET Framework&lt;/a>.&lt;/li>
&lt;li>The .NET Framework rapidly gained popularity, partly due to the convenience of developing in C# rather than Basic or C/C++. C# provided a more developer friendly language than C or C++ for many use cases, and was heavily inspired by Java. &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/">Read more about C#&lt;/a>.&lt;/li>
&lt;li>With the increase in popularity, the .NET Framework started to have more frequent releases and became a standard part of the Windows operating system, installed out of the box rather than on-demand if needed.&lt;/li>
&lt;li>However - the .NET Framework only functioned on Microsoft Windows, which greatly limited its potential uses cases, even as more and more engineers used it for Web, Client Applications and mobile.&lt;/li>
&lt;/ul>
&lt;p>Enter &lt;strong>.NET Core&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Microsoft signaled a &lt;em>radical&lt;/em> switch in their strategy with the appointment of &lt;a href="https://en.wikipedia.org/wiki/Satya_Nadella">Satya Nadella&lt;/a>, becoming increasingly focused on open source, and more importantly, deciding that the Microsoft development toolchain should not &lt;em>force&lt;/em> users to use Windows as their execution environment&lt;/li>
&lt;li>.NET Core was developed as a lightweight version of the .NET Framework, which could run on multiple platforms - including Linux and MacOS. &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">Read more about .NET Core&lt;/a>.&lt;/li>
&lt;li>In a short period of time .NET Core became more and more feature rich, providing a lot of capabilities for web developers and front-end application developers.&lt;/li>
&lt;/ul>
&lt;p>The challenges of &lt;strong>divergence&lt;/strong> and the &lt;strong>.NET Standard&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>As .NET Core became more feature rich, the API became closer to the .NET Framework - but they are still fundamentally different runtimes. A binary compiled for the .NET Core does not run on the .NET Framework and vice-versa.&lt;/li>
&lt;li>To deal with this issue, Microsoft developed the &lt;strong>.NET Standard&lt;/strong> - a specification of a set of APIs. If a runtime offered these APIs, then solutions built on &lt;em>any runtime which meets the standard&lt;/em> could run on any compliant platform.&lt;/li>
&lt;/ul>
&lt;p>What does this mean? Basically, the table below shows the consequences of this. If you build on .NET Core 2.0 (for example), you can also run on the .NET Framework 4.6.1. Mono 5.4, Unity 2018.1 and more, because all of these runtimes implement the &lt;em>.NET Standard 2.0&lt;/em>.&lt;/p>
&lt;p>Of course, some features are always going to be very platform specific, so the standard started out small but has grown over time.&lt;/p>
&lt;p>Moving to &lt;strong>convergence&lt;/strong> and &lt;strong>.NET&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Given that the later versions of the .NET Framework and .NET Core actually follow the same standard, the platforms are actually starting to become more and more similar.&lt;/li>
&lt;li>They are becoming &lt;em>so&lt;/em> similar that it no longer makes sense to maintain them separately. The next major version of &lt;em>both&lt;/em> platforms is &lt;strong>.NET 5&lt;/strong>. This is a new runtime which is the next version of .NET Core &lt;em>and&lt;/em> the .NET Framework.&lt;/li>
&lt;/ul>
&lt;p>This means that the .NET Framework and .NET Core are going to converge into a single platform, which will be wonderful for developers and simplify a complex landscape.&lt;/p>
&lt;p>But what does this mean if you have .NET Framework projects? How do we modernise, and do we have to make trade-offs around compatibility?&lt;/p>
&lt;h1 id="the-challenge-modernisation-and-compatibility">The Challenge: Modernisation and Compatibility&lt;/h1>
&lt;p>I have a number of projects which target the .NET Framework. On &lt;em>all&lt;/em> of these projects I have had multiple requests to migrate to the .NET Core, but I have had to hold off on this work until I could really understand in detail a few things:&lt;/p>
&lt;ol>
&lt;li>What would this mean for &lt;em>consumers&lt;/em> of the libraries? Would they have to change the platform they use? Could this break things for them?&lt;/li>
&lt;li>What would this mean for &lt;em>developers&lt;/em> on the platform? Would they need to change their development environment? Would this cause problems?&lt;/li>
&lt;li>What would this mean for &lt;em>maintainers&lt;/em> of the libraries? Would this greatly increase build and deployment complexity?&lt;/li>
&lt;/ol>
&lt;p>Finally I have found the time to be able to start to address these issues in detail - hopefully the learnings will be useful to anyone who is maintaining a .NET codebase and thinking about the future.&lt;/p>
&lt;h1 id="the-modernisation-process---introducing-our-two-villains">The Modernisation Process - Introducing our two Villains&lt;/h1>
&lt;p>There are two key projects I wanted to modernise. They are both reasonably well used, complex, and have some potentially serious complexities for multi-platform builds.&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/sharpgl">&lt;strong>SharpGL&lt;/strong>&lt;/a> is a library that allows developers to use &lt;a href="https://www.opengl.org/">OpenGL&lt;/a> in .NET applications. The big challenge? OpenGL is cross platform, but SharpGL &lt;em>specifically&lt;/em> provides an interface to the &lt;em>Windows&lt;/em> version of OpenGL. Can this possibly be made more future-proof? Could it ever target other platforms?&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/sharpshell">&lt;strong>SharpShell&lt;/strong>&lt;/a> is a library that allows developers to build &amp;lsquo;Shell Extensions&amp;rsquo; for Windows. Shell extensions are customisations to the Windows user interface, so would not be portable across platforms, but I still want to ensure that the project is future proof.&lt;/p>
&lt;p>What would be the experience with these two projects? I have other .NET projects, but they are far less popular and much more simple, my instinct is that if I can work through the process with &lt;em>these&lt;/em> projects, the others should be more straightforward.&lt;/p>
&lt;p>These are the steps I've followed to modernise. I'll finish the article with a summary of the key learnings.&lt;/p>
&lt;h2 id="step-1---understand-the-domain">Step 1 - Understand the Domain&lt;/h2>
&lt;p>I cannot stress this enough. In all meaningful technology work, &lt;em>understand the domain&lt;/em> you are dealing with. A quick Google on how to migrate, or following the formal migration guide was not enough for me. I knew I had to actually understand, at a reasonably detailed level, the differences in the runtime, the trade-offs, the process, the complexity.&lt;/p>
&lt;p>This article is the result of that work - sometimes writing about a topic is the best way to force yourself to learn it.&lt;/p>
&lt;p>Making changes rapidly and waiting to see what the consequences are can often work for small projects, internal tools and so on, but for a library which is relied upon by others is not good for the community. The last thing I wanted to do was make changes which had unintended consequences for users. So making sure that I learnt about this space, how things work under the hood, and what the expected changes in the future are was critical.&lt;/p>
&lt;p>Hopefully for others the process of understanding the domain will be a little easier with this article to cover the high level topics. During my actual process of writing and migrating, I went a lot deeper than this article goes.&lt;/p>
&lt;p>The key document to follow to actually &lt;em>execute&lt;/em> the migration is the excellent official &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">.NET Framework to .NET Core Porting Guide&lt;/a>.&lt;/p>
&lt;h2 id="step-2---understand-the-goal---multi-platform-builds">Step 2 - Understand the Goal - Multi-Platform Builds&lt;/h2>
&lt;p>Given the understanding of the domain, it made it much easier to understand what the required steps would be. Essentially, all that would be needed would be to target a version of the .NET Framework which adheres to a recent version of the .NET Standard. Once this was done, in theory the project could be built for the .NET Framework &lt;em>and&lt;/em> for .NET Core, and also be ready for the upcoming .NET 5 release.&lt;/p>
&lt;p>Multi-platform builds are supported in Visual Studio 2019. These builds allow us to have a single codebase, but build libraries for multiple platforms (i.e. the .NET Framework and .NET Core). The resulting binaries can be packed as a single package, and when consumers install the package, the appropriate library is installed.&lt;/p>
&lt;p>This introduces the first of the significant consequences - modernising your project means you must migrate it to Visual Studio 2019.&lt;/p>
&lt;p>In the past, this might have been more of an issue, licenses for Visual Studio were expensive, and many organisations were locked onto specific versions for compatibility issues (or because they were slow to upgrade). This seems to be the case less often nowadays, but is still an important consideration.&lt;/p>
&lt;p>My projects were using Visual Studio 2017. This is how the project properties looked:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-target-framework-2017.png" alt="Screenshot: SharpGL Target Framework Properties for Visual Studio 2017">&lt;/p>
&lt;p>Unsurprisingly the .NET Standard isn't mentioned. Time to upgrade to 2019. While I installed it I could reminisce about the excitement of buying Visual C++ .NET Learning Edition:&lt;/p>
&lt;p>&lt;img src="./images/visual-cpp-dotnet-learning-edition.jpg" alt="Photo: Visual C++ .NET 2003 Learning Edition">&lt;/p>
&lt;p>And try and remember what is was like to be a 15 years old. I wonder if that box set is still kicking around somewhere, I want to see it again. So much has changed. But long install processes for Visual Studio haven't, at least they kept that:&lt;/p>
&lt;p>&lt;img src="./images/install-visual-studio-2019.png" alt="Screenshot: Visual Studio 2019 Installer">&lt;/p>
&lt;p>When installing, remember to enable the .NET Core features.&lt;/p>
&lt;h2 id="step-3---migrate-projects-leaf-wise">Step 3 - Migrate Projects &amp;ldquo;Leaf-wise&amp;rdquo;&lt;/h2>
&lt;p>As per the &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Porting Guide&lt;/a>, we need to migrate each of the projects which make up the solution, starting with the &amp;lsquo;leaves&amp;rsquo; (projects which don't depend on other projects) and then moving up the tree to the &amp;lsquo;root&amp;rsquo; projects (projects which are depended on by others).&lt;/p>
&lt;p>Visually, for a solution like SharpGL, that would mean the projects will need to be converted in the following order:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-project-structure.png" alt="Diagram: SharpGL Project Dependency Graph">&lt;/p>
&lt;p>I was expecting each project to have quite different experiences:&lt;/p>
&lt;ul>
&lt;li>&lt;code>SharpGL.Serialization&lt;/code> is just a set of classes which load data from files. In theory, this library should become completely portable.&lt;/li>
&lt;li>&lt;code>SharpGL.WPF&lt;/code> and &lt;code>SharpGL.WinForms&lt;/code> are &lt;em>specifically&lt;/em> for Windows front-end technologies. I expected these to be able to be ported, but don't expect them to work on other platforms (in the future there might be &lt;code>SharpGL.OSx&lt;/code>, or &lt;code>SharpGL.Gnome&lt;/code>, who knows)&lt;/li>
&lt;li>&lt;code>SharpGL.SceneGraph&lt;/code> is a set of classes which represent 3D scenes - things like lights, cameras, materials and so on. I expect &lt;em>some&lt;/em> of this to &amp;lsquo;just work&amp;rsquo;, but things like image loading to perhaps need some tweaking.&lt;/li>
&lt;li>&lt;code>SharpGL&lt;/code> is just a wrapper around the Windows &lt;code>opengl32.dll&lt;/code> library. I can't imagine this &lt;em>working&lt;/em> anywhere but Windows, but how would the project structure porting go and would it build?&lt;/li>
&lt;/ul>
&lt;p>The details on &lt;em>how&lt;/em> to migrate a project are in the &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Porting Guide&lt;/a>, but the general approach will be:&lt;/p>
&lt;ol>
&lt;li>Attempt to convert to the latest project format with the &lt;code>try-convert&lt;/code> tool&lt;/li>
&lt;li>Re-target the project to the .NET Framework 4.7.2 (the first version which supports the .NET standard)&lt;/li>
&lt;li>Repeat for projects which this project depends on, walking the tree of projects to the root&lt;/li>
&lt;li>Run the Portability Analysis tool to see if there are APIs which are not available on certain platforms&lt;/li>
&lt;/ol>
&lt;p>This is how you project might look after migration, having run the &lt;code>try-convert&lt;/code>:&lt;/p>
&lt;p>&lt;img src="./images/migrate-project.png" alt="Screenshot: Ported Visual Studio Project">&lt;/p>
&lt;p>Now we just need to edit the project files and change the line:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;TargetFramework&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>4.7.2&lt;span style="color:#f92672">&amp;lt;/TargetFramework&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;TargetFrameworks&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>netcoreapp2.0;netcoreapp3.0;netcoreapp3.1;net40;net45;net472&lt;span style="color:#f92672">&amp;lt;/TargetFrameworks&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The targets you will choose will depend on the APIs you want to use. There is an Portability Analysis extension available which can build a portability report, here's what one looks like:&lt;/p>
&lt;p>&lt;img src="./images/portability-report-summary.png" alt="Screenshot: Portability Report Summary">&lt;/p>
&lt;p>This will also show the &lt;em>specific&lt;/em> APIs which are not compatible with specific targets:&lt;/p>
&lt;p>&lt;img src="./images/portability-report.png" alt="Screenshot: Portability Report Details">&lt;/p>
&lt;p>Now it's time to move to the next step.&lt;/p>
&lt;h2 id="step-4---refactor-rinse-repeat">Step 4 - Refactor, Rinse, Repeat&lt;/h2>
&lt;p>This is the tricky part. You'll now need to work out whether you want to &lt;em>remove&lt;/em> API calls which are not portable, try and use alternatives, or conditionally compile the code for different platforms.&lt;/p>
&lt;p>If you are using non-portable APIs you may need to use conditional blocks to execute different code depending on the framework used. The &lt;a href="https://docs.microsoft.com/en-us/dotnet/standard/frameworks#how-to-specify-target-frameworks">Target frameworks in SDK-style projects&lt;/a> guide shows how to do this.&lt;/p>
&lt;p>You may also have to manually edit the project file to ensure that certain dependencies are &lt;em>only&lt;/em> used for certain targets. You solution file and dependencies may end up looking something like this:&lt;/p>
&lt;p>&lt;img src="./images/conditional-dependencies.png" alt="Screenshot: Conditional Dependencies">&lt;/p>
&lt;p>Once you have reloaded the project you'll see your dependencies can now be specified on a per-framework basis, and a build generates assemblies for each of the targets:&lt;/p>
&lt;p>&lt;img src="./images/generated-assemblies.png" alt="Screenshot: Generated Assemblies">&lt;/p>
&lt;p>This process might be simple, or complex, depending on the nuances of your project. For me it was fairly iterative - starting by targeting only &lt;code>net40&lt;/code> (the original target framework which I'd used), then adding more and more targets.&lt;/p>
&lt;p>Some targets will simply not be possible - for example .NET Core only supports WinForms and WPF from .NET Core 3.0 onwards; you won't be able to build a WinForms or WPF assembly which targets a lower version, the framework doesn't support it.&lt;/p>
&lt;h2 id="step-5---update-your-builds">Step 5 - Update Your Builds&lt;/h2>
&lt;p>At this stage, having fixed compatibility issues, you should have code which builds in Visual Studio.&lt;/p>
&lt;p>Now I would recommend porting all of your build code to use the &lt;code>dotnet&lt;/code> build system. This is going to maximise the portability and future-proof your project, you'll be able to run the builds on multiple platforms and are using the preferred standard tool (&lt;code>msbuild&lt;/code> will essentially become legacy).&lt;/p>
&lt;p>The way I like to structure things personally is have a set of scripts which you can run to build, test and package the code locally. You can then call these scripts from you CI tool of choice to automate things, but still keep the logic in your own code, rather than hidden away in a build system.&lt;/p>
&lt;p>For example, in my SharpGL project I have the following scripts:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Script&lt;/th>
&lt;th>Usage&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>config.ps1&lt;/code>&lt;/td>
&lt;td>Ensure your machine can run builds by installing necessary components such as &lt;code>nunit&lt;/code>. Should only need to be run once.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>build.ps1&lt;/code>&lt;/td>
&lt;td>Build all solutions.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>test.ps1&lt;/code>&lt;/td>
&lt;td>Run all tests, including those in samples.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>coverage.ps1&lt;/code>&lt;/td>
&lt;td>Create a coverage report. Reports are written to &lt;code>./artifacts/coverage&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>pack.ps1&lt;/code>&lt;/td>
&lt;td>Create all of the SharpGL NuGet packages, which are copied to &lt;code>./artifacts/packages&lt;/code>.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>I updated my scripts to use the &lt;code>dotnet&lt;/code> tool. For example, the &amp;lsquo;build&amp;rsquo; script looks something like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-ps" data-lang="ps">&lt;span style="color:#a6e22e">#&lt;/span> &lt;span style="color:#a6e22e">Run&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">build,&lt;/span> &lt;span style="color:#a6e22e">hiding&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">documentation&lt;/span> &lt;span style="color:#a6e22e">warnings&lt;/span> &lt;span style="color:#a6e22e">for&lt;/span> &lt;span style="color:#a6e22e">pinvoke&lt;/span> &lt;span style="color:#a6e22e">code.&lt;/span>
&lt;span style="color:#a6e22e">$buildCommand&lt;/span> &lt;span style="color:#a6e22e">=&amp;#34;dotnet&lt;/span> &lt;span style="color:#a6e22e">msbuild&lt;/span> &lt;span style="color:#a6e22e">$PSScriptRoot\SharpGL.sln&lt;/span> &lt;span style="color:#a6e22e">-noWarn:CS1591&lt;/span> &lt;span style="color:#a6e22e">-noWarn:CS1573&lt;/span> &lt;span style="color:#a6e22e">-t:Rebuild&lt;/span> &lt;span style="color:#a6e22e">-p:Configuration=Release&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">Write-Host&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;Running:&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;&amp;#34;$buildCommand&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">Invoke-Expression&lt;/span> &lt;span style="color:#a6e22e">$buildCommand&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And the &amp;lsquo;pack&amp;rsquo; script looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-ps" data-lang="ps">&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL/SharpGL.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.SceneGraph/SharpGL.SceneGraph.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.Serialization/SharpGL.Serialization.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.WinForms/SharpGL.WinForms.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.WPF/SharpGL.WPF.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The actual scripts are a little more complex. But the key thing here is that I can run &lt;em>any&lt;/em> part of the CI/CD process locally (to test, debug and so on) or on a CI/CD platform.&lt;/p>
&lt;p>One thing which you can do here is update your &lt;em>project files&lt;/em>. There is no need to maintain a separate &lt;code>*.nuspec&lt;/code> file or &lt;code>project.json&lt;/code> file. All project information can be kept in one place - the project file. These files have been improved considerably and should actually end up being &lt;em>smaller&lt;/em> than the originals, as well as consolidating all of the project information and dependency information into one place.&lt;/p>
&lt;p>You can see the &lt;a href="https://github.com/dwmkerr/sharpgl/pull/177">Pull Request&lt;/a> for SharpGL to see how the project files were updated in this case.&lt;/p>
&lt;p>You will most likely have to &lt;em>conditionally&lt;/em> reference certain components. The dependency for &lt;code>net40&lt;/code> might be different to that for &lt;code>netcoreapp3.0&lt;/code>. You'll see that in many of my project files there is now code like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;ItemGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net40&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net40&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/ItemGroup&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;ItemGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.0&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.1&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.0&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.1&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/ItemGroup&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In my case quite a bit of trial and error was needed to find the appropriate references for each platform.&lt;/p>
&lt;h2 id="step-6---test-test-test">Step 6 - Test, Test, Test&lt;/h2>
&lt;p>Now for the fun part. You are going to &lt;em>really&lt;/em> have to test the new packages on each platform. Sadly, this kind of migration is not something which will have issues exposed via unit tests, you'll need to create test projects which import your packages, ideally for each platform, and make sure they work. There could be runtime errors, particularly if you have made mistakes with the references.&lt;/p>
&lt;p>Many issues will be caught at compile time - some will not.&lt;/p>
&lt;p>Here's a screenshot of me having fun trying out the .NET Framework 4 package for WinForms, and the .NET Core 3.1 package for WPF:&lt;/p>
&lt;p>&lt;img src="./images/test-packages.png" alt="Screenshot: Testing SharpGL">&lt;/p>
&lt;p>How you test your packages will be very dependent on what you are building. If it is highly platform specific then you will likely have to do lots of testing. If it is fairly self-contained code then you might be able to get away with some basic smoke testing.&lt;/p>
&lt;h2 id="step-7---document-compatibility">Step 7 - Document Compatibility&lt;/h2>
&lt;p>If you are supporting multiple platforms and frameworks, it's going to be a lot of help to consumers of your code if you can be very clear about &lt;em>what is supported&lt;/em>.&lt;/p>
&lt;p>This may be more complex than you think. Your library may run fine as part of a .NET Core Console Application on Windows - but does it work on MacOS? What about Linux?&lt;/p>
&lt;p>Here's a screenshot I would never have imagined when I started the SharpGL project - a terminal application running on MacOS which is using the &lt;code>SharpGL.Serialization&lt;/code> library to load geometry from a file:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-on-mac.png" alt="Screenshot: Loading Geometry in SharpGL on MacOS">&lt;/p>
&lt;p>Now of course for something like SharpGL to run on a Mac or Linux, a lot more work would be needed. SharpGL is at its core nothing more than a wrapper around &lt;code>opengl32.dll&lt;/code> on Windows, on other platforms there are no DLLs, but OpenGL &lt;em>is&lt;/em> still available. So support is possible, but not ready yet. So at this stage, docmenting what you know works &lt;em>as well as what doesn't&lt;/em> will be really helpful.&lt;/p>
&lt;p>You might also want to preserve your &amp;lsquo;pre-migration&amp;rsquo; code in a separate branch, in case you have users who for some reason have issues migrating and need to use an older version. For SharpGL, I updated the project page to indicate compatibility, what has been tested and so on:&lt;/p>
&lt;p>&lt;img src="./images/readme-compatability.png" alt="Screenshot: SharpGL README showing compatibility information">&lt;/p>
&lt;h1 id="the-key-learnings">The Key Learnings&lt;/h1>
&lt;p>Here are the key learnings which stood out for me as I worked on migration of these projects.&lt;/p>
&lt;p>&lt;strong>Consumer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>If you are careful, you don't have to break anything for consumers - with multi-targeting you can &lt;em>still&lt;/em> target older frameworks.&lt;/li>
&lt;li>You can potentially greatly increase the compatability of your projects by offering support for .NET Core.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Developer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You need to upgrade to Visual Studio 2019&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;however, you can use Visual Studio for Mac or even the command-line to build across many platforms.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Maintainer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You will have a much larger set of potential consumers, but you will likely find bugs which are framework or platform specific.&lt;/li>
&lt;li>You will likely need to work on migrating your project files and use the latest &lt;code>dotnet&lt;/code> tooling.&lt;/li>
&lt;li>You should be careful to document known compatability issues.&lt;/li>
&lt;/ul>
&lt;p>All in all, the process was less painful than I expected. Now that this work is done I can focus on more exciting things, such as potentially getting projects like SharpGL working on Linux or MacOS, which is much more exciting.&lt;/p>
&lt;p>As always, questions, comments, suggestions, rants, anything are welcome!&lt;/p>
&lt;p>The pull request which migrates the SharpGL project is below:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/sharpgl/pull/177/">github.com/dwmkerr/sharpgl/pull/177/&lt;/a>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Useful References&lt;/strong>&lt;/p>
&lt;p>&lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">Microsoft Docs: .NET Core Documentation&lt;/a>
&lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Microsoft Docs: Overview of porting from .NET Framework to .NET Core&lt;/a>
&lt;a href="https://docs.microsoft.com/en-us/dotnet/standard/frameworks#how-to-specify-target-frameworks">Microsoft Docs: Target frameworks in SDK-style projects&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Observations, tips and tricks for the CKA certification</title><link>https://dwmkerr.com/tips-for-cka/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/tips-for-cka/</guid><description>&lt;p>In this article I'll share some observations, tips and tricks for the &lt;a href="https://www.linuxfoundation.org/">Linux Foundation's&lt;/a> &amp;ldquo;&lt;a href="https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/">Certified Kubernetes Administrator&lt;/a> certification and exam.&lt;/p>
&lt;p>I've been operating Kubernetes in multiple environments for a few years now. I thought this would be an easy certification to get, but I was surprised by how hard it was!&lt;/p>
&lt;p>I took this exam without doing any formal training, I mostly focused on the areas of the curriculum which I knew I was a little weak at. The task-based structure for the exam I thought was really excellent. It took me two attempts to pass, and I learnt a few things along the way.&lt;/p>
&lt;p>Here I'll share some thoughts on the certification which hopefully will be useful if you are considering taking it!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#tip-do-the-right-certification">Tip: Do the right Certification!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-understand-the-format">Tip: Understand the Format!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-your-vim">Tip: Know your Vim&lt;/a>&lt;/li>
&lt;li>&lt;a href="#you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That's it!&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h2 id="tip-do-the-right-certification">Tip: Do the right Certification!&lt;/h2>
&lt;p>The CKA exam tests &lt;em>administration&lt;/em> and &lt;em>operation&lt;/em> skills and techniques for Kubernetes. If you have set up and administered clusters before, this will likely not be too challenging. But if you've never set up a cluster by hand, troubleshot weird issues, fixed clusters and so on, then this is likely going to be very hard.&lt;/p>
&lt;p>There is a certification which is much more geared towards developers who use Kubernetes, but don't necessarily administer it - that's the &lt;a href="https://www.cncf.io/certification/ckad/">CKAD&lt;/a> exam and might be the one to take if you are not too familiar with system administration.&lt;/p>
&lt;h2 id="tip-understand-the-format">Tip: Understand the Format!&lt;/h2>
&lt;p>This is not a multiple choice question exam. It's a task based exam, meaning you have about 22 or so specific tasks to complete, in a web browser which has a terminal connected to a cluster.&lt;/p>
&lt;p>It is open-book - meaning that you can use the &lt;a href="https://kubernetes.io/docs/home/">Kubernetes Documentation&lt;/a> during the exam. It's not a memory test of specific flags for commands or whatever, it will really require you to work with a running cluster. This means you'll have to be pretty familiar with &lt;code>kubectl&lt;/code>, &lt;code>kubeadm&lt;/code> and also Linux in general!&lt;/p>
&lt;h2 id="tip-know-your-vim">Tip: Know your Vim&lt;/h2>
&lt;p>In the two exams I took, &lt;code>nano&lt;/code> was available. But if you are using &lt;code>nano&lt;/code> to work with files you may struggle for time.&lt;/p>
&lt;p>I spent a &lt;em>lot&lt;/em> of time in &lt;code>vim&lt;/code> in the exam. &lt;code>vim&lt;/code> is my main text editor for day to day work, so I'm fairly familiar with it. Knowing how to quickly copy a file (lets say for example a file which represents a deployment) and quickly manipulate the text in it will be crucial. Make sure you are going to be using a text editor which you can be efficient in!&lt;/p>
&lt;p>You won't be using a graphical text editor to work with files, so being competent in a terminal editor like &lt;code>vim&lt;/code> or &lt;code>emacs&lt;/code> could make a big difference. Of course you could install your favourite text editor, but you won't be able to use a graphical editor like VS Code.&lt;/p>
&lt;p>Also, as in most Linux distributions, &lt;code>screen&lt;/code> is available out of the box, and &lt;code>tmux&lt;/code> can also be installed. If you are familiar with either of these terminal mutliplexers it could save you a tonne of time, for example being able to run &lt;code>watch -n 5 -d kubectl get pods&lt;/code> in one pane while applying resources in another.&lt;/p>
&lt;h2 id="you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/h2>
&lt;p>This exam will require you to deal with trivial tasks such as running a deployment or creating a volume. But the questions which focus on that tend to only count for one or two percent of the overall grade each. Questions which deal with troubleshooting actual Kubernetes issues could count for six or seven percent each.&lt;/p>
&lt;p>This means you &lt;em>need&lt;/em> to know how Kubernetes is architecture. The &lt;code>kubelet&lt;/code> which runs on nodes, the API server, the &lt;code>etcd&lt;/code> store, all of these things you &lt;em>have&lt;/em> to understand how they work and how they fit together.&lt;/p>
&lt;p>The online documentation covers the architecture in detail, here's the best place to start:&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">&lt;img src="./images/k8s-architecture.png" alt="Kubernetes Architecture">&lt;/a>&lt;/p>
&lt;p>You will need to know how the control plane works, how nodes communicate, how transport of messages works and is secured if you are going to have a chance at dealing with the harder questions.&lt;/p>
&lt;h2 id="tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/h2>
&lt;p>If you are not familiar with &lt;code>systemctl&lt;/code>, &lt;code>journalctl&lt;/code>, &lt;code>apt&lt;/code>, &lt;code>systemd&lt;/code> units and how the core Kubernetes components are configured, you'll really struggle.&lt;/p>
&lt;p>Look over the &lt;a href="https://github.com/cncf/curriculum">CNCF curriculum&lt;/a> - expect to not just have to know how to deal with &amp;lsquo;happy path&amp;rsquo; situations, but also broken clusters, incorrect configuration and so on.&lt;/p>
&lt;h2 id="tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/h2>
&lt;p>One thing which helped me a lot in my second attempt at the exam was the &lt;code>--dry-run&lt;/code> flag. Before you create resources or change anything, run the operation with the &lt;code>--dry-run&lt;/code> flag and see whether the output is what you would expect.&lt;/p>
&lt;p>This is a quick and easy way to see the changes to the cluster which you are going to apply - and troubleshoot them - before making any actual changes.&lt;/p>
&lt;h2 id="tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/h2>
&lt;p>Networking in Kubernetes is complex. You must be able to troubleshoot networking issues in the cluster to be able to deal with the more complex tasks.&lt;/p>
&lt;p>This means that you should know how to be able to run typical networking tools like &lt;code>dig&lt;/code>, &lt;code>nslookup&lt;/code>, &lt;code>telnet&lt;/code> etc, in the cluster itself.&lt;/p>
&lt;p>If you are not familiar with these tools you might need to take an online course in Kubernetes or Linux Networking Administration before considering this certification. The &lt;a href="https://training.linuxfoundation.org/certification/linux-foundation-certified-sysadmin-lfcs/">Linux Certified Systems Administrator&lt;/a> training would be a good place to start.&lt;/p>
&lt;p>If you have taken the &lt;a href="https://success.docker.com/certification">Docker Certified Associate&lt;/a> exam then some of this should be familiar. If you are not very familiar with how Docker itself works, you'll likely struggle with Kubernetes.&lt;/p>
&lt;h2 id="tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/h2>
&lt;p>There are a lot of tasks which only count for one or two percent each; these ones you should be able to complete in a few minutes. You'll need all the time in the exam to work on the really hard questions which deal with diagnosing and fixing cluster issues.&lt;/p>
&lt;p>Know your core Kubernetes concepts; if you have done the CKAD exam you should be good, if not, check the curriculum and make sure you can quickly complete all of the trivial tasks without wasting too much time.&lt;/p>
&lt;h2 id="thats-it">That's it!&lt;/h2>
&lt;p>Hopefully this was helpful! Good luck if you are taking the exam and hopefully you'll find it a challenging but rewarding experience. I've taken many exams over the years but this was one of the most challenging, but also one of the most enjoyable, I really felt like it was testing practical techniques rather than your ability to just remember random commands and flags.&lt;/p>
&lt;p>As always, if you have any comments or questions, please just add them in the section below!&lt;/p>
&lt;p>&lt;img src="./images/cka-cert.png" alt="CKA Certification">&lt;/p></description><category>CodeProject</category></item><item><title>Supercharge your Java Projects with Conventional Commits, Semantic Versioning and Semantic Releases</title><link>https://dwmkerr.com/conventional-commits-and-semantic-versioning-for-java/</link><pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/conventional-commits-and-semantic-versioning-for-java/</guid><description>&lt;p>In this article we'll look at a few simple techniques which can really supercharge your Java project and make them much easier to work with!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#semantic-versioning">Semantic Versioning&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#why-does-this-matter">Why Does This Matter?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-semantic-versioning-specification">The Semantic Versioning Specification&lt;/a>&lt;/li>
&lt;li>&lt;a href="#using-semantic-versions">Using Semantic Versions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-challenge-of-semantic-versions">The Challenge of Semantic Versions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#conventional-commits">Conventional Commits&lt;/a>&lt;/li>
&lt;li>&lt;a href="#time-for-magic">Time for Magic&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#enforcing-conventional-commits-with-git-hooks">Enforcing Conventional Commits with Git Hooks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#how-the-hook-works">How the Hook Works&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#creating-the-initial-release">Creating the Initial Release&lt;/a>&lt;/li>
&lt;li>&lt;a href="#go-forth-and-devops">Go Forth And DevOps&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-gradle-version">The Gradle Version&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That's It&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;p>&lt;strong>tl;dr&lt;/strong> If you know the concepts, then just jump straight to my fork of &lt;code>standard-version&lt;/code> at &lt;a href="https://github.com/dwmkerr/standard-version">&lt;code>github.com/dwmkerr/standard-veresion&lt;/code>&lt;/a>. It adds support for Java projects. I am currently trying to get it into the mainline, so if you like this, please comment on the &lt;a href="https://github.com/conventional-changelog/standard-version/pull/591">Pull Request&lt;/a> here. &lt;strong>tl;dr end!&lt;/strong>&lt;/p>
&lt;h2 id="semantic-versioning">Semantic Versioning&lt;/h2>
&lt;p>First, let's talk about the idea of a &lt;em>Semantic Version&lt;/em>. A semantic version is nothing more than a versioning scheme you will probably be familiar with, where versions look like this:&lt;/p>
&lt;pre>&lt;code>1.2.3
&lt;/code>&lt;/pre>&lt;p>The only thing special about a &lt;em>Semantic Version&lt;/em> is that we give a very specific meaning to each part of the version. In short:&lt;/p>
&lt;ul>
&lt;li>&lt;code>1&lt;/code> is the &lt;em>major&lt;/em> part of the version&lt;/li>
&lt;li>&lt;code>2&lt;/code> is the &lt;em>minor&lt;/em> part of the version&lt;/li>
&lt;li>&lt;code>3&lt;/code> is the &lt;em>patch&lt;/em> part of the version&lt;/li>
&lt;/ul>
&lt;p>Now we give &lt;em>semantics&lt;/em> (meaning and context) to these parts:&lt;/p>
&lt;p>&lt;strong>Major&lt;/strong>&lt;/p>
&lt;p>A &lt;em>major&lt;/em> version number change means something big has changed, and the API of the software is different to the earlier version. Essentially, this is a potentially &lt;em>breaking&lt;/em> change, so you should only use this new version after carefully reading about the changes.&lt;/p>
&lt;p>&lt;strong>Minor&lt;/strong>&lt;/p>
&lt;p>A &lt;em>minor&lt;/em> version number change means that something has been added or changed, which affects the functionality of the code, but in a &lt;em>non breaking&lt;/em> way. An example would be the addition of a new API. That won't affect existing users, so they can generally safely upgrade minor versions without too much risk.&lt;/p>
&lt;p>&lt;strong>Patch&lt;/strong>&lt;/p>
&lt;p>A &lt;em>patch&lt;/em> version number change means something really inconsequential to the user of the code has changed. It might be new documentation, better logging, but it is generally not a &lt;em>functional&lt;/em> change.&lt;/p>
&lt;h3 id="why-does-this-matter">Why Does This Matter?&lt;/h3>
&lt;p>If we have Semantic Versions, we can be a lot more sure about &lt;em>when it is safe to upgrade&lt;/em>. If we see a &lt;em>major&lt;/em> version change, we know we need to be careful. &lt;em>Minor&lt;/em> changes might need attention, and &lt;em>patches&lt;/em> are almost always going to be safe.&lt;/p>
&lt;p>Managing dependencies and keeping them up to date is hard in software development, and one of the reasons people are wary of updating dependencies is that &lt;em>they don't know if they upgrade will break their code&lt;/em>.&lt;/p>
&lt;p>Semantic Versioning tries to bring a little order to this chaotic world.&lt;/p>
&lt;h3 id="the-semantic-versioning-specification">The Semantic Versioning Specification&lt;/h3>
&lt;p>There is a detailed specification for semantic versioning, which also covers more sophisticated cases, you can find it here:&lt;/p>
&lt;p>&lt;a href="https://semver.org/">https://semver.org/&lt;/a>&lt;/p>
&lt;p>I'd suggest this is recommend reading for &lt;em>any&lt;/em> software engineer!&lt;/p>
&lt;h3 id="using-semantic-versions">Using Semantic Versions&lt;/h3>
&lt;p>Now the easiest way to start with semantic versioning is to simply adhere to the spec! For example, if you make a change which could break something for users, bump the &lt;em>major&lt;/em> part of the version.&lt;/p>
&lt;p>But, things aren't all that easy&amp;hellip;&lt;/p>
&lt;h3 id="the-challenge-of-semantic-versions">The Challenge of Semantic Versions&lt;/h3>
&lt;p>The challenge is this. Imagine you are cutting a new release of your code and many people have contributed. Some bug fixes, some patches, some documentation. How do you look through all of those changes and decide how to appropriately change the version number?&lt;/p>
&lt;p>To solve this problem, say hello to &lt;em>Conventional Commits&lt;/em>.&lt;/p>
&lt;h2 id="conventional-commits">Conventional Commits&lt;/h2>
&lt;p>If you have a commit history like this:&lt;/p>
&lt;pre>&lt;code>Updated the users API
Bugfix
trying the build again, got it working
Bugfix: [JIRA-21] fixed that issue
you can now get user's friends with this change
&lt;/code>&lt;/pre>&lt;p>Then it is &lt;em>very&lt;/em> hard to reason about what is going on. What about if the commit history looked like this?&lt;/p>
&lt;pre>&lt;code>feat(users): [#12] fetching users returns their avatar url
fix(users): [#45] display names with emojis return correctly
build(cicd): update the expired deploy key
fix(docs): [#22] fix broken links to the javadocs
feat(users): [#49] users api optionally returns friends, non-breaking
&lt;/code>&lt;/pre>&lt;p>It's much easier to see what each change means, at least at a high level.&lt;/p>
&lt;p>By having some kind of standard for commit messages, we can do a lot. We can:&lt;/p>
&lt;ul>
&lt;li>Classify changes by type (such as a feature or fix)&lt;/li>
&lt;li>Include a clear description of the change&lt;/li>
&lt;li>Use a convention to indicate a breaking change&lt;/li>
&lt;li>Link to a ticketing system&lt;/li>
&lt;/ul>
&lt;p>Just like semantic versioning, conventional commits have a specification too:&lt;/p>
&lt;p>&lt;a href="https://www.conventionalcommits.org/en/v1.0.0/">https://www.conventionalcommits.org/en/v1.0.0/&lt;/a>&lt;/p>
&lt;h2 id="time-for-magic">Time for Magic&lt;/h2>
&lt;p>Now if we have conventional commits, and want to use semantic versions, we can actually skip the whole process of looking over a commit history to create a new semantic version - we can automate it.&lt;/p>
&lt;p>We can even automate the process of creating a &amp;lsquo;changelog&amp;rsquo;, a list of each change which comes in each version. There's an &lt;em>excellent&lt;/em> library which does this, called &lt;code>standard-version&lt;/code>:&lt;/p>
&lt;p>&lt;a href="https://github.com/conventional-changelog/standard-version">https://github.com/conventional-changelog/standard-version&lt;/a>&lt;/p>
&lt;p>It's maintained by the same group behind conventional commits. The only problem? It only works for JavaScript projects (unless you are willing to write custom code which can be complex).&lt;/p>
&lt;p>But I've updated the library to support Maven projects and Gradle projects, so you can use it for Java now as well!&lt;/p>
&lt;p>Let's see it in action. Here's a very simple Java library built with Maven:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample">https://github.com/dwmkerr/java-maven-standard-version-sample&lt;/a>&lt;/p>
&lt;p>This library has no changelog, no tags, no version data at all except for &lt;code>0.1.0&lt;/code> in the &lt;code>pom.xml&lt;/code> file.&lt;/p>
&lt;p>Now if I was to clone the library, make a change and make a commit, which &lt;em>didn't&lt;/em> follow the conventional commit spec, we'll just see the usual success message:&lt;/p>
&lt;p>&lt;img src="./images/bad-commit-message.png" alt="Bad commit message" width="800px" />&lt;/p>
&lt;p>This is a problem; we want to &lt;em>enforce&lt;/em> conventional commits.&lt;/p>
&lt;h3 id="enforcing-conventional-commits-with-git-hooks">Enforcing Conventional Commits with Git Hooks&lt;/h3>
&lt;p>Git has a powerful &amp;lsquo;hooks&amp;rsquo; facility, which let you run logic at key points in operations. This is a &lt;em>massive&lt;/em> topic on its own, so we're not going to go into lots of details, but if you are interested you can read about them here:&lt;/p>
&lt;p>&lt;a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks">https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks&lt;/a>&lt;/p>
&lt;p>Now the issue with Git Hooks is that they are &lt;em>per user&lt;/em> - if I add a hook to my &lt;code>.git&lt;/code> folder, no one else will get it. We want the same hooks for &lt;em>all&lt;/em> users.&lt;/p>
&lt;p>There are a few ways to get around this. You can set up server side hooks (which could reject a push if it has an invalid commit message), but this isn't easy to do (and with some providers, like GitHub for public projects, not even available as an option). Also, we want fast feedback, so if I make a bad commit message, it fails straight away and I can fix it.&lt;/p>
&lt;p>The way I suggest getting around this is this:&lt;/p>
&lt;ol>
&lt;li>Create a &lt;code>.githooks&lt;/code> folder in your repo&lt;/li>
&lt;li>Instruct people to configure the git repo to look for hooks there&lt;/li>
&lt;/ol>
&lt;p>That way there are no global changes, only project specific ones. We still need to make sure the developer sets up the hooks though! You'll notice in my sample project's &lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample#developer-guide">&lt;code>README.md&lt;/code>&lt;/a> file the first thing I do is instruct people to setup the hooks:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">git config core.hooksPath .githooks
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let's see how the same operation would look if we'd setup the hook first:&lt;/p>
&lt;p>&lt;img src="./images/git-hook-bad-message.png" alt="Bad commit message with hook" width="800px" />&lt;/p>
&lt;p>Our hook has fired off and told us we've not used a conventional commit message - it even let's us know where to go to find out more.&lt;/p>
&lt;p>Let's try a message which should work, as it meets the standard:&lt;/p>
&lt;p>&lt;img src="./images/git-hook-good-message.png" alt="Good commit message with hook" width="800px" />&lt;/p>
&lt;p>Awesome! We've been informed that our message meets the standard (useful to actually remind us that this is being checked!) and the commit has succeeded!&lt;/p>
&lt;p>Remember; we only need to setup the hooks once - it's a one time activity.&lt;/p>
&lt;h3 id="how-the-hook-works">How the Hook Works&lt;/h3>
&lt;p>Hooks are just shell scripts. You can write them in Ruby, Python, whatever. I have written this one in pure Bash because it's really just checking a regex, which Bash is more than capable of. Also, I can't be sure the developer will have Ruby or another tool on their machine.&lt;/p>
&lt;p>The hook is as simple as this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/usr/bin/env bash
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Create a regex for a conventional commit.&lt;/span>
convetional_commit_regex&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">^(build|chore|ci|docs|feat|fix|perf|refactor|revert|style|test)(\([a-z \-]+\))?!?: .+&lt;/span>$&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Get the commit message (the parameter we&amp;#39;re given is just the path to the&lt;/span>
&lt;span style="color:#75715e"># temporary file which holds the message).&lt;/span>
commit_message&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>cat &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$1&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#75715e"># Check the message, if we match, all good baby.&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$commit_message&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">=&lt;/span>~ $convetional_commit_regex &lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo -e &lt;span style="color:#e6db74">&amp;#34;\e[32mCommit message meets Conventional Commit standards...\e[0m&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">0&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Uh-oh, this is not a conventional commit, show an example and link to the spec.&lt;/span>
echo -e &lt;span style="color:#e6db74">&amp;#34;\e[31mThe commit message does not meet the Conventional Commit standard\e[0m&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;An example of a valid message is: &amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34; feat(login): add the &amp;#39;remember me&amp;#39; button&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;More details at: https://www.conventionalcommits.org/en/v1.0.0/#summary&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The only really tricky bit is the regex, and the weird &lt;code>\e[32&lt;/code> type characters which are used to set the colours. You might find it easier to write your hooks in a proper programming language - and for anything more complex I'd suggest that makes far more sense! But if a bit of Bash will do the trick, there's nothing wrong with that.&lt;/p>
&lt;p>As a side-note, if you are into Bash and the shell, check out my online &lt;a href="https://effective-shell.com">Effective Shell&lt;/a> book.
git config core.hooksPath .githooks&lt;/p>
&lt;h2 id="creating-the-initial-release">Creating the Initial Release&lt;/h2>
&lt;p>Now the chances are, if you are interested in this technique, you've probably got an existing project you want to use it on. It probably doesn't have a changelog or conventional commits. That's OK, just start from now.&lt;/p>
&lt;p>Here's how we'd start using the &lt;code>standard-version&lt;/code> library to manage our versions. I've added a new API to the &lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample/tree/release">&lt;code>release&lt;/code>&lt;/a> branch (to keep &lt;code>master&lt;/code> clean for people reading the sample) and committed it.&lt;/p>
&lt;p>Now lets actually create our changelog:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --first-release --packageFiles pom.xml --bumpFiles pom.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="./images/first-release.png" alt="First release" width="800px" />&lt;/p>
&lt;p>Now it's a pain I know, but you need &lt;a href="https://nodejs.org/en/download/">Node.js&lt;/a> installed for this to work. The &lt;code>standard-version&lt;/code> library is built on node, that's what is used to do all of the logic around writing a changelog and working out what the version bump should be. You also have to use my fork &lt;code>@dwmkerr/standard-version&lt;/code> rather than the main version, because at the time of writing my pull request which adds support for &lt;code>pom.xml&lt;/code> files is not yet merged.&lt;/p>
&lt;p>What has happened here is that the &lt;code>standard-version&lt;/code> tool has &lt;em>not&lt;/em> changed the version number. We told it this is the &lt;code>first-release&lt;/code>, meaning we haven't published yet, so there's no need to create a new number. What is &lt;em>has&lt;/em> done is given us a changelog and told use how to push the tags and code. If we push, we can now see the changelog:&lt;/p>
&lt;p>&lt;img src="./images/changelog-v1.png" alt="Changelog v1" width="800px" />&lt;/p>
&lt;p>See how we get a changelog showing the changes, the version and the date? We even have links to the commits for each key change!&lt;/p>
&lt;p>If we'd linked the message to GitHub Issue numbers it'd automatically have links to the issues too!&lt;/p>
&lt;p>Now in this code I deliberately made a mistake - the test for the &lt;code>Goodbye&lt;/code> api is a copy and paste of the &lt;code>Hello&lt;/code> test! And the &lt;code>Goodbye&lt;/code> api has a spelling mistake. Let's fix this and cut a new release.&lt;/p>
&lt;p>I've made the change on the &lt;code>release&lt;/code> branch, now I'll run &lt;code>standard-version&lt;/code> again:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --packageFiles pom.xml --bumpFiles pom.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="./images/second-release.png" alt="Second release" width="800px" />&lt;/p>
&lt;p>Note that there was no need for the &lt;code>--first-release&lt;/code> flag.&lt;/p>
&lt;p>Now this time, a new version has been generated. This was a &lt;code>fix&lt;/code> commit, so it has made it a &lt;em>minor&lt;/em> version bump. If we needed to make it a breaking change, we can use a message with an exclamation after the type, such as &lt;code>fix(goodbye)!: fix the typo&lt;/code>. Check the &lt;code>standard-version&lt;/code> docs for more about this.&lt;/p>
&lt;p>Finally, let's look at our new changelog:&lt;/p>
&lt;p>&lt;img src="./images/second-changelog.png" alt="Second changelog" width="800px" />&lt;/p>
&lt;p>We have even more info now - we have a link to the tag. This is &lt;em>incredibly&lt;/em> useful for managing releases.&lt;/p>
&lt;p>The icing on the cake? Let's look at the &lt;code>pom.xml&lt;/code>:&lt;/p>
&lt;p>&lt;img src="./images/updated-pom.png" alt="Updated pom.xml" width="800px" />&lt;/p>
&lt;p>Note that &lt;em>the version has been updated&lt;/em>. &lt;code>standard-release&lt;/code> is keeping our Git Tags and our Java Library Version numbers &lt;em>automatically in sync&lt;/em>.&lt;/p>
&lt;p>Once you've started doing this and seen it in action for a while, you'll wonder how you lived without it!&lt;/p>
&lt;h2 id="go-forth-and-devops">Go Forth And DevOps&lt;/h2>
&lt;p>This is just the beginning! Think of all the cool things we can do with this in place, here's just a few:&lt;/p>
&lt;ul>
&lt;li>Update our build pipeline so that when we merge into &lt;code>master&lt;/code> we automatically run &lt;code>standard-version&lt;/code>&lt;/li>
&lt;li>Update our build pipeline so that when a new version tag is added, we automatically publish the library&lt;/li>
&lt;li>Send out a slack notification with the changelog when a new version is committed&lt;/li>
&lt;li>Share the changelog with our consumers as our libraries are updated&lt;/li>
&lt;/ul>
&lt;p>With these basic building blocks:&lt;/p>
&lt;ul>
&lt;li>Conventional Commits&lt;/li>
&lt;li>Semantic Versioning&lt;/li>
&lt;li>Enforcing of Commit Standards&lt;/li>
&lt;li>Usage of the &lt;code>standard-release&lt;/code> tool&lt;/li>
&lt;/ul>
&lt;p>We have created a very powerful way to manage what is actually a highly complex process. We've introduced almost no additional complexity, just a few guidelines for developers.&lt;/p>
&lt;h2 id="the-gradle-version">The Gradle Version&lt;/h2>
&lt;p>It's basically the same technique for Gradle, you just tell &lt;code>standard-version&lt;/code> to hit your &lt;code>build.gradle&lt;/code> file;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --packageFiles build.gradle --bumpFiles build.gradle
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's an accompanying sample project at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/java-gradle-standard-version-sample">github.com/dwmkerr/java-gradle-standard-version-sample&lt;/a>&lt;/p>
&lt;p>This is the same as the Maven version in that the &lt;code>master&lt;/code> branch has no &lt;code>standard-version&lt;/code> code or changelogs, just open the &lt;a href="https://github.com/dwmkerr/java-gradle-standard-version-sample/tree/release">&lt;code>release&lt;/code>&lt;/a> branch to see what it looks like after we've applied the same techniques as we did to the Maven version.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>There's a whole world of libraries for this. &lt;a href="https://github.com/commitizen/cz-cli">&lt;code>commitizen&lt;/code>&lt;/a> which helps you write conventional commit messages for example. But I found very little for Java. If you find this useful, please do chip in on the pull request here:&lt;/p>
&lt;p>&lt;a href="https://github.com/conventional-changelog/standard-version/pull/591">https://github.com/conventional-changelog/standard-version/pull/591&lt;/a>&lt;/p>
&lt;p>As it would be great to add it to the mainline. I'm also just finishing off the update which adds support for Gradle.&lt;/p>
&lt;p>As always, questions, comments, suggestions, rants, anything are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell for Beginners</title><link>https://dwmkerr.com/effective-shell-for-beginners/</link><pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-for-beginners/</guid><description>&lt;p>I have rebuilt my &amp;ldquo;Effective Shell&amp;rdquo; series as an online book - it's available now on:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">https://effective-shell.com&lt;/a>&lt;/p>
&lt;p>The whole site is built from a GitHub repo at &lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>. It is open for contributions, changes, issues and suggestions. I've also added a comment section to each page to get input.&lt;/p>
&lt;p>To keep the material as accessible as possible, I have added a new section for beginners, to help anyone who has not used a shell before. It goes over who the book is useful for, what the shell is, and how to set up your computer to work through the material:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">&lt;img src="images/effective-shell-screenshot.png" alt="Effective Shell: Screenshot" width="1024px" />&lt;/a>&lt;/p>
&lt;p>All comments and suggestions are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell Part 7: The Subtleties of Shell Commands</title><link>https://dwmkerr.com/effective-shell-7-shell-commands/</link><pubDate>Tue, 25 Jun 2019 07:25:23 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-7-shell-commands/</guid><description>&lt;p>In this chapter, we'll take a look at the various different types of shell commands that exist and how this can affect your work.&lt;/p>
&lt;p>By the end of this chapter, you might even be able to make sense of the horrifying and perfectly syntactically valid code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">which &lt;span style="color:#66d9ef">$(&lt;/span>where &lt;span style="color:#66d9ef">$(&lt;/span>what &lt;span style="color:#66d9ef">$(&lt;/span>whence &lt;span style="color:#66d9ef">$(&lt;/span>whereis who&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="what-are-commands">What Are Commands?&lt;/h2>
&lt;p>This is &lt;em>really&lt;/em> important to understand! A &lt;em>command&lt;/em> in a shell is something you execute. It might take parameters. Generally it'll have a form like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">command param1 param2
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've already seen many commands during this series:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">ls &lt;span style="color:#75715e"># Show the contents of the current directory&lt;/span>
cd ~ &lt;span style="color:#75715e"># Move to the user&amp;#39;s home&lt;/span>
cat file.txt &lt;span style="color:#75715e"># Output the contents of &amp;#39;file.txt&amp;#39; to stdout&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But to be an effective shell user, you must understand that not all commands are created equal. The differences between the types of commands will affect how you use them.&lt;/p>
&lt;p>There are four types of commands in most shells:&lt;/p>
&lt;ol>
&lt;li>Executables&lt;/li>
&lt;li>&amp;ldquo;Built-Ins&amp;rdquo; (which we'll just call &lt;em>builtins&lt;/em> from now on)&lt;/li>
&lt;li>Functions&lt;/li>
&lt;li>Aliases&lt;/li>
&lt;/ol>
&lt;p>Let's quickly dig in and see a bit more.&lt;/p>
&lt;h2 id="executables---programs">Executables - Programs&lt;/h2>
&lt;p>Executables are just files with the &amp;lsquo;executable&amp;rsquo; bit set&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. If I execute the &lt;code>cat&lt;/code> command, the shell will search for an executable named &lt;code>cat&lt;/code> in my &lt;code>$PATH&lt;/code>. If it finds it, it will run the program.&lt;/p>
&lt;pre>&lt;code>$ cat file.txt
This is a simple text file
&lt;/code>&lt;/pre>&lt;p>What is &lt;code>$PATH&lt;/code>? &lt;code>$PATH&lt;/code> is the standard environment variable used to define &lt;em>where&lt;/em> the shell should search for programs. If we temporarily &lt;em>empty&lt;/em> this variable, the shell won't find the command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span> cat file.txt
bash: cat: No such file or directory
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Normally your &lt;code>$PATH&lt;/code> variable will include the standard locations for Linux programs - folders such as &lt;code>/bin&lt;/code>, &lt;code>/sbin&lt;/code>, &lt;code>/usr/bin&lt;/code> and so on&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>If you were to print the variable, you'd see a bunch of paths (they are separated by colons; I've put them on separate lines for readability):&lt;/p>
&lt;pre>&lt;code>/usr/local/bin
/usr/bin
/bin
/usr/sbin
/sbin
&lt;/code>&lt;/pre>&lt;p>The shell will start with the &lt;em>earlier&lt;/em> locations and move to the later ones. This allows &lt;em>local&lt;/em> flavours of tools to be installed for users, which will take precedence over &lt;em>general&lt;/em> versions of tools.&lt;/p>
&lt;p>There will likely be other locations too - you might see Java folders, package manager folders and so on.&lt;/p>
&lt;h2 id="executables---scripts">Executables - Scripts&lt;/h2>
&lt;p>Imagine we create a text file called &lt;code>dog&lt;/code> in the local folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>echo &lt;span style="color:#e6db74">&amp;#34;🐶 woof 🐶&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If we make the file &lt;em>executable&lt;/em>, by running &lt;code>chmod +x dog&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, then we can run this just like any other program - as long as we tell the shell to look for programs in the current directory:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span> dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>More common would be to run the program by giving a path:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ./dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Or just move it to a standard location that the shell already checks for programs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ mv dog /usr/local/bin
$ dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The point is that executables don't &lt;em>have&lt;/em> to be compiled program code. If a file starts with &lt;code>#!&lt;/code> (the &amp;lsquo;shebang&amp;rsquo;), then the system will try to run the contents of the file with the program specified in the shebang.&lt;/p>
&lt;p>We will look at shebangs in greater detail in a later chapter.&lt;/p>
&lt;h2 id="builtins">Builtins&lt;/h2>
&lt;p>OK, so we've seen executables. What about a command like this?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">local V&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hello&amp;#34;&lt;/span> echo $V
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will not find the &lt;code>local&lt;/code> executable anywhere on your system. It is a &lt;em>builtin&lt;/em> - a special command built directly into the shell program.&lt;/p>
&lt;p>Builtins are often highly specific to your shell. They might be used for programming (&lt;code>local&lt;/code> for example is used to declare a locally scoped variable), or they might be for very shell-specific features.&lt;/p>
&lt;p>This is where we need to take note. As soon as you are running a builtin, you are potentially using a feature that is specific to &lt;em>your&lt;/em> shell, rather than a program that is shared across the system and can be run by &lt;em>any&lt;/em> shell.&lt;/p>
&lt;p>Trying to programmatically execute &lt;code>local&lt;/code> as a process will fail - there is no executable with that name; it is purely a shell construct.&lt;/p>
&lt;p>So how do we know if a command is a builtin? The preferred method is to use the &lt;code>type&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type local
local is a shell builtin
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>type&lt;/code> command (which is &lt;em>itself&lt;/em> a builtin!) can tell you the exact type of shell command.&lt;/p>
&lt;p>Interestingly, you might be using more builtins than you think. &lt;code>echo&lt;/code> is a program, but most of the time you are not executing it when you are in a shell:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a echo
echo is a shell builtin
echo is /bin/echo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By using the &lt;code>-a&lt;/code> flag on &lt;code>type&lt;/code> to show &lt;em>all&lt;/em> commands that match the name, we see that &lt;code>echo&lt;/code> is actually both a builtin &lt;em>and&lt;/em> a program.&lt;/p>
&lt;p>Many simple programs have builtin versions. The shell can execute them much faster.&lt;/p>
&lt;p>Some commands are a builtin so that they can function in a sensible manner. The &lt;code>cd&lt;/code> command changes the current directory - if we executed it as a process, it would change only the directory for the &lt;code>cd&lt;/code> process itself, not the shell, making it much less useful.&lt;/p>
&lt;p>Builtins will vary from shell to shell, but many shells are &amp;lsquo;Bash-like&amp;rsquo; - meaning they will have a set very similar to the Bash builtins, which you can see here:&lt;/p>
&lt;p>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html">https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html&lt;/a>&lt;/p>
&lt;p>As should be familiar from &lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>, you can get help for builtins:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ man source &lt;span style="color:#75715e"># source is a builtin&lt;/span>
BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> BSD General Commands Manual BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span>
NAME
builtin, !, %, &lt;span style="color:#75715e"># ...snip...&lt;/span>
SYNOPSIS
builtin &lt;span style="color:#f92672">[&lt;/span>-options&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">[&lt;/span>args ...&lt;span style="color:#f92672">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, the manual will &lt;em>not&lt;/em> show information on specific builtins, which is a pain. Your shell &lt;em>might&lt;/em> have an option to show more details - for example, in Bash you can use &lt;code>help&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ help source
source: source filename &lt;span style="color:#f92672">[&lt;/span>arguments&lt;span style="color:#f92672">]&lt;/span>
Read and execute commands from FILENAME and &lt;span style="color:#66d9ef">return&lt;/span>. The pathnames
in $PATH are used to find the directory containing FILENAME. If any
ARGUMENTS are supplied, they become the positional parameters when
FILENAME is executed.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But remember: &lt;code>help&lt;/code> is a builtin; you might not find it in all shells (you won't find it in &lt;code>zsh&lt;/code>, for example). This highlights again the challenges of builtins.&lt;/p>
&lt;h2 id="functions">Functions&lt;/h2>
&lt;p>You can define your own shell functions. We will see a lot more of this later, but let's show a quick example for now:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span> exec -l &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$SHELL&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet creates a function that restarts the shell (quite useful if you are messing with shell configuration files or think you might have irreversibly goofed up your current session).&lt;/p>
&lt;p>We can execute this function just like any command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And running &lt;code>type&lt;/code> will show us that this is a function:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type restart-shell
restart-shell is a &lt;span style="color:#66d9ef">function&lt;/span>
restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;span style="color:#f92672">{&lt;/span>
exec -l $SHELL
&lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Functions are one of the most powerful shell constructs we will see; they are extremely useful for building sophisticated logic. We're going to see them in a lot more detail later, but for now it is enough to know that they exist, and can run logic, and are run as commands.&lt;/p>
&lt;h2 id="aliases">Aliases&lt;/h2>
&lt;p>An alias is just a shortcut. Type in a certain set of characters, and the shell will replace them with the value defined in the alias.&lt;/p>
&lt;p>Some common commands are actually already aliases - for example, in my &lt;code>zsh&lt;/code> shell, the &lt;code>ls&lt;/code> command is an alias:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I make sure that when I use the &lt;code>ls&lt;/code> command, the shell always expands it to &lt;code>ls -G&lt;/code>, which colours the output.&lt;/p>
&lt;p>We can quickly define aliases to save on keystrokes. For example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ alias k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;kubectl&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>From this point on, I can use the &lt;code>k&lt;/code> alias as shorthand for the &lt;code>kubectl&lt;/code> command.&lt;/p>
&lt;p>Aliases are far less sophisticated than functions. Think of them as keystroke savers and nothing more, and you won't go far wrong. Aliases are not portable across shells and have certain behaviours which can make them problematic to work with, there will be an entire chapter dedicated to alisases coming up in the series.&lt;/p>
&lt;h2 id="so-what">So What?&lt;/h2>
&lt;p>So we now hopefully have a greater understanding of the variety of shell commands. Not all commands are executables, not all of the commands we &lt;em>think&lt;/em> are executables necessarily are, and some commands might be more sophisticated.&lt;/p>
&lt;p>As a shell user, the key things to remember are:&lt;/p>
&lt;ol>
&lt;li>Executables are &amp;lsquo;safe&amp;rsquo; - they are programs your system can use; your shell just calls out to them.&lt;/li>
&lt;li>Builtins are &lt;em>very&lt;/em> shell-specific and usually control the shell itself&lt;/li>
&lt;li>Functions are powerful ways to write logic but will normally be shell-specific.&lt;/li>
&lt;li>Aliases are conveniences for human operators, but only in the context of an interactive shell.&lt;/li>
&lt;/ol>
&lt;p>To find out how a command is implemented, just use the &lt;code>type -a&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a cat
cat is /bin/cat
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="more-than-you-need-to-know">More than You Need to Know&lt;/h2>
&lt;p>OK, for the masochistic few, you might be wondering about all of the other commands and utilities you may have seen that can tell you about programs and commands:&lt;/p>
&lt;ul>
&lt;li>&lt;code>what&lt;/code>&lt;/li>
&lt;li>&lt;code>whatis&lt;/code>&lt;/li>
&lt;li>&lt;code>which&lt;/code>&lt;/li>
&lt;li>&lt;code>whence&lt;/code>&lt;/li>
&lt;li>&lt;code>where&lt;/code>&lt;/li>
&lt;li>&lt;code>whereis&lt;/code>&lt;/li>
&lt;li>&lt;code>command&lt;/code>&lt;/li>
&lt;li>&lt;code>type&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>A &lt;em>lot&lt;/em> of these are legacy and should be avoided, but for completeness sake, we'll go through them.&lt;/p>
&lt;h3 id="what">&lt;code>what&lt;/code>&lt;/h3>
&lt;p>&lt;code>what&lt;/code> reads out special metadata embedded in a program, generally used to identify the version of source code it was built from:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ what /bin/ls
/bin/ls
Copyright &lt;span style="color:#f92672">(&lt;/span>c&lt;span style="color:#f92672">)&lt;/span> 1989, 1993, &lt;span style="color:#ae81ff">1994&lt;/span>
PROGRAM:ls PROJECT:file_cmds-272.220.1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There should be almost no circumstance in which you need to use it in your day-to-day work, but you might come across it if you &lt;em>meant&lt;/em> to type &lt;code>whatis&lt;/code>.&lt;/p>
&lt;h3 id="whatis">&lt;code>whatis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whatis&lt;/code> searches a local help database for text. This can be useful in tracking down manual pages:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ whatis bash
bash&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - GNU Bourne-Again SHell
bashbug&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - report a bug in bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But I can't imagine it will be a regularly used tool by most users.&lt;/p>
&lt;h3 id="which">&lt;code>which&lt;/code>&lt;/h3>
&lt;p>&lt;code>which&lt;/code> will search your &lt;code>$PATH&lt;/code> to see whether an executable can be found. With the &lt;code>-a&lt;/code> flag, it will show all results.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ which -a vi
/usr/local/bin/vi
/usr/bin/vi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>which&lt;/code> originated in &lt;code>csh&lt;/code>. It remains on many systems for compatibility but in general should be avoided due to potentially odd behaviour&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;h3 id="whence">&lt;code>whence&lt;/code>&lt;/h3>
&lt;p>&lt;code>whence&lt;/code> was added to the Korn shell. You are unlikely to use it unless you are on systems using &lt;code>ksh&lt;/code>. &lt;code>zsh&lt;/code> also has this command, but it should be avoided and considered non-standard.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whence brew
/usr/local/bin/brew
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="where">&lt;code>where&lt;/code>&lt;/h3>
&lt;p>This is a shell builtin that can provide information on commands, similar to &lt;code>type&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% where ls
ls: aliased to ls -G
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, &lt;code>type&lt;/code> should be preferred, as it is more standard.&lt;/p>
&lt;h3 id="whereis">&lt;code>whereis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whereis&lt;/code> is available on some systems and generally operates the same as &lt;code>which&lt;/code>, searching paths for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whereis ls
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, &lt;code>type&lt;/code> should be preferred for compatability.&lt;/p>
&lt;h3 id="command">&lt;code>command&lt;/code>&lt;/h3>
&lt;p>&lt;code>command&lt;/code> is defined in the POSIX standard, so should be expected to be present on most modern systems. Without arguments, it simply executes a command. With the &lt;code>-v&lt;/code> argument, you get a fairly machine-readable or processable response; with the &lt;code>-V&lt;/code> argument, you get a more human readable response:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% command -v ls
alias ls&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;ls -G&amp;#39;&lt;/span>
% command -V ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>command&lt;/code> can be useful in scripts, as we will see in later chapters.&lt;/p>
&lt;h3 id="type">&lt;code>type&lt;/code>&lt;/h3>
&lt;p>&lt;code>type&lt;/code> is part of the Unix standard and will be present in most modern systems. As we've already seen, it will identify the type of command as well as the location for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command can also be used to only search for paths:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -p ls
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Summary&lt;/strong>&lt;/p>
&lt;p>In summary, avoid anything that starts with &amp;lsquo;&lt;code>w&lt;/code>&amp;rsquo;! These are legacy commands, generally needed only when working on older Unix machines. &lt;code>type&lt;/code> or &lt;code>command&lt;/code> should be used instead.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>We will cover permissions and modes in later chapters. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Why these names and locations? It's a long story. The best place to start if you are intersted is the &lt;a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>&lt;code>chmod&lt;/code> changes the mode of a file; &lt;code>+x&lt;/code> means &amp;lsquo;add the executable bit&amp;rsquo;. This tells the operating system the file can be executed. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>&lt;a href="https://unix.stackexchange.com/questions/85249/why-not-use-which-what-to-use-then">Stack Exchange: Why not use “which”? What to use then?&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 6: Everything You Don't Need To Know About Job Control</title><link>https://dwmkerr.com/effective-shell-6-job-control/</link><pubDate>Mon, 10 Jun 2019 08:26:33 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-6-job-control/</guid><description>&lt;p>&lt;em>Job control&lt;/em> is a feature of most shells, which is generally not particularly intuitive to work with. However, knowing the basics can help prevent you from getting yourself into a tangle, and can from time to time make certain tasks a little easier.&lt;/p>
&lt;p>In this chapter, we'll look at the main features of job control, why it can be a problematic, and some alternatives.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-job-control">What Is Job Control?&lt;/h2>
&lt;p>Let's start with an example. I am building a simple web page. It has one &lt;code>index.html&lt;/code> file, one &lt;code>styles.css&lt;/code> file, and one &lt;code>code.js&lt;/code> file. The &lt;code>index.html&lt;/code> file looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">title&lt;/span>&amp;gt;My New Project&amp;lt;/&lt;span style="color:#f92672">title&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text/css&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;styles.css&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Snip... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;/&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Opening the file in a browser doesn't quite work, as it won't load the code or the styles. We need a web server to serve styles and code.&lt;/p>
&lt;p>A super-useful one-liner to run a web server on any machine with Python installed is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, this is so useful that I normally &lt;em>alias&lt;/em> this command, so that I can just type &lt;code>serve&lt;/code>. We'll see aliases in a later chapter.&lt;/p>
&lt;p>For now, if we run this command (you can get &lt;a href="https://github.com/dwmkerr/effective-shell/tree/master/6-job-control/sample">the three sample files here&lt;/a> if you want to try this yourself), then we can open the webpage in a browser, with the styles and code loaded:&lt;/p>
&lt;p>&lt;img src="images/website-screenshot.png" alt="Screenshot: Website" width="600" />&lt;/p>
&lt;p>We can also see that the server has served the HTML, JavaScript, and CSS files:&lt;/p>
&lt;p>&lt;img src="images/server-screenshot.png" alt="Screenshot: Server" width="600" />&lt;/p>
&lt;p>All well and good so far.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>Let's say we want to now continue using our shell, maybe to edit the website with a terminal editor like Vim or Emacs, or we want to zip up the site, or just run any shell command&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We have a problem. The &lt;code>python&lt;/code> process is still running - it's serving the website. Our shell is essentially useless, until we stop the server. See what happens when I try to edit a file:&lt;/p>
&lt;p>&lt;img src="images/blocked-shell.gif" alt="Demo: Blocked Shell" width="600" />&lt;/p>
&lt;p>In the example above, I try to run &lt;code>vi&lt;/code>, but nothing is happening. Standard input is not being read by the server and not being interpreted by the shell.&lt;/p>
&lt;p>I have to kill the server by hitting &lt;code>Ctrl+C&lt;/code> (which sends a &lt;code>SIGINT&lt;/code>&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> - we'll see more about signals later), clear my screen to get rid of all of the error messages, then start again.&lt;/p>
&lt;p>This is obviously not optimal. Let's look at some solutions.&lt;/p>
&lt;h2 id="solution-1-start-the-server-in-the-background">Solution 1: Start the Server in the Background&lt;/h2>
&lt;p>In most shells, you can run a command and instruct the shell to run it in the &lt;em>background&lt;/em>. To do this, you end the line with an ampersand. Here's how the example would look in this case:&lt;/p>
&lt;p>&lt;img src="images/start-in-background.gif" alt="Demo: Starting a Background Job" width="600" />&lt;/p>
&lt;p>By ending the command with an &lt;code>&amp;amp;&lt;/code> ampersand symbol, we instruct the shell to run the command as a &lt;em>background job&lt;/em>. This means that our shell is still functional. The shell has also notified us that this command is running as a background job with a specific &lt;em>job number&lt;/em>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span> &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#ae81ff">19372&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In slightly obtuse language, the shell has informed us that it has started a job in the background, with job number &lt;code>1&lt;/code> and that this job is currently handling the process with ID &lt;code>19372&lt;/code>.&lt;/p>
&lt;p>The ampersand solution is a fairly common pattern used in day-to-day work.&lt;/p>
&lt;h2 id="solution-2-move-the-server-to-the-background">Solution 2: Move the Server to the Background&lt;/h2>
&lt;p>Let's say you forgot to start the command in the background. Most likely in this case you'd kill the server with &lt;code>Ctrl+C&lt;/code> and then start it again with the &lt;code>&amp;amp;&lt;/code> option. However, what if this was a large file download or a task you didn't want to abort?&lt;/p>
&lt;p>In the example below, we'll move the job to the background:&lt;/p>
&lt;p>&lt;img src="images/move-to-background.gif" alt="Demo: Moving a Job to the Background" width="600" />&lt;/p>
&lt;p>The process is currently in the foreground, so my shell is inactive. Hitting &lt;code>Ctrl+Z&lt;/code> sends a &amp;lsquo;suspend&amp;rsquo; signal to the process&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, pausing it and moving it to the background.&lt;/p>
&lt;p>Let's dissect this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
Serving HTTP on 0.0.0.0 port &lt;span style="color:#ae81ff">3000&lt;/span> ...
127.0.0.1 - - &lt;span style="color:#f92672">[&lt;/span>03/Jun/2019 13:38:45&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#e6db74">&amp;#34;GET / HTTP/1.1&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span> -
^Z
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell echos as I type, so we see &lt;code>^Z&lt;/code> (i.e., the &lt;code>Ctrl+Z&lt;/code> chord I entered). The shell responds by moving the process into a background job and suspending it.&lt;/p>
&lt;p>The key here is that it is &lt;em>suspended&lt;/em>. The process is paused. So the web server is no longer serving. If you are following with the sample, reload your browser. The webpage fails to load, as the server process is not able to respond to requests.&lt;/p>
&lt;p>To &lt;em>continue&lt;/em> the job, in the background, we use the &lt;code>bg&lt;/code> (&amp;lsquo;background&amp;rsquo;) command, with a &lt;em>job identifier&lt;/em> (which always starts with a &lt;code>%&lt;/code> symbol - we'll see why soon) to tell the shell to continue the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% bg %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell lets us know the job is being continued, and if we load the webpage again, the content is shown as expected.&lt;/p>
&lt;p>As a final check, we run the &lt;code>jobs&lt;/code> command to see what jobs the shell is running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And there you have it - our server is running as a background job. This is exactly what we would see if we run &lt;code>jobs&lt;/code> after starting the server with an &lt;code>&amp;amp;&lt;/code> at the end. In fact, using an &lt;code>&amp;amp;&lt;/code> is perhaps an easier way to remember how to continue a suspended job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% %1 &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the same way ending a command with &lt;code>&amp;amp;&lt;/code> runs it in the background, ending a job identifier with &lt;code>&amp;amp;&lt;/code> &lt;em>continues&lt;/em> it in the background.&lt;/p>
&lt;p>There is at least one more way to move a job to the background&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>, but I have not yet found it useful in any scenarios, and it is overly complex to explain. See the footnote for details if you are interested.&lt;/p>
&lt;h2 id="moving-background-jobs-to-the-foreground">Moving Background Jobs to the Foreground&lt;/h2>
&lt;p>If you have a job in the background, you can bring it back to the foreground with the &lt;code>fg&lt;/code> (&amp;lsquo;foreground&amp;rsquo;) command. Let's show the jobs, with the &lt;code>jobs&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here I have a background job running a server. Any one of the following commands will bring it back to the foreground:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">fg %1 &lt;span style="color:#75715e"># Explicitly bring Job 1 into the foreground&lt;/span>
%1 &lt;span style="color:#75715e"># ...or in shorthand, just enter the job id...&lt;/span>
fg &lt;span style="color:#75715e"># ...if not given an id, fg and bg assume the most recent job.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the job is in the foreground, and you can interact with the process again however you like.&lt;/p>
&lt;h2 id="cleaning-up-jobs">Cleaning Up Jobs&lt;/h2>
&lt;p>You might realise you cannot continue what you are doing because an old job is &lt;em>still running&lt;/em>. Here's an example:&lt;/p>
&lt;p>&lt;img src="images/kill-job.gif" alt="Demo: Cleaning Up Jobs" width="600" />&lt;/p>
&lt;p>I tried to run my web server, but there was still one running as a background job. The server failed to start because the port is in use.&lt;/p>
&lt;p>To clean it up, I run the &lt;code>jobs&lt;/code> command to list the jobs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's my old web server. Note that even though it is suspended, it'll still be blocking the port it is serving on&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. The process is paused, but it is still holding onto all of the resources it is using.&lt;/p>
&lt;p>Now that I know the job identifier (&lt;code>%1&lt;/code> in this case), I can kill the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% kill %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">22843&lt;/span> terminated python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>This is why job identifiers start with a percentage sign!&lt;/em> The &lt;code>kill&lt;/code> command I have used is not a special job control command (like &lt;code>bg&lt;/code> or &lt;code>fg&lt;/code>). It is the normal &lt;code>kill&lt;/code> command, which terminates a process. But shells that support job control can normally use a job identifier in place of a &lt;em>process identifier&lt;/em>. So rather than working out what the process identifier is that I need to kill, I can just use the job identifier&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="why-you-shouldnt-use-jobs">Why You Shouldn't Use Jobs&lt;/h2>
&lt;p>Avoid jobs. They are not intuitive to interface with, and they suffer from some serious problems.&lt;/p>
&lt;p>The most obvious one is that all jobs write to the same output, meaning you can quickly get garbled output like this:&lt;/p>
&lt;p>&lt;img src="images/output.png" alt="Screenshot: Garbled Output" width="600" />&lt;/p>
&lt;p>This is what happens when I run a job, which just outputs text every second. It's in the background, but it's printing all over my commands. Even running the &lt;code>jobs&lt;/code> command to try and find the job to stop it is difficult.&lt;/p>
&lt;p>Input is even more complex. If a job is &lt;em>running&lt;/em> in the background, but requires input, it will be &lt;em>silently suspended&lt;/em>. This can cause confusion.&lt;/p>
&lt;p>Jobs &lt;em>can&lt;/em> be used in scripts but must be done so with caution and could easily confuse a consumer of the script if they leave background jobs hanging around, which cannot be easily cleaned up&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Handling errors and exit codes for jobs can be problematic, causing confusion, poor error handling, or overly complex code.&lt;/p>
&lt;h2 id="how-to-escape-jobs">How to Escape Jobs&lt;/h2>
&lt;p>If there are two things to take away, it would be this:&lt;/p>
&lt;blockquote>
&lt;p>If you have started running a command in the foreground, and you don't want to stop it and would rather move it to the background, hit &lt;code>Ctrl+Z&lt;/code>. Then Google &amp;ldquo;job control&amp;rdquo;.&lt;/p>
&lt;/blockquote>
&lt;p>And:&lt;/p>
&lt;blockquote>
&lt;p>If you think there is a job running in the background, and it is messing with your screen, type &lt;code>fg&lt;/code> to bring it to the front and kill it with &lt;code>Ctrl+C&lt;/code>. Repeat as needed!&lt;/p>
&lt;/blockquote>
&lt;p>In either case, if you need to do something more subtle, you can return to this reference. But the first command should allow you to get your shell back while you work out how to continue the job, and the second should kill a background job that is messing with your screen.&lt;/p>
&lt;h2 id="alternatives-to-jobs">Alternatives to Jobs&lt;/h2>
&lt;p>If you are using any kind of modern terminal such as iTerm, Terminal or the GNOME Terminal, just open a new tab or split! Much easier.&lt;/p>
&lt;p>The benefit to this is that each tab gets its own standard input and output, so there's no risk of overwriting. And of course you can hide/reveal/rearrange the tabs however you like.&lt;/p>
&lt;p>The traditional alternative to a job for an operator who simply wants more than one thing going on at once would be a &lt;em>terminal multiplexer&lt;/em>, such as &lt;code>screen&lt;/code> or &lt;code>tmux&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/terminal-multiplexer.gif" alt="terminal-multiplexer">&lt;/p>
&lt;p>Multiplexers work in a very similar way to a modern graphical terminal - they manage many shell instances. The benefits to a modern terminal, such as iTerm, is that you have a very intuitive GUI and lots of features.&lt;/p>
&lt;p>The benefits to a multiplexer are that you can run them over SSH sessions to manage complex operations on remote machines and that they run a client-server model, meaning many people can work with many multiplexed processes (and they can persist beyond sessions).&lt;/p>
&lt;p>My personal preference is both - I use a modern terminal &lt;em>and&lt;/em> run everything inside it in &lt;code>tmux&lt;/code>. We'll look at both of these options in later chapters.&lt;/p>
&lt;h2 id="quick-reference">Quick Reference&lt;/h2>
&lt;p>You might find that jobs are useful, or you might find that they are not. Either way, here's a quick reference of some common commands:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Command&lt;/th>
&lt;th>Usage&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>command &amp;amp;&lt;/code>&lt;/td>
&lt;td>Run the command as a background job.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>&amp;lt;Ctrl+Z&amp;gt;&lt;/code>&lt;/td>
&lt;td>Move the current process into a background job, suspended.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>jobs&lt;/code>&lt;/td>
&lt;td>List all jobs.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fg %1&lt;/code>&lt;/td>
&lt;td>Move background job number 1 into the foreground.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>bg %1&lt;/code>&lt;/td>
&lt;td>Continue background job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>kill %1&lt;/code>&lt;/td>
&lt;td>Terminate job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>wait %1&lt;/code>&lt;/td>
&lt;td>Block until job number 1 exits.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>If you want to find out more about the gory details of jobs, the best place to start is the &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">Bash Manual - Job Control Section&lt;/a>, or the &amp;lsquo;Job Control&amp;rsquo; section of your preferred shell's manual.&lt;/p>
&lt;p>I hope you found this useful, and, as always, please leave comments, questions or suggestions below!&lt;/p>
&lt;hr>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you are not a heavy shell user, this might seem unlikely. But if you do a lot of work in shells, such as sysadmin, devops, or do your coding from a terminal, this happens all the time! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Signals like &lt;code>SIGINT&lt;/code>, &lt;code>SIGKILL&lt;/code>, &lt;code>SIGTERM&lt;/code> and so on will be covered in a later chapter. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Technically, &lt;code>SIGTSTP&lt;/code> - which is &amp;lsquo;TTY stop&amp;rsquo;. If you have always wondered about the &amp;lsquo;TTY&amp;rsquo; acroynm, check the previous chatper, &lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Interlude: Understanding the Shell&lt;/a>. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>The alternative method is to use &lt;code>Ctrl+Y&lt;/code>, which will send a &lt;em>delayed interrupt&lt;/em>, which will continue to run the process until it tries to read from &lt;code>stdin&lt;/code>. At this point, the job is suspended and the control given to the shell. The operator can then use &lt;code>bg&lt;/code> or &lt;code>kill&lt;/code> or &lt;code>fg&lt;/code> to either move to the background, stop the process, or keep in the foreground as preferred. See: &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Another super-useful snippet: &lt;code>lsof -i -P -n | grep 8000&lt;/code> to find any process that has a given port open. Another one for the aliases chapter! &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>There are times this is needed. If a job runs &lt;em>many processes&lt;/em> - for example, by running a pipeline - the process identifier will change as the command moves from one stage of the pipeline to the next. The job identifier will remain constant. Remember, a job is a shell &lt;em>command&lt;/em>, so could run many processes. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>To see how bad this can be, create a script that starts jobs, then run it. Then run the &lt;code>jobs&lt;/code> command to see what is running. The output might surprise you! &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Interlude: Understanding the Shell</title><link>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</link><pubDate>Tue, 21 May 2019 09:22:05 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</guid><description>&lt;p>This is the first &amp;lsquo;interlude&amp;rsquo; in my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series. These interludes give some background, history or more flavour to some of the topics.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This one &lt;em>should&lt;/em> be high-level enough for even non-technical readers to enjoy (or at least understand!). I've tried to make sure any term that might be unfamiliar is described in a footnote&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. For the more technical reader, it provides an important grounding on some of the key concepts relating to shells and how they work.&lt;/p>
&lt;h2 id="introduction-for-the-non-technical-reader">Introduction for the Non-Technical Reader&lt;/h2>
&lt;p>It might come as a surprise that &lt;em>many&lt;/em> technical computer users (programmers, data scientists, systems administrators etc) spend a lot of time using an interface which looks like it's from the sixties:&lt;/p>
&lt;p>&lt;img src="images/screenshot-shell.png" alt="Diagram: The Shell" width="600px" />&lt;/p>
&lt;p>If you work with technologists, you might have seen them using an interface like this. This kind of simple, text-based interface is called a &lt;em>shell&lt;/em>, and it has been a common way to interface with computers ever since the first screens and keyboards were created.&lt;/p>
&lt;p>Given how much computing has advanced, why would people use such an interface? Just look at how much the Windows operating-system has changed over the last three decades:&lt;/p>
&lt;p>&lt;img src="images/screenshot-windows-evolution.png" alt="Image: The Evolution of Windows" width="600px" />&lt;/p>
&lt;p>&lt;em>(By Source (WP:NFCC#4), Fair use, &lt;a href="https://en.wikipedia.org/w/index.php?curid=58853841">https://en.wikipedia.org/w/index.php?curid=58853841&lt;/a>)&lt;/em>&lt;/p>
&lt;p>Why would people choose to use such an archaic interface as a shell?&lt;/p>
&lt;ul>
&lt;li>Typing is &lt;em>fast&lt;/em>: A skilled shell user can manipulate a system at dazzling speeds just using a keyboard. Typing commands is generally &lt;em>much&lt;/em> faster than exploring through user interfaces with a mouse&lt;/li>
&lt;li>Shells are &lt;em>programmable&lt;/em>: Users will often being programming as they work in a shell, creating scripts to automate time-consuming or repetetive processes&lt;/li>
&lt;li>Shells are &lt;em>portable&lt;/em>: A shell can be used to interface to almost any type of computer, from a mainframe to a Raspberry Pi, in a very similar way.&lt;/li>
&lt;/ul>
&lt;p>Not all technical users will use a shell regularly, but there are many who will spend the bulk of their time in such an interface. It is such a crucial skill to be able to operate one effectively that I have been writing this series primarily to show ways to be more efficient with this kind of interface.&lt;/p>
&lt;h2 id="introduction-for-the-technical-reader">Introduction for the Technical Reader&lt;/h2>
&lt;p>You may be familar with the shell, but it can be useful to understand some of the surrounding concepts in detail. How does a shell differ from a terminal? What is a &lt;em>tty&lt;/em>? How do shells really work? Hopefully as you read this article you'll discovery something that you didn't know about shells.&lt;/p>
&lt;h2 id="lets-get-started">Let's Get Started!&lt;/h2>
&lt;p>To understand what shells, terminals, command-prompts and so on are and how they relate, we need to start with the basics: how a modern computer works!&lt;/p>
&lt;h2 id="a-computer-in-a-nutshell">A Computer in a Nutshell&lt;/h2>
&lt;p>The diagram below shows a simplified view of a typical computer:&lt;/p>
&lt;p>&lt;img src="images/diagram1-operating-system.png" alt="Diagram: Operating System" width="600px" />&lt;/p>
&lt;p>Already there's a lot going on.&lt;/p>
&lt;p>Your computer is going to have a CPU&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> and memory&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, and almost certainly a network adapter&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> and display adapter&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. Most computers will have at least one hard disk. For home PCs, there'll also likely be a bunch of peripherals, such as a mouse, keyboard, printers, flash drives, webcams and so on.&lt;/p>
&lt;h3 id="the-operating-system">The Operating System&lt;/h3>
&lt;p>The operating system is the piece of software installed on a computer that can interface with the &lt;em>hardware&lt;/em>. Without hardware, such as a CPU, memory, a network adapter, a graphics card, disk drives and so on, there's not much that you can do with the computer. The operating system is the primary interface to this hardware. No normal programs will talk to hardware directly - the operating system abstracts this hardware away and provides a &lt;em>software&lt;/em> interface to it.&lt;/p>
&lt;p>The abstraction the operating system provides is essential. Developers don't need to know the specifics of how to work with individual devices from different vendors; the operating system provides a standardised interface to all of this. It also handles various tasks such as making sure the system starts up properly.&lt;/p>
&lt;p>The operating system is generally broken down into two parts - the &lt;em>kernel&lt;/em> and &lt;em>user space&lt;/em>:&lt;/p>
&lt;p>&lt;img src="images/diagram2-the-kernel-and-user-space.png" alt="Diagram: The Kernel and User Space" width="600px" />&lt;/p>
&lt;p>Let's look at these in more detail.&lt;/p>
&lt;h3 id="the-kernel">The Kernel&lt;/h3>
&lt;p>This is the part of the operating system that is responsible for the most sensitive tasks: interfacing with physical devices, managing the resources that are available for users and programs, starting up the various systems that are needed, and so on.&lt;/p>
&lt;p>Software running in the kernel has direct access to resources, so is &lt;em>extremely&lt;/em> sensitive. The kernel will balance resources between the programs in user space, which we'll look at shortly. If you've ever had to install &amp;lsquo;drivers&amp;rsquo;, these are examples of pieces of software that will run in the kernel - they'll have direct access to a physical device you've installed, and expose it to the rest of the software on the computer.&lt;/p>
&lt;p>Why &amp;lsquo;kernel&amp;rsquo;? The kernel is the soft, edible part of a nut or seed, which is surrounded by a shell. Below you can see a walnut - the kernel is the soft bit in the middle, and the shell surrounds and protects it. This is a useful metaphor that is used for parts of a computer.&lt;/p>
&lt;p>&lt;img src="images/image-walnut.jpg" alt="Image: Photo of a walnut, showing the kernel and the shell" width="200px" />&lt;/p>
&lt;p>&lt;em>(By Kkchaudhary11 - Own work, CC BY-SA 4.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=49069244">https://commons.wikimedia.org/w/index.php?curid=49069244&lt;/a>)&lt;/em>&lt;/p>
&lt;p>The operating system kernel really is the &lt;em>core&lt;/em> of the operating system. It's such a sensitive area of the operating system that we actually want to avoid running software in it if possible&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. And that is where &lt;em>user space&lt;/em> comes in.&lt;/p>
&lt;h3 id="user-space">User Space&lt;/h3>
&lt;p>The vast majority of programs run in &amp;lsquo;user space&amp;rsquo; (also commonly called &amp;lsquo;user land&amp;rsquo;).&lt;/p>
&lt;p>When a program starts, the kernel will allocate it a private segment of memory and provide &lt;em>limited&lt;/em> access to resources. The program is given access to a library of functions by the operating system, which it can use to access resources such as files, devices and so on. Programs in user space are essentially in sandboxes, where there is a limit to how much damage they can do.&lt;/p>
&lt;p>For example, a program running in user space can use the standard &lt;a href="http://man7.org/linux/man-pages/man3/fopen.3.html">&lt;code>fopen&lt;/code>&lt;/a> function, which is provided on almost every operating system as part of the &lt;a href="https://www.gnu.org/software/libc/">C Standard Library&lt;/a>. This allows a program to attempt to open a file. The operating system will make a decision on whether the program is &lt;em>allowed&lt;/em> to open the file (based on things such as permissions, where the file is and so on) and then, if it is OK with the call, will give the program access to the file. Under the hood, this &amp;lsquo;user space&amp;rsquo; call translates to a system call in the kernel.&lt;/p>
&lt;p>Now that the key components have been introduced, we can look at the &lt;em>shell&lt;/em>. The name should come as no surprise, as it is a &lt;em>wrapper&lt;/em> or outer layer to the operating system (which itself contains the sensitive nugget of the kernel).&lt;/p>
&lt;h3 id="the-shell">The Shell&lt;/h3>
&lt;p>So what is the shell? The shell is just a general name for any &lt;em>user space&lt;/em> program that allows access to resources in the system, via some kind of interface.&lt;/p>
&lt;p>Shells come in many different flavours but are generally provided to aid a human operator in accessing the system. This could be interactively, by typing at a terminal, or via scripts, which are files that contain a sequence of commands.&lt;/p>
&lt;p>For example, to see all of the files in a folder, the human operator &lt;em>could&lt;/em> write a program in a language such as C, making system calls to do what they want. But for day-to-day tasks, this would be repetitive. A shell will normally offer us a quick way to do that exact task, without having to manually write a program to do it.&lt;/p>
&lt;p>Here's an example, where a shell is being used to show the &amp;lsquo;png&amp;rsquo; images in the folder I am working in&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/screenshot1-example-shell.png" alt="Screenshot: Browsing Contents of the File System the the Bourne Again Shell" width="600px" />&lt;/p>
&lt;p>So a shell is a user-space program to interface with the computer. But there a few more moving parts than just a shell we are seeing in the image above. There are different types of shells, there are terminal programs, and there are the programs or commands that the shell calls (in the example above, &lt;code>tree&lt;/code> is a program). Let's pick these apart.&lt;/p>
&lt;p>Here's a diagram that more accurately shows what is going on:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We've introduced a few new things here. There's a &lt;em>user&lt;/em>, who is interfacing with a &lt;em>terminal&lt;/em>, which is running a &lt;em>shell&lt;/em>, which is showing a &lt;em>command prompt&lt;/em>. The user has written a command that is calling a program (in this case, the &lt;code>tree&lt;/code> program).&lt;/p>
&lt;p>Let's dissect this bit by bit.&lt;/p>
&lt;h3 id="the-terminal">The Terminal&lt;/h3>
&lt;p>We're not &lt;em>directly&lt;/em> interacting with the &amp;lsquo;shell&amp;rsquo; in this diagram. We're actually using a &lt;em>terminal&lt;/em>. When a user wants to work with a shell interactively, using a keyboard to provide input and a display to see the output on the screen, the user uses a &lt;em>terminal&lt;/em>.&lt;/p>
&lt;p>A terminal is just a program that reads input from the keyboard, passes that input to another program (normally a shell), and displays the results on the screen. A shell program on its own does not do this - it requires a terminal as an interface.&lt;/p>
&lt;p>Why the word &lt;em>terminal&lt;/em>? This makes sense when you look at how people interfaced with computers historically. Input to a computer might be through punch cards, and output would often be via a printer. The &lt;em>Teletype Termimal&lt;/em>&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup> became a common way for users to interface with computers.&lt;/p>
&lt;p>&lt;img src="images/image-asr-33.jpg" alt="Photo: ASR-33 TTY" width="600px" />&lt;/p>
&lt;p>&lt;em>(Photograph by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr, CC BY-SA 2.0 fr, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=17821795">https://commons.wikimedia.org/w/index.php?curid=17821795&lt;/a>)&lt;/em>&lt;/p>
&lt;p>At this time, computers were very large, complex, and expensive machines. It was common to have &lt;em>many&lt;/em> terminals connected to a single large machine (or &amp;lsquo;mainframe&amp;rsquo;), or a few terminals that people would share. But the terminal itself was just a human interface to the operating system. A more modern terminal would be something like an IBM 3486:&lt;/p>
&lt;p>&lt;img src="images/image-ibm3486.jpg" alt="Photo: IBM 3486" width="600px" />&lt;/p>
&lt;p>&lt;em>(By ClickRick - Own work, CC BY-SA 3.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=6693700">https://commons.wikimedia.org/w/index.php?curid=6693700&lt;/a>)&lt;/em>&lt;/p>
&lt;p>This is a very small computer in its own right but still basically just a dumb screen and keyboard connected by a cable to a larger mainframe computer in another location.&lt;/p>
&lt;p>This mechanism is still very much the case today. When I want to work with a computer in a data centre, I don't go and find the machine, plug in a keyboard and a display and directly interface to it. I run a &lt;em>terminal program&lt;/em> on my computer to provide access to the remote machine. My terminal program allows me to use my keyboard and display to work with a remote machine - all via a &lt;em>secure shell&lt;/em> - which is a secured-shell connection over a network.&lt;/p>
&lt;p>So terminals in many ways are quite simple - they are interfaces. But because they are quite simple programs, we can't do much with them. So normally, the first thing that a terminal program will do is run a &lt;em>shell&lt;/em> program - a program that we can use to operate the computer.&lt;/p>
&lt;p>There's nothing special about terminals - anyone can write a program to operate as a terminal, which is why you will see many different terminals around. Examples are the standard &amp;lsquo;terminal&amp;rsquo; app for MacOS X, the &lt;a href="https://wiki.gnome.org/Apps/Terminal/VTE">gnome-terminal&lt;/a> for Linux, and &lt;a href="https://www.iterm2.com/">iTerm2&lt;/a> and &lt;a href="https://hyper.is/">Hyper&lt;/a>. There's a bunch of screenshots of different setups at the end of the article.&lt;/p>
&lt;h2 id="back-to-the-shell">Back to the Shell&lt;/h2>
&lt;p>Now that we've described the terminal, we can go back and look at the shell in detail.&lt;/p>
&lt;p>The shell is the program that is going to take input from somewhere and run a series of commands. When the shell is running in a terminal, it is normally taking input interactively from the user. As the user types in commands, the terminal feeds the input to the shell and presents the output of the shell on the screen.&lt;/p>
&lt;p>A shell program can also take input from files; these files will then generally be &amp;lsquo;shell scripts&amp;rsquo;. This might be used to run automated operations, such as cleaning up certain folders when a computer starts.&lt;/p>
&lt;p>Shells can write output to files or other locations, and so on. You can run a shell program outside of a terminal - you just won't be able to interface with it using a keyboard or display. And in fact, lots of operations happen in this way: automated scripts, startup tasks, installers and so on.&lt;/p>
&lt;p>So what else does a shell do? Most of the features are related to helping human operators work with the system more efficiently.&lt;/p>
&lt;ul>
&lt;li>Quickly enter commands, see the history of commands and quickly restructure commands (see &lt;a href="http://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Effective Shell - Navigating the Command Line&lt;/a>)&lt;/li>
&lt;li>Navigate through the file system, moving from folder to folder (see &lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Effective Shell - Move Around!&lt;/a>), which makes it easier for an operator to navigate the file system.&lt;/li>
&lt;li>Chain the output of commands together - for example, taking the output of one basic program, such as the &lt;code>tree&lt;/code> program we saw, and writing it to a file (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Understanding Pipelines&lt;/a>)&lt;/li>
&lt;li>Offer a programming language, allowing the operator to perform more complicated tasks (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Basic Shell Scripting&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>And a lot more! In fact, that's what the whole &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series is about - how to get the most from these powerful programs, particularly for those who use them regularly.&lt;/p>
&lt;h3 id="the-command-prompt-or-command-line">The Command Prompt or Command Line&lt;/h3>
&lt;p>The last part of the diagram, which we haven't covered yet, is the &lt;em>command prompt&lt;/em>.&lt;/p>
&lt;p>&lt;img src="images/diagram4-command-prompt-1.png" alt="Diagram: Command Prompt" width="300px" />&lt;/p>
&lt;p>When a &lt;em>shell&lt;/em> is running in &lt;em>terminal&lt;/em>, it knows that a human operator will be interfacing with it. So to make sure that the operator has some kind of visual hint that &lt;em>they have to enter commands&lt;/em>, the shell will output some kind of prompt.&lt;/p>
&lt;p>I've included a set of screenshots at the end of the article, just after this section, and you can see how some different command prompts look.&lt;/p>
&lt;p>Note that shells don't have to use command prompts - if you use a shell program to execute a script, there will be no command prompt. Shells only show a prompt when they know they are being used interactively. Many programs which allow a user to operate interactively will show a command prompt.&lt;/p>
&lt;p>Shell command prompts can be customised, so they will often look different from machine to machine (for more details, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Customising the Command Line&lt;/a>). Below is an example that shows a &lt;em>lot&lt;/em> of technical information. This is from the highly popular &lt;a href="https://ohmyz.sh/">oh-my-zsh&lt;/a> framework for the &amp;lsquo;Z Shell&amp;rsquo; shell, which is very popular among developers:&lt;/p>
&lt;p>&lt;img src="images/image-ohmyzsh.jpg" alt="Image: Customised oh-my-zsh" width="600px" />&lt;/p>
&lt;p>*(Source: &lt;a href="https://ohmyz.sh/">https://ohmyz.sh/&lt;/a>)&lt;/p>
&lt;h3 id="shell-commands-and-different-shells">Shell Commands and Different Shells&lt;/h3>
&lt;p>A lot of the &amp;lsquo;commands&amp;rsquo; in a shell, such as &lt;code>cat&lt;/code> (which shows the contents of a file), are actually just simple programs, which will interface with the kernel. No matter what shell you use, these commands will behave the same way, because really all you are doing is calling another progam.&lt;/p>
&lt;p>Some commands, such as &lt;code>cd&lt;/code> (change directory), are built into the shell. Some commands are functions that have been defined, or aliases to other commands (for more details on commands, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Commands&lt;/a>). Commands will often differ between shells.&lt;/p>
&lt;p>Not all shells are created equal - anyone can write a shell program, maybe creating a simple interface to the computer or a highly complex one with many features. In fact, a later article in this series will look at the geneology of the most common shells.&lt;/p>
&lt;p>On most Unix-like systems, the default shell is a program called &lt;code>bash&lt;/code>, which stands for &amp;quot; Bourne Again Shell&amp;rdquo; (the name and history around it will be discussed at length in the later article). But there are many other shells: the C Shell, the Korn Shell, Z Shell and Fish, just to name just a few.&lt;/p>
&lt;p>Users and administators can configure what shell they like to use. When a terminal opens, it will immediately start the user's preferred shell program. It is possible to change this. Different users will have different preferences, given that shells offer varying features. This can cause complexity when working with systems, as we cannot always expect every user to have the same shell, or even for the same shell to be set up consistently, as they can be extensively customised.&lt;/p>
&lt;p>Let's review the earlier diagram again:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell-1.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We can see the real internals of what is going on in this &amp;ldquo;Terminal -&amp;gt; Shell -&amp;gt; Program&amp;rdquo; chain in the diagram above quite easily.&lt;/p>
&lt;p>Try the command &lt;code>pstree -psa $$&lt;/code> in a shell&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/image-psforest.png" alt="Image: Process Tree" width="600px" />&lt;/p>
&lt;p>The first &lt;code>systemd&lt;/code> process is the primary process for the OS - it is process number &lt;code>1&lt;/code>, which initialises everything else. The second &lt;code>systemd&lt;/code> process is the process that is running the interface for my user. We can ignore these for now; they are internals to how the operating system boots and starts processes.&lt;/p>
&lt;p>What is interesting is that we can see a &lt;em>terminal&lt;/em> (the gnome terminal), which has started my preferred &lt;em>shell&lt;/em> (which is &lt;code>zsh&lt;/code>), which is running a &lt;em>command&lt;/em> (the program &lt;code>pstree&lt;/code>). Here we can see the exact chain as shown in the diagram earlier.&lt;/p>
&lt;h3 id="thats-a-wrap">That's a Wrap!&lt;/h3>
&lt;p>These are the key technologies and concepts that surround a shell.&lt;/p>
&lt;p>If you are interested in more technical details of working with shells, then my &lt;a href="https://github.com/effective-shell">Effective Shell&lt;/a> series goes into these topics in depth. The goal of this series is to help teach techniques that making working with shells more efficient.&lt;/p>
&lt;p>To close the article, below are some examples of different terminals, shells, command prompts and so on.&lt;/p>
&lt;h4 id="example-iterm-2--tmux--zsh">Example: iTerm 2 / tmux / zsh&lt;/h4>
&lt;p>&lt;img src="images/example-iterm-zsh.png" alt="Example: iTerm 2, tmux, zsh" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A MacOS operating system&lt;/li>
&lt;li>iTerm2 as the terminal program&lt;/li>
&lt;li>&lt;code>tmux&lt;/code> running as a &amp;lsquo;terminal multiplexer&amp;rsquo; (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell: Terminal Multiplexers&lt;/a>)&lt;/li>
&lt;li>&lt;code>zsh&lt;/code> (Z Shell) as the shell program, using &amp;lsquo;oh my zsh&amp;rsquo;, which is easily recognised by the &lt;code>%&lt;/code> sign in the command prompt.&lt;/li>
&lt;li>A customised command line, which shows the user and folder on one line, with only the &lt;code>%&lt;/code> symbol below, to leave lots of space for the input commands&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>.&lt;/li>
&lt;/ul>
&lt;h4 id="example-bash">Example: Bash&lt;/h4>
&lt;p>&lt;img src="images/example-bash.png" alt="Example: Bash" width="600px" />&lt;/p>
&lt;p>&lt;img src="images/example-bash-root.png" alt="Example: Bash Elevated" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A Linux operating system (Ubuntu 14)&lt;/li>
&lt;li>The gnome terminal&lt;/li>
&lt;li>&lt;code>bash&lt;/code> as the shell&lt;/li>
&lt;li>In the second screenshot, the user has &amp;lsquo;root privileges&amp;rsquo;, and to indicate this, &lt;code>bash&lt;/code> helpfully changes the default command prompt from a dollar sign to a hash sign&lt;/li>
&lt;/ul>
&lt;h4 id="example-windows-explorer">Example: Windows Explorer&lt;/h4>
&lt;p>&lt;img src="images/example-explorer.png" alt="Example: Windows Explorer" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>No terminal&lt;/li>
&lt;li>The &lt;code>explorer.exe&lt;/code> program showing us a &lt;em>graphical&lt;/em> shell&lt;/li>
&lt;/ul>
&lt;p>This looks different from previous examples. The program, which shows the familiar Windows interface, &lt;code>explorer.exe&lt;/code>, is in fact a shell as well, offering interactive access to the operating system and computer resources. The bulk of the Windows APIs to interact with this interface are in the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/desktop/bb773177(v=vs.85).aspx">Shell Library&lt;/a>. I also maintain a popular library for building extensions to the graphical Windows shell - &lt;a href="https://github.com/dwmkerr/sharpshell">sharpshell&lt;/a>.&lt;/p>
&lt;h4 id="example-windows-command-prompt">Example: Windows Command Prompt&lt;/h4>
&lt;p>&lt;img src="images/example-cmd.png" alt="Example: Command Prompt" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The command prompt terminal and shell&lt;/li>
&lt;/ul>
&lt;p>In Windows, the terminal and shell are combined into a single &lt;code>cmd.exe&lt;/code> program. There's an excellent article on the internals - &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft DevBlogs: Windows Command-Line: Inside the Windows Console&lt;/a>&lt;/p>
&lt;h4 id="example-windows-powershell">Example: Windows PowerShell&lt;/h4>
&lt;p>&lt;img src="images/example-powershell.png" alt="Example: Windows Powershell" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The PowerShell terminal&lt;/li>
&lt;/ul>
&lt;p>PowerShell is an improvement on the &amp;lsquo;command prompt&amp;rsquo; program that was originally used in Windows, offering much more functionality for scripting and other modern shell features.&lt;/p>
&lt;h4 id="example-windows-subsystem-for-linux-wsl">Example: Windows Subsystem for Linux (WSL)&lt;/h4>
&lt;p>&lt;img src="images/example-wsl.png" alt="Example: WSL" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The &lt;code>Bash.exe&lt;/code> program&lt;/li>
&lt;/ul>
&lt;p>This screenshot, from &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/faq">MSDN: Frequently Asked Questions about Windows Subsystem for Linux&lt;/a> shows Bash running in Windows. This is a relatively new feature at the time of writing, allowing Windows users to use a Linux interface to the PC. This is a feature that may become increasingly valuable, as in general it is challenging to write shell code that can run on Windows and Unix-like systems.&lt;/p>
&lt;h2 id="share-and-discuss">Share and Discuss&lt;/h2>
&lt;p>If you enjoyed this article, please do share it! Feel free to include suggestions, improvements or corrections in the comments below.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Useful References&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>A simple Linux kernel module, showing how basic kernel programming works in Linux: &lt;a href="https://github.com/dwmkerr/linux-kernel-module">github.com/dwmkerr/linux-kernel-module&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.amazon.com/How-Linux-Works-2nd-Superuser/dp/1593275676">How Linux Works - Brian Ward&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://unix.stackexchange.com/questions/4126/what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con/4132">StackExchange: What is the exact difference between a &amp;lsquo;terminal&amp;rsquo;, a &amp;lsquo;shell&amp;rsquo;, a &amp;lsquo;tty&amp;rsquo;, and a console?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft: Inside the Windows Console&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I'd be fascinated to know if this is at all interesting to less technically inclined people, so please do go ahead and let me know in the comments! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>CPU: central processing unit. This is the chip in the computer that does most of the work (which after many layers of abstraction eventually becomes arithmetic and sending simple instructions to other places). &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Memory is the &amp;lsquo;working space&amp;rsquo; where the state of your system is stored. If you are writing a document, the text lives in memory, until you save it, when it then gets written to a hard drive. Memory is &lt;em>ephemeral&lt;/em> - everything is gone when you turn off the power to it. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>This is the part of your computer that knows how to do things like connect to a WiFi network, or has a network socket you might plug a network cable into. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>This is the part of your computer you plug the screen into. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>This is because a mistake in &lt;em>Kernel Mode&lt;/em> programs can have disasterous effects. It could access any files, no matter who they belong do, control the hardware, install more software - almost anything. Errors in this code can cause terrible issues (like the infamous Windows &amp;lsquo;blue screen of death&amp;rsquo;), and malicious code in the kernel essentially has full access to not only all your data but also your webcam, network adapter and so on. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>As an aside, if you are curious about the visual style of my setup or customisations that have been made, everything in my setup is available online on my &amp;lsquo;dotfiles&amp;rsquo; repo - &lt;a href="https://github.com/dwmkerr/dotfiles">github.com/dwmkerr/dotfiles&lt;/a>. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>And that's where the &amp;lsquo;TTY&amp;rsquo; acronym you will see sometimes comes from. Enter the &lt;code>ps&lt;/code> command, and you'll actually see the TTY interface each process is attached to. This is a topic that will come up later in the series. &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>&lt;code>$$&lt;/code> is a Bash &lt;a href="https://www.tldp.org/LDP/abs/html/internalvariables.html#PROCCID">internal variable&lt;/a>. These will also be covered in a later article in the series. &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>Feel free to see my &lt;a href="https://github.com/dwmkerr/dotfiles">dotfiles&lt;/a> to configure a similar setup for yourself. &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Manipulating Istio and other Custom Kubernetes Resources in Golang</title><link>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</link><pubDate>Mon, 08 Oct 2018 21:34:02 +0000</pubDate><guid>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</guid><description>&lt;p>In this article I'll demonstrate how to use Golang to manipulate Kubernetes Custom Resources, with Istio as an example. No knowledge of Istio is needed, I'll just use it to demonstrate the concepts!&lt;/p>
&lt;p>&lt;img src="images/code-2.jpg" alt="code">&lt;/p>
&lt;p>&lt;a href="https://istio.io">Istio&lt;/a> is a highly popular Service Mesh platform which allows engineers to quickly add telemetry, advanced traffic management and more to their service-based applications.&lt;/p>
&lt;p>One interesting element of how Istio works is that when deployed into a Kubernetes cluster, many key configuration objects are handled as &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources&lt;/a>. Custom Resources are a very powerful Kubernetes feature, which allow you to create your own &amp;lsquo;first class&amp;rsquo; resources (just like Pods, ReplicaSets, Deployments or whatever) and then interface with them using &lt;code>kubectl&lt;/code> or the Kubernetes APIs.&lt;/p>
&lt;p>In this article I'll show you how to interface with these Custom Resources using the Golang Kubernetes client.&lt;/p>
&lt;h2 id="crds-a-quick-overview">CRDs: A Quick Overview&lt;/h2>
&lt;p>When you set up Istio for your cluster, one common thing you will likely do is specify how you will route traffic. This can be quite sophisticated, as shown below:&lt;/p>
&lt;p>&lt;img src="images/TrafficManagementOverview.svg" alt="TrafficManagementOverview">&lt;/p>
&lt;p>&lt;a href="https://istio.io/docs/concepts/traffic-management/">Figure 1: Istio Traffic Management Examples, from istio.io&lt;/a>&lt;/p>
&lt;p>One way for a system like this to be configured would be to have a ConfigMap which contains the definition of how services are routed.&lt;/p>
&lt;p>However, Istio actually registers new types of resources (Custom Resource Definitions) which represent things like Gateways or Services. We can create/update/delete/manipulate them just like any other Kubernetes object.&lt;/p>
&lt;p>For example, I could create a virtual service for the example above with something like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">cat &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF | kubectl create -f -
&lt;/span>&lt;span style="color:#e6db74">apiVersion: networking.istio.io/v1alpha3
&lt;/span>&lt;span style="color:#e6db74">kind: VirtualService
&lt;/span>&lt;span style="color:#e6db74">metadata:
&lt;/span>&lt;span style="color:#e6db74"> name: service2
&lt;/span>&lt;span style="color:#e6db74">spec:
&lt;/span>&lt;span style="color:#e6db74"> hosts:
&lt;/span>&lt;span style="color:#e6db74"> - &amp;#34;*&amp;#34;
&lt;/span>&lt;span style="color:#e6db74"> gateways:
&lt;/span>&lt;span style="color:#e6db74"> - demo1-gateway
&lt;/span>&lt;span style="color:#e6db74"> http:
&lt;/span>&lt;span style="color:#e6db74"> - route:
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v1
&lt;/span>&lt;span style="color:#e6db74"> weight: 95
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v2
&lt;/span>&lt;span style="color:#e6db74"> weight: 5
&lt;/span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, the important thing is not the specific content of this resource, more the fact that I can treat my Istio resources just like I would any other Kubernetes object:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io
NAME AGE
service2 93s
&lt;/code>&lt;/pre>&lt;p>Or:&lt;/p>
&lt;pre>&lt;code>$ kubectl delete virtualservices.networking.istio.io/service2
&lt;/code>&lt;/pre>&lt;p>I can use &lt;code>edit&lt;/code>, &lt;code>describe&lt;/code>, register lifecycle events, watch for changes, and so on.&lt;/p>
&lt;h2 id="working-with-crds-in-golang">Working with CRDs in Golang&lt;/h2>
&lt;p>The &lt;a href="https://github.com/kubernetes/client-go">Golang Kubernetes Client&lt;/a> allows you to create strongly defined types which you can then use to interface with CRDs. An example is in the Red Hat blog post &lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Kubernetes Deep Dive: Code Generation for Custom Resources&lt;/a>.&lt;/p>
&lt;p>This is an excellent approach, but can feel pretty heavy if you want to quickly access some data, and don't want to have to generate a lot of code.&lt;/p>
&lt;p>There is an alternative, which is to use the &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">&lt;code>DynamicClient&lt;/code>&lt;/a>. The &lt;em>preferred&lt;/em> approach seems to be the first, which involves code generation, so little documentation exists for the second approach. However, it is actually very simple.&lt;/p>
&lt;p>Here's an example of how you can list all Istio &lt;code>VirtualService&lt;/code> resources, without having to generate any code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a Dynamic Client to interface with CRDs.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">dynamicClient&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamic&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// List all of the Virtual Services.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServices&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">List&lt;/span>(&lt;span style="color:#a6e22e">metav1&lt;/span>.&lt;span style="color:#a6e22e">ListOptions&lt;/span>{})
&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#66d9ef">range&lt;/span> &lt;span style="color:#a6e22e">virtualServices&lt;/span>.&lt;span style="color:#a6e22e">Items&lt;/span> {
&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;VirtualService: %s\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span>.&lt;span style="color:#a6e22e">GetName&lt;/span>())
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet omits setup and error-handling for clarity, the full example is in the &lt;a href="https://gist.github.com/dwmkerr/09ac0fd98595460456e17d5ef0c77667">k8s-list-virtualservices.go&lt;/a> gist.&lt;/p>
&lt;h2 id="patching-crds-in-golang">Patching CRDs in Golang&lt;/h2>
&lt;p>You may have noticed that the &lt;code>.Resource().Namespace().List()&lt;/code> code looks very similar to the structure for making API calls when using the Kubernetes &lt;code>Clientset&lt;/code>. In fact, it is essentially the same. Looking at &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">the interface&lt;/a>, you can see you have all of the operations you'd expect:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Create&lt;/code>&lt;/li>
&lt;li>&lt;code>Update&lt;/code>&lt;/li>
&lt;li>&lt;code>Delete&lt;/code>&lt;/li>
&lt;li>&lt;code>Get&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>And so on. This is nice because you can use the same trick in my article &amp;lsquo;&lt;a href="https://www.dwmkerr.com/patching-kubernetes-resources-in-golang/">Patching Kubernetes Resources in Golang&lt;/a>&amp;rsquo; to manipulate these entities, without ever having to create a structure to represent it.&lt;/p>
&lt;p>Here's another abbreviated example, this time showing how we can adjust the weight of the routing from the services to 50%/50%:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// Weight the two routes - 50/50.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">patchPayload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> make([]&lt;span style="color:#a6e22e">PatchUInt32Value&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/0/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/1/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">patchPayload&lt;/span>)
&lt;span style="color:#75715e">// Apply the patch to the &amp;#39;service2&amp;#39; service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;service2&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">patchBytes&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>See the full example in the gist &lt;a href="https://gist.github.com/dwmkerr/7332888e092156ce8ce4ea551b0c321f">k8s-patch-virtualservice.go&lt;/a>&lt;/p>
&lt;p>After running the sample, you can use the Kubernetes CLI to verify the changes:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io/service2 -o yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
clusterName: &amp;quot;&amp;quot;
creationTimestamp: 2018-10-08T09:53:16Z
generation: 0
name: service2
namespace: default
resourceVersion: &amp;quot;487435&amp;quot;
selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/virtualservices/service2
uid: fac5930c-cadf-11e8-90a2-42010a94005b
spec:
gateways:
- demo1-gateway
hosts:
- '*'
http:
- route:
- destination:
host: service2
subset: v1
weight: 50
- destination:
host: service2
subset: v2
weight: 50
&lt;/code>&lt;/pre>&lt;h2 id="keep-it-simple">Keep It Simple!&lt;/h2>
&lt;p>That's it! This trick made something I was working on a &lt;em>lot&lt;/em> easier, but it took a little bit of experimentation to get right. I hope you find the approach useful. Please share any thoughts/questions in the comments.&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>The following articles were using in working out this approach:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Red Hat: Deep Dive: Code Generation for Custom Resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Kubernetes Docs: Custom Resources&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>Patching Kubernetes Resources in Golang</title><link>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</link><pubDate>Tue, 24 Jul 2018 06:33:17 +0000</pubDate><guid>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</guid><description>&lt;p>Recently I needed to be able to quickly adjust the number of replicas in a Kubernetes Replication Controller. The original solution I'd seen pulled down the spec, modified it, then updated it. There's a better way!&lt;/p>
&lt;p>&lt;img src="images/patch-1.jpg" alt="Kuberentes Patch API">&lt;/p>
&lt;p>There's a &lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">patch API for Kubernetes resources&lt;/a>. Patching resources is faster and easier than pulling them and updating the spec wholesale. However, the documentation is a little limited.&lt;/p>
&lt;p>After some trial and error I got it working, here's the solution. I thought it might be helpful to share for others!&lt;/p>
&lt;h3 id="the-solution">The Solution&lt;/h3>
&lt;p>I'll start with the solution. If this is all you need, you are good to go. The details of how this works are presented afterwards. In this example I'll update the number of replicas in the &lt;code>my-rc&lt;/code> controller:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">package&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#e6db74">&amp;#34;encoding/json&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">types&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/types&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/kubernetes&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/plugin/pkg/client/auth&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/tools/clientcmd&amp;#34;&lt;/span>
)
&lt;span style="color:#66d9ef">var&lt;/span> (
&lt;span style="color:#75715e">// Leave blank for the default context in your kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">context&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#75715e">// Name of the replication controller to scale, and the desired number of replicas.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">replicationControllerName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;my-rc&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">replicas&lt;/span> = uint32(&lt;span style="color:#ae81ff">3&lt;/span>)
)
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a string.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchStringValue&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a uint32.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchUInt32Value&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientSet&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">Clientset&lt;/span>, &lt;span style="color:#a6e22e">replicasetName&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#a6e22e">scale&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span>) &lt;span style="color:#66d9ef">error&lt;/span> {
&lt;span style="color:#a6e22e">payload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> []&lt;span style="color:#a6e22e">patchUInt32Value&lt;/span>{{
&lt;span style="color:#a6e22e">Op&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Path&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Value&lt;/span>: &lt;span style="color:#a6e22e">scale&lt;/span>,
}}
&lt;span style="color:#a6e22e">payloadBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>)
&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientSet&lt;/span>.
&lt;span style="color:#a6e22e">CoreV1&lt;/span>().
&lt;span style="color:#a6e22e">ReplicationControllers&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).
&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#a6e22e">replicasetName&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">payloadBytes&lt;/span>)
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>() {
&lt;span style="color:#75715e">// Get the local kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to Kubernetes Context %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">context&lt;/span>)
&lt;span style="color:#a6e22e">config&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewNonInteractiveDeferredLoadingClientConfig&lt;/span>(
&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewDefaultClientConfigLoadingRules&lt;/span>(),
&lt;span style="color:#f92672">&amp;amp;&lt;/span>&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">ConfigOverrides&lt;/span>{&lt;span style="color:#a6e22e">CurrentContext&lt;/span>: &lt;span style="color:#a6e22e">context&lt;/span>}).&lt;span style="color:#a6e22e">ClientConfig&lt;/span>()
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Creates the clientset
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Scale our replication controller.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Scaling replication controller %v to %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#a6e22e">err&lt;/span> = &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code is also available in the &lt;a href="https://gist.github.com/dwmkerr/447692c8bba28929ef914239781c4e59">k8s-patch.go&lt;/a> gist.&lt;/p>
&lt;h3 id="the-mechanism">The Mechanism&lt;/h3>
&lt;p>The Kubernetes Patch API supports a few different methods for modifying resources. It is important to be aware that there is not a universally accepted &amp;lsquo;standard&amp;rsquo; approach to representing a &lt;em>change&lt;/em> to a resource in a REST API.&lt;/p>
&lt;p>There are three strategies you can use to patch:&lt;/p>
&lt;ol>
&lt;li>&lt;code>merge&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc7386">JSON Merge Patch Spec (RFC 7386)&lt;/a>&lt;/li>
&lt;li>&lt;code>stragetic&lt;/code>: A strategic merge, which addresses some limitations of the merge patch (noted in &lt;a href="%5Bdocs/devel/api-conventions.md#patch-operations%5D(https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations)">this doc&lt;/a>.&lt;/li>
&lt;li>&lt;code>json&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc6902">JSON Patch Spec (RFC 6902)&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>These are documented in detail at:&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">docs/devel/api-conventions.md#patch-operations&lt;/a>&lt;/p>
&lt;p>The mechanism I've used here is &lt;code>json&lt;/code>, which I think is the clearest to the reader. To use this strategy we need to build a payload describing what we are changing. This might look like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;op&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;value&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">4&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>op&lt;/code> field can be &lt;code>remove&lt;/code>, &lt;code>replace&lt;/code>, &lt;code>add&lt;/code> etc etc (all the details are in the &lt;a href="https://tools.ietf.org/html/rfc6902">RFC 6902)&lt;/a>, or the slightly more readable &lt;a href="jsonpatch.com">jsonpatch.com&lt;/a>). This allows the operation to be very &lt;em>explicit&lt;/em> to the reader, which is helpful. We create a struct which represents an operation on a string or integer (or whatever data type we need), serialize it and pass to the API.&lt;/p>
&lt;p>Under the hood, the Golang client will simply translate this into an HTTP call which will look like something like this:&lt;/p>
&lt;pre>&lt;code>PATCH /api/v1/namespaces/default/replicationcontrollers/app-server-blue HTTP/1.1
Host: 127.0.0.1
Content-Type: application/json-patch+json
Content-Length: 70
[{
&amp;quot;op&amp;quot;: &amp;quot;replace&amp;quot;,
&amp;quot;path&amp;quot;: &amp;quot;/spec/replicas&amp;quot;,
&amp;quot;value&amp;quot;: 4
}]
&lt;/code>&lt;/pre>&lt;p>This corresponds to the documentation on the &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Patch Operations&lt;/a>. Note that the patch operation type is specified in the &lt;code>Content-Type&lt;/code> header.&lt;/p>
&lt;p>Hopefully this'll help you if you need to patch resources, are struggling with the docs and are a Go noob like me! Any tips on how to make the code cleaner or more idomatic would be welcome.&lt;/p>
&lt;p>Thanks to the following articles and issues which helped me unpick this:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://stackoverflow.com/questions/43415728/kubernetes-go-client-patch-example">Stack Overflow: Kubernetes Go Client Patch Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">Kubernetes Docs: Update API Objects in Place Using kubectl patch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Kubernetes Docs: Patch Operations&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>mongo-monitor - a simple CLI to monitor your MongoDB cluster</title><link>https://dwmkerr.com/mongo-monitor-cli/</link><pubDate>Wed, 16 May 2018 20:09:53 +0000</pubDate><guid>https://dwmkerr.com/mongo-monitor-cli/</guid><description>&lt;p>The &lt;code>mongo-monitor&lt;/code> CLI is a lean and simple tool to check the status of a MongoDB server or cluster. The code is on GitHub:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/mongo-monitor">github.com/dwmkerr/mongo-monitor&lt;/a>&lt;/p>
&lt;p>Here's how it looks in action:&lt;/p>
&lt;p>&lt;img src="images/overview.gif" alt="Screenshot: Using the mongo-monitor CLI to monitor a sharded cluster">&lt;/p>
&lt;p>In this animation I am monitoring a simple sharded cluster, and running some example maintenance operations, adding a node to a replicaset, stepping down a primary and shutting down a replicaset node.&lt;/p>
&lt;p>A simple CLI which shows the status in real-time can be very useful to keep open when performing admin, letting you see how your changes affect the cluster as you work on it.&lt;/p>
&lt;h2 id="installing-the-cli">Installing the CLI&lt;/h2>
&lt;p>The CLI is installed with &lt;code>npm&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install -g mongo-monitor
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="connecting-to-a-cluster">Connecting to a Cluster&lt;/h2>
&lt;p>Connect to a cluster by providing a connection string. The tool uses &lt;a href="https://github.com/dwmkerr/mongo-connection-string">&lt;code>mongo-connection-string&lt;/code>&lt;/a> to parse the connection string, so you can be flexible with the input:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Connect to a local instance&lt;/span>
mongo-monitor localhost:27107
&lt;span style="color:#75715e"># Connect to a remote replicaset, authenticated&lt;/span>
mongo-monitor admin:P@sswrd@mdbnode1,mdbnode2,mdbnode3?replicaSet&lt;span style="color:#f92672">=&lt;/span>rs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once a connection is established, the tool will periodically check the status of the cluster. If the cluster is sharded, it will also inspect each individual replicaset.&lt;/p>
&lt;h2 id="replicaset-status">Replicaset Status&lt;/h2>
&lt;p>Here's the kind of output you might get from a replicaset:&lt;/p>
&lt;p>&lt;img src="images/replicaset.jpg" alt="Screenshot: Replicaset Status">&lt;/p>
&lt;p>The name of the replicaset is shown, along with each member. The status of each member is also shown, updating automatically every second.&lt;/p>
&lt;p>This is convenient when administering replicasets, stepping down a master, adding or removing nodes and so on.&lt;/p>
&lt;h2 id="sharded-cluster-status">Sharded Cluster Status&lt;/h2>
&lt;p>When connecting to a sharded cluster, you will get output like this:&lt;/p>
&lt;p>&lt;img src="images/sharded-cluster.jpg" alt="Screenshot: Sharded Cluster Status">&lt;/p>
&lt;p>Each shard is shown, along with the details of the replicaset which make it up.&lt;/p>
&lt;p>Keeping a view like this open is useful when administering sharded clusters, adding or removing shards, desharding, updating the replicasets which make up shards and so on.&lt;/p>
&lt;h2 id="get-involved">Get Involved!&lt;/h2>
&lt;p>If you like the tool, check out the code and feel free to make pull requests with additions! There are a few &lt;a href="https://github.com/dwmkerr/mongo-monitor/issues">issues&lt;/a> on the project already, and there are all sorts of features I'd love to add but haven't had the time, such as:&lt;/p>
&lt;ul>
&lt;li>Being able to see the lag for replicaset members, to see if secondaries are falling behind&lt;/li>
&lt;li>Being able to perform replicaset operations directly from the tool&lt;/li>
&lt;li>Showing the priorities of nodes if they are not the default&lt;/li>
&lt;/ul>
&lt;p>All ideas are welcome, let me know in the comments or repo, and share the tool if you find it useful!&lt;/p></description><category>CodeProject</category></item><item><title>The Death of Microservice Madness in 2018</title><link>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</link><pubDate>Fri, 12 Jan 2018 10:52:25 +0000</pubDate><guid>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</guid><description>&lt;p>&lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">En Español&lt;/a> | &lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit Thread&lt;/a> | &lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News Thread&lt;/a>&lt;/p>
&lt;p>Microservices became a very popular topic over the last couple of years&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. &amp;lsquo;Microservice madness&amp;rsquo; goes something like this:&lt;/p>
&lt;blockquote>
&lt;p>Netflix are great at devops.
Netflix do microservices.
Therefore: If I do microservices, I am great at devops.&lt;/p>
&lt;/blockquote>
&lt;p>There are many cases where great efforts have been made to adopt microservice patterns without necessarily understanding how the costs and benefits will apply to the specifics of the problem at hand.&lt;/p>
&lt;p>I'm going to describe in detail what microservices are, why the pattern is so appealing, and also some of the key challenges that they present.&lt;/p>
&lt;p>I'll finish with a set of simple questions might be valuable to ask yourself when you are considering whether microservices are the right pattern &lt;em>for you&lt;/em>. The questions are at the end of the article.&lt;/p>
&lt;p>&lt;img src="images/letterbox.png" alt="Letterbox sample of diagram">&lt;/p>
&lt;h2 id="what-are-microservices-and-why-are-they-so-popular">What are microservices, and why are they so popular?&lt;/h2>
&lt;p>Let's start with the basics. Here is how a hypothetical video sharing platform might be implemented, first in the form of a monolith (single large unit) and then in the form of microservices:&lt;/p>
&lt;p>&lt;img src="images/video-platform-monolith-microservices.png" alt="Diagram: Comparison of a Video Sharing Platform, Monolith vs Microservice">&lt;/p>
&lt;p>The difference between the two systems is that the first is a single large unit; a monolith. The second is a set of small, specific services. Each service has a specific role.&lt;/p>
&lt;p>When the diagram is drawn &lt;em>at this level of detail&lt;/em>, it is easy to see the appeal. There are a whole host of potential benefits:&lt;/p>
&lt;p>&lt;strong>Independent Development&lt;/strong>: Small, independent components can be built by small, independent teams. A group can work on a change to the &amp;lsquo;Upload&amp;rsquo; service without interfering with the &amp;lsquo;Transcode&amp;rsquo; service, or even knowing about it. The amount of time to learn about a component is greatly reduced, and it is easier to develop new features.&lt;/p>
&lt;p>&lt;strong>Independent Deployment&lt;/strong>: Each individual component can be deployed independently. This allows new features to be released with greater velocity and less risk. Fixes or features for the &amp;lsquo;Streaming&amp;rsquo; component can be deployed without requiring other components to be deployed.&lt;/p>
&lt;p>&lt;strong>Independent Scalability&lt;/strong>: Each component can be scaled independently of each other. During busy periods when new shows are released, the &amp;lsquo;Download&amp;rsquo; component can be scaled up to handle the increased load, without having to scale up every component, which makes elastic scaling more feasible and reduces costs.&lt;/p>
&lt;p>&lt;strong>Reusability&lt;/strong>: Components fulfil a small, specific function. This means that they can more easily be adapted for use in other systems, services or products. The &amp;lsquo;Transcode&amp;rsquo; component could be used by other business units, or even turned into a new business, perhaps offering transcoding services for other groups.&lt;/p>
&lt;p>At this level of detail, the benefits of a microservice model over a monolithic model seem obvious. So if that's the case - why is this pattern only recently in vogue? Where has it been all my life?&lt;/p>
&lt;h2 id="if-this-is-so-great-why-hasnt-it-been-done-before">If this is so great, why hasn't it been done before?&lt;/h2>
&lt;p>There are two answers to this question. One is that &lt;em>it has&lt;/em> - to the best of our technical capabilities, and the other is that more recent technical advances have allowed us to take it to a new level.&lt;/p>
&lt;p>When I started writing the answer to this question, it turned into a &lt;em>long&lt;/em> description, so I'm actually going to separate it into another article and publish it a little later&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. At this stage, I will skip the journey from single program to many programs, ignore ESBs and Service Orientated Architecture, component design and bounded contexts, and so on.&lt;/p>
&lt;p>Those who are interested can read more about the journey separately. Instead I'll say that in many ways we've been doing this for a while, but with the recent explosion in popularity of container technology (Docker in particular) and in orchestration technology (such as Kubernetes, Mesos, Consul and so on) this pattern has become much more viable to implement from a technical standpoint.&lt;/p>
&lt;p>So if we take it as a given that we &lt;em>can&lt;/em> implement a microservice arrangement, we need to think carefully about the &lt;em>should&lt;/em>. We've seen the high-level theoretical benefits, but what about the challenges?&lt;/p>
&lt;h2 id="whats-the-problem-with-microservices">What's the problem with microservices?&lt;/h2>
&lt;p>If microservices are so great, what's the big deal? Here are some of the biggest issues I've seen.&lt;/p>
&lt;p>&lt;strong>Increased complexity for developers&lt;/strong>&lt;/p>
&lt;p>Things &lt;em>can&lt;/em> get a lot harder for developers. In the case where a developer wants to work on a &lt;em>journey&lt;/em>, or feature which might span many services, that developer has to run them all on their machine, or connect to them. This is often more complex than simply running a single program.&lt;/p>
&lt;p>This challenge can be partially mitigated with tooling&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, but as the number of services which makes up a system increases, the more challenges developers will face when running the system as a whole.&lt;/p>
&lt;p>&lt;strong>Increased complexity for operators&lt;/strong>&lt;/p>
&lt;p>For teams who don't develop services, but maintain them, there is an explosion in potential complexity. Instead of perhaps managing a few running services, they are managing dozens, hundreds or thousands of running services. There are more services, more communication paths, and more areas of potential failure.&lt;/p>
&lt;p>&lt;strong>Increased complexity for devops&lt;/strong>&lt;/p>
&lt;p>Reading the two points above, it may grate that operations and development are treated separately, especially given the popularity of devops as a practice (which I am a big proponent of). Doesn't devops mitigate this?&lt;/p>
&lt;p>The challenge is that many organisations still run with separated development and operations teams - and a organisation that does is much more likely to struggle with adoption of microservices.&lt;/p>
&lt;p>For organisations which have adopted devops, it's still hard. Being both a developer and an operator is already tough (but critical to build good software), but having to also understand the nuances of container orchestration systems, particularly systems which are evolving at a rapid pace, is very hard. Which brings me onto the next point.&lt;/p>
&lt;p>&lt;strong>It requires serious expertise&lt;/strong>&lt;/p>
&lt;p>When done by experts, the results can be wonderful. But imagine an organisation where perhaps things are not running smoothly with a single monolithic system. What possible reason would there be that things would be any better by increasing the number of systems, which increases the operational complexity?&lt;/p>
&lt;p>Yes, with effective automation, monitoring, orchestration and so on, this is all possible. But the challenge is rarely the technology - the challenge is finding people who can use it effectively. These skillsets are currently in very high demand, and may be difficult to find.&lt;/p>
&lt;p>&lt;strong>Real world systems often have poorly defined boundaries&lt;/strong>&lt;/p>
&lt;p>In all of the examples we used to describe the benefits of microservices, we spoke about &lt;em>independent&lt;/em> components. However in many cases components are simply not independent. On paper, certain domains may look bounded, but as you get into the muddy details, you may find that they are more challenging to model than you anticipated.&lt;/p>
&lt;p>This is where things can get &lt;em>extremely&lt;/em> complex. If your boundaries are actually not well defined, then what happens is that even though &lt;em>theoretically&lt;/em> services can be deployed in isolation, you find that due to the inter-dependencies between services, you have to deploy &lt;em>sets&lt;/em> of services as a group.&lt;/p>
&lt;p>This then means that you need to manage coherent versions of services which are proven and tested when working together, you don't actually have an independently deployable system, because to deploy a new feature, you need to carefully orchestrate the simultaneous deployment of many services.&lt;/p>
&lt;p>&lt;strong>The complexities of state are often ignored&lt;/strong>&lt;/p>
&lt;p>In the previous example, I mentioned that a feature deployment may require the simultaneous rollout of many versions of many services in tandem. It is tempting to assume that sensible deployment techniques will mitigate this, for example blue/green deployments (which most service orchestration platforms handle with little effort), or multiple versions of a service being run in parallel, with consuming channels deciding which version to use.&lt;/p>
&lt;p>These techniques mitigate a large number of the challenges &lt;em>if the services are stateless&lt;/em>. But stateless services are quite frankly, easy to deal with. In fact, if you have stateless services, then I'd be inclined to consider skipping microservices altogether and consider using a serverless model.&lt;/p>
&lt;p>In reality, many services require state. An example from our video sharing platform might be the subscription service. A new version of the subscriptions service may store data in the subscriptions database in a different shape. If you are running both services in parallel, you are running the system with two schemas at once. If you do a blue green deployment, and other services depend on data in the new shape, then they must be updated &lt;em>at the same time&lt;/em>, and if the subscription service deployment fails and rolls back, they might need to roll back too, with cascading consequences.&lt;/p>
&lt;p>Again, it might be tempting to think that with NoSQL databases these issues of schema go away, but they don't. Databases which don't enforce schema do not lead to schemaless systems - they just mean that schema tends to be managed at the application level, rather than the database level. The fundamental challenge of understanding the shape of your data, and how it evolves, cannot be eliminated.&lt;/p>
&lt;p>&lt;strong>The complexitities of communication are often ignored&lt;/strong>&lt;/p>
&lt;p>As you build a large network of services which depend on each other, the liklihood is that there will be a lot of inter-service communication. This leads to a few challenges. Firstly, there are a lot more points at which things can fail. We must expect that network calls will fail, which means when one service calls another, it should expect to have to retry a number of times at the least. Now when a service has to potentially call many services, we end up in a complicated situation.&lt;/p>
&lt;p>Imagine a user uploads a video in the video sharing service. We might need to run the upload service, pass data to the transcode service, update subscriptions, update recommendations and so on. All of these calls require a degree of orchestration, if things fail we need to retry.&lt;/p>
&lt;p>This retry logic can get hard to manage. Trying to do things synchronously often ends up being untenable, there are too many points of failure. In this case, a more reliable solution is to use asynchronous patterns to handle communication. The challenge here is that asynchronous patterns inherently make a system stateful. As mentioned in the previous point, stateful systems and systems with distributed state are very hard to handle.&lt;/p>
&lt;p>When a microservice system uses message queues for intra-service communication, you essentially have a large database (the message queue or broker) glueing the services together. Again, although it might not seem like a challenge at first, schema will come back to bite you. A service at version X might write a message with a certain format, services which depend on this message will also need to be updated when the sending service changes the details of the message it sends.&lt;/p>
&lt;p>It is possible to have services which can handle messages in many different formats, but this is hard to manage. Now when deploying new versions of services, you will have times where two different versions of a service may be trying to process messages from the same queue, perhaps even messages sent by different versions of a sending service. This can lead to complicated edge cases. To avoid these edge cases, it may be easier to only allow certain versions of messages to exist, meaning that you need to deploy a set of versions of a set of services as a coherent whole, ensuring messages of older versions are drained appropriately first.&lt;/p>
&lt;p>This highlights again that the idea of independent deployments may not hold as expected when you get into the details.&lt;/p>
&lt;p>&lt;strong>Versioning can be hard&lt;/strong>&lt;/p>
&lt;p>To mitigate the challenges mentioned previously, versioning needs to be very carefully managed. Again, there can be a tendency to assume that following a standard such as semver[4] will solve the problem. It doesn't. Semver is a sensible convention to use, but you will still have to track the versions of services and APIs which can work together.&lt;/p>
&lt;p>This can get very challenging very quickly, and may get to the point where you don't know which versions of services will actually work properly together.&lt;/p>
&lt;p>Managing dependencies in software systems is notoriously hard, whether it is node modules, Java modules, C libraries or whatever. The challenges of &lt;em>conflicts between independent components&lt;/em> when consumed by a single entity are very hard to deal with.&lt;/p>
&lt;p>These challenges are hard to deal with when the dependencies are static, and can be patched, updated, edited and so on, but if the dependencies are themselves &lt;em>live services&lt;/em>, then you may not be able to just update them - you may have to run many versions (with the challenges already described) or bring down the system until it is fixed holistically.&lt;/p>
&lt;p>&lt;strong>Distributed Transactions&lt;/strong>&lt;/p>
&lt;p>In situations where you need transaction integrity across an operation, microservices can be very painful. Distributed state is hard to deal with, many small units which can fail make orchestrating transactions very hard.&lt;/p>
&lt;p>It may be tempting to attempt to avoid the problem by making operations idempotent, offering retry mechanisms and so on, and in many cases this might work. But you may have scenarios where you simply need a transaction to fail or succeed, and never be in an intermediate state. The effort involved in working around this or implementing it in a microservice model may be very high.&lt;/p>
&lt;p>&lt;strong>Microservices can be monoliths in disguise&lt;/strong>&lt;/p>
&lt;p>Yes, individual services and components &lt;em>may&lt;/em> be deployed in isolation, however in most cases you are going to have to be running some kind of orchestration platform, such as Kubernetes. If you are using a managed service, such as Google's GKE&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> or Amazon's EKS&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>, then a large amount of the complexity of managing the cluster is handled for you.&lt;/p>
&lt;p>However, if you are managing the cluster yourself, you are managing a large, complicated, mission critical system. Although the individual services may have all of the benefits described earlier, you need to very carefully manage your cluster. Deployments of this system can be hard, updates can be hard, failover can be hard and so on.&lt;/p>
&lt;p>In many cases the overall benefits are still there, but it is important not to trivialise or underestimate the additional complexity of managing another big, complex system. Managed services may help, but in many cases these services are nascent (Amazon EKS was only announced at the end of 2017 for example).&lt;/p>
&lt;p>&lt;strong>Networking Nightmares&lt;/strong>&lt;/p>
&lt;p>A more traditional model of services running on known hosts, with known addresses, has a fairly simple networking setup.&lt;/p>
&lt;p>However, when using microservices, generally there will be many services distributed across many nodes, which typically means there's going to be a &lt;em>much&lt;/em> more complicated networking arrangement. There will be load balancing between services, DNS may be more heavily used, virtual networking layers, etc etc, to attempt to &amp;lsquo;hide&amp;rsquo; the complexity of this networking.&lt;/p>
&lt;p>However, as per &lt;a href="https://github.com/dwmkerr/hacker-laws/#the-law-of-conservation-of-complexity-teslers-law">Tesler's Law&lt;/a> (or the Law of Conservation of Compexlity), this networking complexity is inherent - when you are finding real, runtime issues in larger scale clusters, it can often be at a very low networking level. These sorts of issues can be &lt;em>very&lt;/em> hard to diagnose. I have started tracking some examples at the end of the article, but I think that &lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Migration to Kuberenetes&lt;/a> shows this challenge very well.&lt;/p>
&lt;p>Overall - the transition is still likely to be for the best, but doesn't come without some serious challenges at the networking level, which will require some serious expertise to deal with!&lt;/p>
&lt;h2 id="the-death-of-microservice-madness">The Death of Microservice Madness!&lt;/h2>
&lt;p>Avoid the madness by making careful and considered decisions. To help out on this I've noted a few questions you might want to ask yourself, and what the answers might indicate:&lt;/p>
&lt;p>&lt;img src="images/questions.png" alt="Diagram: Questions to ask yourself when considering microservices">&lt;/p>
&lt;p>You can download a PDF copy here: &lt;a href="https://github.com/dwmkerr/blog/blob/master/articles/2018/microservice-madness/images/microservice-questions.pdf">microservice-questions.pdf&lt;/a>&lt;/p>
&lt;h2 id="final-thoughts-dont-confuse-microservices-with-architecture">Final Thoughts: Don't Confuse Microservices with Architecture&lt;/h2>
&lt;p>I've deliberately avoided the &amp;lsquo;a&amp;rsquo; word in this article. But my friend &lt;a href="http://twitter.com/zoltanarvai">Zoltan&lt;/a> made a very good point when proofing this article (which he has contributed to).&lt;/p>
&lt;p>There is no microservice architecture. Microservices are just another pattern or implementation of components, nothing more, nothing less. Whether they are present in a system or not does not mean that the architecture of the system is solved.&lt;/p>
&lt;p>Microservices relate in many ways more to the technical processes around packaging and operations rather than the intrinsic design of the system. Appropriate boundaries for components continues to be one of the most important challenges in engineering systems.&lt;/p>
&lt;p>Regardless of the size of your services, whether they are in Docker containers or not, you will always need to think carefully about how to put a system together. There are no right answers, and there are a &lt;em>lot&lt;/em> of options.&lt;/p>
&lt;p>I hope you found this article interesting! As always, please do comment below if you have any questions or thoughts. You can also follow some lively discussions on:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="appendix-further-reading">Appendix: Further Reading&lt;/h2>
&lt;p>The following links might be of interest:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://martinfowler.com/bliki/BoundedContext.html">Martin Fowler - Bounded Context&lt;/a> - Martin's articles are great, I'd thoroughly recommend this.&lt;/li>
&lt;li>&lt;a href="https://martinfowler.com/articles/microservices.html">Martin Fowler - Microservices&lt;/a> - An often recommended introduction to the pattern.&lt;/li>
&lt;li>&lt;a href="https://r2m.se/microservices-good-or-bad/">Microservices - Good or Bad?&lt;/a> - Björn Frantzén's thoughts on microservices, after reading this article.&lt;/li>
&lt;li>&lt;a href="http://blog.christianposta.com/microservices/when-not-to-do-microservices/">When Not To Do Microservices&lt;/a> - Excellent post on the topic from Christian Posta&lt;/li>
&lt;li>&lt;a href="http://www.iheavy.com/2017/03/13/30-questions-to-ask-a-serverless-fanboy/">Sean Hull - 30 questions to ask a serverless fanboy&lt;/a> - Interesting thoughts on the challenges of serverless, from a serverless fan!&lt;/li>
&lt;li>&lt;a href="https://youtu.be/NVb7aljfKYo?t=6657">Dave Kerr - Monoliths to Microservices - Practical tips for CI/CD and DevOps in the Microservice world&lt;/a> - A recent conference presentation I did on devops with microservices.&lt;/li>
&lt;li>&lt;a href="https://yermakov.net/microservices-without-fundamentals/">Alexander Yermakov - Microservices without fundamentals&lt;/a> - A response to this article, with Alex's thoughts and counterpoints to the points raised here (see also &lt;a href="https://yermakov.net/microservices-as-a-self-sufficient-concept/">Microservices as a self sufficient concept&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>Please do share anything else you think makes great reading or watching on the topic!&lt;/p>
&lt;hr>
&lt;h2 id="thanks">Thanks&lt;/h2>
&lt;p>Thanks José from &lt;a href="https://www.campusmvp.es">campusmvp.es&lt;/a> for having the article translated in Spanish - &lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">La muerte de la locura de los microservicios en 2018&lt;/a>!&lt;/p>
&lt;h2 id="case-studies">Case Studies&lt;/h2>
&lt;p>Some interesting examples of experiences I am collecting of larger organisations who have made large scale transitions to microservices:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Move to Kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="references">References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice">https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If you don't want to miss the article, you can subscribe to the &lt;a href="http://www.dwmkerr.com/rss/">RSS Feed&lt;/a>, or follow me on &lt;a href="https://www.linkedin.com/in/dwmkerr/">LinkedIn&lt;/a> or &lt;a href="https://twitter.com/dwmkerr">Twitter&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Docker Compose is a good solution, &lt;a href="https://github.com/apparatus/fuge">Fuge&lt;/a> is very clever, and there is also the option of running orchestration locally as is the case with something like MiniKube. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Google Kubernetes Engine, a managed service from Google Cloud Platform for Kubernetes: &lt;a href="https://cloud.google.com/kubernetes-engine/">https://cloud.google.com/kubernetes-engine/&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Amazon Elastic Container Services for Kubernetes, a managed service from Amazon Web Services for Kubernetes: &lt;a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/&lt;/a> &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Simple Continuous Integration for Docker Images</title><link>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</link><pubDate>Thu, 03 Nov 2016 05:14:35 +0000</pubDate><guid>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</guid><description>&lt;p>In this article I'm going to demonstrate a few tips and tricks which can make your life easier when you are building or maintaining Dockerfiles.&lt;/p>
&lt;h2 id="the-need-for-a-build-pipeline">The need for a Build Pipeline&lt;/h2>
&lt;p>Do we really need any kind of continuous integration or build pipeline for Dockerfiles?&lt;/p>
&lt;p>There will be cases when the answer is no. However, if the answer to any of the following questions is &amp;lsquo;yes&amp;rsquo;, it might be worth considering:&lt;/p>
&lt;ol>
&lt;li>Do you want others to be able to contribute to the Dockerfile, perhaps changing the image over time?&lt;/li>
&lt;li>Are there specific functionalities in your Dockerfiles which could break if altered?&lt;/li>
&lt;li>Do you expect to need to release updates to your Dockerfile?&lt;/li>
&lt;/ol>
&lt;p>Essentially, if we are looking at providing some kind of automated quality assurance and automation around building and releasing, then a build pipeline is not a bad idea.&lt;/p>
&lt;h2 id="a-simple-build-pipeline">A simple Build Pipeline&lt;/h2>
&lt;p>Here's what a simple build pipeline could look like. This example is for a Docker Image I just created for local DynamoDB development - &lt;a href="https://github.com/dwmkerr/docker-dynamodb">dwmkerr/docker-dynamodb&lt;/a>:&lt;/p>
&lt;p>&lt;img src="images/Simple-Docker-Image-CI.png" alt="Simple Continous Intergration Pipeline">&lt;/p>
&lt;p>Let's dissect what we've got here.&lt;/p>
&lt;h3 id="the-dockerfile">The Dockerfile&lt;/h3>
&lt;p>This is the main &amp;lsquo;code&amp;rsquo; of the project if you like. The &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/Dockerfile">Dockerfile&lt;/a> is the recipe for the image we create.&lt;/p>
&lt;h3 id="the-continuous-integration-service">The Continuous Integration Service&lt;/h3>
&lt;p>In this case, I am using &lt;a href="https://circleci.com/">CircleCI&lt;/a>, however the approach described would work fine with most CI systems (such as Jenkins, TravisCI and TeamCity). There &lt;em>is&lt;/em> an option to use the &lt;a href="https://docs.docker.com/docker-hub/builds/">Docker Hub Automated Builds&lt;/a>, but I've found this doesn't give the flexibility I need (see &lt;a href="#appendix1whynotdockerhubautomatedbuilds">Why not Docker Hub Automated Builds&lt;/a>).&lt;/p>
&lt;p>Essentially the CI service needs to offer the option to have three distinct steps in the pipeline, each of which must pass for process to proceed:&lt;/p>
&lt;ol>
&lt;li>Build&lt;/li>
&lt;li>Test&lt;/li>
&lt;li>Deploy&lt;/li>
&lt;/ol>
&lt;h3 id="the-build">The Build&lt;/h3>
&lt;p>We can build with tools, script files, whatever. At the moment, I am leaning towards &lt;a href="https://www.gnu.org/software/make/">makefiles&lt;/a>. Normally I only need a few lines of shell script to do a build - anything more complex and the makefile can call a shell script. See also &lt;a href="#appendix2whymakefiles">Why Makefiles?&lt;/a>&lt;/p>
&lt;p>Here's what it might look like:&lt;/p>
&lt;pre>&lt;code>build:
docker build -t dwmkerr/dynamodb:latest .
ifndef BUILD_NUM
$(warning No build number is defined, skipping build number tag.)
else
docker build -t dwmkerr/dynamodb:$(BUILD_NUM) .
endif
&lt;/code>&lt;/pre>&lt;p>This command just builds the &lt;code>Dockerfile&lt;/code> and tags it as &lt;code>dwmkerr/dynamodb:lastest&lt;/code>. If a &lt;code>BUILD_NUM&lt;/code> variable is present, we also create the tag &lt;code>dwmkerr/dynamodb:BUILD_NUM&lt;/code>. This means if we want to deploy to a service such as &lt;a href="https://aws.amazon.com/ecs/">Amazon ECS&lt;/a> we can push a specific build by referring to the image with that tag.&lt;/p>
&lt;h3 id="the-tests">The Tests&lt;/h3>
&lt;p>Again I'm relying on &lt;code>make&lt;/code>. I just want to be able to run &lt;code>make test&lt;/code> - if zero is returned I'm happy. If not, the pipeline should stop and I'll check the output. Here's my test command:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>Not a thing of beauty, but it works. These scripts I'll discuss a little bit later on, in the delightly titled &lt;a href="#appendix3whatarethesetestscripts">What are these test scripts&lt;/a> section.&lt;/p>
&lt;p>For CircleCI, this is enough to have the main part of our pipeline. Here's how the &lt;code>circle.yml&lt;/code> file looks at this stage:&lt;/p>
&lt;pre>&lt;code>machine:
services:
- docker
environment:
# Set the build number, used in makefiles.
BUILD_NUM: $CIRCLE_BUILD_NUM
test:
override:
- make test
&lt;/code>&lt;/pre>&lt;p>(Actually there's a couple of other bits but they're just to make sure circle uses the right version of Docker, &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/circle.yml">see the full circle.yml file here&lt;/a>).&lt;/p>
&lt;h3 id="the-deployments">The Deployments&lt;/h3>
&lt;p>Deployments are trivial as all we need to do is push to the Docker Hub. The &lt;code>make deploy&lt;/code> command looks-a like this:&lt;/p>
&lt;pre>&lt;code>deploy:
docker push dwmkerr/dynamodb:latest
ifndef BUILD_NUM
$(warning No build number is defined, skipping push of build number tag.)
else
docker push dwmkerr/dynamodb:$(BUILD_NUM)
endif
&lt;/code>&lt;/pre>&lt;p>We're pushing the &lt;code>latest&lt;/code> tag and &lt;code>BUILD_NUM&lt;/code> tag if present. To add this to the CircleCI pipeline, we just add the following to &lt;code>circle.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>deployment:
master:
branch: master
commands:
- docker login -e $DOCKER_EMAIL -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
- make deploy
&lt;/code>&lt;/pre>&lt;p>If we have a push to &lt;code>master&lt;/code>, we log in to Docker (using environment variables I configure in the CircleCI UI) and then run &lt;code>make deploy&lt;/code> to push our images.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>That's about it. This is a pretty simple approach, you can see it in action at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/docker-dynamodb">github.com/dwmkerr/docker-dynamodb&lt;/a>&lt;/p>
&lt;p>The rest of this post is a bit of a deep dive into some specific areas I found interesting.&lt;/p>
&lt;h2 id="appendix-1-why-not-docker-hub-automated-builds">Appendix 1: Why not Docker Hub Automated Builds?&lt;/h2>
&lt;p>There are automated builds available in the Docker Hub:&lt;/p>
&lt;p>&lt;img src="images/dockerhubbuilds.png" alt="Docker Hub Automated Builds">&lt;/p>
&lt;p>I'm not using this feauture at the moment, here's a brief roundup of what I think are the current pros and cons:&lt;/p>
&lt;p>Pros&lt;/p>
&lt;ul>
&lt;li>You don't have to goof around installing Docker on a CI platform.&lt;/li>
&lt;li>It allows you to update the description of your Docker image automatically, from the GitHub &lt;code>README.md&lt;/code>.&lt;/li>
&lt;li>It allows you to associate the image with a specific GitHub repo (rather than just linking from the image description).&lt;/li>
&lt;li>Branch management - allowing tags to be built for specific branches.&lt;/li>
&lt;/ul>
&lt;p>Cons&lt;/p>
&lt;ul>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of configurable gating, such as a running a test command prior to deploying.&lt;/li>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of triggering of downstream processes, such as updating environments, sending notifications or whatever.&lt;/li>
&lt;/ul>
&lt;p>The lack of ability to perform tests on the image before deploying it why I'm currently not using the service.&lt;/p>
&lt;p>By doing the testing in a CI system for every pull request and only merging PRs where the tests pass we could mitigate the risk here. This service is worth watching as I'm sure it will evolve quickly.&lt;/p>
&lt;h2 id="appendix-2-why-makefiles">Appendix 2: Why Makefiles?&lt;/h2>
&lt;p>I started coding with a commandline compiler in DOS. When I used my first GUI (Borland Turbo C++) it felt like a huge leap:&lt;/p>
&lt;p>&lt;img src="images/turbocpp.png" alt="Borland Turbo C++">&lt;/p>
&lt;p>Later on I moved onto Microsoft Visual C++ 4.2:&lt;/p>
&lt;p>&lt;img src="images/visualcpp.png" alt="Visual C++ 4.2">&lt;/p>
&lt;p>And you cannot imagine the excitement when I got my boxed edition of Visual Studio .NET:&lt;/p>
&lt;p>&lt;img src="images/visualstudiodotnet.jpg" alt="Visual Studio .NET">&lt;/p>
&lt;p>Wow!&lt;/p>
&lt;p>Anyway, I digress. GNU &lt;code>make&lt;/code> was invented by Leonardo Da Vinci in 1473 to allow you to build something from the commandline, using a fairly consistent syntax.&lt;/p>
&lt;p>It is near ubiquitous on *nix systems. I am increasingly using it as an &amp;lsquo;entry point&amp;rsquo; to builds, as I use variety of languages and platforms. Being able to know that most of the time:&lt;/p>
&lt;pre>&lt;code>make build
make test
&lt;/code>&lt;/pre>&lt;p>Will build and test something is convenient. Makefiles actually are not that great to work with (see &lt;a href="http://stackoverflow.com/questions/448910/makefile-variable-assignment">this&lt;/a>, &lt;a href="http://stackoverflow.com/questions/10121182/multiline-bash-commands-in-makefile">this&lt;/a> and &lt;a href="http://www.conifersystems.com/whitepapers/gnu-make/">this&lt;/a>). I've found as long as you keep the commands simple, they're OK. For anything really complex, I normally have a &lt;code>scripts/&lt;/code> folder, but call the scripts &lt;em>from&lt;/em> the makefile, so that there's still a simple entrypoint.&lt;/p>
&lt;p>I'm not entirely sold on makefiles, but they tend to be my default at the moment if I know I'm going to use the commandline for builds (for example, in Java projects I'll often write a makefile to call Maven or Gradle).&lt;/p>
&lt;p>For things like Node.js, where you have commands like &lt;code>npm test&lt;/code> or &lt;code>npm run xyz&lt;/code> I &lt;em>still&lt;/em> sometimes use makefiles, using &lt;code>npm&lt;/code> for day-to-day dev tests (&lt;code>npm start&lt;/code>) and &lt;code>make&lt;/code> if it's something more complex (e.g. &lt;code>make deploy-sit&lt;/code> to deploy to an SIT environment).&lt;/p>
&lt;h2 id="appendix-3-what-are-these-test-scripts">Appendix 3: What are these test scripts?&lt;/h2>
&lt;p>You may have noticed:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>What's going on here?&lt;/p>
&lt;p>My Docker image is just a wrapper around &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">Amazon's Local DynamoDB tool&lt;/a>. I don't really need to test that tool. But what I wanted to test was the capabilities which lie at the &lt;em>intersection&lt;/em> between &amp;lsquo;native&amp;rsquo; Docker and &amp;lsquo;native&amp;rsquo; DynamoDB.&lt;/p>
&lt;p>For example, I know Docker supports volume mapping. I know DynamoDB supports using a data directory, to allow persistent between runs. I want to test I can combine Docker volume mapping and the DynamoDB data directory features. I know Docker images should default to being ephemeral, I want to test this holds true by default for my image.&lt;/p>
&lt;p>Testing Docker is a little hard - I want to test that I can run containers, start, stop, check state before and after and so on. This is essentially an integration test, it can be tricky to make it truly isolated and deterministic.&lt;/p>
&lt;p>I've given it my best go with these scripts. Here's an example for the &amp;lsquo;ephemeral&amp;rsquo; test, where I'm trying to assert that if I run a container, create a table, stop the container and run a new one, I no longer have the table. Here's the test:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Bomb if anything fails.&lt;/span>
set -e
&lt;span style="color:#75715e"># Kill any running dynamodb containers.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Cleaning up old containers...&amp;#34;&lt;/span>
docker ps -a | grep dwmkerr/dynamodb | awk &lt;span style="color:#e6db74">&amp;#39;{print $1}&amp;#39;&lt;/span> | xargs docker rm -f &lt;span style="color:#f92672">||&lt;/span> true
&lt;span style="color:#75715e"># Run the container.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Checking we can run the container...&amp;#34;&lt;/span>
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># Create a table.&lt;/span>
aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> create-table &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --table-name Supervillains &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --attribute-definitions AttributeName&lt;span style="color:#f92672">=&lt;/span>name,AttributeType&lt;span style="color:#f92672">=&lt;/span>S &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --key-schema AttributeName&lt;span style="color:#f92672">=&lt;/span>name,KeyType&lt;span style="color:#f92672">=&lt;/span>HASH &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --provisioned-throughput ReadCapacityUnits&lt;span style="color:#f92672">=&lt;/span>1,WriteCapacityUnits&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Clean up the container. On CircleCI the FS is BTRFS, so this might fail...&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Stopping and restarting...&amp;#34;&lt;/span>
docker stop $ID &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm $ID &lt;span style="color:#f92672">||&lt;/span> true
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># List the tables - there shouldn&amp;#39;t be any!&lt;/span>
COUNT&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> list-tables &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | jq &lt;span style="color:#e6db74">&amp;#39;.TableNames | length&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> $COUNT -ne &lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Expected to find no tables, found &lt;/span>$COUNT&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>It's a bit dirty - it removes containers from the host, changes things and so on. But it works.&lt;/p>
&lt;p>I did experiment with running these tests &lt;em>in a container&lt;/em>, which has the benefit of giving you a clean host to start with, which you can throw away after each test.&lt;/p>
&lt;p>I had to give up after a little while due to time constraints, but will probably revisit this process. The benefits of running these integration tests in a container is that we get a degree of isolation from the host.&lt;/p>
&lt;p>If anyone is interested, my attempts so far are on this &lt;a href="https://github.com/dwmkerr/docker-dynamodb/pull/2">RFC Pull Request&lt;/a>. Feel free to jump in!&lt;/p></description><category>CodeProject</category></item><item><title>Learn Docker by building a Microservice</title><link>https://dwmkerr.com/learn-docker-by-building-a-microservice/</link><pubDate>Tue, 19 Apr 2016 08:54:39 +0000</pubDate><guid>https://dwmkerr.com/learn-docker-by-building-a-microservice/</guid><description>&lt;p>If you are looking to get your hands dirty and learn all about &lt;a href="https://docker.com">Docker&lt;/a>, then look no further!&lt;/p>
&lt;p>In this article I'm going to show you how Docker works, what all the fuss is about, and how Docker can help with a basic development task - building a microservice.&lt;/p>
&lt;p>We'll use a simple Node.js service with a MySQL backend as an example, going from code running locally to containers running a microservice and database.&lt;/p>
&lt;p align="center">
&lt;img src="images/Article.png" />
&lt;/p>
&lt;p>Once you've read the article, you can find the source code here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h2 id="what-is-docker">What is Docker?&lt;/h2>
&lt;p>At its heart, Docker is software which lets you create an &lt;em>image&lt;/em> (which is a lot like a template for a virtual machine) and then run instances of that image in a &lt;em>container&lt;/em>.&lt;/p>
&lt;p>Docker maintains a vast repository of images, called the &lt;a href="https://hub.docker.com">Docker Hub&lt;/a> which you can use as starting points or as free storage for your own images. You can install Docker, choose an image you'd like to use, then run an instance of it in a container.&lt;/p>
&lt;p>We're going to build images, create containers from images and more in this article.&lt;/p>
&lt;h3 id="install-docker">Install Docker&lt;/h3>
&lt;p>To follow along and use this article, you'll need Docker.&lt;/p>
&lt;p>Check the installation guide for your platform, &lt;a href="https://docs.docker.com/engine/installation/">docs.docker.com/engine/installation&lt;/a>.&lt;/p>
&lt;p>If you are on Mac or Windows, consider using a Virtual Machine. I use Parallels on Mac OS X to run an Ubuntu machine for most development activities. Being able to take snapshots, break things and then revert back is very handy when experimenting.&lt;/p>
&lt;h3 id="try-it-out">Try It Out&lt;/h3>
&lt;p>Enter this command:&lt;/p>
&lt;pre>&lt;code>docker run -it ubuntu
&lt;/code>&lt;/pre>&lt;p>After a bit of spinning, you'll see a prompt like this:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/#
&lt;/code>&lt;/pre>&lt;p>Try out a few commands and then exit the container:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/# lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 14.04.4 LTS
Release: 14.04
Codename: trusty
root@719059da250d:/# exit
&lt;/code>&lt;/pre>&lt;p>This doesn't look like much, but a lot has happened!&lt;/p>
&lt;p>What you are seeing is the bash shell of an &lt;em>isolated&lt;/em> container running Ubuntu, on your machine. It's yours to place with - you can install things on it, run software, whatever you want.&lt;/p>
&lt;p>Here's a diagram and breakdown of what just happened (the digram is from the &lt;a href="https://docs.docker.com/v1.8/introduction/understanding-docker/">&amp;lsquo;Understanding the Architecture&amp;rsquo; Docker Documentation&lt;/a>, which is great):&lt;/p>
&lt;p>&lt;img src="images/Flow.png" alt="Docker Run Flow">&lt;/p>
&lt;ol>
&lt;li>We issue a docker command:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;code>docker&lt;/code>: run the docker client&lt;/li>
&lt;li>&lt;code>run&lt;/code>: the command to run a new container&lt;/li>
&lt;li>&lt;code>-it&lt;/code>: option to give the container an interactive terminal&lt;/li>
&lt;li>&lt;code>ubuntu&lt;/code>: the image to base the container on&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>The docker service running on the host (our machine) checks to see if we have a copy of the requested image locally- which there isn't.&lt;/li>
&lt;li>The docker service checks the public registry (the docker hub) to see if there's an image named &lt;code>ubuntu&lt;/code> available- which there is.&lt;/li>
&lt;li>The docker service downloads the image and stores it in its local cache of images (ready for next time).&lt;/li>
&lt;li>The docker service creates a new container, based on the &lt;code>ubuntu&lt;/code> image.&lt;/li>
&lt;/ol>
&lt;p>Try any of these:&lt;/p>
&lt;pre>&lt;code>docker run -it haskell
docker run -it java
docker run -it python
&lt;/code>&lt;/pre>&lt;p>We're not going to use &lt;a href="https://xkcd.com/1312/">Haskell&lt;/a> today, but you can see, running an environment is very easy.&lt;/p>
&lt;p>It's a snap to build images of our own, with our apps or services on them, databases, whatever we need. We can then run them on any machine with Docker installed - and the image will run in the same, predictable way. We can build our software &lt;em>and the environment it runs on&lt;/em> as code and deploy easily.&lt;/p>
&lt;p>Let's look into a simple microservice as an example.&lt;/p>
&lt;h2 id="the-brief">The Brief&lt;/h2>
&lt;p>We're going to build a microservice which lets us manage a directory of email addresses to phone numbers, using Node.js and MySQL.&lt;/p>
&lt;h2 id="getting-started">Getting Started&lt;/h2>
&lt;p>For doing local development we'll need to install MySQL and create a test database for us to&amp;hellip;&lt;/p>
&lt;p>&amp;hellip;nope.&lt;/p>
&lt;p>Creating a local database and running scripts on it is an easy start, but can get messy. Lots of uncontrolled stuff going on. It might work, we could even control it with some shell scripts checked in to our repo, but what if other developers already have MySQL installed? What if they have a database already with the creative name &amp;lsquo;users&amp;rsquo; which we want to create?&lt;/p>
&lt;h3 id="step-1-creating-a-test-database-server---in-docker">Step 1: Creating a Test Database Server - in Docker&lt;/h3>
&lt;p>This is a great Docker use case. We might not want to run our production database in Docker (perhaps we'll just use Amazon RDS for example), but we can spin up a clean MySQL database in no time as a Docker container for development - leaving our development machine clean and keeping everything we do controlled and repeatable.&lt;/p>
&lt;p>Run the following command:&lt;/p>
&lt;pre>&lt;code>docker run --name db -d -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 mysql:latest
&lt;/code>&lt;/pre>&lt;p>This starts a MySQL instance running, allowing access through port 3306 using the root password 123.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> tells the engine we want to run an image (the image comes at the end, &lt;a href="https://hub.docker.com/_/mysql/">mysql:vlatest&lt;/a>&lt;/li>
&lt;li>&lt;code>--name db&lt;/code> names this container &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-d&lt;/code> (or &lt;code>--detach&lt;/code>) detach - i.e. run the container in the background.&lt;/li>
&lt;li>&lt;code>-e MYSQL_ROOT_PASSWORD=123&lt;/code> (or &lt;code>--env&lt;/code>) environment variables - tells docker we want to provide an environment variable. The variable following it is what the MySQL image checks for setting the default root password.&lt;/li>
&lt;li>&lt;code>-p 3306:3306&lt;/code> (or &lt;code>--publish&lt;/code> tells the engine that we want to map the port 3306 from inside the container to out port 3306.&lt;/li>
&lt;/ol>
&lt;p>The last part is really important - even though that's the MySQL default port, if we don't tell docker explicitly we want to map it, it will block access through that port (because containers are isolated until you tell them you want access).&lt;/p>
&lt;p>The return value of this function is the &lt;em>container id&lt;/em>, a reference to the container which you can use to stop it, restart it, issue commands on it and so on. Let's see which containers are running:&lt;/p>
&lt;pre>&lt;code>$ docker ps
CONTAINER ID IMAGE ... NAMES
36e68b966fd0 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>The key information is the container ID, image and name. Let's connect to this image and see what's there:&lt;/p>
&lt;pre>&lt;code>$ docker exec -it db /bin/bash
root@36e68b966fd0:/# mysql -uroot -p123
mysql&amp;gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
+--------------------+
1 rows in set (0.01 sec)
mysql&amp;gt; exit
Bye
root@36e68b966fd0:/# exit
&lt;/code>&lt;/pre>&lt;p>This is pretty clever too:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker exec -it db&lt;/code> tells docker we want to execute a command on the container named &lt;code>db&lt;/code> (we could also use the id, or just the first few letters of the id). &lt;code>-it&lt;/code> ensures we have an interactive terminal.&lt;/li>
&lt;li>&lt;code>mysql -uroot -p123&lt;/code> the command we actually run as a process in the container, which in this case is just the mysql client.&lt;/li>
&lt;/ol>
&lt;p>We can create databases, tables, users, whatever we need.&lt;/p>
&lt;h3 id="wrapping-up-the-test-database">Wrapping up the Test Database&lt;/h3>
&lt;p>Running MySQL inside a container has already introduced a few Docker tricks, but let's pause here and move onto the service. For now, we'll have create a &lt;code>test-database&lt;/code> folder with a script to start the database, stop the database and setup test data:&lt;/p>
&lt;pre>&lt;code>test-database\setup.sql
test-database\start.sh
test-database\stop.sh
&lt;/code>&lt;/pre>&lt;p>Start is simple:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Run the MySQL container, with a database named &amp;#39;users&amp;#39; and credentials&lt;/span>
&lt;span style="color:#75715e"># for a users-service user which can access it.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Starting DB...&amp;#34;&lt;/span>
docker run --name db -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_ROOT_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_DATABASE&lt;span style="color:#f92672">=&lt;/span>users -e MYSQL_USER&lt;span style="color:#f92672">=&lt;/span>users_service -e MYSQL_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -p 3306:3306 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> mysql:latest
&lt;span style="color:#75715e"># Wait for the database service to start up.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Waiting for DB to start up...&amp;#34;&lt;/span>
docker exec db mysqladmin --silent --wait&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">30&lt;/span> -uusers_service -p123 ping &lt;span style="color:#f92672">||&lt;/span> exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Run the setup script.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Setting up initial data...&amp;#34;&lt;/span>
docker exec -i db mysql -uusers_service -p123 users &amp;lt; setup.sql
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This script runs the database image in a detached container (i.e. in the background), with a user set up to access a &lt;code>users&lt;/code> database, then waits for the database server to start up, then runs a &lt;code>setup.sql&lt;/code> script to set initial data.&lt;/p>
&lt;p>&lt;code>setup.sql&lt;/code> is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">
&lt;span style="color:#66d9ef">create&lt;/span> &lt;span style="color:#66d9ef">table&lt;/span> directory (user_id INT &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> AUTO_INCREMENT &lt;span style="color:#66d9ef">PRIMARY&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span>, email TEXT, phone_number TEXT);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">homer@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1111&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">marge@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1112&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">maggie@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1113&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">lisa@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1114&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">bart@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1115&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>stop.sh&lt;/code> script will stop the container and remove it (containers are left around by docker by default so that they can be restared quickly, we don't really need that feature for this example):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Stop the db and remove the container.&lt;/span>
docker stop db &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm db
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We're going to make this even more slick later on, simplifying this further. Check the code at this stage by looking at the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step1">step1&lt;/a> branch of the repo.&lt;/p>
&lt;h3 id="step-2-creating-a-microservice-in-nodejs">Step 2: Creating a Microservice in Node.js&lt;/h3>
&lt;p>This article is really focused on learning Docker, so I'm not going to spend ages on the Node.js microservice. Instead, I'll highlight the areas and takeaways.&lt;/p>
&lt;pre>&lt;code>test-database/ # contains the code seen in Step 1
users-service/ # root of our node.js microservice
- package.json # dependencies, metadata
- index.js # main entrypoint of the app
- api/ # our apis and api tests
- config/ # config for the app
- repository/ # abstraction over our db
- server/ # server setup code
&lt;/code>&lt;/pre>&lt;p>Let's take this apart bit by bit. The first section to look at is &lt;code>repository&lt;/code>. It can be useful to wrap your database access in some kind of class or abstraction, to allow to mock it for testing purposes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// repository.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Exposes a single function - &amp;#39;connect&amp;#39;, which returns
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// a connected repository. Call &amp;#39;disconnect&amp;#39; on this object when you&amp;#39;re done.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">mysql&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;mysql&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Class which holds an open connection to a repository
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// and exposes some simple functions for accessing data.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span> {
&lt;span style="color:#a6e22e">constructor&lt;/span>(&lt;span style="color:#a6e22e">connection&lt;/span>) {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">connection&lt;/span>;
}
&lt;span style="color:#a6e22e">getUsers&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the users: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#a6e22e">resolve&lt;/span>((&lt;span style="color:#a6e22e">results&lt;/span> &lt;span style="color:#f92672">||&lt;/span> []).&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
});
});
}
&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Fetch the customer.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory WHERE email = ?&amp;#39;&lt;/span>, [&lt;span style="color:#a6e22e">email&lt;/span>], (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the user: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">results&lt;/span>.&lt;span style="color:#a6e22e">length&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">undefined&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">resolve&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
});
});
}
&lt;span style="color:#a6e22e">disconnect&lt;/span>() {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">end&lt;/span>();
}
}
&lt;span style="color:#75715e">// One and only exported function, returns a connected repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">connectionSettings&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A host must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A user must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A password must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A port must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span>(&lt;span style="color:#a6e22e">mysql&lt;/span>.&lt;span style="color:#a6e22e">createConnection&lt;/span>(&lt;span style="color:#a6e22e">connectionSettings&lt;/span>)));
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's probably a lot of better ways to do this! But basically we can create a &lt;code>Repository&lt;/code> object like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;127.0.0.1&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users_service&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;123&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>);
});
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;homer@thesimpsons.com&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">user&lt;/span>);
})
&lt;span style="color:#75715e">// ...when you are done...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's also a set of unit tests in the &lt;code>repository/repository.spec.js&lt;/code> file. Now that we've got a repo, we can create a server. This is &lt;code>server/server.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// server.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;express&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">morgan&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;morgan&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Make sure we have a repository and port provided.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a connected repository.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a port.&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Create the app, add some logging.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span>();
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">use&lt;/span>(&lt;span style="color:#a6e22e">morgan&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;dev&amp;#39;&lt;/span>));
&lt;span style="color:#75715e">// Add the APIs to the app.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;../api/users&amp;#39;&lt;/span>)(&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>);
&lt;span style="color:#75715e">// Start the app, creating a running server which we return.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">listen&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">server&lt;/span>);
});
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This module exposes a &lt;code>start&lt;/code> function, which we can use like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server);
&lt;/span>&lt;span style="color:#e6db74">server.start({port: 8080, repo: repository}).then((svr) =&amp;gt; {
&lt;/span>&lt;span style="color:#e6db74"> // we&amp;#39;&lt;/span>&lt;span style="color:#a6e22e">ve&lt;/span> &lt;span style="color:#a6e22e">got&lt;/span> &lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#a6e22e">running&lt;/span> &lt;span style="color:#a6e22e">http&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">:&lt;/span>)
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice that &lt;code>server.js&lt;/code> uses &lt;code>api/users/js&lt;/code>? Here it is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// users.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Defines the users api. Add to a server by calling:
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// require(&amp;#39;./users&amp;#39;)
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#75715e">// Only export - adds the API to the app with the given options.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/users&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>, &lt;span style="color:#a6e22e">next&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>.&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; { &lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Get the email.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">email&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;When searching for a user, the email must be specified, e.g: &amp;#39;/search?email=homer@thesimpsons.com&amp;#39;.&amp;#34;&lt;/span>);
}
&lt;span style="color:#75715e">// Get the user from the repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">user&lt;/span>) {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">404&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;User not found.&amp;#39;&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Both of these files have unit tests adjacent to the source.&lt;/p>
&lt;p>We'll need config. Rather than using a specialised library, a simple file will do the trick - &lt;code>config/config.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can &lt;code>require&lt;/code> config as needed. Currently, most config is hard coded, but as you can see from &lt;code>port&lt;/code> it's easy to add environment variables as an option.&lt;/p>
&lt;p>Final step - stringing it together with an &lt;code>index.js&lt;/code> file which composes everything:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// index.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Entrypoint to the application. Opens a repository to the MySQL
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// server and starts the server.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">repository&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./repository/repository&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./config/config&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Lots of verbose logging when we&amp;#39;re starting up...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;--- Customer Service---&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to customer repository...&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Log unhandled exceptions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;uncaughtException&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Exception&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;unhandledRejection&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">promise&lt;/span>){
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Rejection&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">database&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connected. Starting server...&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span>({
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>,
&lt;span style="color:#a6e22e">repository&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>
});
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">app&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Server started successfully, running on port &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;close&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a little error handling and beyond that we're just loading config, creating a repo and starting our server.&lt;/p>
&lt;p>That's the microservice. It allows us to get all users, or search a user:&lt;/p>
&lt;pre>&lt;code>HTTP GET /users # gets all users
HTTP GET /search?email=homer@thesimpons.com # searches by email
&lt;/code>&lt;/pre>&lt;p>If you checkout the code, you'll see that there's a few commands available for you:&lt;/p>
&lt;pre>&lt;code>cd ./users-service
npm install # setup everything
npm test # unit test - no need for a test database running
npm start # run the server - you must have a test database running
npm run debug # run the server in debug mode, opens a browser with the inspector
npm run lint # check to see if the code is beautiful
&lt;/code>&lt;/pre>&lt;p>Asides from the code you've seen we have:&lt;/p>
&lt;ol>
&lt;li>Node Inspector for debugging&lt;/li>
&lt;li>Mocha/shoud/supertest for unit tests&lt;/li>
&lt;li>ESLint for linting&lt;/li>
&lt;/ol>
&lt;p>That's it!&lt;/p>
&lt;p>Run the test database with:&lt;/p>
&lt;pre>&lt;code>cd test-database/
./start.sh
&lt;/code>&lt;/pre>&lt;p>Then the service with:&lt;/p>
&lt;pre>&lt;code>cd ../users-service/
npm start
&lt;/code>&lt;/pre>&lt;p>You can point your browser to &lt;a href="http://localhost:8123/users">localhost:8123/users&lt;/a> and see it in action. If you are using Docker Machine (i.e. you're on Mac or Windows) then &lt;code>localhost&lt;/code> won't work, you need the IP of the docker machine instead. You can use &lt;code>docker-machine ip&lt;/code> to get it.&lt;/p>
&lt;p>We've whipped through building the service quickly. If you'd like to see this code before we continue, check the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step2">step2&lt;/a> branch.&lt;/p>
&lt;h1 id="step-3-dockerising-our-microservice">Step 3: Dockerising our Microservice&lt;/h1>
&lt;p>OK now it gets fun!&lt;/p>
&lt;p>So we have a microservice which we can run on a dev box, as long as it has a compatible version of Node.js installed. What we'd like to do is set up our service so that we can create a &lt;em>Docker Image&lt;/em> from it, allowing us to deploy our service anywhere which supports docker.&lt;/p>
&lt;p>The way we do this is create a &lt;em>Dockerfile&lt;/em>. A Dockerfile is a recipe that tells the Docker engine how to build your image. We'll create a simple Dockerfile in our &lt;code>users-service&lt;/code> directory and start to explore how we can adapt it to our needs.&lt;/p>
&lt;h2 id="creating-the-dockerfile">Creating the Dockerfile&lt;/h2>
&lt;p>Create a new text file called &lt;code>Dockerfile&lt;/code> at &lt;code>users-service/&lt;/code> with the content below:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Run node
CMD [&amp;quot;node&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>Now run the commands below to build the image and run the a container from it:&lt;/p>
&lt;pre>&lt;code>docker build -t node4 . # Builds a new image
docker run -it node4 # Run a container with this image, interactive
&lt;/code>&lt;/pre>&lt;p>Let's look at the build command first.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker build&lt;/code> tell the engine we want to create a new image.&lt;/li>
&lt;li>&lt;code>-t node4&lt;/code> tag this image with the tag &lt;code>node4&lt;/code>. We can refer to this image by tag from now on.&lt;/li>
&lt;li>&lt;code>.&lt;/code> use the current directory to find the &lt;code>Dockerfile&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>After some console output you'll see we have a new image created. You can see all images on your system with &lt;code>docker images&lt;/code>. The next command should be fairly familiar from what we've done so far:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> run a new container from an image.&lt;/li>
&lt;li>&lt;code>-it&lt;/code> use an interactive terminal.&lt;/li>
&lt;li>&lt;code>node4&lt;/code> the tag of the image we want to use in the container.&lt;/li>
&lt;/ol>
&lt;p>When we run this image, we get a node repl, check the current version like so:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">version&lt;/span>
&lt;span style="color:#e6db74">&amp;#39;v4.4.0&amp;#39;&lt;/span>
&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">exit&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is potentially different to the node version on your current machine.&lt;/p>
&lt;h2 id="examining-the-dockerfile">Examining the Dockerfile&lt;/h2>
&lt;p>Looking at the dockerfile we can see quite easily what is going on:&lt;/p>
&lt;ol>
&lt;li>&lt;code>FROM node:4&lt;/code> the first thing we specify in a Dockerfile is the base image. A quick google finds the &lt;a href="https://hub.docker.com/_/node/">node organisation page on the docker hub&lt;/a> showing all of the available images. This is essentially bare bones ubuntu with node installed.&lt;/li>
&lt;li>&lt;code>CMD [&amp;quot;node&amp;quot;]&lt;/code> the &lt;code>CMD&lt;/code> command tells docker that this image should run the node executable. When the executable terminates, the container shuts down.&lt;/li>
&lt;/ol>
&lt;p>With the addition of a few more commands, we can update our Dockerfile so that it runs our service:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Add everything in the current directory to our image, in the 'app' folder.
ADD . /app
# Install dependencies
RUN cd /app; \
npm install --production
# Expose our server port.
EXPOSE 8123
# Run our app.
CMD [&amp;quot;node&amp;quot;, &amp;quot;/app/index.js&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>The only addition here is that we use the &lt;code>ADD&lt;/code> command to copy everything&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> in the current directory to a folder in the container called &lt;code>app/&lt;/code> . We then use &lt;code>RUN&lt;/code> to run a command in the image, which installs our modules. Finally, we &lt;code>EXPOSE&lt;/code> the server port, telling docker we intend to support inbound connections on &lt;code>8123&lt;/code>, then run our server code.&lt;/p>
&lt;p>Ensure the test-database service is running, then build and run the image again:&lt;/p>
&lt;pre>&lt;code>docker build -t users-service .
docker run -it -p 8123:8123 users-service
&lt;/code>&lt;/pre>&lt;p>If you navigate to &lt;code>localhost:8123/users&lt;/code> in a browser you should see an error, checking the console shows our container is reporting some issues:&lt;/p>
&lt;pre>&lt;code>--- Customer Service---
Connecting to customer repository...
Connected. Starting server...
Server started successfully, running on port 8123.
GET /users 500 23.958 ms - 582
Error: An error occured getting the users: Error: connect ECONNREFUSED 127.0.0.1:3306
at Query._callback (/app/repository/repository.js:21:25)
at Query.Sequence.end (/app/node_modules/mysql/lib/protocol/sequences/Sequence.js:96:24)
at /app/node_modules/mysql/lib/protocol/Protocol.js:399:18
at Array.forEach (native)
at /app/node_modules/mysql/lib/protocol/Protocol.js:398:13
at nextTickCallbackWith0Args (node.js:420:9)
at process._tickCallback (node.js:349:13)
&lt;/code>&lt;/pre>&lt;p>Yikes! So the connection from our &lt;code>users-service&lt;/code> container to the &lt;code>test-database&lt;/code> container is being refused. We might try running &lt;code>docker ps&lt;/code> to see all containers running:&lt;/p>
&lt;pre>&lt;code>CONTAINER ID IMAGE PORTS NAMES
a97958850c66 users-service 0.0.0.0:8123-&amp;gt;8123/tcp kickass_perlman
47f91343db01 mysql:latest 0.0.0.0:3306-&amp;gt;3306/tcp db
&lt;/code>&lt;/pre>&lt;p>They're both there, so what is going on?&lt;/p>
&lt;h2 id="linking-containers">Linking Containers&lt;/h2>
&lt;p>The issue we've seen is actually to be expected. Docker containers are supposed to be isolated, so it wouldn't make much sense if we could create connections between containers without us explicitly allowing it.&lt;/p>
&lt;p>Yes, we can connect from our machine (the host) to a container, because we've opened ports for that (using the &lt;code>-p 8123:8123&lt;/code> argument for example). If we allowed containers to talk to each other in the same way, then two containers running on the same machine would be able to communicate, even if the developers didn't intend it, and that's a recipe for disaster, especially when we might have a cluster of machines whos job it is to run containers from different applications.&lt;/p>
&lt;p>If we're going to connect from one container to another, we need to &lt;em>link&lt;/em> them, which tells docker that we explicitly want to allow communication between the two. There are two ways of doing this, the first is the &amp;lsquo;old fasioned&amp;rsquo; but quite simple way, the second we'll see a little later.&lt;/p>
&lt;h3 id="linking-containers-with-the-link-parameter">Linking Containers with the &amp;lsquo;link&amp;rsquo; parameter&lt;/h3>
&lt;p>When we run a container, we can tell docker that we intend to connect to another container using the &lt;code>link&lt;/code> parameter. In our case, we can run our service correctly like this:&lt;/p>
&lt;pre>&lt;code>docker run -it -p 8123:8123 --link db:db -e DATABASE_HOST=DB users-service
&lt;/code>&lt;/pre>&lt;ol>
&lt;li>&lt;code>docker run -it&lt;/code> run a docker image in a container, with an interactive terminal.&lt;/li>
&lt;li>&lt;code>-p 8123:8123&lt;/code> map the host port 8123 to the container port 8123.&lt;/li>
&lt;li>&lt;code>link db:db&lt;/code> link to the container named &lt;code>db&lt;/code> and refer to it as &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-e DATABASE_HOST=db&lt;/code> set the &lt;code>DATABASE_HOST&lt;/code> environment variable to &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>users-service&lt;/code> the name of the image to run in our container.&lt;/li>
&lt;/ol>
&lt;p>Now when we go to &lt;code>localhost:8123/users&lt;/code> everything works.&lt;/p>
&lt;h4 id="how-it-works">How it works&lt;/h4>
&lt;p>Remember our config file for the service? It allowed us to specify a database host with an environment variable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>When we run the container, we set this environment variable to &lt;code>DB&lt;/code>, which means we're connecting to a host called &lt;code>DB&lt;/code>. This is &lt;em>automatically&lt;/em> set up for us by the docker engine when we link to a container.&lt;/p>
&lt;p>To see this in action, try running &lt;code>docker ps&lt;/code> to list all running containers. Look up the name of the container running the &lt;code>users-service&lt;/code>, which will be a random name such as &lt;code>trusting_jang&lt;/code>:&lt;/p>
&lt;pre>&lt;code>docker ps
CONTAINER ID IMAGE ... NAMES
ac9449d3d552 users-service ... trusting_jang
47f91343db01 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>Now we can look at the hosts available on our container:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 db 47f91343db01 # linking magic!!
172.17.0.3 ac9449d3d552
&lt;/code>&lt;/pre>&lt;p>Remember how &lt;code>docker exec&lt;/code> works? Choose a container name and then whatever follows is the command you'll execute on the container, in our case &lt;code>cat /etc/hosts&lt;/code>.&lt;/p>
&lt;p>OK the hosts file doesn't have the &lt;code># linking magic!!&lt;/code> comment, that's so you can see - docker has added &lt;code>db&lt;/code> to our hosts file so we can refer to the linked container by hostname. This is one consequence of linking. Here's the other:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang printenv | grep DB
DB_PORT=tcp://172.17.0.2:3306
DB_PORT_3306_TCP=tcp://172.17.0.2:3306
DB_PORT_3306_TCP_ADDR=172.17.0.2
DB_PORT_3306_TCP_PORT=3306
DB_PORT_3306_TCP_PROTO=tcp
DB_NAME=/trusting_jang/db
&lt;/code>&lt;/pre>&lt;p>From this command we can also see that when docker links a container, it also provides a set of environment variables with some helpful information. We know the host, tcp port and container name.&lt;/p>
&lt;p>That's step 3 complete - we have a MySQL database running happily in a container, we have a node.js microservice which we can run locally or in a container of its own, and we know how to link them together.&lt;/p>
&lt;p>You can check out how the code looks at this stage by going to the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step3">step3&lt;/a> branch.&lt;/p>
&lt;h1 id="step-4-integration-testing-the-environment">Step 4: Integration Testing the Environment&lt;/h1>
&lt;p>We can now write an integration test which calls the actual server, running as a docker container, calling the containerised test database.&lt;/p>
&lt;p>Writing the integration test can be done in whatever language or on whatever platform you want, within reason, but to keep things simple I'm using Node.js as we've already seen Mocha and Supertest in our project.&lt;/p>
&lt;p>In a new folder, called &lt;code>integration-tests&lt;/code> we've got a single &lt;code>index.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;supertest&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">should&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;should&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">describe&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;users-service&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">api&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;http://localhost:8123&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">it&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;returns a 200 for a known user&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">done&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">api&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search?email=homer@thesimpsons.com&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">expect&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>, &lt;span style="color:#a6e22e">done&lt;/span>);
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will check an API call and show the results of the test&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>As long as your &lt;code>users-service&lt;/code> and &lt;code>test-database&lt;/code> are running, the tests will pass. However, at this stage the services are getting a little harder to handle:&lt;/p>
&lt;ol>
&lt;li>We have to use a shell script to start and stop the database&lt;/li>
&lt;li>We have to remember a sequence of commands to start the users service against the database&lt;/li>
&lt;li>We have to use node directly to run the integration tests&lt;/li>
&lt;/ol>
&lt;p>Now that we're a little more familiar with Docker we can fix these issues.&lt;/p>
&lt;h3 id="simplifiying-the-test-database">Simplifiying the Test Database&lt;/h3>
&lt;p>Currently we have the following files for the test database:&lt;/p>
&lt;pre>&lt;code>/test-database/start.sh
/test-database/stop.sh
/test-database/setup.sql
&lt;/code>&lt;/pre>&lt;p>Now that we're more familar with Docker, we can improve on this. Looking into the &lt;a href="https://hub.docker.com/_/mysql/">mysql image documentation&lt;/a> on Docker Hub there's a note which tells us any &lt;code>.sql&lt;/code> or &lt;code>.sh&lt;/code> file added to the image's &lt;code>/docker-entrypoint-initdb.d&lt;/code> folder will be executed when setting up the DB.&lt;/p>
&lt;p>This means we can replace our &lt;code>start.sh&lt;/code> and &lt;code>stop.sh&lt;/code> scripts with a &lt;code>Dockerfile&lt;/code>:&lt;/p>
&lt;pre>&lt;code>FROM mysql:5
ENV MYSQL_ROOT_PASSWORD 123
ENV MYSQL_DATABASE users
ENV MYSQL_USER users_service
ENV MYSQL_PASSWORD 123
ADD setup.sql /docker-entrypoint-initdb.d
&lt;/code>&lt;/pre>&lt;p>Now to run our test database it is just:&lt;/p>
&lt;pre>&lt;code>docker build -t test-database .
docker run --name db test-database
&lt;/code>&lt;/pre>&lt;h3 id="composing">Composing&lt;/h3>
&lt;p>Building and running each container is still somewhat time consuming. We can take things a step further with the &lt;a href="https://docs.docker.com/compose/">Docker Compose&lt;/a> tool.&lt;/p>
&lt;p>Docker Compose lets you create a file which defines each container in your system, the relationships between them, and build or run them all.&lt;/p>
&lt;p>First, &lt;a href="https://docs.docker.com/compose/install/">install Docker Compose&lt;/a>. Now create a new file in the root of your project called &lt;code>docker-compose.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>Now check this out:&lt;/p>
&lt;pre>&lt;code>docker-compose build
docker-compose up
&lt;/code>&lt;/pre>&lt;p>Docker Compose has built all of the images needed for our application, created containers fromthem, run them in the correct order and started the whole stack!&lt;/p>
&lt;p>The &lt;code>docker-compose build&lt;/code> command builds each image which is listed in the &lt;code>docker-compose.yml&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>The &lt;code>build&lt;/code> value for each of our services tells docker where to go to find the &lt;code>Dockerfile&lt;/code>. When we run &lt;code>docker-compose up&lt;/code>, docker starts all of our services. Notice from the &lt;code>Dockerfile&lt;/code> we can specify ports and dependencies. Actually, there's a whole bunch of config we can change here.&lt;/p>
&lt;p>In another terminal, run &lt;code>docker compose down&lt;/code> to gracefully shut down the containers.&lt;/p>
&lt;h1 id="winding-up">Winding Up&lt;/h1>
&lt;p>We've seen a lot of docker in this article, but there's a lot more to it. I hope this has shown some of the interesting and useful things that you can use docker for in your workflow.&lt;/p>
&lt;p>As usual, questions and comments are welcomed! I'd also strongly recommend the document &lt;a href="https://docs.docker.com/engine/understanding-docker/">Understanding Docker&lt;/a> to get a deeper understanding of how docker works.&lt;/p>
&lt;p>You can see the final source code for the project built in this article at &lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h1 id="notes">Notes&lt;/h1>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Copying everything is actually a bad idea, because we will also copy the node_modules folder. Generally it is a better idea explicitly list the files or folders you want to copy, or use a .dockerignore file, which works just like the .gitignore file. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If the server isn't running, it will actually show a rather annoying exception, due to a bug in supertest, see &lt;a href="https://github.com/visionmedia/supertest/issues/314">github.com/visionmedia/supertest/issues/314&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item></channel></rss>