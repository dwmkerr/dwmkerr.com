<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on dwmkerr.com</title><link>https://dwmkerr.com/categories/kubernetes/</link><description>Recent content in Kubernetes on dwmkerr.com</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Copright &amp;copy; Dave Kerr</copyright><lastBuildDate>Thu, 04 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://dwmkerr.com/categories/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Observations, tips and tricks for the CKA certification</title><link>https://dwmkerr.com/tips-for-cka/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/tips-for-cka/</guid><description>&lt;p>In this article I&amp;rsquo;ll share some observations, tips and tricks for the &lt;a href="https://www.linuxfoundation.org/">Linux Foundation&amp;rsquo;s&lt;/a> &amp;ldquo;&lt;a href="https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/">Certified Kubernetes Administrator&lt;/a> certification and exam.&lt;/p>
&lt;p>I&amp;rsquo;ve been operating Kubernetes in multiple environments for a few years now. I thought this would be an easy certification to get, but I was surprised by how hard it was!&lt;/p>
&lt;p>I took this exam without doing any formal training, I mostly focused on the areas of the curriculum which I knew I was a little weak at. The task-based structure for the exam I thought was really excellent. It took me two attempts to pass, and I learnt a few things along the way.&lt;/p>
&lt;p>Here I&amp;rsquo;ll share some thoughts on the certification which hopefully will be useful if you are considering taking it!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#tip-do-the-right-certification">Tip: Do the right Certification!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-understand-the-format">Tip: Understand the Format!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-your-vim">Tip: Know your Vim&lt;/a>&lt;/li>
&lt;li>&lt;a href="#you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That&amp;rsquo;s it!&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h2 id="tip-do-the-right-certification">Tip: Do the right Certification!&lt;/h2>
&lt;p>The CKA exam tests &lt;em>administration&lt;/em> and &lt;em>operation&lt;/em> skills and techniques for Kubernetes. If you have set up and administered clusters before, this will likely not be too challenging. But if you&amp;rsquo;ve never set up a cluster by hand, troubleshot weird issues, fixed clusters and so on, then this is likely going to be very hard.&lt;/p>
&lt;p>There is a certification which is much more geared towards developers who use Kubernetes, but don&amp;rsquo;t necessarily administer it - that&amp;rsquo;s the &lt;a href="https://www.cncf.io/certification/ckad/">CKAD&lt;/a> exam and might be the one to take if you are not too familiar with system administration.&lt;/p>
&lt;h2 id="tip-understand-the-format">Tip: Understand the Format!&lt;/h2>
&lt;p>This is not a multiple choice question exam. It&amp;rsquo;s a task based exam, meaning you have about 22 or so specific tasks to complete, in a web browser which has a terminal connected to a cluster.&lt;/p>
&lt;p>It is open-book - meaning that you can use the &lt;a href="https://kubernetes.io/docs/home/">Kubernetes Documentation&lt;/a> during the exam. It&amp;rsquo;s not a memory test of specific flags for commands or whatever, it will really require you to work with a running cluster. This means you&amp;rsquo;ll have to be pretty familiar with &lt;code>kubectl&lt;/code>, &lt;code>kubeadm&lt;/code> and also Linux in general!&lt;/p>
&lt;h2 id="tip-know-your-vim">Tip: Know your Vim&lt;/h2>
&lt;p>In the two exams I took, &lt;code>nano&lt;/code> was available. But if you are using &lt;code>nano&lt;/code> to work with files you may struggle for time.&lt;/p>
&lt;p>I spent a &lt;em>lot&lt;/em> of time in &lt;code>vim&lt;/code> in the exam. &lt;code>vim&lt;/code> is my main text editor for day to day work, so I&amp;rsquo;m fairly familiar with it. Knowing how to quickly copy a file (lets say for example a file which represents a deployment) and quickly manipulate the text in it will be crucial. Make sure you are going to be using a text editor which you can be efficient in!&lt;/p>
&lt;p>You won&amp;rsquo;t be using a graphical text editor to work with files, so being competent in a terminal editor like &lt;code>vim&lt;/code> or &lt;code>emacs&lt;/code> could make a big difference. Of course you could install your favourite text editor, but you won&amp;rsquo;t be able to use a graphical editor like VS Code.&lt;/p>
&lt;p>Also, as in most Linux distributions, &lt;code>screen&lt;/code> is available out of the box, and &lt;code>tmux&lt;/code> can also be installed. If you are familiar with either of these terminal mutliplexers it could save you a tonne of time, for example being able to run &lt;code>watch -n 5 -d kubectl get pods&lt;/code> in one pane while applying resources in another.&lt;/p>
&lt;h2 id="you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/h2>
&lt;p>This exam will require you to deal with trivial tasks such as running a deployment or creating a volume. But the questions which focus on that tend to only count for one or two percent of the overall grade each. Questions which deal with troubleshooting actual Kubernetes issues could count for six or seven percent each.&lt;/p>
&lt;p>This means you &lt;em>need&lt;/em> to know how Kubernetes is architecture. The &lt;code>kubelet&lt;/code> which runs on nodes, the API server, the &lt;code>etcd&lt;/code> store, all of these things you &lt;em>have&lt;/em> to understand how they work and how they fit together.&lt;/p>
&lt;p>The online documentation covers the architecture in detail, here&amp;rsquo;s the best place to start:&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">&lt;img src="./images/k8s-architecture.png" alt="Kubernetes Architecture">&lt;/a>&lt;/p>
&lt;p>You will need to know how the control plane works, how nodes communicate, how transport of messages works and is secured if you are going to have a chance at dealing with the harder questions.&lt;/p>
&lt;h2 id="tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/h2>
&lt;p>If you are not familiar with &lt;code>systemctl&lt;/code>, &lt;code>journalctl&lt;/code>, &lt;code>apt&lt;/code>, &lt;code>systemd&lt;/code> units and how the core Kubernetes components are configured, you&amp;rsquo;ll really struggle.&lt;/p>
&lt;p>Look over the &lt;a href="https://github.com/cncf/curriculum">CNCF curriculum&lt;/a> - expect to not just have to know how to deal with &amp;lsquo;happy path&amp;rsquo; situations, but also broken clusters, incorrect configuration and so on.&lt;/p>
&lt;h2 id="tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/h2>
&lt;p>One thing which helped me a lot in my second attempt at the exam was the &lt;code>--dry-run&lt;/code> flag. Before you create resources or change anything, run the operation with the &lt;code>--dry-run&lt;/code> flag and see whether the output is what you would expect.&lt;/p>
&lt;p>This is a quick and easy way to see the changes to the cluster which you are going to apply - and troubleshoot them - before making any actual changes.&lt;/p>
&lt;h2 id="tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/h2>
&lt;p>Networking in Kubernetes is complex. You must be able to troubleshoot networking issues in the cluster to be able to deal with the more complex tasks.&lt;/p>
&lt;p>This means that you should know how to be able to run typical networking tools like &lt;code>dig&lt;/code>, &lt;code>nslookup&lt;/code>, &lt;code>telnet&lt;/code> etc, in the cluster itself.&lt;/p>
&lt;p>If you are not familiar with these tools you might need to take an online course in Kubernetes or Linux Networking Administration before considering this certification. The &lt;a href="https://training.linuxfoundation.org/certification/linux-foundation-certified-sysadmin-lfcs/">Linux Certified Systems Administrator&lt;/a> training would be a good place to start.&lt;/p>
&lt;p>If you have taken the &lt;a href="https://success.docker.com/certification">Docker Certified Associate&lt;/a> exam then some of this should be familiar. If you are not very familiar with how Docker itself works, you&amp;rsquo;ll likely struggle with Kubernetes.&lt;/p>
&lt;h2 id="tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/h2>
&lt;p>There are a lot of tasks which only count for one or two percent each; these ones you should be able to complete in a few minutes. You&amp;rsquo;ll need all the time in the exam to work on the really hard questions which deal with diagnosing and fixing cluster issues.&lt;/p>
&lt;p>Know your core Kubernetes concepts; if you have done the CKAD exam you should be good, if not, check the curriculum and make sure you can quickly complete all of the trivial tasks without wasting too much time.&lt;/p>
&lt;h2 id="thats-it">That&amp;rsquo;s it!&lt;/h2>
&lt;p>Hopefully this was helpful! Good luck if you are taking the exam and hopefully you&amp;rsquo;ll find it a challenging but rewarding experience. I&amp;rsquo;ve taken many exams over the years but this was one of the most challenging, but also one of the most enjoyable, I really felt like it was testing practical techniques rather than your ability to just remember random commands and flags.&lt;/p>
&lt;p>As always, if you have any comments or questions, please just add them in the section below!&lt;/p>
&lt;p>&lt;img src="./images/cka-cert.png" alt="CKA Certification">&lt;/p></description><category>CodeProject</category></item><item><title>Manipulating Istio and other Custom Kubernetes Resources in Golang</title><link>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</link><pubDate>Mon, 08 Oct 2018 21:34:02 +0000</pubDate><guid>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</guid><description>&lt;p>In this article I&amp;rsquo;ll demonstrate how to use Golang to manipulate Kubernetes Custom Resources, with Istio as an example. No knowledge of Istio is needed, I&amp;rsquo;ll just use it to demonstrate the concepts!&lt;/p>
&lt;p>&lt;img src="images/code-2.jpg" alt="code">&lt;/p>
&lt;p>&lt;a href="https://istio.io">Istio&lt;/a> is a highly popular Service Mesh platform which allows engineers to quickly add telemetry, advanced traffic management and more to their service-based applications.&lt;/p>
&lt;p>One interesting element of how Istio works is that when deployed into a Kubernetes cluster, many key configuration objects are handled as &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources&lt;/a>. Custom Resources are a very powerful Kubernetes feature, which allow you to create your own &amp;lsquo;first class&amp;rsquo; resources (just like Pods, ReplicaSets, Deployments or whatever) and then interface with them using &lt;code>kubectl&lt;/code> or the Kubernetes APIs.&lt;/p>
&lt;p>In this article I&amp;rsquo;ll show you how to interface with these Custom Resources using the Golang Kubernetes client.&lt;/p>
&lt;h2 id="crds-a-quick-overview">CRDs: A Quick Overview&lt;/h2>
&lt;p>When you set up Istio for your cluster, one common thing you will likely do is specify how you will route traffic. This can be quite sophisticated, as shown below:&lt;/p>
&lt;p>&lt;img src="images/TrafficManagementOverview.svg" alt="TrafficManagementOverview">&lt;/p>
&lt;p>&lt;a href="https://istio.io/docs/concepts/traffic-management/">Figure 1: Istio Traffic Management Examples, from istio.io&lt;/a>&lt;/p>
&lt;p>One way for a system like this to be configured would be to have a ConfigMap which contains the definition of how services are routed.&lt;/p>
&lt;p>However, Istio actually registers new types of resources (Custom Resource Definitions) which represent things like Gateways or Services. We can create/update/delete/manipulate them just like any other Kubernetes object.&lt;/p>
&lt;p>For example, I could create a virtual service for the example above with something like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cat &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF | kubectl create -f -
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">apiVersion: networking.istio.io/v1alpha3
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">kind: VirtualService
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">metadata:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> name: service2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">spec:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> hosts:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - &amp;#34;*&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> gateways:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - demo1-gateway
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> http:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - route:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> subset: v1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> weight: 95
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> subset: v2
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> weight: 5
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, the important thing is not the specific content of this resource, more the fact that I can treat my Istio resources just like I would any other Kubernetes object:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl get virtualservices.networking.istio.io
NAME AGE
service2 93s
&lt;/code>&lt;/pre>&lt;p>Or:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl delete virtualservices.networking.istio.io/service2
&lt;/code>&lt;/pre>&lt;p>I can use &lt;code>edit&lt;/code>, &lt;code>describe&lt;/code>, register lifecycle events, watch for changes, and so on.&lt;/p>
&lt;h2 id="working-with-crds-in-golang">Working with CRDs in Golang&lt;/h2>
&lt;p>The &lt;a href="https://github.com/kubernetes/client-go">Golang Kubernetes Client&lt;/a> allows you to create strongly defined types which you can then use to interface with CRDs. An example is in the Red Hat blog post &lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Kubernetes Deep Dive: Code Generation for Custom Resources&lt;/a>.&lt;/p>
&lt;p>This is an excellent approach, but can feel pretty heavy if you want to quickly access some data, and don&amp;rsquo;t want to have to generate a lot of code.&lt;/p>
&lt;p>There is an alternative, which is to use the &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">&lt;code>DynamicClient&lt;/code>&lt;/a>. The &lt;em>preferred&lt;/em> approach seems to be the first, which involves code generation, so little documentation exists for the second approach. However, it is actually very simple.&lt;/p>
&lt;p>Here&amp;rsquo;s an example of how you can list all Istio &lt;code>VirtualService&lt;/code> resources, without having to generate any code:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create a Dynamic Client to interface with CRDs.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">dynamicClient&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamic&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// List all of the Virtual Services.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServices&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">List&lt;/span>(&lt;span style="color:#a6e22e">metav1&lt;/span>.&lt;span style="color:#a6e22e">ListOptions&lt;/span>{})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#66d9ef">range&lt;/span> &lt;span style="color:#a6e22e">virtualServices&lt;/span>.&lt;span style="color:#a6e22e">Items&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;VirtualService: %s\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span>.&lt;span style="color:#a6e22e">GetName&lt;/span>())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet omits setup and error-handling for clarity, the full example is in the &lt;a href="https://gist.github.com/dwmkerr/09ac0fd98595460456e17d5ef0c77667">k8s-list-virtualservices.go&lt;/a> gist.&lt;/p>
&lt;h2 id="patching-crds-in-golang">Patching CRDs in Golang&lt;/h2>
&lt;p>You may have noticed that the &lt;code>.Resource().Namespace().List()&lt;/code> code looks very similar to the structure for making API calls when using the Kubernetes &lt;code>Clientset&lt;/code>. In fact, it is essentially the same. Looking at &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">the interface&lt;/a>, you can see you have all of the operations you&amp;rsquo;d expect:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Create&lt;/code>&lt;/li>
&lt;li>&lt;code>Update&lt;/code>&lt;/li>
&lt;li>&lt;code>Delete&lt;/code>&lt;/li>
&lt;li>&lt;code>Get&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>And so on. This is nice because you can use the same trick in my article &amp;lsquo;&lt;a href="https://www.dwmkerr.com/patching-kubernetes-resources-in-golang/">Patching Kubernetes Resources in Golang&lt;/a>&amp;rsquo; to manipulate these entities, without ever having to create a structure to represent it.&lt;/p>
&lt;p>Here&amp;rsquo;s another abbreviated example, this time showing how we can adjust the weight of the routing from the services to 50%/50%:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Weight the two routes - 50/50.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">patchPayload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> make([]&lt;span style="color:#a6e22e">PatchUInt32Value&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/0/weight&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/1/weight&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a6e22e">patchBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">patchPayload&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// Apply the patch to the &amp;#39;service2&amp;#39; service.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;service2&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">patchBytes&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>See the full example in the gist &lt;a href="https://gist.github.com/dwmkerr/7332888e092156ce8ce4ea551b0c321f">k8s-patch-virtualservice.go&lt;/a>&lt;/p>
&lt;p>After running the sample, you can use the Kubernetes CLI to verify the changes:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl get virtualservices.networking.istio.io/service2 -o yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
clusterName: &amp;#34;&amp;#34;
creationTimestamp: 2018-10-08T09:53:16Z
generation: 0
name: service2
namespace: default
resourceVersion: &amp;#34;487435&amp;#34;
selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/virtualservices/service2
uid: fac5930c-cadf-11e8-90a2-42010a94005b
spec:
gateways:
- demo1-gateway
hosts:
- &amp;#39;*&amp;#39;
http:
- route:
- destination:
host: service2
subset: v1
weight: 50
- destination:
host: service2
subset: v2
weight: 50
&lt;/code>&lt;/pre>&lt;h2 id="keep-it-simple">Keep It Simple!&lt;/h2>
&lt;p>That&amp;rsquo;s it! This trick made something I was working on a &lt;em>lot&lt;/em> easier, but it took a little bit of experimentation to get right. I hope you find the approach useful. Please share any thoughts/questions in the comments.&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>The following articles were using in working out this approach:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Red Hat: Deep Dive: Code Generation for Custom Resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Kubernetes Docs: Custom Resources&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>Patching Kubernetes Resources in Golang</title><link>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</link><pubDate>Tue, 24 Jul 2018 06:33:17 +0000</pubDate><guid>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</guid><description>&lt;p>Recently I needed to be able to quickly adjust the number of replicas in a Kubernetes Replication Controller. The original solution I&amp;rsquo;d seen pulled down the spec, modified it, then updated it. There&amp;rsquo;s a better way!&lt;/p>
&lt;p>&lt;img src="images/patch-1.jpg" alt="Kuberentes Patch API">&lt;/p>
&lt;p>There&amp;rsquo;s a &lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">patch API for Kubernetes resources&lt;/a>. Patching resources is faster and easier than pulling them and updating the spec wholesale. However, the documentation is a little limited.&lt;/p>
&lt;p>After some trial and error I got it working, here&amp;rsquo;s the solution. I thought it might be helpful to share for others!&lt;/p>
&lt;h3 id="the-solution">The Solution&lt;/h3>
&lt;p>I&amp;rsquo;ll start with the solution. If this is all you need, you are good to go. The details of how this works are presented afterwards. In this example I&amp;rsquo;ll update the number of replicas in the &lt;code>my-rc&lt;/code> controller:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">package&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;encoding/json&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">types&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/types&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/kubernetes&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/plugin/pkg/client/auth&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/tools/clientcmd&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Leave blank for the default context in your kube config.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">context&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Name of the replication controller to scale, and the desired number of replicas.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">replicationControllerName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;my-rc&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">replicas&lt;/span> = uint32(&lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a string.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchStringValue&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;op&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;path&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;value&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a uint32.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchUInt32Value&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;op&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;path&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span> &lt;span style="color:#e6db74">`json:&amp;#34;value&amp;#34;`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientSet&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">Clientset&lt;/span>, &lt;span style="color:#a6e22e">replicasetName&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#a6e22e">scale&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span>) &lt;span style="color:#66d9ef">error&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">payload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> []&lt;span style="color:#a6e22e">patchUInt32Value&lt;/span>{{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Op&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Path&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Value&lt;/span>: &lt;span style="color:#a6e22e">scale&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">payloadBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientSet&lt;/span>.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">CoreV1&lt;/span>().
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">ReplicationControllers&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#a6e22e">replicasetName&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">payloadBytes&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Get the local kube config.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to Kubernetes Context %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">context&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">config&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewNonInteractiveDeferredLoadingClientConfig&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewDefaultClientConfigLoadingRules&lt;/span>(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;amp;&lt;/span>&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">ConfigOverrides&lt;/span>{&lt;span style="color:#a6e22e">CurrentContext&lt;/span>: &lt;span style="color:#a6e22e">context&lt;/span>}).&lt;span style="color:#a6e22e">ClientConfig&lt;/span>()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Creates the clientset
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Scale our replication controller.
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Scaling replication controller %v to %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">err&lt;/span> = &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code is also available in the &lt;a href="https://gist.github.com/dwmkerr/447692c8bba28929ef914239781c4e59">k8s-patch.go&lt;/a> gist.&lt;/p>
&lt;h3 id="the-mechanism">The Mechanism&lt;/h3>
&lt;p>The Kubernetes Patch API supports a few different methods for modifying resources. It is important to be aware that there is not a universally accepted &amp;lsquo;standard&amp;rsquo; approach to representing a &lt;em>change&lt;/em> to a resource in a REST API.&lt;/p>
&lt;p>There are three strategies you can use to patch:&lt;/p>
&lt;ol>
&lt;li>&lt;code>merge&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc7386">JSON Merge Patch Spec (RFC 7386)&lt;/a>&lt;/li>
&lt;li>&lt;code>stragetic&lt;/code>: A strategic merge, which addresses some limitations of the merge patch (noted in &lt;a href="%5Bdocs/devel/api-conventions.md#patch-operations%5D(https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations)">this doc&lt;/a>.&lt;/li>
&lt;li>&lt;code>json&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc6902">JSON Patch Spec (RFC 6902)&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>These are documented in detail at:&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">docs/devel/api-conventions.md#patch-operations&lt;/a>&lt;/p>
&lt;p>The mechanism I&amp;rsquo;ve used here is &lt;code>json&lt;/code>, which I think is the clearest to the reader. To use this strategy we need to build a payload describing what we are changing. This might look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;op&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;#34;value&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">4&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>op&lt;/code> field can be &lt;code>remove&lt;/code>, &lt;code>replace&lt;/code>, &lt;code>add&lt;/code> etc etc (all the details are in the &lt;a href="https://tools.ietf.org/html/rfc6902">RFC 6902)&lt;/a>, or the slightly more readable &lt;a href="jsonpatch.com">jsonpatch.com&lt;/a>). This allows the operation to be very &lt;em>explicit&lt;/em> to the reader, which is helpful. We create a struct which represents an operation on a string or integer (or whatever data type we need), serialize it and pass to the API.&lt;/p>
&lt;p>Under the hood, the Golang client will simply translate this into an HTTP call which will look like something like this:&lt;/p>
&lt;pre tabindex="0">&lt;code>PATCH /api/v1/namespaces/default/replicationcontrollers/app-server-blue HTTP/1.1
Host: 127.0.0.1
Content-Type: application/json-patch+json
Content-Length: 70
[{
&amp;#34;op&amp;#34;: &amp;#34;replace&amp;#34;,
&amp;#34;path&amp;#34;: &amp;#34;/spec/replicas&amp;#34;,
&amp;#34;value&amp;#34;: 4
}]
&lt;/code>&lt;/pre>&lt;p>This corresponds to the documentation on the &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Patch Operations&lt;/a>. Note that the patch operation type is specified in the &lt;code>Content-Type&lt;/code> header.&lt;/p>
&lt;p>Hopefully this&amp;rsquo;ll help you if you need to patch resources, are struggling with the docs and are a Go noob like me! Any tips on how to make the code cleaner or more idomatic would be welcome.&lt;/p>
&lt;p>Thanks to the following articles and issues which helped me unpick this:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://stackoverflow.com/questions/43415728/kubernetes-go-client-patch-example">Stack Overflow: Kubernetes Go Client Patch Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">Kubernetes Docs: Update API Objects in Place Using kubectl patch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Kubernetes Docs: Patch Operations&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>The Death of Microservice Madness in 2018</title><link>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</link><pubDate>Fri, 12 Jan 2018 10:52:25 +0000</pubDate><guid>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</guid><description>&lt;p>&lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">En Español&lt;/a> | &lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit Thread&lt;/a> | &lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News Thread&lt;/a>&lt;/p>
&lt;p>Microservices became a very popular topic over the last couple of years&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. &amp;lsquo;Microservice madness&amp;rsquo; goes something like this:&lt;/p>
&lt;blockquote>
&lt;p>Netflix are great at devops.
Netflix do microservices.
Therefore: If I do microservices, I am great at devops.&lt;/p>
&lt;/blockquote>
&lt;p>There are many cases where great efforts have been made to adopt microservice patterns without necessarily understanding how the costs and benefits will apply to the specifics of the problem at hand.&lt;/p>
&lt;p>I&amp;rsquo;m going to describe in detail what microservices are, why the pattern is so appealing, and also some of the key challenges that they present.&lt;/p>
&lt;p>I&amp;rsquo;ll finish with a set of simple questions might be valuable to ask yourself when you are considering whether microservices are the right pattern &lt;em>for you&lt;/em>. The questions are at the end of the article.&lt;/p>
&lt;p>&lt;img src="images/letterbox.png" alt="Letterbox sample of diagram">&lt;/p>
&lt;h2 id="what-are-microservices-and-why-are-they-so-popular">What are microservices, and why are they so popular?&lt;/h2>
&lt;p>Let&amp;rsquo;s start with the basics. Here is how a hypothetical video sharing platform might be implemented, first in the form of a monolith (single large unit) and then in the form of microservices:&lt;/p>
&lt;p>&lt;img src="images/video-platform-monolith-microservices.png" alt="Diagram: Comparison of a Video Sharing Platform, Monolith vs Microservice">&lt;/p>
&lt;p>The difference between the two systems is that the first is a single large unit; a monolith. The second is a set of small, specific services. Each service has a specific role.&lt;/p>
&lt;p>When the diagram is drawn &lt;em>at this level of detail&lt;/em>, it is easy to see the appeal. There are a whole host of potential benefits:&lt;/p>
&lt;p>&lt;strong>Independent Development&lt;/strong>: Small, independent components can be built by small, independent teams. A group can work on a change to the &amp;lsquo;Upload&amp;rsquo; service without interfering with the &amp;lsquo;Transcode&amp;rsquo; service, or even knowing about it. The amount of time to learn about a component is greatly reduced, and it is easier to develop new features.&lt;/p>
&lt;p>&lt;strong>Independent Deployment&lt;/strong>: Each individual component can be deployed independently. This allows new features to be released with greater velocity and less risk. Fixes or features for the &amp;lsquo;Streaming&amp;rsquo; component can be deployed without requiring other components to be deployed.&lt;/p>
&lt;p>&lt;strong>Independent Scalability&lt;/strong>: Each component can be scaled independently of each other. During busy periods when new shows are released, the &amp;lsquo;Download&amp;rsquo; component can be scaled up to handle the increased load, without having to scale up every component, which makes elastic scaling more feasible and reduces costs.&lt;/p>
&lt;p>&lt;strong>Reusability&lt;/strong>: Components fulfil a small, specific function. This means that they can more easily be adapted for use in other systems, services or products. The &amp;lsquo;Transcode&amp;rsquo; component could be used by other business units, or even turned into a new business, perhaps offering transcoding services for other groups.&lt;/p>
&lt;p>At this level of detail, the benefits of a microservice model over a monolithic model seem obvious. So if that&amp;rsquo;s the case - why is this pattern only recently in vogue? Where has it been all my life?&lt;/p>
&lt;h2 id="if-this-is-so-great-why-hasnt-it-been-done-before">If this is so great, why hasn&amp;rsquo;t it been done before?&lt;/h2>
&lt;p>There are two answers to this question. One is that &lt;em>it has&lt;/em> - to the best of our technical capabilities, and the other is that more recent technical advances have allowed us to take it to a new level.&lt;/p>
&lt;p>When I started writing the answer to this question, it turned into a &lt;em>long&lt;/em> description, so I&amp;rsquo;m actually going to separate it into another article and publish it a little later&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. At this stage, I will skip the journey from single program to many programs, ignore ESBs and Service Orientated Architecture, component design and bounded contexts, and so on.&lt;/p>
&lt;p>Those who are interested can read more about the journey separately. Instead I&amp;rsquo;ll say that in many ways we&amp;rsquo;ve been doing this for a while, but with the recent explosion in popularity of container technology (Docker in particular) and in orchestration technology (such as Kubernetes, Mesos, Consul and so on) this pattern has become much more viable to implement from a technical standpoint.&lt;/p>
&lt;p>So if we take it as a given that we &lt;em>can&lt;/em> implement a microservice arrangement, we need to think carefully about the &lt;em>should&lt;/em>. We&amp;rsquo;ve seen the high-level theoretical benefits, but what about the challenges?&lt;/p>
&lt;h2 id="whats-the-problem-with-microservices">What&amp;rsquo;s the problem with microservices?&lt;/h2>
&lt;p>If microservices are so great, what&amp;rsquo;s the big deal? Here are some of the biggest issues I&amp;rsquo;ve seen.&lt;/p>
&lt;p>&lt;strong>Increased complexity for developers&lt;/strong>&lt;/p>
&lt;p>Things &lt;em>can&lt;/em> get a lot harder for developers. In the case where a developer wants to work on a &lt;em>journey&lt;/em>, or feature which might span many services, that developer has to run them all on their machine, or connect to them. This is often more complex than simply running a single program.&lt;/p>
&lt;p>This challenge can be partially mitigated with tooling&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, but as the number of services which makes up a system increases, the more challenges developers will face when running the system as a whole.&lt;/p>
&lt;p>&lt;strong>Increased complexity for operators&lt;/strong>&lt;/p>
&lt;p>For teams who don&amp;rsquo;t develop services, but maintain them, there is an explosion in potential complexity. Instead of perhaps managing a few running services, they are managing dozens, hundreds or thousands of running services. There are more services, more communication paths, and more areas of potential failure.&lt;/p>
&lt;p>&lt;strong>Increased complexity for devops&lt;/strong>&lt;/p>
&lt;p>Reading the two points above, it may grate that operations and development are treated separately, especially given the popularity of devops as a practice (which I am a big proponent of). Doesn&amp;rsquo;t devops mitigate this?&lt;/p>
&lt;p>The challenge is that many organisations still run with separated development and operations teams - and a organisation that does is much more likely to struggle with adoption of microservices.&lt;/p>
&lt;p>For organisations which have adopted devops, it&amp;rsquo;s still hard. Being both a developer and an operator is already tough (but critical to build good software), but having to also understand the nuances of container orchestration systems, particularly systems which are evolving at a rapid pace, is very hard. Which brings me onto the next point.&lt;/p>
&lt;p>&lt;strong>It requires serious expertise&lt;/strong>&lt;/p>
&lt;p>When done by experts, the results can be wonderful. But imagine an organisation where perhaps things are not running smoothly with a single monolithic system. What possible reason would there be that things would be any better by increasing the number of systems, which increases the operational complexity?&lt;/p>
&lt;p>Yes, with effective automation, monitoring, orchestration and so on, this is all possible. But the challenge is rarely the technology - the challenge is finding people who can use it effectively. These skillsets are currently in very high demand, and may be difficult to find.&lt;/p>
&lt;p>&lt;strong>Real world systems often have poorly defined boundaries&lt;/strong>&lt;/p>
&lt;p>In all of the examples we used to describe the benefits of microservices, we spoke about &lt;em>independent&lt;/em> components. However in many cases components are simply not independent. On paper, certain domains may look bounded, but as you get into the muddy details, you may find that they are more challenging to model than you anticipated.&lt;/p>
&lt;p>This is where things can get &lt;em>extremely&lt;/em> complex. If your boundaries are actually not well defined, then what happens is that even though &lt;em>theoretically&lt;/em> services can be deployed in isolation, you find that due to the inter-dependencies between services, you have to deploy &lt;em>sets&lt;/em> of services as a group.&lt;/p>
&lt;p>This then means that you need to manage coherent versions of services which are proven and tested when working together, you don&amp;rsquo;t actually have an independently deployable system, because to deploy a new feature, you need to carefully orchestrate the simultaneous deployment of many services.&lt;/p>
&lt;p>&lt;strong>The complexities of state are often ignored&lt;/strong>&lt;/p>
&lt;p>In the previous example, I mentioned that a feature deployment may require the simultaneous rollout of many versions of many services in tandem. It is tempting to assume that sensible deployment techniques will mitigate this, for example blue/green deployments (which most service orchestration platforms handle with little effort), or multiple versions of a service being run in parallel, with consuming channels deciding which version to use.&lt;/p>
&lt;p>These techniques mitigate a large number of the challenges &lt;em>if the services are stateless&lt;/em>. But stateless services are quite frankly, easy to deal with. In fact, if you have stateless services, then I&amp;rsquo;d be inclined to consider skipping microservices altogether and consider using a serverless model.&lt;/p>
&lt;p>In reality, many services require state. An example from our video sharing platform might be the subscription service. A new version of the subscriptions service may store data in the subscriptions database in a different shape. If you are running both services in parallel, you are running the system with two schemas at once. If you do a blue green deployment, and other services depend on data in the new shape, then they must be updated &lt;em>at the same time&lt;/em>, and if the subscription service deployment fails and rolls back, they might need to roll back too, with cascading consequences.&lt;/p>
&lt;p>Again, it might be tempting to think that with NoSQL databases these issues of schema go away, but they don&amp;rsquo;t. Databases which don&amp;rsquo;t enforce schema do not lead to schemaless systems - they just mean that schema tends to be managed at the application level, rather than the database level. The fundamental challenge of understanding the shape of your data, and how it evolves, cannot be eliminated.&lt;/p>
&lt;p>&lt;strong>The complexitities of communication are often ignored&lt;/strong>&lt;/p>
&lt;p>As you build a large network of services which depend on each other, the liklihood is that there will be a lot of inter-service communication. This leads to a few challenges. Firstly, there are a lot more points at which things can fail. We must expect that network calls will fail, which means when one service calls another, it should expect to have to retry a number of times at the least. Now when a service has to potentially call many services, we end up in a complicated situation.&lt;/p>
&lt;p>Imagine a user uploads a video in the video sharing service. We might need to run the upload service, pass data to the transcode service, update subscriptions, update recommendations and so on. All of these calls require a degree of orchestration, if things fail we need to retry.&lt;/p>
&lt;p>This retry logic can get hard to manage. Trying to do things synchronously often ends up being untenable, there are too many points of failure. In this case, a more reliable solution is to use asynchronous patterns to handle communication. The challenge here is that asynchronous patterns inherently make a system stateful. As mentioned in the previous point, stateful systems and systems with distributed state are very hard to handle.&lt;/p>
&lt;p>When a microservice system uses message queues for intra-service communication, you essentially have a large database (the message queue or broker) glueing the services together. Again, although it might not seem like a challenge at first, schema will come back to bite you. A service at version X might write a message with a certain format, services which depend on this message will also need to be updated when the sending service changes the details of the message it sends.&lt;/p>
&lt;p>It is possible to have services which can handle messages in many different formats, but this is hard to manage. Now when deploying new versions of services, you will have times where two different versions of a service may be trying to process messages from the same queue, perhaps even messages sent by different versions of a sending service. This can lead to complicated edge cases. To avoid these edge cases, it may be easier to only allow certain versions of messages to exist, meaning that you need to deploy a set of versions of a set of services as a coherent whole, ensuring messages of older versions are drained appropriately first.&lt;/p>
&lt;p>This highlights again that the idea of independent deployments may not hold as expected when you get into the details.&lt;/p>
&lt;p>&lt;strong>Versioning can be hard&lt;/strong>&lt;/p>
&lt;p>To mitigate the challenges mentioned previously, versioning needs to be very carefully managed. Again, there can be a tendency to assume that following a standard such as semver[4] will solve the problem. It doesn&amp;rsquo;t. Semver is a sensible convention to use, but you will still have to track the versions of services and APIs which can work together.&lt;/p>
&lt;p>This can get very challenging very quickly, and may get to the point where you don&amp;rsquo;t know which versions of services will actually work properly together.&lt;/p>
&lt;p>Managing dependencies in software systems is notoriously hard, whether it is node modules, Java modules, C libraries or whatever. The challenges of &lt;em>conflicts between independent components&lt;/em> when consumed by a single entity are very hard to deal with.&lt;/p>
&lt;p>These challenges are hard to deal with when the dependencies are static, and can be patched, updated, edited and so on, but if the dependencies are themselves &lt;em>live services&lt;/em>, then you may not be able to just update them - you may have to run many versions (with the challenges already described) or bring down the system until it is fixed holistically.&lt;/p>
&lt;p>&lt;strong>Distributed Transactions&lt;/strong>&lt;/p>
&lt;p>In situations where you need transaction integrity across an operation, microservices can be very painful. Distributed state is hard to deal with, many small units which can fail make orchestrating transactions very hard.&lt;/p>
&lt;p>It may be tempting to attempt to avoid the problem by making operations idempotent, offering retry mechanisms and so on, and in many cases this might work. But you may have scenarios where you simply need a transaction to fail or succeed, and never be in an intermediate state. The effort involved in working around this or implementing it in a microservice model may be very high.&lt;/p>
&lt;p>&lt;strong>Microservices can be monoliths in disguise&lt;/strong>&lt;/p>
&lt;p>Yes, individual services and components &lt;em>may&lt;/em> be deployed in isolation, however in most cases you are going to have to be running some kind of orchestration platform, such as Kubernetes. If you are using a managed service, such as Google&amp;rsquo;s GKE&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> or Amazon&amp;rsquo;s EKS&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>, then a large amount of the complexity of managing the cluster is handled for you.&lt;/p>
&lt;p>However, if you are managing the cluster yourself, you are managing a large, complicated, mission critical system. Although the individual services may have all of the benefits described earlier, you need to very carefully manage your cluster. Deployments of this system can be hard, updates can be hard, failover can be hard and so on.&lt;/p>
&lt;p>In many cases the overall benefits are still there, but it is important not to trivialise or underestimate the additional complexity of managing another big, complex system. Managed services may help, but in many cases these services are nascent (Amazon EKS was only announced at the end of 2017 for example).&lt;/p>
&lt;p>&lt;strong>Networking Nightmares&lt;/strong>&lt;/p>
&lt;p>A more traditional model of services running on known hosts, with known addresses, has a fairly simple networking setup.&lt;/p>
&lt;p>However, when using microservices, generally there will be many services distributed across many nodes, which typically means there&amp;rsquo;s going to be a &lt;em>much&lt;/em> more complicated networking arrangement. There will be load balancing between services, DNS may be more heavily used, virtual networking layers, etc etc, to attempt to &amp;lsquo;hide&amp;rsquo; the complexity of this networking.&lt;/p>
&lt;p>However, as per &lt;a href="https://github.com/dwmkerr/hacker-laws/#the-law-of-conservation-of-complexity-teslers-law">Tesler&amp;rsquo;s Law&lt;/a> (or the Law of Conservation of Compexlity), this networking complexity is inherent - when you are finding real, runtime issues in larger scale clusters, it can often be at a very low networking level. These sorts of issues can be &lt;em>very&lt;/em> hard to diagnose. I have started tracking some examples at the end of the article, but I think that &lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder&amp;rsquo;s Migration to Kuberenetes&lt;/a> shows this challenge very well.&lt;/p>
&lt;p>Overall - the transition is still likely to be for the best, but doesn&amp;rsquo;t come without some serious challenges at the networking level, which will require some serious expertise to deal with!&lt;/p>
&lt;h2 id="the-death-of-microservice-madness">The Death of Microservice Madness!&lt;/h2>
&lt;p>Avoid the madness by making careful and considered decisions. To help out on this I&amp;rsquo;ve noted a few questions you might want to ask yourself, and what the answers might indicate:&lt;/p>
&lt;p>&lt;img src="images/questions.png" alt="Diagram: Questions to ask yourself when considering microservices">&lt;/p>
&lt;p>You can download a PDF copy here: &lt;a href="https://github.com/dwmkerr/blog/blob/master/articles/2018/microservice-madness/images/microservice-questions.pdf">microservice-questions.pdf&lt;/a>&lt;/p>
&lt;h2 id="final-thoughts-dont-confuse-microservices-with-architecture">Final Thoughts: Don&amp;rsquo;t Confuse Microservices with Architecture&lt;/h2>
&lt;p>I&amp;rsquo;ve deliberately avoided the &amp;lsquo;a&amp;rsquo; word in this article. But my friend &lt;a href="http://twitter.com/zoltanarvai">Zoltan&lt;/a> made a very good point when proofing this article (which he has contributed to).&lt;/p>
&lt;p>There is no microservice architecture. Microservices are just another pattern or implementation of components, nothing more, nothing less. Whether they are present in a system or not does not mean that the architecture of the system is solved.&lt;/p>
&lt;p>Microservices relate in many ways more to the technical processes around packaging and operations rather than the intrinsic design of the system. Appropriate boundaries for components continues to be one of the most important challenges in engineering systems.&lt;/p>
&lt;p>Regardless of the size of your services, whether they are in Docker containers or not, you will always need to think carefully about how to put a system together. There are no right answers, and there are a &lt;em>lot&lt;/em> of options.&lt;/p>
&lt;p>I hope you found this article interesting! As always, please do comment below if you have any questions or thoughts. You can also follow some lively discussions on:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="appendix-further-reading">Appendix: Further Reading&lt;/h2>
&lt;p>The following links might be of interest:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://martinfowler.com/bliki/BoundedContext.html">Martin Fowler - Bounded Context&lt;/a> - Martin&amp;rsquo;s articles are great, I&amp;rsquo;d thoroughly recommend this.&lt;/li>
&lt;li>&lt;a href="https://martinfowler.com/articles/microservices.html">Martin Fowler - Microservices&lt;/a> - An often recommended introduction to the pattern.&lt;/li>
&lt;li>&lt;a href="https://r2m.se/microservices-good-or-bad/">Microservices - Good or Bad?&lt;/a> - Björn Frantzén&amp;rsquo;s thoughts on microservices, after reading this article.&lt;/li>
&lt;li>&lt;a href="http://blog.christianposta.com/microservices/when-not-to-do-microservices/">When Not To Do Microservices&lt;/a> - Excellent post on the topic from Christian Posta&lt;/li>
&lt;li>&lt;a href="http://www.iheavy.com/2017/03/13/30-questions-to-ask-a-serverless-fanboy/">Sean Hull - 30 questions to ask a serverless fanboy&lt;/a> - Interesting thoughts on the challenges of serverless, from a serverless fan!&lt;/li>
&lt;li>&lt;a href="https://youtu.be/NVb7aljfKYo?t=6657">Dave Kerr - Monoliths to Microservices - Practical tips for CI/CD and DevOps in the Microservice world&lt;/a> - A recent conference presentation I did on devops with microservices.&lt;/li>
&lt;li>&lt;a href="https://yermakov.net/microservices-without-fundamentals/">Alexander Yermakov - Microservices without fundamentals&lt;/a> - A response to this article, with Alex&amp;rsquo;s thoughts and counterpoints to the points raised here (see also &lt;a href="https://yermakov.net/microservices-as-a-self-sufficient-concept/">Microservices as a self sufficient concept&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>Please do share anything else you think makes great reading or watching on the topic!&lt;/p>
&lt;hr>
&lt;h2 id="thanks">Thanks&lt;/h2>
&lt;p>Thanks José from &lt;a href="https://www.campusmvp.es">campusmvp.es&lt;/a> for having the article translated in Spanish - &lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">La muerte de la locura de los microservicios en 2018&lt;/a>!&lt;/p>
&lt;h2 id="case-studies">Case Studies&lt;/h2>
&lt;p>Some interesting examples of experiences I am collecting of larger organisations who have made large scale transitions to microservices:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder&amp;rsquo;s Move to Kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="references">References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice">https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If you don&amp;rsquo;t want to miss the article, you can subscribe to the &lt;a href="http://www.dwmkerr.com/rss/">RSS Feed&lt;/a>, or follow me on &lt;a href="https://www.linkedin.com/in/dwmkerr/">LinkedIn&lt;/a> or &lt;a href="https://twitter.com/dwmkerr">Twitter&lt;/a>.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Docker Compose is a good solution, &lt;a href="https://github.com/apparatus/fuge">Fuge&lt;/a> is very clever, and there is also the option of running orchestration locally as is the case with something like MiniKube.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Google Kubernetes Engine, a managed service from Google Cloud Platform for Kubernetes: &lt;a href="https://cloud.google.com/kubernetes-engine/">https://cloud.google.com/kubernetes-engine/&lt;/a>&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Amazon Elastic Container Services for Kubernetes, a managed service from Amazon Web Services for Kubernetes: &lt;a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/&lt;/a>&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Integrating OpenShift and Splunk for Docker Container Logging</title><link>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</link><pubDate>Sun, 29 Oct 2017 07:15:04 +0000</pubDate><guid>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</guid><description>&lt;p>In this article I&amp;rsquo;m going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.&lt;/p>
&lt;p>These techniques could easily be adapted for a standard Kubernetes installation as well!&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>The techniques used in this article are based on the &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging">Kubernetes Logging Cluster Administration Guide&lt;/a>. I also found Jason Poon&amp;rsquo;s article &lt;a href="http://jasonpoon.ca/2017/04/03/kubernetes-logging-with-splunk/">Kubernetes Logging with Splunk&lt;/a> very helpful.&lt;/p>
&lt;p>First, clone the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">Terraform AWS OpenShift&lt;/a> repo:&lt;/p>
&lt;pre tabindex="0">&lt;code>git clone git@github.com:dwmkerr/terraform-aws-openshift
&lt;/code>&lt;/pre>&lt;p>This repo can be used to create a vanilla OpenShift cluster. I&amp;rsquo;m adding &amp;lsquo;recipes&amp;rsquo; to the project, which will allow you to mix in more features (but still keep the main codebase clean). For now, let&amp;rsquo;s merge in the &amp;lsquo;splunk&amp;rsquo; recipe:&lt;/p>
&lt;pre tabindex="0">&lt;code>cd terraform-aws-openshift
git pull origin recipes/splunk
&lt;/code>&lt;/pre>&lt;p>Pulling this recipe in adds the extra config and scripts required to set up Splunk&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Now we&amp;rsquo;ve got the code, we can get started!&lt;/p>
&lt;h2 id="create-the-infrastructure">Create the Infrastructure&lt;/h2>
&lt;p>To create the cluster, you&amp;rsquo;ll need to install the &lt;a href="https://aws.amazon.com/cli/">AWS CLI&lt;/a> and log in, and install &lt;a href="https://www.terraform.io/downloads.html">Terraform&lt;/a>.&lt;/p>
&lt;p>Before you continue, &lt;font color="red">&lt;strong>be aware&lt;/strong>&lt;/font>: the machines on AWS we&amp;rsquo;ll create are going to run to about $250 per month:&lt;/p>
&lt;p>&lt;img src="images/aws-cost.png" alt="AWS Cost Calculator">&lt;/p>
&lt;p>Once you are logged in with the AWS CLI just run:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make infrastructure
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You&amp;rsquo;ll be asked to specify a region:&lt;/p>
&lt;p>&lt;img src="images/region.png" alt="Specify Region">&lt;/p>
&lt;p>Any &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">AWS region&lt;/a> will work fine, use &lt;code>us-east-1&lt;/code> if you are not sure.&lt;/p>
&lt;p>It&amp;rsquo;ll take about 5 minutes for Terraform to build the required infrastructure, which looks like this:&lt;/p>
&lt;p>&lt;img src="images/splunk-architecture.png" alt="AWS Infrastructure">&lt;/p>
&lt;p>Once it&amp;rsquo;s done you&amp;rsquo;ll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/apply-complete.png" alt="Apply Complete">&lt;/p>
&lt;p>The infrastructure is ready! A few of the most useful parameters are shown as output variables. If you log into AWS you&amp;rsquo;ll see our new instances, as well as the VPC, network settings etc etc:&lt;/p>
&lt;p>&lt;img src="images/aws.png" alt="AWS">&lt;/p>
&lt;h2 id="installing-openshift">Installing OpenShift&lt;/h2>
&lt;p>Installing OpenShift is easy:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make openshift
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will take quite some time to run (sometimes up to 30 minutes). Once it is complete you&amp;rsquo;ll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/openshift-complete.png" alt="OpenShift Installation Complete">&lt;/p>
&lt;p>You can now open the OpenShift console. Use the public address of the master node (which you can get with &lt;code>$(terraform output master-url)&lt;/code>), or just run:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make browse-openshift
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The default username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You&amp;rsquo;ll see we have a clean installation and are ready to create our first project:&lt;/p>
&lt;p>&lt;img src="images/welcome-to-openshift.png" alt="Welcome to OpenShift">&lt;/p>
&lt;p>Close the console for now.&lt;/p>
&lt;h2 id="installing-splunk">Installing Splunk&lt;/h2>
&lt;p>You&amp;rsquo;ve probably figured out the pattern by now&amp;hellip;&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make splunk
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once this command is complete, you can open the Splunk console with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make browse-splunk
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again the username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You can change the password on login, or leave it:&lt;/p>
&lt;p>&lt;img src="images/splunk-home.png" alt="Splunk Login">&lt;/p>
&lt;p>You can close the Splunk console now, we&amp;rsquo;ll come back to it shortly.&lt;/p>
&lt;h2 id="demoing-splunk-and-openshift">Demoing Splunk and OpenShift&lt;/h2>
&lt;p>To see Splunk and OpenShift in action, it helps to have some kind of processing going on in the cluster. You can create a very basic sample project which will spin up two nodes which just write a counter every second as a way to get something running:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make sample
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will create a simple &amp;lsquo;counter&amp;rsquo; service:&lt;/p>
&lt;p>&lt;img src="images/counter-service.png" alt="Screenshot: The counter service">&lt;/p>
&lt;p>We can see the logs in OpenShift:&lt;/p>
&lt;p>&lt;img src="images/counter-service-logs.png" alt="Screenshot: The counter service logs">&lt;/p>
&lt;p>Almost immediately you&amp;rsquo;ll be able to see the data in Splunk:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk-data-summary.png" alt="Screenshot: The Splunk data explorer">&lt;/p>
&lt;p>And because of the way the log files are named, we can even rip out the namespace, pod, container and id:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>That&amp;rsquo;s it! You have OpenShift running, Splunk set up and automatically forwarding of all container logs. Enjoy!&lt;/p>
&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>I&amp;rsquo;ve tried to keep the setup as simple as possible. Here&amp;rsquo;s how it works.&lt;/p>
&lt;h3 id="how-log-files-are-written">How Log Files Are Written&lt;/h3>
&lt;p>The Docker Engine has a &lt;a href="https://docs.docker.com/engine/admin/logging/overview/">log driver&lt;/a> which determines how container logs are handled&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. It defaults to the &lt;code>json-file&lt;/code> driver, which means that logs are written as a json file to:&lt;/p>
&lt;pre tabindex="0">&lt;code>/var/lib/docker/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;p>Or visually:&lt;/p>
&lt;p>&lt;img src="images/logging-docker-1.png" alt="Diagram: How Docker writes log files">&lt;/p>
&lt;p>Normally we wouldn&amp;rsquo;t touch this file, in theory it is supposed to be used internally&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> and we would use &lt;code>docker logs &amp;lt;container-id&amp;gt;&lt;/code>.&lt;/p>
&lt;p>In theory, all we need to do is use a &lt;a href="http://docs.splunk.com/Documentation/Forwarder/7.0.0/Forwarder/Abouttheuniversalforwarder">Splunk Forwarder&lt;/a> to send this file to our indexer. The only problem is that we only get the container ID from the file name, finding the right container ID for your container can be a pain. However, we are running on Kubernetes, which means the picture is a little different&amp;hellip;&lt;/p>
&lt;h3 id="how-log-files-are-written---on-kubernetes">How Log Files Are Written - on Kubernetes&lt;/h3>
&lt;p>When running on Kubernetes, things are little different. On machines with &lt;code>systemd&lt;/code>, the log driver for the docker engine is set to &lt;code>journald&lt;/code> (see &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Kubernetes - Logging Architecture&lt;/a>.&lt;/p>
&lt;p>It &lt;em>is&lt;/em> possible to forward &lt;code>journald&lt;/code> to Splunk, but only by streaming it to a file and then forwarding the file. Given that we need to use a file as an intermediate, it seems easier just to change the driver back to &lt;code>json-file&lt;/code> and forward that.&lt;/p>
&lt;p>So first, we configure the docker engine to use &lt;code>json-file&lt;/code> (see &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/blob/recipes/splunk/scripts/postinstall-master.sh">this file&lt;/a>):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>sed -i &lt;span style="color:#e6db74">&amp;#39;/OPTIONS=.*/c\OPTIONS=&amp;#34;--selinux-enabled --insecure-registry 172.30.0.0/16 --log-driver=json-file --log-opt max-size=1M --log-opt max-file=3&amp;#34;&amp;#39;&lt;/span> /etc/sysconfig/docker
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we just change the options to default to the &lt;code>json-file&lt;/code> driver, with a max file size of 1MB (and maximum of three files, so we don&amp;rsquo;t chew all the space on the host).&lt;/p>
&lt;p>Now the cool thing about Kubernetes is that it creates symlinks to the log files, which have much more descriptive names:&lt;/p>
&lt;p>&lt;img src="images/logging-k8s.png" alt="Symlink diagram">&lt;/p>
&lt;p>We still have the original container log, in the same location. But we also have a pod container log (which is a symlink to the container log) and another container log, which is a symlink to the pod container log.&lt;/p>
&lt;p>This means we can read the container log, and extract some really useful information from the file name. The container log file name has the following format:&lt;/p>
&lt;pre tabindex="0">&lt;code>/var/log/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;h3 id="how-log-files-are-read">How Log Files Are Read&lt;/h3>
&lt;p>Now that we are writing the log files to a well defined location, reading them is straightforward. The diagram below shows how we use a splunk-forwarder to complete the picture:&lt;/p>
&lt;p>&lt;img src="images/how-logs-are-read.png" alt="Diagram: How logs are read">&lt;/p>
&lt;p>First, we create a DaemonSet, which ensures we run a specific pod on every node.&lt;/p>
&lt;p>The DaemonSet runs with a new account which has the &amp;lsquo;any id&amp;rsquo; privilege, allowing it to run as root. We then mount the log folders into the container (which are owned by root, which is why our container needs these extra permissions to read the files).&lt;/p>
&lt;p>The pod contains a splunk-forwarder container, which is configured to monitor the &lt;code>/var/log/containers&lt;/code> folder. It also monitors the docker socket, allowing us to see docker events. The forwarder is also configured with the IP address of the Splunk Indexer.&lt;/p>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>As a reference, you can also see the recipe pull request to see what changes from a &amp;lsquo;vanilla&amp;rsquo; installation to add Splunk: &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/pull/16">Splunk Recipe Pull Request&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>It is useful to check the documentation on logging drivers for Docker. See &lt;a href="https://docs.docker.com/engine/admin/logging/overview/#supported-logging-drivers">Configure Logging Drivers&lt;/a> and &lt;a href="https://docs.docker.com/engine/extend/plugins_logging/">Docker Log Driver Plugins&lt;/a>. It is possible to create custom log drivers. However, at the time of writing only the journald and json-file log drivers will work with the integrated logging view in OpenShift.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item></channel></rss>