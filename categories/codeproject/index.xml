<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CodeProject on dwmkerr.com</title><link>https://dwmkerr.com/categories/codeproject/</link><description>Recent content in CodeProject on dwmkerr.com</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Copright &amp;copy; Dave Kerr</copyright><lastBuildDate>Thu, 04 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://dwmkerr.com/categories/codeproject/index.xml" rel="self" type="application/rss+xml"/><item><title>Observations, tips and tricks for the CKA certification</title><link>https://dwmkerr.com/tips-for-cka/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/tips-for-cka/</guid><description>&lt;p>In this article I'll share some observations, tips and tricks for the &lt;a href="https://www.linuxfoundation.org/">Linux Foundation's&lt;/a> &amp;ldquo;&lt;a href="https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/">Certified Kubernetes Administrator&lt;/a> certification and exam.&lt;/p>
&lt;p>I've been operating Kubernetes in multiple environments for a few years now. I thought this would be an easy certification to get, but I was surprised by how hard it was!&lt;/p>
&lt;p>I took this exam without doing any formal training, I mostly focused on the areas of the curriculum which I knew I was a little weak at. The task-based structure for the exam I thought was really excellent. It took me two attempts to pass, and I learnt a few things along the way.&lt;/p>
&lt;p>Here I'll share some thoughts on the certification which hopefully will be useful if you are considering taking it!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#tip-do-the-right-certification">Tip: Do the right Certification!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-understand-the-format">Tip: Understand the Format!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-your-vim">Tip: Know your Vim&lt;/a>&lt;/li>
&lt;li>&lt;a href="#you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That's it!&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h2 id="tip-do-the-right-certification">Tip: Do the right Certification!&lt;/h2>
&lt;p>The CKA exam tests &lt;em>administration&lt;/em> and &lt;em>operation&lt;/em> skills and techniques for Kubernetes. If you have set up and administered clusters before, this will likely not be too challenging. But if you've never set up a cluster by hand, troubleshot weird issues, fixed clusters and so on, then this is likely going to be very hard.&lt;/p>
&lt;p>There is a certification which is much more geared towards developers who use Kubernetes, but don't necessarily administer it - that's the &lt;a href="https://www.cncf.io/certification/ckad/">CKAD&lt;/a> exam and might be the one to take if you are not too familiar with system administration.&lt;/p>
&lt;h2 id="tip-understand-the-format">Tip: Understand the Format!&lt;/h2>
&lt;p>This is not a multiple choice question exam. It's a task based exam, meaning you have about 22 or so specific tasks to complete, in a web browser which has a terminal connected to a cluster.&lt;/p>
&lt;p>It is open-book - meaning that you can use the &lt;a href="https://kubernetes.io/docs/home/">Kubernetes Documentation&lt;/a> during the exam. It's not a memory test of specific flags for commands or whatever, it will really require you to work with a running cluster. This means you'll have to be pretty familiar with &lt;code>kubectl&lt;/code>, &lt;code>kubeadm&lt;/code> and also Linux in general!&lt;/p>
&lt;h2 id="tip-know-your-vim">Tip: Know your Vim&lt;/h2>
&lt;p>In the two exams I took, &lt;code>nano&lt;/code> was available. But if you are using &lt;code>nano&lt;/code> to work with files you may struggle for time.&lt;/p>
&lt;p>I spent a &lt;em>lot&lt;/em> of time in &lt;code>vim&lt;/code> in the exam. &lt;code>vim&lt;/code> is my main text editor for day to day work, so I'm fairly familiar with it. Knowing how to quickly copy a file (lets say for example a file which represents a deployment) and quickly manipulate the text in it will be crucial. Make sure you are going to be using a text editor which you can be efficient in!&lt;/p>
&lt;p>You won't be using a graphical text editor to work with files, so being competent in a terminal editor like &lt;code>vim&lt;/code> or &lt;code>emacs&lt;/code> could make a big difference. Of course you could install your favourite text editor, but you won't be able to use a graphical editor like VS Code.&lt;/p>
&lt;p>Also, as in most Linux distributions, &lt;code>screen&lt;/code> is available out of the box, and &lt;code>tmux&lt;/code> can also be installed. If you are familiar with either of these terminal mutliplexers it could save you a tonne of time, for example being able to run &lt;code>watch -n 5 -d kubectl get pods&lt;/code> in one pane while applying resources in another.&lt;/p>
&lt;h2 id="you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/h2>
&lt;p>This exam will require you to deal with trivial tasks such as running a deployment or creating a volume. But the questions which focus on that tend to only count for one or two percent of the overall grade each. Questions which deal with troubleshooting actual Kubernetes issues could count for six or seven percent each.&lt;/p>
&lt;p>This means you &lt;em>need&lt;/em> to know how Kubernetes is architecture. The &lt;code>kubelet&lt;/code> which runs on nodes, the API server, the &lt;code>etcd&lt;/code> store, all of these things you &lt;em>have&lt;/em> to understand how they work and how they fit together.&lt;/p>
&lt;p>The online documentation covers the architecture in detail, here's the best place to start:&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">&lt;img src="./images/k8s-architecture.png" alt="Kubernetes Architecture">&lt;/a>&lt;/p>
&lt;p>You will need to know how the control plane works, how nodes communicate, how transport of messages works and is secured if you are going to have a chance at dealing with the harder questions.&lt;/p>
&lt;h2 id="tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/h2>
&lt;p>If you are not familiar with &lt;code>systemctl&lt;/code>, &lt;code>journalctl&lt;/code>, &lt;code>apt&lt;/code>, &lt;code>systemd&lt;/code> units and how the core Kubernetes components are configured, you'll really struggle.&lt;/p>
&lt;p>Look over the &lt;a href="https://github.com/cncf/curriculum">CNCF curriculum&lt;/a> - expect to not just have to know how to deal with &amp;lsquo;happy path&amp;rsquo; situations, but also broken clusters, incorrect configuration and so on.&lt;/p>
&lt;h2 id="tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/h2>
&lt;p>One thing which helped me a lot in my second attempt at the exam was the &lt;code>--dry-run&lt;/code> flag. Before you create resources or change anything, run the operation with the &lt;code>--dry-run&lt;/code> flag and see whether the output is what you would expect.&lt;/p>
&lt;p>This is a quick and easy way to see the changes to the cluster which you are going to apply - and troubleshoot them - before making any actual changes.&lt;/p>
&lt;h2 id="tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/h2>
&lt;p>Networking in Kubernetes is complex. You must be able to troubleshoot networking issues in the cluster to be able to deal with the more complex tasks.&lt;/p>
&lt;p>This means that you should know how to be able to run typical networking tools like &lt;code>dig&lt;/code>, &lt;code>nslookup&lt;/code>, &lt;code>telnet&lt;/code> etc, in the cluster itself.&lt;/p>
&lt;p>If you are not familiar with these tools you might need to take an online course in Kubernetes or Linux Networking Administration before considering this certification. The &lt;a href="https://training.linuxfoundation.org/certification/linux-foundation-certified-sysadmin-lfcs/">Linux Certified Systems Administrator&lt;/a> training would be a good place to start.&lt;/p>
&lt;p>If you have taken the &lt;a href="https://success.docker.com/certification">Docker Certified Associate&lt;/a> exam then some of this should be familiar. If you are not very familiar with how Docker itself works, you'll likely struggle with Kubernetes.&lt;/p>
&lt;h2 id="tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/h2>
&lt;p>There are a lot of tasks which only count for one or two percent each; these ones you should be able to complete in a few minutes. You'll need all the time in the exam to work on the really hard questions which deal with diagnosing and fixing cluster issues.&lt;/p>
&lt;p>Know your core Kubernetes concepts; if you have done the CKAD exam you should be good, if not, check the curriculum and make sure you can quickly complete all of the trivial tasks without wasting too much time.&lt;/p>
&lt;h2 id="thats-it">That's it!&lt;/h2>
&lt;p>Hopefully this was helpful! Good luck if you are taking the exam and hopefully you'll find it a challenging but rewarding experience. I've taken many exams over the years but this was one of the most challenging, but also one of the most enjoyable, I really felt like it was testing practical techniques rather than your ability to just remember random commands and flags.&lt;/p>
&lt;p>As always, if you have any comments or questions, please just add them in the section below!&lt;/p>
&lt;p>&lt;img src="./images/cka-cert.png" alt="CKA Certification">&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell for Beginners</title><link>https://dwmkerr.com/effective-shell-for-beginners/</link><pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-for-beginners/</guid><description>&lt;p>I have rebuilt my &amp;ldquo;Effective Shell&amp;rdquo; series as an online book - it's available now on:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">https://effective-shell.com&lt;/a>&lt;/p>
&lt;p>The whole site is built from a GitHub repo at &lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>. It is open for contributions, changes, issues and suggestions. I've also added a comment section to each page to get input.&lt;/p>
&lt;p>To keep the material as accessible as possible, I have added a new section for beginners, to help anyone who has not used a shell before. It goes over who the book is useful for, what the shell is, and how to set up your computer to work through the material:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">&lt;img src="images/effective-shell-screenshot.png" alt="Effective Shell: Screenshot" width="1024px" />&lt;/a>&lt;/p>
&lt;p>All comments and suggestions are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell Part 7: The Subtleties of Shell Commands</title><link>https://dwmkerr.com/effective-shell-7-shell-commands/</link><pubDate>Tue, 25 Jun 2019 07:25:23 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-7-shell-commands/</guid><description>&lt;p>In this chapter, we'll take a look at the various different types of shell commands that exist and how this can affect your work.&lt;/p>
&lt;p>By the end of this chapter, you might even be able to make sense of the horrifying and perfectly syntactically valid code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">which &lt;span style="color:#66d9ef">$(&lt;/span>where &lt;span style="color:#66d9ef">$(&lt;/span>what &lt;span style="color:#66d9ef">$(&lt;/span>whence &lt;span style="color:#66d9ef">$(&lt;/span>whereis who&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="what-are-commands">What Are Commands?&lt;/h2>
&lt;p>This is &lt;em>really&lt;/em> important to understand! A &lt;em>command&lt;/em> in a shell is something you execute. It might take parameters. Generally it'll have a form like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">command param1 param2
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've already seen many commands during this series:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">ls &lt;span style="color:#75715e"># Show the contents of the current directory&lt;/span>
cd ~ &lt;span style="color:#75715e"># Move to the user&amp;#39;s home&lt;/span>
cat file.txt &lt;span style="color:#75715e"># Output the contents of &amp;#39;file.txt&amp;#39; to stdout&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But to be an effective shell user, you must understand that not all commands are created equal. The differences between the types of commands will affect how you use them.&lt;/p>
&lt;p>There are four types of commands in most shells:&lt;/p>
&lt;ol>
&lt;li>Executables&lt;/li>
&lt;li>&amp;ldquo;Built-Ins&amp;rdquo; (which we'll just call &lt;em>builtins&lt;/em> from now on)&lt;/li>
&lt;li>Functions&lt;/li>
&lt;li>Aliases&lt;/li>
&lt;/ol>
&lt;p>Let's quickly dig in and see a bit more.&lt;/p>
&lt;h2 id="executables---programs">Executables - Programs&lt;/h2>
&lt;p>Executables are just files with the &amp;lsquo;executable&amp;rsquo; bit set&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. If I execute the &lt;code>cat&lt;/code> command, the shell will search for an executable named &lt;code>cat&lt;/code> in my &lt;code>$PATH&lt;/code>. If it finds it, it will run the program.&lt;/p>
&lt;pre>&lt;code>$ cat file.txt
This is a simple text file
&lt;/code>&lt;/pre>&lt;p>What is &lt;code>$PATH&lt;/code>? &lt;code>$PATH&lt;/code> is the standard environment variable used to define &lt;em>where&lt;/em> the shell should search for programs. If we temporarily &lt;em>empty&lt;/em> this variable, the shell won't find the command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span> cat file.txt
bash: cat: No such file or directory
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Normally your &lt;code>$PATH&lt;/code> variable will include the standard locations for Linux programs - folders such as &lt;code>/bin&lt;/code>, &lt;code>/sbin&lt;/code>, &lt;code>/usr/bin&lt;/code> and so on&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>If you were to print the variable, you'd see a bunch of paths (they are separated by colons; I've put them on separate lines for readability):&lt;/p>
&lt;pre>&lt;code>/usr/local/bin
/usr/bin
/bin
/usr/sbin
/sbin
&lt;/code>&lt;/pre>&lt;p>The shell will start with the &lt;em>earlier&lt;/em> locations and move to the later ones. This allows &lt;em>local&lt;/em> flavours of tools to be installed for users, which will take precedence over &lt;em>general&lt;/em> versions of tools.&lt;/p>
&lt;p>There will likely be other locations too - you might see Java folders, package manager folders and so on.&lt;/p>
&lt;h2 id="executables---scripts">Executables - Scripts&lt;/h2>
&lt;p>Imagine we create a text file called &lt;code>dog&lt;/code> in the local folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>echo &lt;span style="color:#e6db74">&amp;#34;🐶 woof 🐶&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If we make the file &lt;em>executable&lt;/em>, by running &lt;code>chmod +x dog&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, then we can run this just like any other program - as long as we tell the shell to look for programs in the current directory:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span> dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>More common would be to run the program by giving a path:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ./dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Or just move it to a standard location that the shell already checks for programs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ mv dog /usr/local/bin
$ dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The point is that executables don't &lt;em>have&lt;/em> to be compiled program code. If a file starts with &lt;code>#!&lt;/code> (the &amp;lsquo;shebang&amp;rsquo;), then the system will try to run the contents of the file with the program specified in the shebang.&lt;/p>
&lt;p>We will look at shebangs in greater detail in a later chapter.&lt;/p>
&lt;h2 id="builtins">Builtins&lt;/h2>
&lt;p>OK, so we've seen executables. What about a command like this?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">local V&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hello&amp;#34;&lt;/span> echo $V
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will not find the &lt;code>local&lt;/code> executable anywhere on your system. It is a &lt;em>builtin&lt;/em> - a special command built directly into the shell program.&lt;/p>
&lt;p>Builtins are often highly specific to your shell. They might be used for programming (&lt;code>local&lt;/code> for example is used to declare a locally scoped variable), or they might be for very shell-specific features.&lt;/p>
&lt;p>This is where we need to take note. As soon as you are running a builtin, you are potentially using a feature that is specific to &lt;em>your&lt;/em> shell, rather than a program that is shared across the system and can be run by &lt;em>any&lt;/em> shell.&lt;/p>
&lt;p>Trying to programmatically execute &lt;code>local&lt;/code> as a process will fail - there is no executable with that name; it is purely a shell construct.&lt;/p>
&lt;p>So how do we know if a command is a builtin? The preferred method is to use the &lt;code>type&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type local
local is a shell builtin
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>type&lt;/code> command (which is &lt;em>itself&lt;/em> a builtin!) can tell you the exact type of shell command.&lt;/p>
&lt;p>Interestingly, you might be using more builtins than you think. &lt;code>echo&lt;/code> is a program, but most of the time you are not executing it when you are in a shell:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a echo
echo is a shell builtin
echo is /bin/echo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By using the &lt;code>-a&lt;/code> flag on &lt;code>type&lt;/code> to show &lt;em>all&lt;/em> commands that match the name, we see that &lt;code>echo&lt;/code> is actually both a builtin &lt;em>and&lt;/em> a program.&lt;/p>
&lt;p>Many simple programs have builtin versions. The shell can execute them much faster.&lt;/p>
&lt;p>Some commands are a builtin so that they can function in a sensible manner. The &lt;code>cd&lt;/code> command changes the current directory - if we executed it as a process, it would change only the directory for the &lt;code>cd&lt;/code> process itself, not the shell, making it much less useful.&lt;/p>
&lt;p>Builtins will vary from shell to shell, but many shells are &amp;lsquo;Bash-like&amp;rsquo; - meaning they will have a set very similar to the Bash builtins, which you can see here:&lt;/p>
&lt;p>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html">https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html&lt;/a>&lt;/p>
&lt;p>As should be familiar from &lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>, you can get help for builtins:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ man source &lt;span style="color:#75715e"># source is a builtin&lt;/span>
BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> BSD General Commands Manual BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span>
NAME
builtin, !, %, &lt;span style="color:#75715e"># ...snip...&lt;/span>
SYNOPSIS
builtin &lt;span style="color:#f92672">[&lt;/span>-options&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">[&lt;/span>args ...&lt;span style="color:#f92672">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, the manual will &lt;em>not&lt;/em> show information on specific builtins, which is a pain. Your shell &lt;em>might&lt;/em> have an option to show more details - for example, in Bash you can use &lt;code>help&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ help source
source: source filename &lt;span style="color:#f92672">[&lt;/span>arguments&lt;span style="color:#f92672">]&lt;/span>
Read and execute commands from FILENAME and &lt;span style="color:#66d9ef">return&lt;/span>. The pathnames
in $PATH are used to find the directory containing FILENAME. If any
ARGUMENTS are supplied, they become the positional parameters when
FILENAME is executed.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But remember: &lt;code>help&lt;/code> is a builtin; you might not find it in all shells (you won't find it in &lt;code>zsh&lt;/code>, for example). This highlights again the challenges of builtins.&lt;/p>
&lt;h2 id="functions">Functions&lt;/h2>
&lt;p>You can define your own shell functions. We will see a lot more of this later, but let's show a quick example for now:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span> exec -l &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$SHELL&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet creates a function that restarts the shell (quite useful if you are messing with shell configuration files or think you might have irreversibly goofed up your current session).&lt;/p>
&lt;p>We can execute this function just like any command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And running &lt;code>type&lt;/code> will show us that this is a function:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type restart-shell
restart-shell is a &lt;span style="color:#66d9ef">function&lt;/span>
restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;span style="color:#f92672">{&lt;/span>
exec -l $SHELL
&lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Functions are one of the most powerful shell constructs we will see; they are extremely useful for building sophisticated logic. We're going to see them in a lot more detail later, but for now it is enough to know that they exist, and can run logic, and are run as commands.&lt;/p>
&lt;h2 id="aliases">Aliases&lt;/h2>
&lt;p>An alias is just a shortcut. Type in a certain set of characters, and the shell will replace them with the value defined in the alias.&lt;/p>
&lt;p>Some common commands are actually already aliases - for example, in my &lt;code>zsh&lt;/code> shell, the &lt;code>ls&lt;/code> command is an alias:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I make sure that when I use the &lt;code>ls&lt;/code> command, the shell always expands it to &lt;code>ls -G&lt;/code>, which colours the output.&lt;/p>
&lt;p>We can quickly define aliases to save on keystrokes. For example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ alias k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;kubectl&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>From this point on, I can use the &lt;code>k&lt;/code> alias as shorthand for the &lt;code>kubectl&lt;/code> command.&lt;/p>
&lt;p>Aliases are far less sophisticated than functions. Think of them as keystroke savers and nothing more, and you won't go far wrong. Aliases are not portable across shells and have certain behaviours which can make them problematic to work with, there will be an entire chapter dedicated to alisases coming up in the series.&lt;/p>
&lt;h2 id="so-what">So What?&lt;/h2>
&lt;p>So we now hopefully have a greater understanding of the variety of shell commands. Not all commands are executables, not all of the commands we &lt;em>think&lt;/em> are executables necessarily are, and some commands might be more sophisticated.&lt;/p>
&lt;p>As a shell user, the key things to remember are:&lt;/p>
&lt;ol>
&lt;li>Executables are &amp;lsquo;safe&amp;rsquo; - they are programs your system can use; your shell just calls out to them.&lt;/li>
&lt;li>Builtins are &lt;em>very&lt;/em> shell-specific and usually control the shell itself&lt;/li>
&lt;li>Functions are powerful ways to write logic but will normally be shell-specific.&lt;/li>
&lt;li>Aliases are conveniences for human operators, but only in the context of an interactive shell.&lt;/li>
&lt;/ol>
&lt;p>To find out how a command is implemented, just use the &lt;code>type -a&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a cat
cat is /bin/cat
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="more-than-you-need-to-know">More than You Need to Know&lt;/h2>
&lt;p>OK, for the masochistic few, you might be wondering about all of the other commands and utilities you may have seen that can tell you about programs and commands:&lt;/p>
&lt;ul>
&lt;li>&lt;code>what&lt;/code>&lt;/li>
&lt;li>&lt;code>whatis&lt;/code>&lt;/li>
&lt;li>&lt;code>which&lt;/code>&lt;/li>
&lt;li>&lt;code>whence&lt;/code>&lt;/li>
&lt;li>&lt;code>where&lt;/code>&lt;/li>
&lt;li>&lt;code>whereis&lt;/code>&lt;/li>
&lt;li>&lt;code>command&lt;/code>&lt;/li>
&lt;li>&lt;code>type&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>A &lt;em>lot&lt;/em> of these are legacy and should be avoided, but for completeness sake, we'll go through them.&lt;/p>
&lt;h3 id="what">&lt;code>what&lt;/code>&lt;/h3>
&lt;p>&lt;code>what&lt;/code> reads out special metadata embedded in a program, generally used to identify the version of source code it was built from:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ what /bin/ls
/bin/ls
Copyright &lt;span style="color:#f92672">(&lt;/span>c&lt;span style="color:#f92672">)&lt;/span> 1989, 1993, &lt;span style="color:#ae81ff">1994&lt;/span>
PROGRAM:ls PROJECT:file_cmds-272.220.1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There should be almost no circumstance in which you need to use it in your day-to-day work, but you might come across it if you &lt;em>meant&lt;/em> to type &lt;code>whatis&lt;/code>.&lt;/p>
&lt;h3 id="whatis">&lt;code>whatis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whatis&lt;/code> searches a local help database for text. This can be useful in tracking down manual pages:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ whatis bash
bash&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - GNU Bourne-Again SHell
bashbug&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - report a bug in bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But I can't imagine it will be a regularly used tool by most users.&lt;/p>
&lt;h3 id="which">&lt;code>which&lt;/code>&lt;/h3>
&lt;p>&lt;code>which&lt;/code> will search your &lt;code>$PATH&lt;/code> to see whether an executable can be found. With the &lt;code>-a&lt;/code> flag, it will show all results.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ which -a vi
/usr/local/bin/vi
/usr/bin/vi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>which&lt;/code> originated in &lt;code>csh&lt;/code>. It remains on many systems for compatibility but in general should be avoided due to potentially odd behaviour&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;h3 id="whence">&lt;code>whence&lt;/code>&lt;/h3>
&lt;p>&lt;code>whence&lt;/code> was added to the Korn shell. You are unlikely to use it unless you are on systems using &lt;code>ksh&lt;/code>. &lt;code>zsh&lt;/code> also has this command, but it should be avoided and considered non-standard.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whence brew
/usr/local/bin/brew
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="where">&lt;code>where&lt;/code>&lt;/h3>
&lt;p>This is a shell builtin that can provide information on commands, similar to &lt;code>type&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% where ls
ls: aliased to ls -G
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, &lt;code>type&lt;/code> should be preferred, as it is more standard.&lt;/p>
&lt;h3 id="whereis">&lt;code>whereis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whereis&lt;/code> is available on some systems and generally operates the same as &lt;code>which&lt;/code>, searching paths for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whereis ls
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, &lt;code>type&lt;/code> should be preferred for compatability.&lt;/p>
&lt;h3 id="command">&lt;code>command&lt;/code>&lt;/h3>
&lt;p>&lt;code>command&lt;/code> is defined in the POSIX standard, so should be expected to be present on most modern systems. Without arguments, it simply executes a command. With the &lt;code>-v&lt;/code> argument, you get a fairly machine-readable or processable response; with the &lt;code>-V&lt;/code> argument, you get a more human readable response:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% command -v ls
alias ls&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;ls -G&amp;#39;&lt;/span>
% command -V ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>command&lt;/code> can be useful in scripts, as we will see in later chapters.&lt;/p>
&lt;h3 id="type">&lt;code>type&lt;/code>&lt;/h3>
&lt;p>&lt;code>type&lt;/code> is part of the Unix standard and will be present in most modern systems. As we've already seen, it will identify the type of command as well as the location for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command can also be used to only search for paths:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -p ls
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Summary&lt;/strong>&lt;/p>
&lt;p>In summary, avoid anything that starts with &amp;lsquo;&lt;code>w&lt;/code>&amp;rsquo;! These are legacy commands, generally needed only when working on older Unix machines. &lt;code>type&lt;/code> or &lt;code>command&lt;/code> should be used instead.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>We will cover permissions and modes in later chapters. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Why these names and locations? It's a long story. The best place to start if you are intersted is the &lt;a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>&lt;code>chmod&lt;/code> changes the mode of a file; &lt;code>+x&lt;/code> means &amp;lsquo;add the executable bit&amp;rsquo;. This tells the operating system the file can be executed. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>&lt;a href="https://unix.stackexchange.com/questions/85249/why-not-use-which-what-to-use-then">Stack Exchange: Why not use “which”? What to use then?&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 6: Everything You Don't Need To Know About Job Control</title><link>https://dwmkerr.com/effective-shell-6-job-control/</link><pubDate>Mon, 10 Jun 2019 08:26:33 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-6-job-control/</guid><description>&lt;p>&lt;em>Job control&lt;/em> is a feature of most shells, which is generally not particularly intuitive to work with. However, knowing the basics can help prevent you from getting yourself into a tangle, and can from time to time make certain tasks a little easier.&lt;/p>
&lt;p>In this chapter, we'll look at the main features of job control, why it can be a problematic, and some alternatives.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-job-control">What Is Job Control?&lt;/h2>
&lt;p>Let's start with an example. I am building a simple web page. It has one &lt;code>index.html&lt;/code> file, one &lt;code>styles.css&lt;/code> file, and one &lt;code>code.js&lt;/code> file. The &lt;code>index.html&lt;/code> file looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">title&lt;/span>&amp;gt;My New Project&amp;lt;/&lt;span style="color:#f92672">title&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text/css&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;styles.css&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Snip... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;/&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Opening the file in a browser doesn't quite work, as it won't load the code or the styles. We need a web server to serve styles and code.&lt;/p>
&lt;p>A super-useful one-liner to run a web server on any machine with Python installed is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, this is so useful that I normally &lt;em>alias&lt;/em> this command, so that I can just type &lt;code>serve&lt;/code>. We'll see aliases in a later chapter.&lt;/p>
&lt;p>For now, if we run this command (you can get &lt;a href="https://github.com/dwmkerr/effective-shell/tree/master/6-job-control/sample">the three sample files here&lt;/a> if you want to try this yourself), then we can open the webpage in a browser, with the styles and code loaded:&lt;/p>
&lt;p>&lt;img src="images/website-screenshot.png" alt="Screenshot: Website" width="600" />&lt;/p>
&lt;p>We can also see that the server has served the HTML, JavaScript, and CSS files:&lt;/p>
&lt;p>&lt;img src="images/server-screenshot.png" alt="Screenshot: Server" width="600" />&lt;/p>
&lt;p>All well and good so far.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>Let's say we want to now continue using our shell, maybe to edit the website with a terminal editor like Vim or Emacs, or we want to zip up the site, or just run any shell command&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We have a problem. The &lt;code>python&lt;/code> process is still running - it's serving the website. Our shell is essentially useless, until we stop the server. See what happens when I try to edit a file:&lt;/p>
&lt;p>&lt;img src="images/blocked-shell.gif" alt="Demo: Blocked Shell" width="600" />&lt;/p>
&lt;p>In the example above, I try to run &lt;code>vi&lt;/code>, but nothing is happening. Standard input is not being read by the server and not being interpreted by the shell.&lt;/p>
&lt;p>I have to kill the server by hitting &lt;code>Ctrl+C&lt;/code> (which sends a &lt;code>SIGINT&lt;/code>&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> - we'll see more about signals later), clear my screen to get rid of all of the error messages, then start again.&lt;/p>
&lt;p>This is obviously not optimal. Let's look at some solutions.&lt;/p>
&lt;h2 id="solution-1-start-the-server-in-the-background">Solution 1: Start the Server in the Background&lt;/h2>
&lt;p>In most shells, you can run a command and instruct the shell to run it in the &lt;em>background&lt;/em>. To do this, you end the line with an ampersand. Here's how the example would look in this case:&lt;/p>
&lt;p>&lt;img src="images/start-in-background.gif" alt="Demo: Starting a Background Job" width="600" />&lt;/p>
&lt;p>By ending the command with an &lt;code>&amp;amp;&lt;/code> ampersand symbol, we instruct the shell to run the command as a &lt;em>background job&lt;/em>. This means that our shell is still functional. The shell has also notified us that this command is running as a background job with a specific &lt;em>job number&lt;/em>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span> &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#ae81ff">19372&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In slightly obtuse language, the shell has informed us that it has started a job in the background, with job number &lt;code>1&lt;/code> and that this job is currently handling the process with ID &lt;code>19372&lt;/code>.&lt;/p>
&lt;p>The ampersand solution is a fairly common pattern used in day-to-day work.&lt;/p>
&lt;h2 id="solution-2-move-the-server-to-the-background">Solution 2: Move the Server to the Background&lt;/h2>
&lt;p>Let's say you forgot to start the command in the background. Most likely in this case you'd kill the server with &lt;code>Ctrl+C&lt;/code> and then start it again with the &lt;code>&amp;amp;&lt;/code> option. However, what if this was a large file download or a task you didn't want to abort?&lt;/p>
&lt;p>In the example below, we'll move the job to the background:&lt;/p>
&lt;p>&lt;img src="images/move-to-background.gif" alt="Demo: Moving a Job to the Background" width="600" />&lt;/p>
&lt;p>The process is currently in the foreground, so my shell is inactive. Hitting &lt;code>Ctrl+Z&lt;/code> sends a &amp;lsquo;suspend&amp;rsquo; signal to the process&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, pausing it and moving it to the background.&lt;/p>
&lt;p>Let's dissect this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
Serving HTTP on 0.0.0.0 port &lt;span style="color:#ae81ff">3000&lt;/span> ...
127.0.0.1 - - &lt;span style="color:#f92672">[&lt;/span>03/Jun/2019 13:38:45&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#e6db74">&amp;#34;GET / HTTP/1.1&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span> -
^Z
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell echos as I type, so we see &lt;code>^Z&lt;/code> (i.e., the &lt;code>Ctrl+Z&lt;/code> chord I entered). The shell responds by moving the process into a background job and suspending it.&lt;/p>
&lt;p>The key here is that it is &lt;em>suspended&lt;/em>. The process is paused. So the web server is no longer serving. If you are following with the sample, reload your browser. The webpage fails to load, as the server process is not able to respond to requests.&lt;/p>
&lt;p>To &lt;em>continue&lt;/em> the job, in the background, we use the &lt;code>bg&lt;/code> (&amp;lsquo;background&amp;rsquo;) command, with a &lt;em>job identifier&lt;/em> (which always starts with a &lt;code>%&lt;/code> symbol - we'll see why soon) to tell the shell to continue the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% bg %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell lets us know the job is being continued, and if we load the webpage again, the content is shown as expected.&lt;/p>
&lt;p>As a final check, we run the &lt;code>jobs&lt;/code> command to see what jobs the shell is running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And there you have it - our server is running as a background job. This is exactly what we would see if we run &lt;code>jobs&lt;/code> after starting the server with an &lt;code>&amp;amp;&lt;/code> at the end. In fact, using an &lt;code>&amp;amp;&lt;/code> is perhaps an easier way to remember how to continue a suspended job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% %1 &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the same way ending a command with &lt;code>&amp;amp;&lt;/code> runs it in the background, ending a job identifier with &lt;code>&amp;amp;&lt;/code> &lt;em>continues&lt;/em> it in the background.&lt;/p>
&lt;p>There is at least one more way to move a job to the background&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>, but I have not yet found it useful in any scenarios, and it is overly complex to explain. See the footnote for details if you are interested.&lt;/p>
&lt;h2 id="moving-background-jobs-to-the-foreground">Moving Background Jobs to the Foreground&lt;/h2>
&lt;p>If you have a job in the background, you can bring it back to the foreground with the &lt;code>fg&lt;/code> (&amp;lsquo;foreground&amp;rsquo;) command. Let's show the jobs, with the &lt;code>jobs&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here I have a background job running a server. Any one of the following commands will bring it back to the foreground:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">fg %1 &lt;span style="color:#75715e"># Explicitly bring Job 1 into the foreground&lt;/span>
%1 &lt;span style="color:#75715e"># ...or in shorthand, just enter the job id...&lt;/span>
fg &lt;span style="color:#75715e"># ...if not given an id, fg and bg assume the most recent job.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the job is in the foreground, and you can interact with the process again however you like.&lt;/p>
&lt;h2 id="cleaning-up-jobs">Cleaning Up Jobs&lt;/h2>
&lt;p>You might realise you cannot continue what you are doing because an old job is &lt;em>still running&lt;/em>. Here's an example:&lt;/p>
&lt;p>&lt;img src="images/kill-job.gif" alt="Demo: Cleaning Up Jobs" width="600" />&lt;/p>
&lt;p>I tried to run my web server, but there was still one running as a background job. The server failed to start because the port is in use.&lt;/p>
&lt;p>To clean it up, I run the &lt;code>jobs&lt;/code> command to list the jobs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's my old web server. Note that even though it is suspended, it'll still be blocking the port it is serving on&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. The process is paused, but it is still holding onto all of the resources it is using.&lt;/p>
&lt;p>Now that I know the job identifier (&lt;code>%1&lt;/code> in this case), I can kill the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% kill %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">22843&lt;/span> terminated python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>This is why job identifiers start with a percentage sign!&lt;/em> The &lt;code>kill&lt;/code> command I have used is not a special job control command (like &lt;code>bg&lt;/code> or &lt;code>fg&lt;/code>). It is the normal &lt;code>kill&lt;/code> command, which terminates a process. But shells that support job control can normally use a job identifier in place of a &lt;em>process identifier&lt;/em>. So rather than working out what the process identifier is that I need to kill, I can just use the job identifier&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="why-you-shouldnt-use-jobs">Why You Shouldn't Use Jobs&lt;/h2>
&lt;p>Avoid jobs. They are not intuitive to interface with, and they suffer from some serious problems.&lt;/p>
&lt;p>The most obvious one is that all jobs write to the same output, meaning you can quickly get garbled output like this:&lt;/p>
&lt;p>&lt;img src="images/output.png" alt="Screenshot: Garbled Output" width="600" />&lt;/p>
&lt;p>This is what happens when I run a job, which just outputs text every second. It's in the background, but it's printing all over my commands. Even running the &lt;code>jobs&lt;/code> command to try and find the job to stop it is difficult.&lt;/p>
&lt;p>Input is even more complex. If a job is &lt;em>running&lt;/em> in the background, but requires input, it will be &lt;em>silently suspended&lt;/em>. This can cause confusion.&lt;/p>
&lt;p>Jobs &lt;em>can&lt;/em> be used in scripts but must be done so with caution and could easily confuse a consumer of the script if they leave background jobs hanging around, which cannot be easily cleaned up&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Handling errors and exit codes for jobs can be problematic, causing confusion, poor error handling, or overly complex code.&lt;/p>
&lt;h2 id="how-to-escape-jobs">How to Escape Jobs&lt;/h2>
&lt;p>If there are two things to take away, it would be this:&lt;/p>
&lt;blockquote>
&lt;p>If you have started running a command in the foreground, and you don't want to stop it and would rather move it to the background, hit &lt;code>Ctrl+Z&lt;/code>. Then Google &amp;ldquo;job control&amp;rdquo;.&lt;/p>
&lt;/blockquote>
&lt;p>And:&lt;/p>
&lt;blockquote>
&lt;p>If you think there is a job running in the background, and it is messing with your screen, type &lt;code>fg&lt;/code> to bring it to the front and kill it with &lt;code>Ctrl+C&lt;/code>. Repeat as needed!&lt;/p>
&lt;/blockquote>
&lt;p>In either case, if you need to do something more subtle, you can return to this reference. But the first command should allow you to get your shell back while you work out how to continue the job, and the second should kill a background job that is messing with your screen.&lt;/p>
&lt;h2 id="alternatives-to-jobs">Alternatives to Jobs&lt;/h2>
&lt;p>If you are using any kind of modern terminal such as iTerm, Terminal or the GNOME Terminal, just open a new tab or split! Much easier.&lt;/p>
&lt;p>The benefit to this is that each tab gets its own standard input and output, so there's no risk of overwriting. And of course you can hide/reveal/rearrange the tabs however you like.&lt;/p>
&lt;p>The traditional alternative to a job for an operator who simply wants more than one thing going on at once would be a &lt;em>terminal multiplexer&lt;/em>, such as &lt;code>screen&lt;/code> or &lt;code>tmux&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/terminal-multiplexer.gif" alt="terminal-multiplexer">&lt;/p>
&lt;p>Multiplexers work in a very similar way to a modern graphical terminal - they manage many shell instances. The benefits to a modern terminal, such as iTerm, is that you have a very intuitive GUI and lots of features.&lt;/p>
&lt;p>The benefits to a multiplexer are that you can run them over SSH sessions to manage complex operations on remote machines and that they run a client-server model, meaning many people can work with many multiplexed processes (and they can persist beyond sessions).&lt;/p>
&lt;p>My personal preference is both - I use a modern terminal &lt;em>and&lt;/em> run everything inside it in &lt;code>tmux&lt;/code>. We'll look at both of these options in later chapters.&lt;/p>
&lt;h2 id="quick-reference">Quick Reference&lt;/h2>
&lt;p>You might find that jobs are useful, or you might find that they are not. Either way, here's a quick reference of some common commands:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Command&lt;/th>
&lt;th>Usage&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>command &amp;amp;&lt;/code>&lt;/td>
&lt;td>Run the command as a background job.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>&amp;lt;Ctrl+Z&amp;gt;&lt;/code>&lt;/td>
&lt;td>Move the current process into a background job, suspended.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>jobs&lt;/code>&lt;/td>
&lt;td>List all jobs.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fg %1&lt;/code>&lt;/td>
&lt;td>Move background job number 1 into the foreground.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>bg %1&lt;/code>&lt;/td>
&lt;td>Continue background job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>kill %1&lt;/code>&lt;/td>
&lt;td>Terminate job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>wait %1&lt;/code>&lt;/td>
&lt;td>Block until job number 1 exits.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>If you want to find out more about the gory details of jobs, the best place to start is the &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">Bash Manual - Job Control Section&lt;/a>, or the &amp;lsquo;Job Control&amp;rsquo; section of your preferred shell's manual.&lt;/p>
&lt;p>I hope you found this useful, and, as always, please leave comments, questions or suggestions below!&lt;/p>
&lt;hr>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you are not a heavy shell user, this might seem unlikely. But if you do a lot of work in shells, such as sysadmin, devops, or do your coding from a terminal, this happens all the time! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Signals like &lt;code>SIGINT&lt;/code>, &lt;code>SIGKILL&lt;/code>, &lt;code>SIGTERM&lt;/code> and so on will be covered in a later chapter. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Technically, &lt;code>SIGTSTP&lt;/code> - which is &amp;lsquo;TTY stop&amp;rsquo;. If you have always wondered about the &amp;lsquo;TTY&amp;rsquo; acroynm, check the previous chatper, &lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Interlude: Understanding the Shell&lt;/a>. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>The alternative method is to use &lt;code>Ctrl+Y&lt;/code>, which will send a &lt;em>delayed interrupt&lt;/em>, which will continue to run the process until it tries to read from &lt;code>stdin&lt;/code>. At this point, the job is suspended and the control given to the shell. The operator can then use &lt;code>bg&lt;/code> or &lt;code>kill&lt;/code> or &lt;code>fg&lt;/code> to either move to the background, stop the process, or keep in the foreground as preferred. See: &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Another super-useful snippet: &lt;code>lsof -i -P -n | grep 8000&lt;/code> to find any process that has a given port open. Another one for the aliases chapter! &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>There are times this is needed. If a job runs &lt;em>many processes&lt;/em> - for example, by running a pipeline - the process identifier will change as the command moves from one stage of the pipeline to the next. The job identifier will remain constant. Remember, a job is a shell &lt;em>command&lt;/em>, so could run many processes. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>To see how bad this can be, create a script that starts jobs, then run it. Then run the &lt;code>jobs&lt;/code> command to see what is running. The output might surprise you! &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Interlude: Understanding the Shell</title><link>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</link><pubDate>Tue, 21 May 2019 09:22:05 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</guid><description>&lt;p>This is the first &amp;lsquo;interlude&amp;rsquo; in my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series. These interludes give some background, history or more flavour to some of the topics.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This one &lt;em>should&lt;/em> be high-level enough for even non-technical readers to enjoy (or at least understand!). I've tried to make sure any term that might be unfamiliar is described in a footnote&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. For the more technical reader, it provides an important grounding on some of the key concepts relating to shells and how they work.&lt;/p>
&lt;h2 id="introduction-for-the-non-technical-reader">Introduction for the Non-Technical Reader&lt;/h2>
&lt;p>It might come as a surprise that &lt;em>many&lt;/em> technical computer users (programmers, data scientists, systems administrators etc) spend a lot of time using an interface which looks like it's from the sixties:&lt;/p>
&lt;p>&lt;img src="images/screenshot-shell.png" alt="Diagram: The Shell" width="600px" />&lt;/p>
&lt;p>If you work with technologists, you might have seen them using an interface like this. This kind of simple, text-based interface is called a &lt;em>shell&lt;/em>, and it has been a common way to interface with computers ever since the first screens and keyboards were created.&lt;/p>
&lt;p>Given how much computing has advanced, why would people use such an interface? Just look at how much the Windows operating-system has changed over the last three decades:&lt;/p>
&lt;p>&lt;img src="images/screenshot-windows-evolution.png" alt="Image: The Evolution of Windows" width="600px" />&lt;/p>
&lt;p>&lt;em>(By Source (WP:NFCC#4), Fair use, &lt;a href="https://en.wikipedia.org/w/index.php?curid=58853841">https://en.wikipedia.org/w/index.php?curid=58853841&lt;/a>)&lt;/em>&lt;/p>
&lt;p>Why would people choose to use such an archaic interface as a shell?&lt;/p>
&lt;ul>
&lt;li>Typing is &lt;em>fast&lt;/em>: A skilled shell user can manipulate a system at dazzling speeds just using a keyboard. Typing commands is generally &lt;em>much&lt;/em> faster than exploring through user interfaces with a mouse&lt;/li>
&lt;li>Shells are &lt;em>programmable&lt;/em>: Users will often being programming as they work in a shell, creating scripts to automate time-consuming or repetetive processes&lt;/li>
&lt;li>Shells are &lt;em>portable&lt;/em>: A shell can be used to interface to almost any type of computer, from a mainframe to a Raspberry Pi, in a very similar way.&lt;/li>
&lt;/ul>
&lt;p>Not all technical users will use a shell regularly, but there are many who will spend the bulk of their time in such an interface. It is such a crucial skill to be able to operate one effectively that I have been writing this series primarily to show ways to be more efficient with this kind of interface.&lt;/p>
&lt;h2 id="introduction-for-the-technical-reader">Introduction for the Technical Reader&lt;/h2>
&lt;p>You may be familar with the shell, but it can be useful to understand some of the surrounding concepts in detail. How does a shell differ from a terminal? What is a &lt;em>tty&lt;/em>? How do shells really work? Hopefully as you read this article you'll discovery something that you didn't know about shells.&lt;/p>
&lt;h2 id="lets-get-started">Let's Get Started!&lt;/h2>
&lt;p>To understand what shells, terminals, command-prompts and so on are and how they relate, we need to start with the basics: how a modern computer works!&lt;/p>
&lt;h2 id="a-computer-in-a-nutshell">A Computer in a Nutshell&lt;/h2>
&lt;p>The diagram below shows a simplified view of a typical computer:&lt;/p>
&lt;p>&lt;img src="images/diagram1-operating-system.png" alt="Diagram: Operating System" width="600px" />&lt;/p>
&lt;p>Already there's a lot going on.&lt;/p>
&lt;p>Your computer is going to have a CPU&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> and memory&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, and almost certainly a network adapter&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> and display adapter&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. Most computers will have at least one hard disk. For home PCs, there'll also likely be a bunch of peripherals, such as a mouse, keyboard, printers, flash drives, webcams and so on.&lt;/p>
&lt;h3 id="the-operating-system">The Operating System&lt;/h3>
&lt;p>The operating system is the piece of software installed on a computer that can interface with the &lt;em>hardware&lt;/em>. Without hardware, such as a CPU, memory, a network adapter, a graphics card, disk drives and so on, there's not much that you can do with the computer. The operating system is the primary interface to this hardware. No normal programs will talk to hardware directly - the operating system abstracts this hardware away and provides a &lt;em>software&lt;/em> interface to it.&lt;/p>
&lt;p>The abstraction the operating system provides is essential. Developers don't need to know the specifics of how to work with individual devices from different vendors; the operating system provides a standardised interface to all of this. It also handles various tasks such as making sure the system starts up properly.&lt;/p>
&lt;p>The operating system is generally broken down into two parts - the &lt;em>kernel&lt;/em> and &lt;em>user space&lt;/em>:&lt;/p>
&lt;p>&lt;img src="images/diagram2-the-kernel-and-user-space.png" alt="Diagram: The Kernel and User Space" width="600px" />&lt;/p>
&lt;p>Let's look at these in more detail.&lt;/p>
&lt;h3 id="the-kernel">The Kernel&lt;/h3>
&lt;p>This is the part of the operating system that is responsible for the most sensitive tasks: interfacing with physical devices, managing the resources that are available for users and programs, starting up the various systems that are needed, and so on.&lt;/p>
&lt;p>Software running in the kernel has direct access to resources, so is &lt;em>extremely&lt;/em> sensitive. The kernel will balance resources between the programs in user space, which we'll look at shortly. If you've ever had to install &amp;lsquo;drivers&amp;rsquo;, these are examples of pieces of software that will run in the kernel - they'll have direct access to a physical device you've installed, and expose it to the rest of the software on the computer.&lt;/p>
&lt;p>Why &amp;lsquo;kernel&amp;rsquo;? The kernel is the soft, edible part of a nut or seed, which is surrounded by a shell. Below you can see a walnut - the kernel is the soft bit in the middle, and the shell surrounds and protects it. This is a useful metaphor that is used for parts of a computer.&lt;/p>
&lt;p>&lt;img src="images/image-walnut.jpg" alt="Image: Photo of a walnut, showing the kernel and the shell" width="200px" />&lt;/p>
&lt;p>&lt;em>(By Kkchaudhary11 - Own work, CC BY-SA 4.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=49069244">https://commons.wikimedia.org/w/index.php?curid=49069244&lt;/a>)&lt;/em>&lt;/p>
&lt;p>The operating system kernel really is the &lt;em>core&lt;/em> of the operating system. It's such a sensitive area of the operating system that we actually want to avoid running software in it if possible&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. And that is where &lt;em>user space&lt;/em> comes in.&lt;/p>
&lt;h3 id="user-space">User Space&lt;/h3>
&lt;p>The vast majority of programs run in &amp;lsquo;user space&amp;rsquo; (also commonly called &amp;lsquo;user land&amp;rsquo;).&lt;/p>
&lt;p>When a program starts, the kernel will allocate it a private segment of memory and provide &lt;em>limited&lt;/em> access to resources. The program is given access to a library of functions by the operating system, which it can use to access resources such as files, devices and so on. Programs in user space are essentially in sandboxes, where there is a limit to how much damage they can do.&lt;/p>
&lt;p>For example, a program running in user space can use the standard &lt;a href="http://man7.org/linux/man-pages/man3/fopen.3.html">&lt;code>fopen&lt;/code>&lt;/a> function, which is provided on almost every operating system as part of the &lt;a href="https://www.gnu.org/software/libc/">C Standard Library&lt;/a>. This allows a program to attempt to open a file. The operating system will make a decision on whether the program is &lt;em>allowed&lt;/em> to open the file (based on things such as permissions, where the file is and so on) and then, if it is OK with the call, will give the program access to the file. Under the hood, this &amp;lsquo;user space&amp;rsquo; call translates to a system call in the kernel.&lt;/p>
&lt;p>Now that the key components have been introduced, we can look at the &lt;em>shell&lt;/em>. The name should come as no surprise, as it is a &lt;em>wrapper&lt;/em> or outer layer to the operating system (which itself contains the sensitive nugget of the kernel).&lt;/p>
&lt;h3 id="the-shell">The Shell&lt;/h3>
&lt;p>So what is the shell? The shell is just a general name for any &lt;em>user space&lt;/em> program that allows access to resources in the system, via some kind of interface.&lt;/p>
&lt;p>Shells come in many different flavours but are generally provided to aid a human operator in accessing the system. This could be interactively, by typing at a terminal, or via scripts, which are files that contain a sequence of commands.&lt;/p>
&lt;p>For example, to see all of the files in a folder, the human operator &lt;em>could&lt;/em> write a program in a language such as C, making system calls to do what they want. But for day-to-day tasks, this would be repetitive. A shell will normally offer us a quick way to do that exact task, without having to manually write a program to do it.&lt;/p>
&lt;p>Here's an example, where a shell is being used to show the &amp;lsquo;png&amp;rsquo; images in the folder I am working in&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/screenshot1-example-shell.png" alt="Screenshot: Browsing Contents of the File System the the Bourne Again Shell" width="600px" />&lt;/p>
&lt;p>So a shell is a user-space program to interface with the computer. But there a few more moving parts than just a shell we are seeing in the image above. There are different types of shells, there are terminal programs, and there are the programs or commands that the shell calls (in the example above, &lt;code>tree&lt;/code> is a program). Let's pick these apart.&lt;/p>
&lt;p>Here's a diagram that more accurately shows what is going on:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We've introduced a few new things here. There's a &lt;em>user&lt;/em>, who is interfacing with a &lt;em>terminal&lt;/em>, which is running a &lt;em>shell&lt;/em>, which is showing a &lt;em>command prompt&lt;/em>. The user has written a command that is calling a program (in this case, the &lt;code>tree&lt;/code> program).&lt;/p>
&lt;p>Let's dissect this bit by bit.&lt;/p>
&lt;h3 id="the-terminal">The Terminal&lt;/h3>
&lt;p>We're not &lt;em>directly&lt;/em> interacting with the &amp;lsquo;shell&amp;rsquo; in this diagram. We're actually using a &lt;em>terminal&lt;/em>. When a user wants to work with a shell interactively, using a keyboard to provide input and a display to see the output on the screen, the user uses a &lt;em>terminal&lt;/em>.&lt;/p>
&lt;p>A terminal is just a program that reads input from the keyboard, passes that input to another program (normally a shell), and displays the results on the screen. A shell program on its own does not do this - it requires a terminal as an interface.&lt;/p>
&lt;p>Why the word &lt;em>terminal&lt;/em>? This makes sense when you look at how people interfaced with computers historically. Input to a computer might be through punch cards, and output would often be via a printer. The &lt;em>Teletype Termimal&lt;/em>&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup> became a common way for users to interface with computers.&lt;/p>
&lt;p>&lt;img src="images/image-asr-33.jpg" alt="Photo: ASR-33 TTY" width="600px" />&lt;/p>
&lt;p>&lt;em>(Photograph by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr, CC BY-SA 2.0 fr, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=17821795">https://commons.wikimedia.org/w/index.php?curid=17821795&lt;/a>)&lt;/em>&lt;/p>
&lt;p>At this time, computers were very large, complex, and expensive machines. It was common to have &lt;em>many&lt;/em> terminals connected to a single large machine (or &amp;lsquo;mainframe&amp;rsquo;), or a few terminals that people would share. But the terminal itself was just a human interface to the operating system. A more modern terminal would be something like an IBM 3486:&lt;/p>
&lt;p>&lt;img src="images/image-ibm3486.jpg" alt="Photo: IBM 3486" width="600px" />&lt;/p>
&lt;p>&lt;em>(By ClickRick - Own work, CC BY-SA 3.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=6693700">https://commons.wikimedia.org/w/index.php?curid=6693700&lt;/a>)&lt;/em>&lt;/p>
&lt;p>This is a very small computer in its own right but still basically just a dumb screen and keyboard connected by a cable to a larger mainframe computer in another location.&lt;/p>
&lt;p>This mechanism is still very much the case today. When I want to work with a computer in a data centre, I don't go and find the machine, plug in a keyboard and a display and directly interface to it. I run a &lt;em>terminal program&lt;/em> on my computer to provide access to the remote machine. My terminal program allows me to use my keyboard and display to work with a remote machine - all via a &lt;em>secure shell&lt;/em> - which is a secured-shell connection over a network.&lt;/p>
&lt;p>So terminals in many ways are quite simple - they are interfaces. But because they are quite simple programs, we can't do much with them. So normally, the first thing that a terminal program will do is run a &lt;em>shell&lt;/em> program - a program that we can use to operate the computer.&lt;/p>
&lt;p>There's nothing special about terminals - anyone can write a program to operate as a terminal, which is why you will see many different terminals around. Examples are the standard &amp;lsquo;terminal&amp;rsquo; app for MacOS X, the &lt;a href="https://wiki.gnome.org/Apps/Terminal/VTE">gnome-terminal&lt;/a> for Linux, and &lt;a href="https://www.iterm2.com/">iTerm2&lt;/a> and &lt;a href="https://hyper.is/">Hyper&lt;/a>. There's a bunch of screenshots of different setups at the end of the article.&lt;/p>
&lt;h2 id="back-to-the-shell">Back to the Shell&lt;/h2>
&lt;p>Now that we've described the terminal, we can go back and look at the shell in detail.&lt;/p>
&lt;p>The shell is the program that is going to take input from somewhere and run a series of commands. When the shell is running in a terminal, it is normally taking input interactively from the user. As the user types in commands, the terminal feeds the input to the shell and presents the output of the shell on the screen.&lt;/p>
&lt;p>A shell program can also take input from files; these files will then generally be &amp;lsquo;shell scripts&amp;rsquo;. This might be used to run automated operations, such as cleaning up certain folders when a computer starts.&lt;/p>
&lt;p>Shells can write output to files or other locations, and so on. You can run a shell program outside of a terminal - you just won't be able to interface with it using a keyboard or display. And in fact, lots of operations happen in this way: automated scripts, startup tasks, installers and so on.&lt;/p>
&lt;p>So what else does a shell do? Most of the features are related to helping human operators work with the system more efficiently.&lt;/p>
&lt;ul>
&lt;li>Quickly enter commands, see the history of commands and quickly restructure commands (see &lt;a href="http://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Effective Shell - Navigating the Command Line&lt;/a>)&lt;/li>
&lt;li>Navigate through the file system, moving from folder to folder (see &lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Effective Shell - Move Around!&lt;/a>), which makes it easier for an operator to navigate the file system.&lt;/li>
&lt;li>Chain the output of commands together - for example, taking the output of one basic program, such as the &lt;code>tree&lt;/code> program we saw, and writing it to a file (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Understanding Pipelines&lt;/a>)&lt;/li>
&lt;li>Offer a programming language, allowing the operator to perform more complicated tasks (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Basic Shell Scripting&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>And a lot more! In fact, that's what the whole &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series is about - how to get the most from these powerful programs, particularly for those who use them regularly.&lt;/p>
&lt;h3 id="the-command-prompt-or-command-line">The Command Prompt or Command Line&lt;/h3>
&lt;p>The last part of the diagram, which we haven't covered yet, is the &lt;em>command prompt&lt;/em>.&lt;/p>
&lt;p>&lt;img src="images/diagram4-command-prompt-1.png" alt="Diagram: Command Prompt" width="300px" />&lt;/p>
&lt;p>When a &lt;em>shell&lt;/em> is running in &lt;em>terminal&lt;/em>, it knows that a human operator will be interfacing with it. So to make sure that the operator has some kind of visual hint that &lt;em>they have to enter commands&lt;/em>, the shell will output some kind of prompt.&lt;/p>
&lt;p>I've included a set of screenshots at the end of the article, just after this section, and you can see how some different command prompts look.&lt;/p>
&lt;p>Note that shells don't have to use command prompts - if you use a shell program to execute a script, there will be no command prompt. Shells only show a prompt when they know they are being used interactively. Many programs which allow a user to operate interactively will show a command prompt.&lt;/p>
&lt;p>Shell command prompts can be customised, so they will often look different from machine to machine (for more details, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Customising the Command Line&lt;/a>). Below is an example that shows a &lt;em>lot&lt;/em> of technical information. This is from the highly popular &lt;a href="https://ohmyz.sh/">oh-my-zsh&lt;/a> framework for the &amp;lsquo;Z Shell&amp;rsquo; shell, which is very popular among developers:&lt;/p>
&lt;p>&lt;img src="images/image-ohmyzsh.jpg" alt="Image: Customised oh-my-zsh" width="600px" />&lt;/p>
&lt;p>*(Source: &lt;a href="https://ohmyz.sh/">https://ohmyz.sh/&lt;/a>)&lt;/p>
&lt;h3 id="shell-commands-and-different-shells">Shell Commands and Different Shells&lt;/h3>
&lt;p>A lot of the &amp;lsquo;commands&amp;rsquo; in a shell, such as &lt;code>cat&lt;/code> (which shows the contents of a file), are actually just simple programs, which will interface with the kernel. No matter what shell you use, these commands will behave the same way, because really all you are doing is calling another progam.&lt;/p>
&lt;p>Some commands, such as &lt;code>cd&lt;/code> (change directory), are built into the shell. Some commands are functions that have been defined, or aliases to other commands (for more details on commands, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Commands&lt;/a>). Commands will often differ between shells.&lt;/p>
&lt;p>Not all shells are created equal - anyone can write a shell program, maybe creating a simple interface to the computer or a highly complex one with many features. In fact, a later article in this series will look at the geneology of the most common shells.&lt;/p>
&lt;p>On most Unix-like systems, the default shell is a program called &lt;code>bash&lt;/code>, which stands for &amp;quot; Bourne Again Shell&amp;rdquo; (the name and history around it will be discussed at length in the later article). But there are many other shells: the C Shell, the Korn Shell, Z Shell and Fish, just to name just a few.&lt;/p>
&lt;p>Users and administators can configure what shell they like to use. When a terminal opens, it will immediately start the user's preferred shell program. It is possible to change this. Different users will have different preferences, given that shells offer varying features. This can cause complexity when working with systems, as we cannot always expect every user to have the same shell, or even for the same shell to be set up consistently, as they can be extensively customised.&lt;/p>
&lt;p>Let's review the earlier diagram again:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell-1.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We can see the real internals of what is going on in this &amp;ldquo;Terminal -&amp;gt; Shell -&amp;gt; Program&amp;rdquo; chain in the diagram above quite easily.&lt;/p>
&lt;p>Try the command &lt;code>pstree -psa $$&lt;/code> in a shell&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/image-psforest.png" alt="Image: Process Tree" width="600px" />&lt;/p>
&lt;p>The first &lt;code>systemd&lt;/code> process is the primary process for the OS - it is process number &lt;code>1&lt;/code>, which initialises everything else. The second &lt;code>systemd&lt;/code> process is the process that is running the interface for my user. We can ignore these for now; they are internals to how the operating system boots and starts processes.&lt;/p>
&lt;p>What is interesting is that we can see a &lt;em>terminal&lt;/em> (the gnome terminal), which has started my preferred &lt;em>shell&lt;/em> (which is &lt;code>zsh&lt;/code>), which is running a &lt;em>command&lt;/em> (the program &lt;code>pstree&lt;/code>). Here we can see the exact chain as shown in the diagram earlier.&lt;/p>
&lt;h3 id="thats-a-wrap">That's a Wrap!&lt;/h3>
&lt;p>These are the key technologies and concepts that surround a shell.&lt;/p>
&lt;p>If you are interested in more technical details of working with shells, then my &lt;a href="https://github.com/effective-shell">Effective Shell&lt;/a> series goes into these topics in depth. The goal of this series is to help teach techniques that making working with shells more efficient.&lt;/p>
&lt;p>To close the article, below are some examples of different terminals, shells, command prompts and so on.&lt;/p>
&lt;h4 id="example-iterm-2--tmux--zsh">Example: iTerm 2 / tmux / zsh&lt;/h4>
&lt;p>&lt;img src="images/example-iterm-zsh.png" alt="Example: iTerm 2, tmux, zsh" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A MacOS operating system&lt;/li>
&lt;li>iTerm2 as the terminal program&lt;/li>
&lt;li>&lt;code>tmux&lt;/code> running as a &amp;lsquo;terminal multiplexer&amp;rsquo; (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell: Terminal Multiplexers&lt;/a>)&lt;/li>
&lt;li>&lt;code>zsh&lt;/code> (Z Shell) as the shell program, using &amp;lsquo;oh my zsh&amp;rsquo;, which is easily recognised by the &lt;code>%&lt;/code> sign in the command prompt.&lt;/li>
&lt;li>A customised command line, which shows the user and folder on one line, with only the &lt;code>%&lt;/code> symbol below, to leave lots of space for the input commands&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>.&lt;/li>
&lt;/ul>
&lt;h4 id="example-bash">Example: Bash&lt;/h4>
&lt;p>&lt;img src="images/example-bash.png" alt="Example: Bash" width="600px" />&lt;/p>
&lt;p>&lt;img src="images/example-bash-root.png" alt="Example: Bash Elevated" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A Linux operating system (Ubuntu 14)&lt;/li>
&lt;li>The gnome terminal&lt;/li>
&lt;li>&lt;code>bash&lt;/code> as the shell&lt;/li>
&lt;li>In the second screenshot, the user has &amp;lsquo;root privileges&amp;rsquo;, and to indicate this, &lt;code>bash&lt;/code> helpfully changes the default command prompt from a dollar sign to a hash sign&lt;/li>
&lt;/ul>
&lt;h4 id="example-windows-explorer">Example: Windows Explorer&lt;/h4>
&lt;p>&lt;img src="images/example-explorer.png" alt="Example: Windows Explorer" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>No terminal&lt;/li>
&lt;li>The &lt;code>explorer.exe&lt;/code> program showing us a &lt;em>graphical&lt;/em> shell&lt;/li>
&lt;/ul>
&lt;p>This looks different from previous examples. The program, which shows the familiar Windows interface, &lt;code>explorer.exe&lt;/code>, is in fact a shell as well, offering interactive access to the operating system and computer resources. The bulk of the Windows APIs to interact with this interface are in the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/desktop/bb773177(v=vs.85).aspx">Shell Library&lt;/a>. I also maintain a popular library for building extensions to the graphical Windows shell - &lt;a href="https://github.com/dwmkerr/sharpshell">sharpshell&lt;/a>.&lt;/p>
&lt;h4 id="example-windows-command-prompt">Example: Windows Command Prompt&lt;/h4>
&lt;p>&lt;img src="images/example-cmd.png" alt="Example: Command Prompt" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The command prompt terminal and shell&lt;/li>
&lt;/ul>
&lt;p>In Windows, the terminal and shell are combined into a single &lt;code>cmd.exe&lt;/code> program. There's an excellent article on the internals - &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft DevBlogs: Windows Command-Line: Inside the Windows Console&lt;/a>&lt;/p>
&lt;h4 id="example-windows-powershell">Example: Windows PowerShell&lt;/h4>
&lt;p>&lt;img src="images/example-powershell.png" alt="Example: Windows Powershell" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The PowerShell terminal&lt;/li>
&lt;/ul>
&lt;p>PowerShell is an improvement on the &amp;lsquo;command prompt&amp;rsquo; program that was originally used in Windows, offering much more functionality for scripting and other modern shell features.&lt;/p>
&lt;h4 id="example-windows-subsystem-for-linux-wsl">Example: Windows Subsystem for Linux (WSL)&lt;/h4>
&lt;p>&lt;img src="images/example-wsl.png" alt="Example: WSL" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The &lt;code>Bash.exe&lt;/code> program&lt;/li>
&lt;/ul>
&lt;p>This screenshot, from &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/faq">MSDN: Frequently Asked Questions about Windows Subsystem for Linux&lt;/a> shows Bash running in Windows. This is a relatively new feature at the time of writing, allowing Windows users to use a Linux interface to the PC. This is a feature that may become increasingly valuable, as in general it is challenging to write shell code that can run on Windows and Unix-like systems.&lt;/p>
&lt;h2 id="share-and-discuss">Share and Discuss&lt;/h2>
&lt;p>If you enjoyed this article, please do share it! Feel free to include suggestions, improvements or corrections in the comments below.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Useful References&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>A simple Linux kernel module, showing how basic kernel programming works in Linux: &lt;a href="https://github.com/dwmkerr/linux-kernel-module">github.com/dwmkerr/linux-kernel-module&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.amazon.com/How-Linux-Works-2nd-Superuser/dp/1593275676">How Linux Works - Brian Ward&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://unix.stackexchange.com/questions/4126/what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con/4132">StackExchange: What is the exact difference between a &amp;lsquo;terminal&amp;rsquo;, a &amp;lsquo;shell&amp;rsquo;, a &amp;lsquo;tty&amp;rsquo;, and a console?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft: Inside the Windows Console&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I'd be fascinated to know if this is at all interesting to less technically inclined people, so please do go ahead and let me know in the comments! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>CPU: central processing unit. This is the chip in the computer that does most of the work (which after many layers of abstraction eventually becomes arithmetic and sending simple instructions to other places). &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Memory is the &amp;lsquo;working space&amp;rsquo; where the state of your system is stored. If you are writing a document, the text lives in memory, until you save it, when it then gets written to a hard drive. Memory is &lt;em>ephemeral&lt;/em> - everything is gone when you turn off the power to it. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>This is the part of your computer that knows how to do things like connect to a WiFi network, or has a network socket you might plug a network cable into. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>This is the part of your computer you plug the screen into. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>This is because a mistake in &lt;em>Kernel Mode&lt;/em> programs can have disasterous effects. It could access any files, no matter who they belong do, control the hardware, install more software - almost anything. Errors in this code can cause terrible issues (like the infamous Windows &amp;lsquo;blue screen of death&amp;rsquo;), and malicious code in the kernel essentially has full access to not only all your data but also your webcam, network adapter and so on. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>As an aside, if you are curious about the visual style of my setup or customisations that have been made, everything in my setup is available online on my &amp;lsquo;dotfiles&amp;rsquo; repo - &lt;a href="https://github.com/dwmkerr/dotfiles">github.com/dwmkerr/dotfiles&lt;/a>. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>And that's where the &amp;lsquo;TTY&amp;rsquo; acronym you will see sometimes comes from. Enter the &lt;code>ps&lt;/code> command, and you'll actually see the TTY interface each process is attached to. This is a topic that will come up later in the series. &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>&lt;code>$$&lt;/code> is a Bash &lt;a href="https://www.tldp.org/LDP/abs/html/internalvariables.html#PROCCID">internal variable&lt;/a>. These will also be covered in a later article in the series. &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>Feel free to see my &lt;a href="https://github.com/dwmkerr/dotfiles">dotfiles&lt;/a> to configure a similar setup for yourself. &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell 4: Move Around!</title><link>https://dwmkerr.com/effective-shell-4-moving-around/</link><pubDate>Mon, 11 Mar 2019 09:02:00 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-4-moving-around/</guid><description>&lt;p>This is the fourth part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series, a set of practical examples of ways to be more efficient with everyday tasks in the shell or at the command line.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article we'll look at the key elements of navigation in the shell.&lt;/p>
&lt;h2 id="getting-comfortable-moving-around">Getting Comfortable Moving Around&lt;/h2>
&lt;p>You might already spend a lot of time in the shell, running various command line programs or using tooling for development projects or operational tasks. But you might also still switch back to a more visual paradigm for working with files, directories and resources.&lt;/p>
&lt;p>Being able to perform everyday file and folder manipulation tasks directly from the shell can really speed up your workflow. Let's look at some common tasks and see how we can work with them in the shell. Along the way we'll also introduce some of the most frequently used tools and commands to work with the filesystem.&lt;/p>
&lt;h2 id="where-am-i">Where Am I?&lt;/h2>
&lt;p>The first command to become familiar with is &lt;code>pwd&lt;/code> (&amp;lsquo;print working directory&amp;rsquo;). This command will echo the current absolute path. You can also use the &lt;code>$PWD&lt;/code> environment variable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ echo $PWD
/Users/dave/repos/github/dwmkerr/effective-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Depending on your shell, or your command-line setup (which we will discuss in a later chapter), you might also see your working directly on the command-line.&lt;/p>
&lt;h2 id="changing-directory">Changing Directory&lt;/h2>
&lt;p>Most likely one of the most familiar commands out there, the &lt;code>cd&lt;/code> or &lt;code>chdir&lt;/code> function changes the current directory:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd
$ pwd
/users/dave
$ cd -
~/repos/github/dwmkerr/effective-shell
$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd ~
$ pwd
/users/dave
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we can see that running &lt;code>cd&lt;/code> with no parameters moves to the users &amp;lsquo;home&amp;rsquo; directory. This directory is always available in the &lt;code>$HOME&lt;/code> environment variable.&lt;/p>
&lt;p>Running &lt;code>cd -&lt;/code> will switch &lt;em>back&lt;/em> to the previous directory — this is very useful if you want to quickly jump somewhere and then back again.&lt;/p>
&lt;p>You can use &lt;code>~&lt;/code> as an alias for the home directory, allowing you to quickly move to personal folders, with commands such as &lt;code>cd ~/Downloads&lt;/code>.&lt;/p>
&lt;p>Most commonly, you will specify a path when changing directory. This can be a fully qualified path, or it can be a relative path:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ cd /dev
$ cd ~/repos
$ cd ./github
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can use the special link &lt;code>..&lt;/code>, which is a folder that points to the &lt;em>parent&lt;/em> directory to move &amp;lsquo;upwards&amp;rsquo;:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd ../../
$ pwd
/Users/dave/repos/github
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="exploring-a-directory">Exploring a Directory&lt;/h2>
&lt;p>Once we are in a directory, we will often want to see the contents. The &lt;code>ls&lt;/code> (&amp;ldquo;list directory contents&amp;rdquo;) command is useful here:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ ls
1-navigating-the-command-line LICENSE
2-clipboard-gymnastics README.md
3-getting-help sed.1
4-moving-around
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By default, the &lt;code>ls&lt;/code> command will list the files and directories. We can show more information with the &lt;code>-l&lt;/code> (&amp;ldquo;long format&amp;rdquo;) flag:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ls -l
total &lt;span style="color:#ae81ff">48&lt;/span>
drwxr-xr-x &lt;span style="color:#ae81ff">6&lt;/span> dave staff &lt;span style="color:#ae81ff">192&lt;/span> Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 1-navigating-the-command-line
drwxr-xr-x &lt;span style="color:#ae81ff">5&lt;/span> dave staff &lt;span style="color:#ae81ff">160&lt;/span> Oct &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 2-clipboard-gymnastics
drwxr-xr-x &lt;span style="color:#ae81ff">4&lt;/span> dave staff &lt;span style="color:#ae81ff">128&lt;/span> Dec &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 3-getting-help
drwxr-xr-x &lt;span style="color:#ae81ff">3&lt;/span> dave staff &lt;span style="color:#ae81ff">96&lt;/span> Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:39 4-moving-around
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">1066&lt;/span> Jun &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> LICENSE
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">561&lt;/span> Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:30 README.md
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">15707&lt;/span> Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 sed.1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we can see the permissions, the link count (which is rarely particularly useful and varies from platform to platform), the owner, the group, the size and the modification date (as well as the name).&lt;/p>
&lt;p>We can make the sizes more human readable, and sort by size with a few more flags &lt;code>-h&lt;/code> (&amp;ldquo;human readable&amp;rdquo;) and &lt;code>-s&lt;/code> (&amp;ldquo;sort by size&amp;rdquo;):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ls -lhS
total &lt;span style="color:#ae81ff">48&lt;/span>
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 15K Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 sed.1
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 1.0K Jun &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> LICENSE
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 561B Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:30 README.md
drwxr-xr-x &lt;span style="color:#ae81ff">6&lt;/span> dave staff 192B Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 1-navigating-the-command-line
drwxr-xr-x &lt;span style="color:#ae81ff">5&lt;/span> dave staff 160B Oct &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 2-clipboard-gymnastics
drwxr-xr-x &lt;span style="color:#ae81ff">4&lt;/span> dave staff 128B Dec &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 3-getting-help
drwxr-xr-x &lt;span style="color:#ae81ff">3&lt;/span> dave staff 96B Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:39 4-moving-around
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are &lt;em>lot&lt;/em> of options for &lt;code>ls&lt;/code>. Check the chapter &lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Getting Help&lt;/a> for some tips on how to get more information on a command!&lt;/p>
&lt;h2 id="managing-the-directory-stack">Managing the Directory Stack&lt;/h2>
&lt;p>You might find that you want to move to a number of directories, then return to where you started. This can be particularly useful when scripting. You can use the &lt;code>pushd&lt;/code> (&amp;ldquo;push onto directory stack&amp;rdquo;) and &lt;code>popd&lt;/code> (&amp;ldquo;pop from directory stack&amp;rdquo;) commands to add or remove directories from the stack:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
&lt;span style="color:#75715e"># OK - I&amp;#39;m writing my article at the moment, but want to check my downloads, and come back shortly...&lt;/span>
&lt;span style="color:#75715e"># Move to the downloads folder...&lt;/span>
$ ls
aws-nuke-v2.8.0-darwin-amd64
&lt;span style="color:#75715e"># OK cool - the tool I was downloading has arrived, let&amp;#39;s use it...&lt;/span>
cd aws-nuke-v2.8.0-darwin-amd64
./aws-nuke
&lt;span style="color:#75715e"># Now I want to go back to my article...&lt;/span>
$ popd
~/Downloads ~/repos/github/dwmkerr/effective-shell
~/Downloads
$ popd
~/repos/github/dwmkerr/effective-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this case, using &lt;code>cd -&lt;/code> would not be sufficient — that would just switch us from the &lt;code>aws-nuke&lt;/code> folder to &lt;code>Downloads&lt;/code> and back again. But by using the &lt;em>directory stack&lt;/em> we can save where we are, move, and then &amp;lsquo;pop&amp;rsquo; our way back to where we started.&lt;/p>
&lt;h2 id="auto-completion">Auto-Completion&lt;/h2>
&lt;p>Pressing &lt;code>tab&lt;/code> when using commands like &lt;code>cd&lt;/code> will generally show an auto-completion menu:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ cd ~/repos/ &lt;span style="color:#75715e"># press &amp;#39;tab&amp;#39; now...&lt;/span>
github/ gitlab/ local/ scratch/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pressing tab again will cycle through options, and shift-tab will cycle backwards. Enter will select an option, escape (or Ctrl-C) will cancel.&lt;/p>
&lt;p>Some shells, such as &lt;code>zsh&lt;/code>, support even more advanced auto-completion. For example, we can auto-complete to fill in partially specified directory names:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% cd ~/r/g/d/e &lt;span style="color:#75715e"># press tab now...&lt;/span>
% cd ~/repos/github/dwmkerr/effective-
effective-container-engineering/ effective-shell/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Auto-completion is generally &lt;em>very&lt;/em> shell specific. We'll look more into the different shells that are available in later chapters. But in general, if you are uncertain, pressing tab will often show a sensible set of options.&lt;/p>
&lt;h2 id="thats-it">That's It!&lt;/h2>
&lt;p>This is a small chapter, but an important one. Later on, as we start to do more file and system manipulation from the shell, moving and copying files and so on, we will build on these concepts. But it is critical to first know the basics of how to move around the filesystem with the shell.&lt;/p></description><category>CodeProject</category></item><item><title>Dynamic and Configurable Availability Zones in Terraform</title><link>https://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</link><pubDate>Tue, 11 Dec 2018 21:24:34 +0000</pubDate><guid>https://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</guid><description>&lt;p>When building Terraform modules, it is a common requirement to want to allow the client to be able to choose which region resources are created in, and which availability zones are used.&lt;/p>
&lt;p>I've seen a few ways of doing this, none of which felt entirely satisfactory. After a bit of experimentation I've come up with a solution which I think really works nicely. This solution avoids having to know in advance how many availability zones we'll support.&lt;/p>
&lt;p>&lt;img src="images/screenshot-1.jpg" alt="screenshot">&lt;/p>
&lt;p>To demonstrate, I've set up a module which deploys a cluster of web servers. My goal is to be able to configure the region, VPC CIDR block, subnets and subnet CIDR blocks as below:&lt;/p>
&lt;pre>&lt;code>module &amp;quot;cluster&amp;quot; {
source = &amp;quot;github.com/dwmkerr/terraform-aws-vpc&amp;quot;
# Note how we can specify any number of availability zones here...
region = &amp;quot;ap-northeast-2&amp;quot;
vpc_cidr = &amp;quot;10.0.0.0/16&amp;quot;
subnets = {
ap-northeast-2a = &amp;quot;10.0.1.0/24&amp;quot;
ap-northeast-2b = &amp;quot;10.0.2.0/24&amp;quot;
ap-northeast-2c = &amp;quot;10.0.3.0/24&amp;quot;
}
# This just defines the number of web servers to deploy, and uses
# adds my public key so I can SSH into the servers...
web_server_count = &amp;quot;3&amp;quot;
public_key_path = &amp;quot;~/.ssh/id_rsa.pub&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>The example module is at &lt;a href="https://github.com/dwmkerr/terraform-aws-vpc">github.com/dwmkerr/terraform-aws-vpc&lt;/a>. Let's take a look at some of the key elements.&lt;/p>
&lt;h2 id="the-variables">The Variables&lt;/h2>
&lt;p>We define the required variables very explicitly, with descriptions and a variable type to avoid confusion:&lt;/p>
&lt;pre>&lt;code>variable &amp;quot;region&amp;quot; {
description = &amp;quot;The region to deploy the VPC in, e.g: us-east-1.&amp;quot;
type = &amp;quot;string&amp;quot;
}
variable &amp;quot;vpc_cidr&amp;quot; {
description = &amp;quot;The CIDR block for the VPC, e.g: 10.0.0.0/16&amp;quot;
type = &amp;quot;string&amp;quot;
}
variable &amp;quot;subnets&amp;quot; {
description = &amp;quot;A map of availability zones to CIDR blocks, which will be set up as subnets.&amp;quot;
type = &amp;quot;map&amp;quot;
}
&lt;/code>&lt;/pre>&lt;h2 id="the-vpc">The VPC&lt;/h2>
&lt;p>Now that we have defined the variables, we can set up the VPC:&lt;/p>
&lt;pre>&lt;code>// Define the VPC.
resource &amp;quot;aws_vpc&amp;quot; &amp;quot;cluster&amp;quot; {
cidr_block = &amp;quot;${var.vpc_cidr}&amp;quot;
enable_dns_hostnames = true
}
// An Internet Gateway for the VPC.
resource &amp;quot;aws_internet_gateway&amp;quot; &amp;quot;cluster_gateway&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
}
// Create one public subnet per key in the subnet map.
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
cidr_block = &amp;quot;${element(values(var.subnets), count.index)}&amp;quot;
map_public_ip_on_launch = true
depends_on = [&amp;quot;aws_internet_gateway.cluster_gateway&amp;quot;]
availability_zone = &amp;quot;${element(keys(var.subnets), count.index)}&amp;quot;
}
// Create a route table allowing all addresses access to the IGW.
resource &amp;quot;aws_route_table&amp;quot; &amp;quot;public&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
route {
cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
gateway_id = &amp;quot;${aws_internet_gateway.cluster_gateway.id}&amp;quot;
}
}
// Now associate the route table with the public subnet - giving
// all public subnet instances access to the internet.
resource &amp;quot;aws_route_table_association&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
subnet_id = &amp;quot;${element(aws_subnet.public-subnet.*.id, count.index)}&amp;quot;
route_table_id = &amp;quot;${aws_route_table.public.id}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>There are a few things of interest here. First, we can easily build a variable number of subnets by using the &lt;code>count&lt;/code> field on the &lt;code>aws_subnet&lt;/code> resource:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
availability_zone = &amp;quot;${element(keys(var.subnets), count.index)}&amp;quot;
cidr_block = &amp;quot;${element(values(var.subnets), count.index)}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>By using the &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html">Terraform Interpolation Syntax&lt;/a>, and in particular the &lt;code>count&lt;/code>, &lt;code>keys&lt;/code>, &lt;code>values&lt;/code> and &lt;code>element&lt;/code> functions, we can grab the subnet name and CIDR block from the variables.&lt;/p>
&lt;h2 id="the-web-server-cluster">The Web Server Cluster&lt;/h2>
&lt;p>A cluster of web servers behind a load balancer are created by the module, to demonstrate that it works. There is little of interest in the script except for how the subnets are referenced:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_autoscaling_group&amp;quot; &amp;quot;cluster_node&amp;quot; {
name = &amp;quot;cluster_node&amp;quot;
vpc_zone_identifier = [&amp;quot;${aws_subnet.public-subnet.*.id}&amp;quot;]
launch_configuration = &amp;quot;${aws_launch_configuration.cluster_node.name}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>Note that we can specify the entire list of subnet ids by using the &lt;code>*&lt;/code> symbol in the resource path - &lt;code>[&amp;quot;${aws_subnet.public-subnet.*.id}&amp;quot;]&lt;/code>.&lt;/p>
&lt;h2 id="thats-it">That's It!&lt;/h2>
&lt;p>That's really all there is to it. I quite like this approach. I think it makes it very clear what is going on with the infrastructure, and is fairly manageable.&lt;/p>
&lt;p>One question which may be raised is why I am not using the &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html#cidrsubnet-iprange-newbits-netnum-">&lt;code>cidrsubnet&lt;/code>&lt;/a> function to automatically calculate the CIDR blocks for the subnets. The reason is purely one of preference - I prefer to explicitly specify the CIDR blocks and use various patterns to set conventions. For example, if I see an IP address such as &lt;code>10.0.3.121&lt;/code> then it is in the third AZ of my public subnet, or &lt;code>10.2.2.11&lt;/code> is in the second AZ of my locked down data zone.&lt;/p>
&lt;p>You can see a sample Terraform module which uses this pattern at: &lt;a href="https://github.com/dwmkerr/terraform-aws-vpc-example">github.com/dwmkerr/terraform-aws-vpc-example&lt;/a>. This module also has a basic build pipeline and is published on the &lt;a href="https://registry.terraform.io/modules/dwmkerr/vpc-example">Terraform Registry&lt;/a>. I'll also be updating my &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">AWS Openshift&lt;/a> module to use this pattern.&lt;/p></description><category>CodeProject</category></item><item><title>A portable and magic-free way to open Pull Requests from the Command Line</title><link>https://dwmkerr.com/a-portable-and-magic-free-way-to-open-pull-requests-from-the-command-line/</link><pubDate>Wed, 10 Oct 2018 09:17:26 +0000</pubDate><guid>https://dwmkerr.com/a-portable-and-magic-free-way-to-open-pull-requests-from-the-command-line/</guid><description>&lt;p>This little bash snippet will let you open a GitHub or GitLab pull request from the command line on most Unix-like systems (OSX, Ubuntu, etc), without using any magic libraries, ZSH tricks or other dependencies.&lt;/p>
&lt;p>&lt;img src="images/gpr.png" alt="gpr">&lt;/p>
&lt;p>Here's how it looks in action OSX:&lt;/p>
&lt;p>&lt;img src="images/gpr.gif" alt="gpr">&lt;/p>
&lt;p>And Ubuntu:&lt;/p>
&lt;p>&lt;img src="images/gpr-ubuntu.gif" alt="gpr-ubuntu">&lt;/p>
&lt;p>The script is available as the &lt;a href="https://gist.github.com/dwmkerr/bae3fdca2d7208ec5d0008911d79b47d">&lt;code>gpr.sh&lt;/code>&lt;/a> gist. You can also find it in my &lt;a href="https://github.com/dwmkerr/dotfiles">dotfiles&lt;/a>, in the &lt;a href="https://github.com/dwmkerr/dotfiles/blob/master/profile/git.sh">git.sh&lt;/a> file.&lt;/p>
&lt;h2 id="the-script">The Script&lt;/h2>
&lt;p>Here's the script in its entirety:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Colour constants for nicer output.&lt;/span>
GREEN&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0;32m&amp;#39;&lt;/span>
RESET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0m&amp;#39;&lt;/span>
&lt;span style="color:#75715e"># Push the current branch to origin, set upstream, open the PR page if possible.&lt;/span>
gpr&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Get the current branch name, or use &amp;#39;HEAD&amp;#39; if we cannot get it.&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>git symbolic-ref -q HEAD&lt;span style="color:#66d9ef">)&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch##refs/heads/&lt;span style="color:#e6db74">}&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#66d9ef">:-&lt;/span>HEAD&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#75715e"># Pushing take a little while, so let the user know we&amp;#39;re working.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening pull request for &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Push to origin, grabbing the output but then echoing it back.&lt;/span>
push_output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>git push origin -u &lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span> 2&amp;gt;&amp;amp;1&lt;span style="color:#e6db74">`&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#75715e"># If there&amp;#39;s anything which starts with http, it&amp;#39;s a good guess it&amp;#39;ll be a&lt;/span>
&lt;span style="color:#75715e"># link to GitHub/GitLab/Whatever. So open it.&lt;/span>
link&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span> | grep -o &lt;span style="color:#e6db74">&amp;#39;http.*&amp;#39;&lt;/span> | sed -e &lt;span style="color:#e6db74">&amp;#39;s/[[:space:]]*$//&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
python -mwebbrowser &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>Blow-by-blow, let's take a look.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Colour constants for nicer output.&lt;/span>
GREEN&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0;32m&amp;#39;&lt;/span>
RESET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0m&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To make colouring console output easier, we create strings with the escape code required to set the &amp;lsquo;green&amp;rsquo; colour, and reset the text colour.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">gpr&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Get the current branch name, or use &amp;#39;HEAD&amp;#39; if we cannot get it.&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>git symbolic-ref -q HEAD&lt;span style="color:#66d9ef">)&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch##refs/heads/&lt;span style="color:#e6db74">}&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#66d9ef">:-&lt;/span>HEAD&lt;span style="color:#e6db74">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we define the &lt;code>gpr&lt;/code> (Git Pull Request) function. We'll need to push the current branch, so we need to get the current branch name. There's plenty of discussion on how this works on &lt;a href="https://stackoverflow.com/questions/6245570/how-to-get-the-current-branch-name-in-git">Stack Overflow: How to get the current branch name in Git&lt;/a>. Essentially we just get the symbolic name for the head of our current branch, which will be something like this:&lt;/p>
&lt;pre>&lt;code>refs/heads/my-new-branch
&lt;/code>&lt;/pre>&lt;p>We then use &lt;a href="https://www.tldp.org/LDP/abs/html/string-manipulation.html">Bash substring removal&lt;/a> to rip out the &lt;code>ref/heads/&lt;/code> part. If we have no branch (for example, we are detached) we just use &lt;code>HEAD&lt;/code> a the branch name.&lt;/p>
&lt;p>Next we have this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash"> &lt;span style="color:#75715e"># Pushing take a little while, so let the user know we&amp;#39;re working.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening pull request for &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Push to origin, grabbing the output but then echoing it back.&lt;/span>
push_output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>git push origin -u &lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span> 2&amp;gt;&amp;amp;1&lt;span style="color:#e6db74">`&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've previously defined some strings which include the escape codes to colour terminal output. Now we just show the user the branch we're going to push, push it and then store all of the output in the &lt;code>push_output&lt;/code> variable.&lt;/p>
&lt;p>The &lt;code>2&amp;gt;&amp;amp;1&lt;/code> idiom is a common one. This simply makes sure we put all &lt;code>stderr&lt;/code> output (which is always file descriptor 2) into &lt;code>stdout&lt;/code> (which is always file descriptor 1). This means whether the program writes output to &lt;code>stdout&lt;/code> or &lt;code>stderr&lt;/code>, we capture it. There's a nice write-up on this in the blog post &amp;lsquo;&lt;a href="https://www.brianstorti.com/understanding-shell-script-idiom-redirect/">Understanding Shell Script's idiom: 2&amp;gt;&amp;amp;1
&lt;/a>'.&lt;/p>
&lt;p>The output from Git push will be dependent on the Git server being used. For GitHub it'll look like this:&lt;/p>
&lt;pre>&lt;code>remote:
remote: Create a pull request for 'feat/doc-cleanup' on GitHub by visiting:
remote: https://github.com/dwmkerr/dotfiles/pull/new/feat/doc-cleanup
remote:
To github.com:dwmkerr/dotfiles
* [new branch] feat/doc-cleanup -&amp;gt; feat/doc-cleanup
Branch feat/doc-cleanup set up to track remote branch feat/doc-cleanup from origin.
&lt;/code>&lt;/pre>&lt;p>Now all we want to do is see if there is any text which starts with &lt;code>http&lt;/code> and if there is, then open it. Here's how we do that:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash"> &lt;span style="color:#75715e"># If there&amp;#39;s anything which starts with http, it&amp;#39;s a good guess it&amp;#39;ll be a&lt;/span>
&lt;span style="color:#75715e"># link to GitHub/GitLab/Whatever. So open it.&lt;/span>
link&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span> | grep -o &lt;span style="color:#e6db74">&amp;#39;http.*&amp;#39;&lt;/span> | sed -e &lt;span style="color:#e6db74">&amp;#39;s/[[:space:]]*$//&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
python -mwebbrowser &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This uses &lt;code>grep&lt;/code> to rip out everything from &lt;code>http&lt;/code> onwards, and the &lt;code>sed&lt;/code> to remove any trailing whitespace. If we have found a link, we use &lt;code>python&lt;/code> to open it (which is a fairly safe cross-platform solution).&lt;/p>
&lt;p>That's it! When you have a branch ready which you want to push and create a pull request from, just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">gpr
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And the branch will be pushed to &lt;code>origin&lt;/code>, and if there is a Pull Request webpage, it'll be opened.&lt;/p>
&lt;h2 id="prior-art">Prior Art&lt;/h2>
&lt;p>My colleague Tobias recently shared a nice trick we worked out to open a GitLab merge request - which also now works for GitHub:&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">git push and directly open PR in Chrome - works for &lt;a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github&lt;/a> &amp;amp; &lt;a href="https://twitter.com/gitlab?ref_src=twsrc%5Etfw">@gitlab&lt;/a> 🚀&lt;br>&lt;br>Here is how to set it up 👉 &lt;a href="https://t.co/YfNTmdwTFt">https://t.co/YfNTmdwTFt&lt;/a> &lt;a href="https://twitter.com/hashtag/github?src=hash&amp;amp;ref_src=twsrc%5Etfw">#github&lt;/a> &lt;a href="https://twitter.com/hashtag/gitlab?src=hash&amp;amp;ref_src=twsrc%5Etfw">#gitlab&lt;/a> &lt;a href="https://t.co/ISE9kVZmw1">pic.twitter.com/ISE9kVZmw1&lt;/a>&lt;/p>&amp;mdash; Tobias Büschel (@TobiasBueschel) &lt;a href="https://twitter.com/TobiasBueschel/status/1042452158430502915?ref_src=twsrc%5Etfw">September 19, 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I wanted to be able to use the same trick in Ubuntu and other Linux distros, but realised it relied on &lt;a href="https://github.com/robbyrussell/oh-my-zsh">oh-my-zsh&lt;/a> and assumed OSX with Chrome as the browser, so tweaked it to the above. Thanks Tobi!&lt;/p></description><category>CodeProject</category></item><item><title>Manipulating Istio and other Custom Kubernetes Resources in Golang</title><link>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</link><pubDate>Mon, 08 Oct 2018 21:34:02 +0000</pubDate><guid>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</guid><description>&lt;p>In this article I'll demonstrate how to use Golang to manipulate Kubernetes Custom Resources, with Istio as an example. No knowledge of Istio is needed, I'll just use it to demonstrate the concepts!&lt;/p>
&lt;p>&lt;img src="images/code-2.jpg" alt="code">&lt;/p>
&lt;p>&lt;a href="https://istio.io">Istio&lt;/a> is a highly popular Service Mesh platform which allows engineers to quickly add telemetry, advanced traffic management and more to their service-based applications.&lt;/p>
&lt;p>One interesting element of how Istio works is that when deployed into a Kubernetes cluster, many key configuration objects are handled as &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources&lt;/a>. Custom Resources are a very powerful Kubernetes feature, which allow you to create your own &amp;lsquo;first class&amp;rsquo; resources (just like Pods, ReplicaSets, Deployments or whatever) and then interface with them using &lt;code>kubectl&lt;/code> or the Kubernetes APIs.&lt;/p>
&lt;p>In this article I'll show you how to interface with these Custom Resources using the Golang Kubernetes client.&lt;/p>
&lt;h2 id="crds-a-quick-overview">CRDs: A Quick Overview&lt;/h2>
&lt;p>When you set up Istio for your cluster, one common thing you will likely do is specify how you will route traffic. This can be quite sophisticated, as shown below:&lt;/p>
&lt;p>&lt;img src="images/TrafficManagementOverview.svg" alt="TrafficManagementOverview">&lt;/p>
&lt;p>&lt;a href="https://istio.io/docs/concepts/traffic-management/">Figure 1: Istio Traffic Management Examples, from istio.io&lt;/a>&lt;/p>
&lt;p>One way for a system like this to be configured would be to have a ConfigMap which contains the definition of how services are routed.&lt;/p>
&lt;p>However, Istio actually registers new types of resources (Custom Resource Definitions) which represent things like Gateways or Services. We can create/update/delete/manipulate them just like any other Kubernetes object.&lt;/p>
&lt;p>For example, I could create a virtual service for the example above with something like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">cat &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF | kubectl create -f -
&lt;/span>&lt;span style="color:#e6db74">apiVersion: networking.istio.io/v1alpha3
&lt;/span>&lt;span style="color:#e6db74">kind: VirtualService
&lt;/span>&lt;span style="color:#e6db74">metadata:
&lt;/span>&lt;span style="color:#e6db74"> name: service2
&lt;/span>&lt;span style="color:#e6db74">spec:
&lt;/span>&lt;span style="color:#e6db74"> hosts:
&lt;/span>&lt;span style="color:#e6db74"> - &amp;#34;*&amp;#34;
&lt;/span>&lt;span style="color:#e6db74"> gateways:
&lt;/span>&lt;span style="color:#e6db74"> - demo1-gateway
&lt;/span>&lt;span style="color:#e6db74"> http:
&lt;/span>&lt;span style="color:#e6db74"> - route:
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v1
&lt;/span>&lt;span style="color:#e6db74"> weight: 95
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v2
&lt;/span>&lt;span style="color:#e6db74"> weight: 5
&lt;/span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, the important thing is not the specific content of this resource, more the fact that I can treat my Istio resources just like I would any other Kubernetes object:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io
NAME AGE
service2 93s
&lt;/code>&lt;/pre>&lt;p>Or:&lt;/p>
&lt;pre>&lt;code>$ kubectl delete virtualservices.networking.istio.io/service2
&lt;/code>&lt;/pre>&lt;p>I can use &lt;code>edit&lt;/code>, &lt;code>describe&lt;/code>, register lifecycle events, watch for changes, and so on.&lt;/p>
&lt;h2 id="working-with-crds-in-golang">Working with CRDs in Golang&lt;/h2>
&lt;p>The &lt;a href="https://github.com/kubernetes/client-go">Golang Kubernetes Client&lt;/a> allows you to create strongly defined types which you can then use to interface with CRDs. An example is in the Red Hat blog post &lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Kubernetes Deep Dive: Code Generation for Custom Resources&lt;/a>.&lt;/p>
&lt;p>This is an excellent approach, but can feel pretty heavy if you want to quickly access some data, and don't want to have to generate a lot of code.&lt;/p>
&lt;p>There is an alternative, which is to use the &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">&lt;code>DynamicClient&lt;/code>&lt;/a>. The &lt;em>preferred&lt;/em> approach seems to be the first, which involves code generation, so little documentation exists for the second approach. However, it is actually very simple.&lt;/p>
&lt;p>Here's an example of how you can list all Istio &lt;code>VirtualService&lt;/code> resources, without having to generate any code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a Dynamic Client to interface with CRDs.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">dynamicClient&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamic&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// List all of the Virtual Services.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServices&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">List&lt;/span>(&lt;span style="color:#a6e22e">metav1&lt;/span>.&lt;span style="color:#a6e22e">ListOptions&lt;/span>{})
&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#66d9ef">range&lt;/span> &lt;span style="color:#a6e22e">virtualServices&lt;/span>.&lt;span style="color:#a6e22e">Items&lt;/span> {
&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;VirtualService: %s\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span>.&lt;span style="color:#a6e22e">GetName&lt;/span>())
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet omits setup and error-handling for clarity, the full example is in the &lt;a href="https://gist.github.com/dwmkerr/09ac0fd98595460456e17d5ef0c77667">k8s-list-virtualservices.go&lt;/a> gist.&lt;/p>
&lt;h2 id="patching-crds-in-golang">Patching CRDs in Golang&lt;/h2>
&lt;p>You may have noticed that the &lt;code>.Resource().Namespace().List()&lt;/code> code looks very similar to the structure for making API calls when using the Kubernetes &lt;code>Clientset&lt;/code>. In fact, it is essentially the same. Looking at &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">the interface&lt;/a>, you can see you have all of the operations you'd expect:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Create&lt;/code>&lt;/li>
&lt;li>&lt;code>Update&lt;/code>&lt;/li>
&lt;li>&lt;code>Delete&lt;/code>&lt;/li>
&lt;li>&lt;code>Get&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>And so on. This is nice because you can use the same trick in my article &amp;lsquo;&lt;a href="https://www.dwmkerr.com/patching-kubernetes-resources-in-golang/">Patching Kubernetes Resources in Golang&lt;/a>&amp;rsquo; to manipulate these entities, without ever having to create a structure to represent it.&lt;/p>
&lt;p>Here's another abbreviated example, this time showing how we can adjust the weight of the routing from the services to 50%/50%:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// Weight the two routes - 50/50.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">patchPayload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> make([]&lt;span style="color:#a6e22e">PatchUInt32Value&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/0/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/1/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">patchPayload&lt;/span>)
&lt;span style="color:#75715e">// Apply the patch to the &amp;#39;service2&amp;#39; service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;service2&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">patchBytes&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>See the full example in the gist &lt;a href="https://gist.github.com/dwmkerr/7332888e092156ce8ce4ea551b0c321f">k8s-patch-virtualservice.go&lt;/a>&lt;/p>
&lt;p>After running the sample, you can use the Kubernetes CLI to verify the changes:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io/service2 -o yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
clusterName: &amp;quot;&amp;quot;
creationTimestamp: 2018-10-08T09:53:16Z
generation: 0
name: service2
namespace: default
resourceVersion: &amp;quot;487435&amp;quot;
selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/virtualservices/service2
uid: fac5930c-cadf-11e8-90a2-42010a94005b
spec:
gateways:
- demo1-gateway
hosts:
- '*'
http:
- route:
- destination:
host: service2
subset: v1
weight: 50
- destination:
host: service2
subset: v2
weight: 50
&lt;/code>&lt;/pre>&lt;h2 id="keep-it-simple">Keep It Simple!&lt;/h2>
&lt;p>That's it! This trick made something I was working on a &lt;em>lot&lt;/em> easier, but it took a little bit of experimentation to get right. I hope you find the approach useful. Please share any thoughts/questions in the comments.&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>The following articles were using in working out this approach:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Red Hat: Deep Dive: Code Generation for Custom Resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Kubernetes Docs: Custom Resources&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>Procedural Smiles - Animating SVG with pure JavaScript</title><link>https://dwmkerr.com/procedural-smiles-animating-svg-with-pure-javascript/</link><pubDate>Sun, 29 Jul 2018 23:36:46 +0000</pubDate><guid>https://dwmkerr.com/procedural-smiles-animating-svg-with-pure-javascript/</guid><description>&lt;p>I recently needed to be able to generate a simple face image, with the face being able to scale from happy to sad.&lt;/p>
&lt;p>(&lt;em>Why&lt;/em> I needed to do this is a long story!)&lt;/p>
&lt;p>This gave me the opportunity to have a play with SVG, which is something I've not done in a while and always wished I could spend more time with. You can see the result below, move the slider to see the smile animate:&lt;/p>
&lt;p data-height="265" data-theme-id="0" data-slug-hash="ejejeX" data-default-tab="result" data-user="dwmkerr" data-pen-title="SVG Smile" class="codepen">See the Pen &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX/">SVG Smile&lt;/a> by Dave Kerr (&lt;a href="https://codepen.io/dwmkerr">@dwmkerr&lt;/a>) on &lt;a href="https://codepen.io">CodePen&lt;/a>.&lt;/p>
&lt;script async src="https://static.codepen.io/assets/embed/ei.js">&lt;/script>
&lt;p>Source: &lt;a href="https://github.com/dwmkerr/svg-smile">github.com/dwmkerr/svg-smile/&lt;/a>
CodePen: &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX">codepen.io/dwmkerr/pen/ejejeX&lt;/a>&lt;/p>
&lt;h3 id="how-it-works---geometry">How it works - geometry&lt;/h3>
&lt;p>This is quite a simple effect to achieve, the trick is just to work out how the geometry of the smile will work:&lt;/p>
&lt;p>&lt;img src="images/points.jpg" alt="Smile Geometry" />&lt;/p>
&lt;p>The black points are the start and end point of the smile, the red points are the control points for the &lt;a href="%5E1">bezier curve&lt;/a>. This means that we can scale from a smile to a frown by just interpolating the position of the anchor and control points from the two extremes shown above.&lt;/p>
&lt;p>The face itself (without styling) just looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">svg&lt;/span> &lt;span style="color:#a6e22e">viewbox&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0 0 120 120&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;translate(60 60)&amp;#39;&lt;/span>&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> First the main circle for the face. &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;50&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Then the left eye... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-20&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-10&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Then the right... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;20&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-10&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> The smile bezier curve. &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;translate(0, 25)&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">path&lt;/span>
&lt;span style="color:#a6e22e">d&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,-10 C-20,10 20,10 20,-10&amp;#34;&lt;/span> /&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">svg&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The trick here is really just to use whatever coordinate system works for you. I start by defining a viewbox that gives me some space, translate the origin and then put the main circle of the face slap bang in the middle at &lt;code>(0, 0)&lt;/code>.&lt;/p>
&lt;p>The code to interpolate the smile control points is easier again if we shift the origin of the smile as well. This technique works well for SVGs (or any computer graphics), manipulate and transform to get the coordinate system to work for you and make it easier to reason about what is going on.&lt;/p>
&lt;h3 id="how-it-works---animation">How it works - animation&lt;/h3>
&lt;p>I've not animated SVG before. When looking into doing this, the vast majority of tips, blogs, articles and so on were suggesting to use a libary (common suggestions were &lt;a href="https://maxwellito.github.io/vivus/">vivus&lt;/a>, &lt;a href="http://snapsvg.io/">snap.svg&lt;/a> and &lt;a href="http://svgjs.com/">svg.js&lt;/a>).&lt;/p>
&lt;p>I've got no doubt that when you know what you are doing with SVG, using a library is a huge accelerator and saves on boilerplate. But if you don't know what a library is doing, what it is wrapping, or the problems it is solving for you, you are likely missing out some fundamentals.&lt;/p>
&lt;p>Using a library is great if you know &lt;em>what the problem is you are solving&lt;/em>. But if you don't, you end up never really learning. I had no idea whether this would be challenging to do with the pure SVG APIs and definitely wanted to work by hand.&lt;/p>
&lt;p>After some experimentation, I was able to write the markup which would move the smile to a frown:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;translate(0, 25)&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">path&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;smilepath&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">d&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,-10 C-20,10 20,10 20,-10&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">animate&lt;/span>
&lt;span style="color:#a6e22e">attributeName&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;d&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">attributeType&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;XML&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">to&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,10 C-20,-10 20,-10 20,10&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">dur&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;3s&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">repeatCount&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;indefinite&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">fill&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;freeze&amp;#34;&lt;/span>
/&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">path&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The geometry we've already seen, all we've done here is swap the position of each anchor and its associated control point. The trick is just making sure that we get the attributes of the &lt;code>animate&lt;/code> element right.&lt;/p>
&lt;p>Once this is done, the final step is just to make it all programmatic. The code to generate the geometry of the path, based on a scale from 0 (sad) to 1 (happy) is online, but the interesting thing is how to run the animation:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// note that &amp;#39;scale&amp;#39; is 0-&amp;gt;1 (sad-&amp;gt;happy)
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">points&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">writeSmilePoints&lt;/span>(&lt;span style="color:#a6e22e">smilePoints&lt;/span>(&lt;span style="color:#a6e22e">scale&lt;/span>));
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">svg&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">getElementById&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;svg&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">smilePath&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">getElementById&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;smilepath&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">animate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">createElementNS&lt;/span>(&lt;span style="color:#a6e22e">svg&lt;/span>.&lt;span style="color:#a6e22e">namespaceURI&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;animate&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;attributeName&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;d&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;attributeType&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;XML&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;to&amp;#39;&lt;/span>,&lt;span style="color:#a6e22e">points&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;dur&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;0.3s&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;repeatCount&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;1&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;fill&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;freeze&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">smilePath&lt;/span>.&lt;span style="color:#a6e22e">appendChild&lt;/span>(&lt;span style="color:#a6e22e">animate&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">beginElement&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's not much to it. The bulk of the code is just setting up the attributes for the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/animate">&lt;code>animate&lt;/code>&lt;/a> tag. Then we add it to the path as a child and call &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGAnimationElement">&lt;code>beginElement&lt;/code>&lt;/a> to start the animation.&lt;/p>
&lt;p>The face is coloured in a similar way. Interpolating between a happy Simpsons yellow and angry red in JavaScript, then setting an &lt;code>animate&lt;/code> element to target the &lt;code>fill&lt;/code> of the appropriate circle.&lt;/p>
&lt;h3 id="wrapping-up">Wrapping Up&lt;/h3>
&lt;p>Playing with graphics is fun! This is only the most basic scratching of the surface of what SVG can do. The JavaScript to animate is trivial (although I can appreciate that browser inconsistencies and so on mean a libary is probably useful at some point).&lt;/p>
&lt;p>The code is available on GitHub at &lt;a href="https://github.com/dwmkerr/svg-smile">github.com/dwmkerr/svg-smile&lt;/a> or on CodePen:&lt;/p>
&lt;p data-height="265" data-theme-id="0" data-slug-hash="ejejeX" data-default-tab="js,result" data-user="dwmkerr" data-pen-title="SVG Smile" class="codepen">See the Pen &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX/">SVG Smile&lt;/a> by Dave Kerr (&lt;a href="https://codepen.io/dwmkerr">@dwmkerr&lt;/a>) on &lt;a href="https://codepen.io">CodePen&lt;/a>.&lt;/p>
&lt;script async src="https://static.codepen.io/assets/embed/ei.js">&lt;/script></description><category>CodeProject</category></item><item><title>Patching Kubernetes Resources in Golang</title><link>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</link><pubDate>Tue, 24 Jul 2018 06:33:17 +0000</pubDate><guid>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</guid><description>&lt;p>Recently I needed to be able to quickly adjust the number of replicas in a Kubernetes Replication Controller. The original solution I'd seen pulled down the spec, modified it, then updated it. There's a better way!&lt;/p>
&lt;p>&lt;img src="images/patch-1.jpg" alt="Kuberentes Patch API">&lt;/p>
&lt;p>There's a &lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">patch API for Kubernetes resources&lt;/a>. Patching resources is faster and easier than pulling them and updating the spec wholesale. However, the documentation is a little limited.&lt;/p>
&lt;p>After some trial and error I got it working, here's the solution. I thought it might be helpful to share for others!&lt;/p>
&lt;h3 id="the-solution">The Solution&lt;/h3>
&lt;p>I'll start with the solution. If this is all you need, you are good to go. The details of how this works are presented afterwards. In this example I'll update the number of replicas in the &lt;code>my-rc&lt;/code> controller:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">package&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#e6db74">&amp;#34;encoding/json&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">types&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/types&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/kubernetes&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/plugin/pkg/client/auth&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/tools/clientcmd&amp;#34;&lt;/span>
)
&lt;span style="color:#66d9ef">var&lt;/span> (
&lt;span style="color:#75715e">// Leave blank for the default context in your kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">context&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#75715e">// Name of the replication controller to scale, and the desired number of replicas.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">replicationControllerName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;my-rc&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">replicas&lt;/span> = uint32(&lt;span style="color:#ae81ff">3&lt;/span>)
)
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a string.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchStringValue&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a uint32.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchUInt32Value&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientSet&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">Clientset&lt;/span>, &lt;span style="color:#a6e22e">replicasetName&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#a6e22e">scale&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span>) &lt;span style="color:#66d9ef">error&lt;/span> {
&lt;span style="color:#a6e22e">payload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> []&lt;span style="color:#a6e22e">patchUInt32Value&lt;/span>{{
&lt;span style="color:#a6e22e">Op&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Path&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Value&lt;/span>: &lt;span style="color:#a6e22e">scale&lt;/span>,
}}
&lt;span style="color:#a6e22e">payloadBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>)
&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientSet&lt;/span>.
&lt;span style="color:#a6e22e">CoreV1&lt;/span>().
&lt;span style="color:#a6e22e">ReplicationControllers&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).
&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#a6e22e">replicasetName&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">payloadBytes&lt;/span>)
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>() {
&lt;span style="color:#75715e">// Get the local kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to Kubernetes Context %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">context&lt;/span>)
&lt;span style="color:#a6e22e">config&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewNonInteractiveDeferredLoadingClientConfig&lt;/span>(
&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewDefaultClientConfigLoadingRules&lt;/span>(),
&lt;span style="color:#f92672">&amp;amp;&lt;/span>&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">ConfigOverrides&lt;/span>{&lt;span style="color:#a6e22e">CurrentContext&lt;/span>: &lt;span style="color:#a6e22e">context&lt;/span>}).&lt;span style="color:#a6e22e">ClientConfig&lt;/span>()
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Creates the clientset
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Scale our replication controller.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Scaling replication controller %v to %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#a6e22e">err&lt;/span> = &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code is also available in the &lt;a href="https://gist.github.com/dwmkerr/447692c8bba28929ef914239781c4e59">k8s-patch.go&lt;/a> gist.&lt;/p>
&lt;h3 id="the-mechanism">The Mechanism&lt;/h3>
&lt;p>The Kubernetes Patch API supports a few different methods for modifying resources. It is important to be aware that there is not a universally accepted &amp;lsquo;standard&amp;rsquo; approach to representing a &lt;em>change&lt;/em> to a resource in a REST API.&lt;/p>
&lt;p>There are three strategies you can use to patch:&lt;/p>
&lt;ol>
&lt;li>&lt;code>merge&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc7386">JSON Merge Patch Spec (RFC 7386)&lt;/a>&lt;/li>
&lt;li>&lt;code>stragetic&lt;/code>: A strategic merge, which addresses some limitations of the merge patch (noted in &lt;a href="%5Bdocs/devel/api-conventions.md#patch-operations%5D(https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations)">this doc&lt;/a>.&lt;/li>
&lt;li>&lt;code>json&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc6902">JSON Patch Spec (RFC 6902)&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>These are documented in detail at:&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">docs/devel/api-conventions.md#patch-operations&lt;/a>&lt;/p>
&lt;p>The mechanism I've used here is &lt;code>json&lt;/code>, which I think is the clearest to the reader. To use this strategy we need to build a payload describing what we are changing. This might look like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;op&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;value&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">4&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>op&lt;/code> field can be &lt;code>remove&lt;/code>, &lt;code>replace&lt;/code>, &lt;code>add&lt;/code> etc etc (all the details are in the &lt;a href="https://tools.ietf.org/html/rfc6902">RFC 6902)&lt;/a>, or the slightly more readable &lt;a href="jsonpatch.com">jsonpatch.com&lt;/a>). This allows the operation to be very &lt;em>explicit&lt;/em> to the reader, which is helpful. We create a struct which represents an operation on a string or integer (or whatever data type we need), serialize it and pass to the API.&lt;/p>
&lt;p>Under the hood, the Golang client will simply translate this into an HTTP call which will look like something like this:&lt;/p>
&lt;pre>&lt;code>PATCH /api/v1/namespaces/default/replicationcontrollers/app-server-blue HTTP/1.1
Host: 127.0.0.1
Content-Type: application/json-patch+json
Content-Length: 70
[{
&amp;quot;op&amp;quot;: &amp;quot;replace&amp;quot;,
&amp;quot;path&amp;quot;: &amp;quot;/spec/replicas&amp;quot;,
&amp;quot;value&amp;quot;: 4
}]
&lt;/code>&lt;/pre>&lt;p>This corresponds to the documentation on the &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Patch Operations&lt;/a>. Note that the patch operation type is specified in the &lt;code>Content-Type&lt;/code> header.&lt;/p>
&lt;p>Hopefully this'll help you if you need to patch resources, are struggling with the docs and are a Go noob like me! Any tips on how to make the code cleaner or more idomatic would be welcome.&lt;/p>
&lt;p>Thanks to the following articles and issues which helped me unpick this:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://stackoverflow.com/questions/43415728/kubernetes-go-client-patch-example">Stack Overflow: Kubernetes Go Client Patch Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">Kubernetes Docs: Update API Objects in Place Using kubectl patch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Kubernetes Docs: Patch Operations&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>mongo-monitor - a simple CLI to monitor your MongoDB cluster</title><link>https://dwmkerr.com/mongo-monitor-cli/</link><pubDate>Wed, 16 May 2018 20:09:53 +0000</pubDate><guid>https://dwmkerr.com/mongo-monitor-cli/</guid><description>&lt;p>The &lt;code>mongo-monitor&lt;/code> CLI is a lean and simple tool to check the status of a MongoDB server or cluster. The code is on GitHub:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/mongo-monitor">github.com/dwmkerr/mongo-monitor&lt;/a>&lt;/p>
&lt;p>Here's how it looks in action:&lt;/p>
&lt;p>&lt;img src="images/overview.gif" alt="Screenshot: Using the mongo-monitor CLI to monitor a sharded cluster">&lt;/p>
&lt;p>In this animation I am monitoring a simple sharded cluster, and running some example maintenance operations, adding a node to a replicaset, stepping down a primary and shutting down a replicaset node.&lt;/p>
&lt;p>A simple CLI which shows the status in real-time can be very useful to keep open when performing admin, letting you see how your changes affect the cluster as you work on it.&lt;/p>
&lt;h2 id="installing-the-cli">Installing the CLI&lt;/h2>
&lt;p>The CLI is installed with &lt;code>npm&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install -g mongo-monitor
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="connecting-to-a-cluster">Connecting to a Cluster&lt;/h2>
&lt;p>Connect to a cluster by providing a connection string. The tool uses &lt;a href="https://github.com/dwmkerr/mongo-connection-string">&lt;code>mongo-connection-string&lt;/code>&lt;/a> to parse the connection string, so you can be flexible with the input:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Connect to a local instance&lt;/span>
mongo-monitor localhost:27107
&lt;span style="color:#75715e"># Connect to a remote replicaset, authenticated&lt;/span>
mongo-monitor admin:P@sswrd@mdbnode1,mdbnode2,mdbnode3?replicaSet&lt;span style="color:#f92672">=&lt;/span>rs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once a connection is established, the tool will periodically check the status of the cluster. If the cluster is sharded, it will also inspect each individual replicaset.&lt;/p>
&lt;h2 id="replicaset-status">Replicaset Status&lt;/h2>
&lt;p>Here's the kind of output you might get from a replicaset:&lt;/p>
&lt;p>&lt;img src="images/replicaset.jpg" alt="Screenshot: Replicaset Status">&lt;/p>
&lt;p>The name of the replicaset is shown, along with each member. The status of each member is also shown, updating automatically every second.&lt;/p>
&lt;p>This is convenient when administering replicasets, stepping down a master, adding or removing nodes and so on.&lt;/p>
&lt;h2 id="sharded-cluster-status">Sharded Cluster Status&lt;/h2>
&lt;p>When connecting to a sharded cluster, you will get output like this:&lt;/p>
&lt;p>&lt;img src="images/sharded-cluster.jpg" alt="Screenshot: Sharded Cluster Status">&lt;/p>
&lt;p>Each shard is shown, along with the details of the replicaset which make it up.&lt;/p>
&lt;p>Keeping a view like this open is useful when administering sharded clusters, adding or removing shards, desharding, updating the replicasets which make up shards and so on.&lt;/p>
&lt;h2 id="get-involved">Get Involved!&lt;/h2>
&lt;p>If you like the tool, check out the code and feel free to make pull requests with additions! There are a few &lt;a href="https://github.com/dwmkerr/mongo-monitor/issues">issues&lt;/a> on the project already, and there are all sorts of features I'd love to add but haven't had the time, such as:&lt;/p>
&lt;ul>
&lt;li>Being able to see the lag for replicaset members, to see if secondaries are falling behind&lt;/li>
&lt;li>Being able to perform replicaset operations directly from the tool&lt;/li>
&lt;li>Showing the priorities of nodes if they are not the default&lt;/li>
&lt;/ul>
&lt;p>All ideas are welcome, let me know in the comments or repo, and share the tool if you find it useful!&lt;/p></description><category>CodeProject</category></item><item><title>The Death of Microservice Madness in 2018</title><link>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</link><pubDate>Fri, 12 Jan 2018 10:52:25 +0000</pubDate><guid>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</guid><description>&lt;p>&lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">En Español&lt;/a> | &lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit Thread&lt;/a> | &lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News Thread&lt;/a>&lt;/p>
&lt;p>Microservices became a very popular topic over the last couple of years&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. &amp;lsquo;Microservice madness&amp;rsquo; goes something like this:&lt;/p>
&lt;blockquote>
&lt;p>Netflix are great at devops.
Netflix do microservices.
Therefore: If I do microservices, I am great at devops.&lt;/p>
&lt;/blockquote>
&lt;p>There are many cases where great efforts have been made to adopt microservice patterns without necessarily understanding how the costs and benefits will apply to the specifics of the problem at hand.&lt;/p>
&lt;p>I'm going to describe in detail what microservices are, why the pattern is so appealing, and also some of the key challenges that they present.&lt;/p>
&lt;p>I'll finish with a set of simple questions might be valuable to ask yourself when you are considering whether microservices are the right pattern &lt;em>for you&lt;/em>. The questions are at the end of the article.&lt;/p>
&lt;p>&lt;img src="images/letterbox.png" alt="Letterbox sample of diagram">&lt;/p>
&lt;h2 id="what-are-microservices-and-why-are-they-so-popular">What are microservices, and why are they so popular?&lt;/h2>
&lt;p>Let's start with the basics. Here is how a hypothetical video sharing platform might be implemented, first in the form of a monolith (single large unit) and then in the form of microservices:&lt;/p>
&lt;p>&lt;img src="images/video-platform-monolith-microservices.png" alt="Diagram: Comparison of a Video Sharing Platform, Monolith vs Microservice">&lt;/p>
&lt;p>The difference between the two systems is that the first is a single large unit; a monolith. The second is a set of small, specific services. Each service has a specific role.&lt;/p>
&lt;p>When the diagram is drawn &lt;em>at this level of detail&lt;/em>, it is easy to see the appeal. There are a whole host of potential benefits:&lt;/p>
&lt;p>&lt;strong>Independent Development&lt;/strong>: Small, independent components can be built by small, independent teams. A group can work on a change to the &amp;lsquo;Upload&amp;rsquo; service without interfering with the &amp;lsquo;Transcode&amp;rsquo; service, or even knowing about it. The amount of time to learn about a component is greatly reduced, and it is easier to develop new features.&lt;/p>
&lt;p>&lt;strong>Independent Deployment&lt;/strong>: Each individual component can be deployed independently. This allows new features to be released with greater velocity and less risk. Fixes or features for the &amp;lsquo;Streaming&amp;rsquo; component can be deployed without requiring other components to be deployed.&lt;/p>
&lt;p>&lt;strong>Independent Scalability&lt;/strong>: Each component can be scaled independently of each other. During busy periods when new shows are released, the &amp;lsquo;Download&amp;rsquo; component can be scaled up to handle the increased load, without having to scale up every component, which makes elastic scaling more feasible and reduces costs.&lt;/p>
&lt;p>&lt;strong>Reusability&lt;/strong>: Components fulfil a small, specific function. This means that they can more easily be adapted for use in other systems, services or products. The &amp;lsquo;Transcode&amp;rsquo; component could be used by other business units, or even turned into a new business, perhaps offering transcoding services for other groups.&lt;/p>
&lt;p>At this level of detail, the benefits of a microservice model over a monolithic model seem obvious. So if that's the case - why is this pattern only recently in vogue? Where has it been all my life?&lt;/p>
&lt;h2 id="if-this-is-so-great-why-hasnt-it-been-done-before">If this is so great, why hasn't it been done before?&lt;/h2>
&lt;p>There are two answers to this question. One is that &lt;em>it has&lt;/em> - to the best of our technical capabilities, and the other is that more recent technical advances have allowed us to take it to a new level.&lt;/p>
&lt;p>When I started writing the answer to this question, it turned into a &lt;em>long&lt;/em> description, so I'm actually going to separate it into another article and publish it a little later&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. At this stage, I will skip the journey from single program to many programs, ignore ESBs and Service Orientated Architecture, component design and bounded contexts, and so on.&lt;/p>
&lt;p>Those who are interested can read more about the journey separately. Instead I'll say that in many ways we've been doing this for a while, but with the recent explosion in popularity of container technology (Docker in particular) and in orchestration technology (such as Kubernetes, Mesos, Consul and so on) this pattern has become much more viable to implement from a technical standpoint.&lt;/p>
&lt;p>So if we take it as a given that we &lt;em>can&lt;/em> implement a microservice arrangement, we need to think carefully about the &lt;em>should&lt;/em>. We've seen the high-level theoretical benefits, but what about the challenges?&lt;/p>
&lt;h2 id="whats-the-problem-with-microservices">What's the problem with microservices?&lt;/h2>
&lt;p>If microservices are so great, what's the big deal? Here are some of the biggest issues I've seen.&lt;/p>
&lt;p>&lt;strong>Increased complexity for developers&lt;/strong>&lt;/p>
&lt;p>Things &lt;em>can&lt;/em> get a lot harder for developers. In the case where a developer wants to work on a &lt;em>journey&lt;/em>, or feature which might span many services, that developer has to run them all on their machine, or connect to them. This is often more complex than simply running a single program.&lt;/p>
&lt;p>This challenge can be partially mitigated with tooling&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, but as the number of services which makes up a system increases, the more challenges developers will face when running the system as a whole.&lt;/p>
&lt;p>&lt;strong>Increased complexity for operators&lt;/strong>&lt;/p>
&lt;p>For teams who don't develop services, but maintain them, there is an explosion in potential complexity. Instead of perhaps managing a few running services, they are managing dozens, hundreds or thousands of running services. There are more services, more communication paths, and more areas of potential failure.&lt;/p>
&lt;p>&lt;strong>Increased complexity for devops&lt;/strong>&lt;/p>
&lt;p>Reading the two points above, it may grate that operations and development are treated separately, especially given the popularity of devops as a practice (which I am a big proponent of). Doesn't devops mitigate this?&lt;/p>
&lt;p>The challenge is that many organisations still run with separated development and operations teams - and a organisation that does is much more likely to struggle with adoption of microservices.&lt;/p>
&lt;p>For organisations which have adopted devops, it's still hard. Being both a developer and an operator is already tough (but critical to build good software), but having to also understand the nuances of container orchestration systems, particularly systems which are evolving at a rapid pace, is very hard. Which brings me onto the next point.&lt;/p>
&lt;p>&lt;strong>It requires serious expertise&lt;/strong>&lt;/p>
&lt;p>When done by experts, the results can be wonderful. But imagine an organisation where perhaps things are not running smoothly with a single monolithic system. What possible reason would there be that things would be any better by increasing the number of systems, which increases the operational complexity?&lt;/p>
&lt;p>Yes, with effective automation, monitoring, orchestration and so on, this is all possible. But the challenge is rarely the technology - the challenge is finding people who can use it effectively. These skillsets are currently in very high demand, and may be difficult to find.&lt;/p>
&lt;p>&lt;strong>Real world systems often have poorly defined boundaries&lt;/strong>&lt;/p>
&lt;p>In all of the examples we used to describe the benefits of microservices, we spoke about &lt;em>independent&lt;/em> components. However in many cases components are simply not independent. On paper, certain domains may look bounded, but as you get into the muddy details, you may find that they are more challenging to model than you anticipated.&lt;/p>
&lt;p>This is where things can get &lt;em>extremely&lt;/em> complex. If your boundaries are actually not well defined, then what happens is that even though &lt;em>theoretically&lt;/em> services can be deployed in isolation, you find that due to the inter-dependencies between services, you have to deploy &lt;em>sets&lt;/em> of services as a group.&lt;/p>
&lt;p>This then means that you need to manage coherent versions of services which are proven and tested when working together, you don't actually have an independently deployable system, because to deploy a new feature, you need to carefully orchestrate the simultaneous deployment of many services.&lt;/p>
&lt;p>&lt;strong>The complexities of state are often ignored&lt;/strong>&lt;/p>
&lt;p>In the previous example, I mentioned that a feature deployment may require the simultaneous rollout of many versions of many services in tandem. It is tempting to assume that sensible deployment techniques will mitigate this, for example blue/green deployments (which most service orchestration platforms handle with little effort), or multiple versions of a service being run in parallel, with consuming channels deciding which version to use.&lt;/p>
&lt;p>These techniques mitigate a large number of the challenges &lt;em>if the services are stateless&lt;/em>. But stateless services are quite frankly, easy to deal with. In fact, if you have stateless services, then I'd be inclined to consider skipping microservices altogether and consider using a serverless model.&lt;/p>
&lt;p>In reality, many services require state. An example from our video sharing platform might be the subscription service. A new version of the subscriptions service may store data in the subscriptions database in a different shape. If you are running both services in parallel, you are running the system with two schemas at once. If you do a blue green deployment, and other services depend on data in the new shape, then they must be updated &lt;em>at the same time&lt;/em>, and if the subscription service deployment fails and rolls back, they might need to roll back too, with cascading consequences.&lt;/p>
&lt;p>Again, it might be tempting to think that with NoSQL databases these issues of schema go away, but they don't. Databases which don't enforce schema do not lead to schemaless systems - they just mean that schema tends to be managed at the application level, rather than the database level. The fundamental challenge of understanding the shape of your data, and how it evolves, cannot be eliminated.&lt;/p>
&lt;p>&lt;strong>The complexitities of communication are often ignored&lt;/strong>&lt;/p>
&lt;p>As you build a large network of services which depend on each other, the liklihood is that there will be a lot of inter-service communication. This leads to a few challenges. Firstly, there are a lot more points at which things can fail. We must expect that network calls will fail, which means when one service calls another, it should expect to have to retry a number of times at the least. Now when a service has to potentially call many services, we end up in a complicated situation.&lt;/p>
&lt;p>Imagine a user uploads a video in the video sharing service. We might need to run the upload service, pass data to the transcode service, update subscriptions, update recommendations and so on. All of these calls require a degree of orchestration, if things fail we need to retry.&lt;/p>
&lt;p>This retry logic can get hard to manage. Trying to do things synchronously often ends up being untenable, there are too many points of failure. In this case, a more reliable solution is to use asynchronous patterns to handle communication. The challenge here is that asynchronous patterns inherently make a system stateful. As mentioned in the previous point, stateful systems and systems with distributed state are very hard to handle.&lt;/p>
&lt;p>When a microservice system uses message queues for intra-service communication, you essentially have a large database (the message queue or broker) glueing the services together. Again, although it might not seem like a challenge at first, schema will come back to bite you. A service at version X might write a message with a certain format, services which depend on this message will also need to be updated when the sending service changes the details of the message it sends.&lt;/p>
&lt;p>It is possible to have services which can handle messages in many different formats, but this is hard to manage. Now when deploying new versions of services, you will have times where two different versions of a service may be trying to process messages from the same queue, perhaps even messages sent by different versions of a sending service. This can lead to complicated edge cases. To avoid these edge cases, it may be easier to only allow certain versions of messages to exist, meaning that you need to deploy a set of versions of a set of services as a coherent whole, ensuring messages of older versions are drained appropriately first.&lt;/p>
&lt;p>This highlights again that the idea of independent deployments may not hold as expected when you get into the details.&lt;/p>
&lt;p>&lt;strong>Versioning can be hard&lt;/strong>&lt;/p>
&lt;p>To mitigate the challenges mentioned previously, versioning needs to be very carefully managed. Again, there can be a tendency to assume that following a standard such as semver[4] will solve the problem. It doesn't. Semver is a sensible convention to use, but you will still have to track the versions of services and APIs which can work together.&lt;/p>
&lt;p>This can get very challenging very quickly, and may get to the point where you don't know which versions of services will actually work properly together.&lt;/p>
&lt;p>Managing dependencies in software systems is notoriously hard, whether it is node modules, Java modules, C libraries or whatever. The challenges of &lt;em>conflicts between independent components&lt;/em> when consumed by a single entity are very hard to deal with.&lt;/p>
&lt;p>These challenges are hard to deal with when the dependencies are static, and can be patched, updated, edited and so on, but if the dependencies are themselves &lt;em>live services&lt;/em>, then you may not be able to just update them - you may have to run many versions (with the challenges already described) or bring down the system until it is fixed holistically.&lt;/p>
&lt;p>&lt;strong>Distributed Transactions&lt;/strong>&lt;/p>
&lt;p>In situations where you need transaction integrity across an operation, microservices can be very painful. Distributed state is hard to deal with, many small units which can fail make orchestrating transactions very hard.&lt;/p>
&lt;p>It may be tempting to attempt to avoid the problem by making operations idempotent, offering retry mechanisms and so on, and in many cases this might work. But you may have scenarios where you simply need a transaction to fail or succeed, and never be in an intermediate state. The effort involved in working around this or implementing it in a microservice model may be very high.&lt;/p>
&lt;p>&lt;strong>Microservices can be monoliths in disguise&lt;/strong>&lt;/p>
&lt;p>Yes, individual services and components &lt;em>may&lt;/em> be deployed in isolation, however in most cases you are going to have to be running some kind of orchestration platform, such as Kubernetes. If you are using a managed service, such as Google's GKE&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> or Amazon's EKS&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>, then a large amount of the complexity of managing the cluster is handled for you.&lt;/p>
&lt;p>However, if you are managing the cluster yourself, you are managing a large, complicated, mission critical system. Although the individual services may have all of the benefits described earlier, you need to very carefully manage your cluster. Deployments of this system can be hard, updates can be hard, failover can be hard and so on.&lt;/p>
&lt;p>In many cases the overall benefits are still there, but it is important not to trivialise or underestimate the additional complexity of managing another big, complex system. Managed services may help, but in many cases these services are nascent (Amazon EKS was only announced at the end of 2017 for example).&lt;/p>
&lt;p>&lt;strong>Networking Nightmares&lt;/strong>&lt;/p>
&lt;p>A more traditional model of services running on known hosts, with known addresses, has a fairly simple networking setup.&lt;/p>
&lt;p>However, when using microservices, generally there will be many services distributed across many nodes, which typically means there's going to be a &lt;em>much&lt;/em> more complicated networking arrangement. There will be load balancing between services, DNS may be more heavily used, virtual networking layers, etc etc, to attempt to &amp;lsquo;hide&amp;rsquo; the complexity of this networking.&lt;/p>
&lt;p>However, as per &lt;a href="https://github.com/dwmkerr/hacker-laws/#the-law-of-conservation-of-complexity-teslers-law">Tesler's Law&lt;/a> (or the Law of Conservation of Compexlity), this networking complexity is inherent - when you are finding real, runtime issues in larger scale clusters, it can often be at a very low networking level. These sorts of issues can be &lt;em>very&lt;/em> hard to diagnose. I have started tracking some examples at the end of the article, but I think that &lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Migration to Kuberenetes&lt;/a> shows this challenge very well.&lt;/p>
&lt;p>Overall - the transition is still likely to be for the best, but doesn't come without some serious challenges at the networking level, which will require some serious expertise to deal with!&lt;/p>
&lt;h2 id="the-death-of-microservice-madness">The Death of Microservice Madness!&lt;/h2>
&lt;p>Avoid the madness by making careful and considered decisions. To help out on this I've noted a few questions you might want to ask yourself, and what the answers might indicate:&lt;/p>
&lt;p>&lt;img src="images/questions.png" alt="Diagram: Questions to ask yourself when considering microservices">&lt;/p>
&lt;p>You can download a PDF copy here: &lt;a href="https://github.com/dwmkerr/blog/blob/master/articles/2018/microservice-madness/images/microservice-questions.pdf">microservice-questions.pdf&lt;/a>&lt;/p>
&lt;h2 id="final-thoughts-dont-confuse-microservices-with-architecture">Final Thoughts: Don't Confuse Microservices with Architecture&lt;/h2>
&lt;p>I've deliberately avoided the &amp;lsquo;a&amp;rsquo; word in this article. But my friend &lt;a href="http://twitter.com/zoltanarvai">Zoltan&lt;/a> made a very good point when proofing this article (which he has contributed to).&lt;/p>
&lt;p>There is no microservice architecture. Microservices are just another pattern or implementation of components, nothing more, nothing less. Whether they are present in a system or not does not mean that the architecture of the system is solved.&lt;/p>
&lt;p>Microservices relate in many ways more to the technical processes around packaging and operations rather than the intrinsic design of the system. Appropriate boundaries for components continues to be one of the most important challenges in engineering systems.&lt;/p>
&lt;p>Regardless of the size of your services, whether they are in Docker containers or not, you will always need to think carefully about how to put a system together. There are no right answers, and there are a &lt;em>lot&lt;/em> of options.&lt;/p>
&lt;p>I hope you found this article interesting! As always, please do comment below if you have any questions or thoughts. You can also follow some lively discussions on:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="appendix-further-reading">Appendix: Further Reading&lt;/h2>
&lt;p>The following links might be of interest:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://martinfowler.com/bliki/BoundedContext.html">Martin Fowler - Bounded Context&lt;/a> - Martin's articles are great, I'd thoroughly recommend this.&lt;/li>
&lt;li>&lt;a href="https://martinfowler.com/articles/microservices.html">Martin Fowler - Microservices&lt;/a> - An often recommended introduction to the pattern.&lt;/li>
&lt;li>&lt;a href="https://r2m.se/microservices-good-or-bad/">Microservices - Good or Bad?&lt;/a> - Björn Frantzén's thoughts on microservices, after reading this article.&lt;/li>
&lt;li>&lt;a href="http://blog.christianposta.com/microservices/when-not-to-do-microservices/">When Not To Do Microservices&lt;/a> - Excellent post on the topic from Christian Posta&lt;/li>
&lt;li>&lt;a href="http://www.iheavy.com/2017/03/13/30-questions-to-ask-a-serverless-fanboy/">Sean Hull - 30 questions to ask a serverless fanboy&lt;/a> - Interesting thoughts on the challenges of serverless, from a serverless fan!&lt;/li>
&lt;li>&lt;a href="https://youtu.be/NVb7aljfKYo?t=6657">Dave Kerr - Monoliths to Microservices - Practical tips for CI/CD and DevOps in the Microservice world&lt;/a> - A recent conference presentation I did on devops with microservices.&lt;/li>
&lt;li>&lt;a href="https://yermakov.net/microservices-without-fundamentals/">Alexander Yermakov - Microservices without fundamentals&lt;/a> - A response to this article, with Alex's thoughts and counterpoints to the points raised here (see also &lt;a href="https://yermakov.net/microservices-as-a-self-sufficient-concept/">Microservices as a self sufficient concept&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>Please do share anything else you think makes great reading or watching on the topic!&lt;/p>
&lt;hr>
&lt;h2 id="thanks">Thanks&lt;/h2>
&lt;p>Thanks José from &lt;a href="https://www.campusmvp.es">campusmvp.es&lt;/a> for having the article translated in Spanish - &lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">La muerte de la locura de los microservicios en 2018&lt;/a>!&lt;/p>
&lt;h2 id="case-studies">Case Studies&lt;/h2>
&lt;p>Some interesting examples of experiences I am collecting of larger organisations who have made large scale transitions to microservices:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Move to Kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="references">References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice">https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If you don't want to miss the article, you can subscribe to the &lt;a href="http://www.dwmkerr.com/rss/">RSS Feed&lt;/a>, or follow me on &lt;a href="https://www.linkedin.com/in/dwmkerr/">LinkedIn&lt;/a> or &lt;a href="https://twitter.com/dwmkerr">Twitter&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Docker Compose is a good solution, &lt;a href="https://github.com/apparatus/fuge">Fuge&lt;/a> is very clever, and there is also the option of running orchestration locally as is the case with something like MiniKube. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Google Kubernetes Engine, a managed service from Google Cloud Platform for Kubernetes: &lt;a href="https://cloud.google.com/kubernetes-engine/">https://cloud.google.com/kubernetes-engine/&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Amazon Elastic Container Services for Kubernetes, a managed service from Amazon Web Services for Kubernetes: &lt;a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/&lt;/a> &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 3: Getting Help</title><link>https://dwmkerr.com/effective-shell-part-3-getting-hepl/</link><pubDate>Tue, 19 Dec 2017 09:05:18 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-3-getting-hepl/</guid><description>&lt;p>This is the third part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series - practical examples of ways to be more efficient with everyday tasks in a shell.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article I'll show you how to quickly get help when working with tools in the shell, without disrupting your flow!&lt;/p>
&lt;h2 id="getting-help-is-important">Getting Help is Important!&lt;/h2>
&lt;p>If you are trying to be more effective when using the shell, it is crucial to know how to quickly look things up.&lt;/p>
&lt;p>There'll be many circumstances where you'll need to open a browser to search for help, but there's also a wealth of information only a few keystrokes away. Looking up parameters, checking how to run commads, C library docs or useful information like ASCII charts are available directly in the system.&lt;/p>
&lt;p>Before we look at the standard way of accessing documentation on unix-like systems, which is the &lt;code>man&lt;/code> command, I'm going to introduce &lt;a href="https://github.com/tldr-pages/tldr">&lt;code>tldr&lt;/code>&lt;/a>.&lt;/p>
&lt;p>Nine times out of ten I get the help I need in a few seconds with &lt;code>tldr&lt;/code>, so if you take only one thing away from the article, take the first section. Then if you want to learn more about the system manuals, read on!&lt;/p>
&lt;h2 id="tldr">tl;dr&lt;/h2>
&lt;p>Let's say I need to find and replace some text in a file. I know I can do this with the &lt;code>sed&lt;/code> command, but have forgotten the syntax.&lt;/p>
&lt;p>All I need to do is run &lt;code>tldr sed&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/tldr-sed.png" alt="tldr sed screenshot">&lt;/p>
&lt;p>The first example is exactly what I'm looking for. Now for any more detail than a few basic examples, I'm going to have to go to the manual, but it's overkill for the basics. Here's what &lt;code>man sed&lt;/code> shows me:&lt;/p>
&lt;p>&lt;img src="images/man-sed.png" alt="sed manpage">&lt;/p>
&lt;p>And this is just page one of six! There's a &lt;em>lot&lt;/em> of detail, which is great sometimes, but for a quick lookup, &lt;code>tldr&lt;/code> is perfect.&lt;/p>
&lt;p>You can install the &lt;a href="https://github.com/tldr-pages/tldr">&lt;code>tldr&lt;/code>&lt;/a> tool with &lt;code>npm install -g tldr&lt;/code>. It's open source and community maintained.&lt;/p>
&lt;p>Now a lot of the time, you are still going to need more help or more detail. For the rest of the article, we'll dive a bit deeper into &lt;code>man&lt;/code>, the system manual pages.&lt;/p>
&lt;h2 id="understanding-man">Understanding &amp;lsquo;man&amp;rsquo;&lt;/h2>
&lt;p>Most tools you encounter in the shell have manual pages available. Many people will be familiar with the &lt;code>man&lt;/code> command to get help on a tool, but let's take a look in a bit more detail, there's actually a lot more available than just the documentation for common commands.&lt;/p>
&lt;h3 id="getting-help-on-a-command">Getting help on a command&lt;/h3>
&lt;p>The most basic way to get help on a command is with &lt;code>man&lt;/code>. Here's an example:&lt;/p>
&lt;pre>&lt;code>$ man cp
CP(1) BSD General Commands Manual CP(1)
NAME
cp -- copy files
SYNOPSIS
cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file
cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ...
target_directory
DESCRIPTION
In the first synopsis form, the cp utility copies the contents of the
source_file to the target_file. In the second synopsis form, the con-
tents of each named source_file is copied to the destination
target_directory. The names of the files themselves are not changed. If
cp detects an attempt to copy a file to itself, the copy will fail.
...
&lt;/code>&lt;/pre>&lt;p>The &lt;code>man&lt;/code> command opens the manual for the given tool. These manuals should contain all command line options and details of how to use the tool.&lt;/p>
&lt;p>You can scroll up and down through the content with the arrow keys, this is because the information is presented in the shell &lt;em>pager&lt;/em>, which is a tool for looking through content which might not easily fit on a screen.&lt;/p>
&lt;h3 id="using-the-pager">Using the pager&lt;/h3>
&lt;p>The first thing you might notice is that you can move through the manual pages with the arrow keys.&lt;/p>
&lt;p>Manpages are just text files, and &lt;code>man&lt;/code> opens them in a pager tool, which is what is providing the keyboard interface to look through the file.&lt;/p>
&lt;p>On most systems, the pager will be the &lt;code>less&lt;/code> program. There are lots of commands you can use to navigate through files with &lt;code>less&lt;/code>, but the bare essentials are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>d&lt;/code> - Scroll down half a page&lt;/li>
&lt;li>&lt;code>u&lt;/code> - Scroll up half a page&lt;/li>
&lt;li>&lt;code>j&lt;/code> / &lt;code>k&lt;/code> - Scroll down or up a line. You can also use the arrow keys for this&lt;/li>
&lt;li>&lt;code>q&lt;/code> - Quit&lt;/li>
&lt;li>&lt;code>/&amp;lt;search&amp;gt;&lt;/code> - Search for text&lt;/li>
&lt;li>&lt;code>n&lt;/code> - When searching, find the next occurrence&lt;/li>
&lt;li>&lt;code>N&lt;/code> - When searching, find the previous occurrence&lt;/li>
&lt;/ul>
&lt;p>There are &lt;em>many&lt;/em> other commands, but the set above is normally what I find myself using the most.&lt;/p>
&lt;p>If you are interested, you can actually see what your pager is with the command below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ echo $PAGER
less
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>$PAGER&lt;/code> environment variable is used to tell the shell what program to use for paging. More details are found with &lt;code>man man&lt;/code>.&lt;/p>
&lt;p>You can put any text content into your pager - try this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">ls -al /usr/bin | less
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This lists the contents of the &lt;code>/usr/bin&lt;/code> folder, piping the output to &lt;code>less&lt;/code> so we can easily scroll through it.&lt;/p>
&lt;p>There are alternative pagers available (on many Unix-y systems you'll have &lt;code>less&lt;/code>, &lt;code>more&lt;/code> and &lt;code>most&lt;/code>) but in general you'll normally get what you need with &lt;code>less&lt;/code>.&lt;/p>
&lt;h3 id="whats-with-the-numbers">What's with the numbers?&lt;/h3>
&lt;p>You'll often see tools referred to in manpages with numbers after them. Take a look at &lt;code>man less&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/numbers.png" alt="Screenshot of numbers">&lt;/p>
&lt;p>The number is the manual &lt;strong>Section Number&lt;/strong>. The different sections of the manual are documented be found on most unix-like systems in &lt;code>man&lt;/code>'s documentation, which you can check by running &lt;code>man man&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Here's what you'd get on Ubuntu 16:&lt;/p>
&lt;p>| 1 | Executable programs or shell commands |
| 2 | System calls (functions provided by the kernel) |
| 3 | Library calls (functions within program libraries) |
| 4 | Special files (usually found in /dev) |
| 5 | File formats and conventions eg /etc/passwd |
| 6 | Games |
| 7 | Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7) |
| 8 | System administration commands (usually only for root) |
| 9 | Kernel routines [Non standard] |&lt;/p>
&lt;p>We'll go through the setions in detail shorltly.&lt;/p>
&lt;p>You can specifically choose &lt;em>which&lt;/em> section of the manual you are looking in by using:&lt;/p>
&lt;pre>&lt;code>man &amp;lt;section&amp;gt; &amp;lt;search&amp;gt;
&lt;/code>&lt;/pre>&lt;p>You can also get more information about the sections themselves by opening up the &lt;code>intro&lt;/code> page. For example:&lt;/p>
&lt;pre>&lt;code>$ man 1 intro
INTRO(1) BSD General Commands Manual INTRO(1)
NAME
intro -- introduction to general commands (tools and utilities)
DESCRIPTION
Section one of the manual contains most of the commands which comprise...
&lt;/code>&lt;/pre>&lt;p>Why would you do this, and why would you care? A few examples from each section show how this can be quite useful to know about.&lt;/p>
&lt;h4 id="section-1-programs-and-shell-commands">Section 1: Programs and Shell Commands&lt;/h4>
&lt;p>These are programs, probably what you are going to be looking up most regularly! For example, &lt;code>man 1 time&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>TIME(1) BSD General Commands Manual TIME(1)
NAME
time -- time command execution
SYNOPSIS
time [-lp] utility
DESCRIPTION
The time utility executes and times utility. After the utility finishes, time writes the total time
elapsed, the time consumed by system overhead, and the time used to execute utility to the standard
error stream. Times are reported in seconds.
...
&lt;/code>&lt;/pre>&lt;h4 id="section-2-system-calls">Section 2: System Calls&lt;/h4>
&lt;p>You'll probably not use this section unless you are doing systems programming&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. This section contains info on the avaiable Linux Kernel system calls. For example, running &lt;code>man 2 chown&lt;/code> gives:&lt;/p>
&lt;pre>&lt;code>CHOWN(2) BSD System Calls Manual CHOWN(2)
NAME
chown, fchown, lchown, fchownat -- change owner and group of a file
SYNOPSIS
#include &amp;lt;unistd.h&amp;gt;
int
chown(const char *path, uid_t owner, gid_t group);
...
&lt;/code>&lt;/pre>&lt;h4 id="section-3-library-calls">Section 3: Library Calls&lt;/h4>
&lt;p>These are the manpages for the C standard library functions. For example, &lt;code>man 3 time&lt;/code>:&lt;/p>
&lt;pre>&lt;code>TIME(3) BSD Library Functions Manual TIME(3)
NAME
time -- get time of day
LIBRARY
Standard C Library (libc, -lc)
SYNOPSIS
#include &amp;lt;time.h&amp;gt;
time_t
time(time_t *tloc);
...
&lt;/code>&lt;/pre>&lt;p>Here we can see why the sections are important to know about.&lt;/p>
&lt;p>Running &lt;code>man time&lt;/code> would &lt;em>not&lt;/em> open the page above, because &lt;code>man&lt;/code> searches the library in ascending section order, meaning that it actually finds &lt;code>time(1)&lt;/code> and shows the pages for the &lt;code>time&lt;/code> program, not the &lt;code>time&lt;/code> C library call.&lt;/p>
&lt;p>Because of the potential ambiguity of names if no section number is included, in lots of Linux documentation you'll see the man section number written next to library calls, system calls, programs and so on (things will refer to &lt;code>sed(1)&lt;/code> or &lt;code>time(3)&lt;/code> for example.&lt;/p>
&lt;h4 id="section-4-devices">Section 4: Devices&lt;/h4>
&lt;p>This section deals with the special devices which live in the &lt;code>/dev/*&lt;/code> folder. For example, running &lt;code>man 4 random&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>RANDOM(4) BSD Kernel Interfaces Manual RANDOM(4)
NAME
random , urandom -- random data source devices.
SYNOPSIS
pseudo-device random
DESCRIPTION
The random device produces uniformly distributed random byte values of
potentially high quality.
...
&lt;/code>&lt;/pre>&lt;p>Again, we see that section numbers can be important. If you just run &lt;code>man random&lt;/code>, you'll see:&lt;/p>
&lt;pre>&lt;code>RANDOM(3) BSD Library Functions Manual RANDOM(3)
NAME
initstate, random, setstate, srandom, srandomdev -- better random num-
ber generator; routines for changing generators
LIBRARY
Standard C Library (libc, -lc)
SYNOPSIS
#include &amp;lt;stdlib.h&amp;gt;
char *
initstate(unsigned seed, char *state, size_t size);
long
random(void);
...
&lt;/code>&lt;/pre>&lt;p>Which is the manpage for &lt;code>random(3)&lt;/code>, which is C library function, not the &lt;code>/dev/random&lt;/code> file!&lt;/p>
&lt;h4 id="section-5-file-formats">Section 5: File Formats&lt;/h4>
&lt;p>This section details special files in the system. For example, &lt;code>man 5 crontab&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>CRONTAB(5) BSD File Formats Manual CRONTAB(5)
NAME
crontab -- tables for driving cron
DESCRIPTION
A crontab file contains instructions to the cron(8) daemon of the gen-
eral form: ``run this command at this time on this date''. Each user
has their own crontab, and commands in any given crontab will be exe-
cuted as the user who owns the crontab. Uucp and News will usually
have their own crontabs, eliminating the need for explicitly running
su(1) as part of a cron command.
...
&lt;/code>&lt;/pre>&lt;p>Which describes the crontab file used to define scheduled tasks. Again, this is different to &lt;code>man crontab&lt;/code> which would document &lt;code>crontab(1)&lt;/code>. Similarly, &lt;code>man 5 passwd&lt;/code> is going to show something quite different to &lt;code>man passwd&lt;/code>.&lt;/p>
&lt;h4 id="section-6-games">Section 6: Games&lt;/h4>
&lt;p>Nothing says it better than &lt;code>man 6 intro&lt;/code> itself (this'll not work on a Mac sadly, but try it on another Linux system):&lt;/p>
&lt;pre>&lt;code>...
DESCRIPTION
Section 6 of the manual describes all the games and funny little programs available on the system.
...
&lt;/code>&lt;/pre>&lt;p>There are probably a few silly programs available on your system, here you'll find their manuals. For example, &lt;code>man 6 banner&lt;/code> on a Mac shows:&lt;/p>
&lt;pre>&lt;code>BANNER(6) BSD Games Manual BANNER(6)
NAME
banner -- print large banner on printer
SYNOPSIS
banner [-d] [-t] [-w width] message ...
DESCRIPTION
Banner prints a large, high quality banner on the standard output. If
the message is omitted, it prompts for and reads one line of its stan-
dard input.
...
&lt;/code>&lt;/pre>&lt;p>This section is going to be highly dependent on your OS!&lt;/p>
&lt;h4 id="section-7-miscellaneous">Section 7: Miscellaneous&lt;/h4>
&lt;p>This is where you'll find additional assorted documentation. For example, &lt;code>man 7 ascii&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>ASCII(7) BSD Miscellaneous Information Manual ASCII(7)
NAME
ascii -- octal, hexadecimal and decimal ASCII character sets
DESCRIPTION
The octal set:
000 nul 001 soh 002 stx 003 etx 004 eot 005 enq 006 ack 007 bel
...
&lt;/code>&lt;/pre>&lt;h4 id="section-8-system-commands">Section 8: System Commands&lt;/h4>
&lt;p>We've actually already seen one of these commands mentioned, in the manpage for &lt;code>crontab(5)&lt;/code> it mentions &lt;code>cron(8)&lt;/code>. Let's see, with &lt;code>man 8 cron&lt;/code>:&lt;/p>
&lt;pre>&lt;code>CRON(8) BSD System Manager's Manual CRON(8)
NAME
cron -- daemon to execute scheduled commands (Vixie Cron)
SYNOPSIS
cron [-s] [-o] [-x debugflag[,...]]
&lt;/code>&lt;/pre>&lt;p>These are commands which sysadmins would normally run. You might open section eight unexpectedly, for example &lt;code>man chmod&lt;/code> will open &lt;code>chmod(1)&lt;/code>, but &lt;code>man chown&lt;/code> will open &lt;code>chown(8)&lt;/code>, as it is a system command.&lt;/p>
&lt;p>Some distributions might vary for Section Nine. On my Mac it contains information about the kernel interfaces, a C style guide and some more.&lt;/p>
&lt;h4 id="getting-the-index-of-manual-section">Getting the Index of Manual Section&lt;/h4>
&lt;p>Manpages are just files on the filesystem, so you can get the index of a section just by looking in the appropriate folder.&lt;/p>
&lt;p>For example, to index the available system calls, try &lt;code>ls /usr/share/man/man2&lt;/code>:&lt;/p>
&lt;pre>&lt;code>EV_SET.2
FD_CLR.2
FD_COPY.2
FD_ISSET.2
FD_SET.2
FD_ZERO.2
_exit.2
accept.2
access.2
acct.2
...
&lt;/code>&lt;/pre>&lt;p>This is quick and easy way to see what sort of entries you have on your system. If you want to work out where an entry lives, use the &lt;code>-w&lt;/code> flag:&lt;/p>
&lt;pre>&lt;code>$ man -w printf
/usr/share/man/man1/printf.1
&lt;/code>&lt;/pre>&lt;h3 id="searching-the-manual">Searching the Manual&lt;/h3>
&lt;p>You can search the manpage titles and summaries with &lt;code>man -k&lt;/code>. For example, &lt;code>man -k cpu&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>cpuwalk.d(1m) - Measure which CPUs a process runs on. Uses DTrace
dispqlen.d(1m) - dispatcher queue length by CPU. Uses DTrace
gasm(n), grammar::me::cpu::gasm(n) - ME assembler
&lt;/code>&lt;/pre>&lt;p>You can find more advanced options for searching by using your newfound &lt;code>man&lt;/code> skills on &lt;code>man&lt;/code> itself.&lt;/p>
&lt;h2 id="thats-enough">That's Enough!&lt;/h2>
&lt;p>I'd recommend &lt;code>tldr&lt;/code> as a first-call for checking to see how to use a command.&lt;/p>
&lt;p>&lt;code>man&lt;/code> is a powerful tool to dive deeper into how programs and components of the system work. Like many tools which have been around for a long time, there's a lot you can do with &lt;code>man&lt;/code>. Much of it you'll likely never need, so I've tried to keep this article to the basics.&lt;/p>
&lt;p>Understanding manpage sections is useful - you'll see them referenced again and again in documentation on the system and online.&lt;/p>
&lt;p>I hope this helps you save some time when you are working! Please let me know in the comments if you have any questions or thoughts.&lt;/p>
&lt;p>You can also check out the &lt;a href="https://github.com/dwmkerr/effective-shell">rest of the effective shell series&lt;/a>.&lt;/p>
&lt;h2 id="appendix-dash">Appendix: Dash&lt;/h2>
&lt;p>As a final note, if you find yourself using &lt;code>man&lt;/code> a lot because you work offline (I fly a lot so find it very helpful when on a plane with no WiFi), you should also look at &lt;em>Dash&lt;/em>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Dash is simply an offline documentation aggregator. It can download online manuals for many, many different programming languages, frameworks, technologies and so on. I actually have a &lt;code>vim&lt;/code> keyboard command to open the word under the cursor in dash, with the documentation automatically set based on the type of the file.&lt;/p>
&lt;p>This is super-useful if you are offline at lot and need more sophisticated offline documentation. You can find out more about it at &lt;a href="https://kapeli.com/dash">https://kapeli.com/dash&lt;/a>.&lt;/p>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Weirdly satisfying to run. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Which it is always fun to try if you get the chance, and a great way to learn more about the fundamentals of the operating system. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Dash is a paid product. Full disclosure - I don't get any money from them or anyone else to write about anything, all content is 100% based on my experiences. I don't run ads on my site either. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Integrating OpenShift and Splunk for Docker Container Logging</title><link>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</link><pubDate>Sun, 29 Oct 2017 07:15:04 +0000</pubDate><guid>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</guid><description>&lt;p>In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.&lt;/p>
&lt;p>These techniques could easily be adapted for a standard Kubernetes installation as well!&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>The techniques used in this article are based on the &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging">Kubernetes Logging Cluster Administration Guide&lt;/a>. I also found Jason Poon's article &lt;a href="http://jasonpoon.ca/2017/04/03/kubernetes-logging-with-splunk/">Kubernetes Logging with Splunk&lt;/a> very helpful.&lt;/p>
&lt;p>First, clone the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">Terraform AWS OpenShift&lt;/a> repo:&lt;/p>
&lt;pre>&lt;code>git clone git@github.com:dwmkerr/terraform-aws-openshift
&lt;/code>&lt;/pre>&lt;p>This repo can be used to create a vanilla OpenShift cluster. I'm adding &amp;lsquo;recipes&amp;rsquo; to the project, which will allow you to mix in more features (but still keep the main codebase clean). For now, let's merge in the &amp;lsquo;splunk&amp;rsquo; recipe:&lt;/p>
&lt;pre>&lt;code>cd terraform-aws-openshift
git pull origin recipes/splunk
&lt;/code>&lt;/pre>&lt;p>Pulling this recipe in adds the extra config and scripts required to set up Splunk&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Now we've got the code, we can get started!&lt;/p>
&lt;h2 id="create-the-infrastructure">Create the Infrastructure&lt;/h2>
&lt;p>To create the cluster, you'll need to install the &lt;a href="https://aws.amazon.com/cli/">AWS CLI&lt;/a> and log in, and install &lt;a href="https://www.terraform.io/downloads.html">Terraform&lt;/a>.&lt;/p>
&lt;p>Before you continue, &lt;font color="red">&lt;strong>be aware&lt;/strong>&lt;/font>: the machines on AWS we'll create are going to run to about $250 per month:&lt;/p>
&lt;p>&lt;img src="images/aws-cost.png" alt="AWS Cost Calculator">&lt;/p>
&lt;p>Once you are logged in with the AWS CLI just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make infrastructure
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You'll be asked to specify a region:&lt;/p>
&lt;p>&lt;img src="images/region.png" alt="Specify Region">&lt;/p>
&lt;p>Any &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">AWS region&lt;/a> will work fine, use &lt;code>us-east-1&lt;/code> if you are not sure.&lt;/p>
&lt;p>It'll take about 5 minutes for Terraform to build the required infrastructure, which looks like this:&lt;/p>
&lt;p>&lt;img src="images/splunk-architecture.png" alt="AWS Infrastructure">&lt;/p>
&lt;p>Once it's done you'll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/apply-complete.png" alt="Apply Complete">&lt;/p>
&lt;p>The infrastructure is ready! A few of the most useful parameters are shown as output variables. If you log into AWS you'll see our new instances, as well as the VPC, network settings etc etc:&lt;/p>
&lt;p>&lt;img src="images/aws.png" alt="AWS">&lt;/p>
&lt;h2 id="installing-openshift">Installing OpenShift&lt;/h2>
&lt;p>Installing OpenShift is easy:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make openshift
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will take quite some time to run (sometimes up to 30 minutes). Once it is complete you'll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/openshift-complete.png" alt="OpenShift Installation Complete">&lt;/p>
&lt;p>You can now open the OpenShift console. Use the public address of the master node (which you can get with &lt;code>$(terraform output master-url)&lt;/code>), or just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make browse-openshift
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The default username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You'll see we have a clean installation and are ready to create our first project:&lt;/p>
&lt;p>&lt;img src="images/welcome-to-openshift.png" alt="Welcome to OpenShift">&lt;/p>
&lt;p>Close the console for now.&lt;/p>
&lt;h2 id="installing-splunk">Installing Splunk&lt;/h2>
&lt;p>You've probably figured out the pattern by now&amp;hellip;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make splunk
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once this command is complete, you can open the Splunk console with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make browse-splunk
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again the username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You can change the password on login, or leave it:&lt;/p>
&lt;p>&lt;img src="images/splunk-home.png" alt="Splunk Login">&lt;/p>
&lt;p>You can close the Splunk console now, we'll come back to it shortly.&lt;/p>
&lt;h2 id="demoing-splunk-and-openshift">Demoing Splunk and OpenShift&lt;/h2>
&lt;p>To see Splunk and OpenShift in action, it helps to have some kind of processing going on in the cluster. You can create a very basic sample project which will spin up two nodes which just write a counter every second as a way to get something running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make sample
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will create a simple &amp;lsquo;counter&amp;rsquo; service:&lt;/p>
&lt;p>&lt;img src="images/counter-service.png" alt="Screenshot: The counter service">&lt;/p>
&lt;p>We can see the logs in OpenShift:&lt;/p>
&lt;p>&lt;img src="images/counter-service-logs.png" alt="Screenshot: The counter service logs">&lt;/p>
&lt;p>Almost immediately you'll be able to see the data in Splunk:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk-data-summary.png" alt="Screenshot: The Splunk data explorer">&lt;/p>
&lt;p>And because of the way the log files are named, we can even rip out the namespace, pod, container and id:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>That's it! You have OpenShift running, Splunk set up and automatically forwarding of all container logs. Enjoy!&lt;/p>
&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>I've tried to keep the setup as simple as possible. Here's how it works.&lt;/p>
&lt;h3 id="how-log-files-are-written">How Log Files Are Written&lt;/h3>
&lt;p>The Docker Engine has a &lt;a href="https://docs.docker.com/engine/admin/logging/overview/">log driver&lt;/a> which determines how container logs are handled&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. It defaults to the &lt;code>json-file&lt;/code> driver, which means that logs are written as a json file to:&lt;/p>
&lt;pre>&lt;code>/var/lib/docker/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;p>Or visually:&lt;/p>
&lt;p>&lt;img src="images/logging-docker-1.png" alt="Diagram: How Docker writes log files">&lt;/p>
&lt;p>Normally we wouldn't touch this file, in theory it is supposed to be used internally&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> and we would use &lt;code>docker logs &amp;lt;container-id&amp;gt;&lt;/code>.&lt;/p>
&lt;p>In theory, all we need to do is use a &lt;a href="http://docs.splunk.com/Documentation/Forwarder/7.0.0/Forwarder/Abouttheuniversalforwarder">Splunk Forwarder&lt;/a> to send this file to our indexer. The only problem is that we only get the container ID from the file name, finding the right container ID for your container can be a pain. However, we are running on Kubernetes, which means the picture is a little different&amp;hellip;&lt;/p>
&lt;h3 id="how-log-files-are-written---on-kubernetes">How Log Files Are Written - on Kubernetes&lt;/h3>
&lt;p>When running on Kubernetes, things are little different. On machines with &lt;code>systemd&lt;/code>, the log driver for the docker engine is set to &lt;code>journald&lt;/code> (see &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Kubernetes - Logging Architecture&lt;/a>.&lt;/p>
&lt;p>It &lt;em>is&lt;/em> possible to forward &lt;code>journald&lt;/code> to Splunk, but only by streaming it to a file and then forwarding the file. Given that we need to use a file as an intermediate, it seems easier just to change the driver back to &lt;code>json-file&lt;/code> and forward that.&lt;/p>
&lt;p>So first, we configure the docker engine to use &lt;code>json-file&lt;/code> (see &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/blob/recipes/splunk/scripts/postinstall-master.sh">this file&lt;/a>):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sed -i &lt;span style="color:#e6db74">&amp;#39;/OPTIONS=.*/c\OPTIONS=&amp;#34;--selinux-enabled --insecure-registry 172.30.0.0/16 --log-driver=json-file --log-opt max-size=1M --log-opt max-file=3&amp;#34;&amp;#39;&lt;/span> /etc/sysconfig/docker
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we just change the options to default to the &lt;code>json-file&lt;/code> driver, with a max file size of 1MB (and maximum of three files, so we don't chew all the space on the host).&lt;/p>
&lt;p>Now the cool thing about Kubernetes is that it creates symlinks to the log files, which have much more descriptive names:&lt;/p>
&lt;p>&lt;img src="images/logging-k8s.png" alt="Symlink diagram">&lt;/p>
&lt;p>We still have the original container log, in the same location. But we also have a pod container log (which is a symlink to the container log) and another container log, which is a symlink to the pod container log.&lt;/p>
&lt;p>This means we can read the container log, and extract some really useful information from the file name. The container log file name has the following format:&lt;/p>
&lt;pre>&lt;code>/var/log/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;h3 id="how-log-files-are-read">How Log Files Are Read&lt;/h3>
&lt;p>Now that we are writing the log files to a well defined location, reading them is straightforward. The diagram below shows how we use a splunk-forwarder to complete the picture:&lt;/p>
&lt;p>&lt;img src="images/how-logs-are-read.png" alt="Diagram: How logs are read">&lt;/p>
&lt;p>First, we create a DaemonSet, which ensures we run a specific pod on every node.&lt;/p>
&lt;p>The DaemonSet runs with a new account which has the &amp;lsquo;any id&amp;rsquo; privilege, allowing it to run as root. We then mount the log folders into the container (which are owned by root, which is why our container needs these extra permissions to read the files).&lt;/p>
&lt;p>The pod contains a splunk-forwarder container, which is configured to monitor the &lt;code>/var/log/containers&lt;/code> folder. It also monitors the docker socket, allowing us to see docker events. The forwarder is also configured with the IP address of the Splunk Indexer.&lt;/p>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>As a reference, you can also see the recipe pull request to see what changes from a &amp;lsquo;vanilla&amp;rsquo; installation to add Splunk: &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/pull/16">Splunk Recipe Pull Request&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>It is useful to check the documentation on logging drivers for Docker. See &lt;a href="https://docs.docker.com/engine/admin/logging/overview/#supported-logging-drivers">Configure Logging Drivers&lt;/a> and &lt;a href="https://docs.docker.com/engine/extend/plugins_logging/">Docker Log Driver Plugins&lt;/a>. It is possible to create custom log drivers. However, at the time of writing only the journald and json-file log drivers will work with the integrated logging view in OpenShift. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 2: Become a Clipboard Gymnast</title><link>https://dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/</link><pubDate>Tue, 10 Oct 2017 09:57:54 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/</guid><description>&lt;p>This is the second part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series, which contains practical tips for using the shell to help with every day tasks and be more efficient:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article I'll show you how you can use the shell as an efficient tool to compliment how you use the clipboard.&lt;/p>
&lt;p>&lt;em>Note for Linux Users: In this article I'll use the &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> commands to access the clipboard, which are available on a Mac only. To get access to the same commands on other platforms, check &lt;a href="#appendixclipboardaccessonlinux">Appendix: Clipboard Access on Linux&lt;/a>&lt;/em>.&lt;/p>
&lt;h2 id="use-the-shell-on-the-clipboard">Use the Shell on the Clipboard&lt;/h2>
&lt;p>You can easily use shell commands on the contents of your clipboard. Just use &lt;code>pbpaste&lt;/code> to output the clipboard, run the output through some commands, then use &lt;code>pbcopy&lt;/code> to copy the result.&lt;/p>
&lt;p>Try copying the following text:&lt;/p>
&lt;pre>&lt;code>Kirk Van Houten
Timothy Lovejoy
Artie Ziff
&lt;/code>&lt;/pre>&lt;p>Then in the shell, run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">pbpaste
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You should see the contents of the clipboard. Now we'll look at some ways that shell access to the clipboard can help with common tasks.&lt;/p>
&lt;h2 id="removing-formatting">Removing Formatting&lt;/h2>
&lt;p>Don't you hate it when you have to copy formatted text and don't have an easy way to paste it as &lt;em>unformatted&lt;/em> text? Here's an example, I want to copy this Wikipedia page on &amp;lsquo;bash&amp;rsquo;, and paste it into a Word document:&lt;/p>
&lt;p>&lt;img src="images/strip-formatting-before.png" alt="Copying and pasting with formatting">&lt;/p>
&lt;p>Many programs have a shortcut to paste the contents of the clipboard (such as &amp;lsquo;command + shift + v&amp;rsquo;) but if you are like me you might find yourself pasting &lt;em>into&lt;/em> a plain text editor just to copy &lt;em>out&lt;/em> the plain text.&lt;/p>
&lt;p>If you just run the command &lt;code>pbpaste | pbcopy&lt;/code>, you can easily strip the formatting:&lt;/p>
&lt;p>&lt;img src="images/strip-formatting-after-2.png" alt="Stripping formatting from the clipboard">&lt;/p>
&lt;p>We're just piping out the clipboard (which ends up as plain text, cause we're in a terminal!) and then piping that plain text &lt;em>back into the clipboard&lt;/em>, replacing the formatted text which was there before.&lt;/p>
&lt;p>This little trick can be very useful. But we can use the same pattern to quickly manipulate the contents of the clipboard in more sophisticated ways.&lt;/p>
&lt;h2 id="manipulating-text">Manipulating Text&lt;/h2>
&lt;p>Let's say someone has emailed me a list of people I need to invite to an event:&lt;/p>
&lt;p>&lt;img src="images/email_list_excel.png" alt="Email List">&lt;/p>
&lt;p>The problem is:&lt;/p>
&lt;ol>
&lt;li>The list is in Excel and is formatted&lt;/li>
&lt;li>The list has duplicates&lt;/li>
&lt;li>I need to turn each name into an email address like &lt;a href="mailto:'Artie_Ziff@simpsons.com">'Artie_Ziff@simpsons.com&lt;/a>&amp;rsquo;&lt;/li>
&lt;/ol>
&lt;p>And I want to email everyone quickly.&lt;/p>
&lt;p>We can quickly handle this task without leaving the shell.&lt;/p>
&lt;p>Copy the raw text below if you want to try out the same commands and follow along:&lt;/p>
&lt;pre>&lt;code>Artie Ziff
Kirk Van Houten
Timothy Lovejoy
Artie Ziff
Nick Riviera
Seymore Skinner
Hank Scorpio
Timothy Lovejoy
John Frink
Cletus Spuckler
Ruth Powers
Artie Ziff
Agnes Skinner
Helen Lovejoy
&lt;/code>&lt;/pre>&lt;p>First, we copy the text to the clipboard.&lt;/p>
&lt;p>Now we can paste and sort:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort
Agnes Skinner
Artie Ziff
Artie Ziff
Artie Ziff
Cletus Spuckler
Hank Scorpio
Helen Lovejoy
John Frink
Kirk Van Houten
Nick Riviera
Ruth Powers
Seymore Skinner
Timothy Lovejoy
Timothy Lovejoy
&lt;/code>&lt;/pre>&lt;p>Then remove the duplicates:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq
Agnes Skinner
Artie Ziff
Cletus Spuckler
Hank Scorpio
Helen Lovejoy
John Frink
Kirk Van Houten
Nick Riviera
Ruth Powers
Seymore Skinner
Timothy Lovejoy
&lt;/code>&lt;/pre>&lt;p>Replace the underscore with an ampersand:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr &amp;quot; &amp;quot; &amp;quot;_&amp;quot;
Agnes_Skinner
Artie_Ziff
Cletus_Spuckler
Hank_Scorpio
Helen_Lovejoy
John_Frink
Kirk_Van_Houten
Nick_Riviera
Ruth_Powers
Seymore_Skinner
Timothy_Lovejoy
&lt;/code>&lt;/pre>&lt;p>Then add the final part of the email address:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr &amp;quot; &amp;quot; &amp;quot;_&amp;quot; | sed 's/$/@simpsons.com/'
Agnes_Skinner@simpsons.com
Artie_Ziff@simpsons.com
Cletus_Spuckler@simpsons.com
Hank_Scorpio@simpsons.com
Helen_Lovejoy@simpsons.com
John_Frink@simpsons.com
Kirk_Van_Houten@simpsons.com
Nick_Riviera@simpsons.com
Ruth_Powers@simpsons.com
Seymore_Skinner@simpsons.com
Timothy_Lovejoy@simpsons.com
&lt;/code>&lt;/pre>&lt;p>This looks perfect! We can now put the transformed text back onto the clipboard:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr ' ' '_' | sed 's/$/@simpsons.com' | pbcopy
&lt;/code>&lt;/pre>&lt;p>All in all we have the following pipeline:&lt;/p>
&lt;ol>
&lt;li>&lt;code>pbpaste&lt;/code> - output the clipboard&lt;/li>
&lt;li>&lt;code>sort&lt;/code> - order the output&lt;/li>
&lt;li>&lt;code>uniq&lt;/code> - deduplicate the rows&lt;/li>
&lt;li>&lt;code>tr ' ' '_'&lt;/code> - replace spaces with underscores&lt;/li>
&lt;li>&lt;code>sed /$/@simpsons.com&lt;/code> - add the email domain to the end of the row&lt;/li>
&lt;/ol>
&lt;p>Building this in one go is hard, let's look at little more at the pipeline.&lt;/p>
&lt;h2 id="thinking-in-pipelines">Thinking in Pipelines&lt;/h2>
&lt;p>Some of these commands might be unfamiliar, some might not make sense, and you might be thinking &amp;lsquo;how would I remember that&amp;rsquo;. Actually, there are many ways to solve the problem above, this is the one I came up with by &lt;em>iteratively&lt;/em> changing my input text.&lt;/p>
&lt;p>Here's what I mean - you'll see that I actually build a pipeline like this step-by-step:&lt;/p>
&lt;p>&lt;img src="images/pipeline.gif" alt="Animation of the process of building a pipeline">&lt;/p>
&lt;p>You can see in the screenshots that I start simple, and step by step add the stages we need.&lt;/p>
&lt;p>(P.S - if you are wondering how I am jumping backwards and forwards a word at a time, check the last chapter &amp;lsquo;&lt;a href="www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Navigating the Command Line&lt;/a>').&lt;/p>
&lt;p>What we're doing here is only possible because these simple commands all follow &amp;lsquo;the Unix Philosophy&amp;rsquo;. They do one thing well, and each command expects it's input to become the input of &lt;em>another&lt;/em> command later on. Specifically:&lt;/p>
&lt;ol>
&lt;li>The commands are primitive and simple - &lt;code>sort&lt;/code> is sorting a list, &lt;code>uniq&lt;/code> is making elements unique.&lt;/li>
&lt;li>The commands don't produce unnecessary output - &lt;code>sort&lt;/code> doesn't add a header such as &lt;code>Sorted Items&lt;/code>, which is great because otherwise it would clutter our pipeline.&lt;/li>
&lt;li>We are chaining commands together, the output of one becomes the input of another.&lt;/li>
&lt;/ol>
&lt;p>We don't need a command such as &amp;lsquo;Take a muddy list, sort and clean it, then turn pairs of words into an email address&amp;rsquo; - with a few simple &amp;lsquo;workhorse&amp;rsquo; commands we can easily build this functionality ourselves.&lt;/p>
&lt;p>These workhorse commands will be introduced and detailed as we go through the series. We'll also spend a lot more time looking at pipelines.&lt;/p>
&lt;p>I hope this was useful! Please comment if you have any questions or tips. To see further articles as they come out, follow the repo at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>&lt;/p>
&lt;p>Or just follow &lt;a href="https://twitter.com/dwmkerr">@dwmkerr&lt;/a> on Twitter.&lt;/p>
&lt;h1 id="appendix---clipboard-access-on-linux">Appendix - Clipboard Access on Linux&lt;/h1>
&lt;p>If you are using Linux, there is no &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> commands. You can use the &lt;a href="https://linux.die.net/man/1/xclip">&lt;code>xclip&lt;/code>&lt;/a> tool to create equivalent commands.&lt;/p>
&lt;p>First, install &lt;code>xclip&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo apt-get install -y xclip
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then add the following to your &lt;code>.bashrc&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Create mac style aliases for clipboard access.&lt;/span>
alias pbcopy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;xclip -selection c&amp;#34;&lt;/span>
alias pbpaste&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;xclip -selection c -o&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Obviously you can use any alias you like! The article assumes that &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> have been used.&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell Part 1: Navigating the Command Line</title><link>https://dwmkerr.com/effective-shell-part-1-navigating-the-command-line/</link><pubDate>Sun, 11 Jun 2017 23:05:40 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-1-navigating-the-command-line/</guid><description>&lt;p>This is the &lt;a href="https://github.com/dwmkerr/effective-shell">first part of a series&lt;/a> I am writing which contains practical tips for using the shell more effectively.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I can't think of a better place to start than &lt;em>navigating the command line&lt;/em>. As you start to do more and more in the shell, text in the command line can quickly become hard to handle. In this article I'll show some simple tricks for working with the command line more effectively.&lt;/p>
&lt;p>Here's a quick reference diagram, the rest of the article goes into the details!&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/effective-shell">&lt;img src="images/command-line-3.png" alt="command line">&lt;/a>&lt;/p>
&lt;p>This article, examples and diagrams are available at &lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>.&lt;/p>
&lt;!-- TOC depthFrom:2 depthTo:3 withLinks:1 updateOnSave:1 orderedList:0 -->
&lt;ul>
&lt;li>&lt;a href="#basicnavigation">Basic Navigation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#searching">Searching&lt;/a>&lt;/li>
&lt;li>&lt;a href="#editinginplace">Editing In-Place&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clearthescreen">Clear the Screen&lt;/a>&lt;/li>
&lt;li>&lt;a href="#protipallthekeys">Pro Tip: All The Keys!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#protiptransposing">Pro Tip: Transposing!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#closingthoughts">Closing Thoughts&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="basic-navigation">Basic Navigation&lt;/h2>
&lt;p>Let's assume we have a very simple command we are writing, which is going to write a quote to a text file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">echo &lt;span style="color:#e6db74">&amp;#34;The trouble with writing fiction is that it has to make sense,
&lt;/span>&lt;span style="color:#e6db74">whereas real life doesn&amp;#39;t. -- Iain M. Banks&amp;#34;&lt;/span> &amp;gt;&amp;gt; quote.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Navigating around long lines of text is a slow process if you are only relying on the arrow keys, so take the time to learn the following shortcuts:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Action&lt;/th>
&lt;th>Shortcut&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Go to beginning / end&lt;/td>
&lt;td>&lt;p>&lt;code>Ctrl + a&lt;/code>, &lt;code>Ctrl + e&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/begin-end.gif" target="_blank">&lt;img src="images/begin-end.gif" alt="begin / end" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Go backwards / forwards one word&lt;/td>
&lt;td>&lt;code>Alt + b&lt;/code> / &lt;code>Alt + f&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/forward-backwards.gif" target="_blank">&lt;img src="images/forward-backwards.gif" alt="backward / forward" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete a word / undo&lt;/td>
&lt;td>&lt;code>Ctrl + w&lt;/code> / &lt;code>Ctrl + -&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-undo.gif" target="_blank">&lt;img src="images/delete-undo.gif" alt="delete / undo" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete next word&lt;/td>
&lt;td>&lt;code>Alt + d&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-next-word.gif" target="_blank">&lt;img src="images/delete-next-word.gif" alt="delete next word" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete all the way to the beginning[^1]&lt;/td>
&lt;td>&lt;code>Ctrl + u&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-to-beginning.gif" target="_blank">&lt;img src="images/delete-to-beginning.gif" alt="delete to beginning" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete all the way to the end&lt;/td>
&lt;td>&lt;code>Ctrl + k&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-to-end.gif" target="_blank">&lt;img src="images/delete-to-end.gif" alt="delete to end" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>&lt;/tbody>&lt;/table>
&lt;p>Note that if you are on a Mac, you might need to tweak your console to allow the &amp;lsquo;Alt&amp;rsquo; key to work.&lt;/p>
&lt;p>For iTerm2, go to settings (Command + ,) &amp;gt; Profiles Tab &amp;gt; select the profile you are using &amp;gt; Keys tab. There, you should see Left Option key and Right Option Key with three radio buttons. Select &amp;ldquo;Esc+&amp;rdquo; for the Left Option Key.&lt;/p>
&lt;p>For Terminal, go to Profiles Tab &amp;gt; Keyboard Tab &amp;gt; check &amp;ldquo;Use Option as Meta key&amp;rdquo; at the bottom of the screen.&lt;/p>
&lt;h2 id="searching">Searching&lt;/h2>
&lt;p>Once you have the basic navigation commands down, the next essential is searching. Let's assume we've run the following three commands:&lt;/p>
&lt;pre>&lt;code>$ command1 param1 param2 param3
$ command2 param4 param5 param6
$ command3 param7 param8 param9
&lt;/code>&lt;/pre>&lt;p>You can search backwards or forwards with &lt;code>Ctrl + r&lt;/code> and &lt;code>Ctrl + s&lt;/code>. This will search in the current command and then iteratively through previous commands:&lt;/p>
&lt;p>&lt;img src="images/search-backwards-and-forwards.gif" alt="search backwards and forwards">&lt;/p>
&lt;p>This is useful for searching in the current command, but can be also used to quickly search backwards and forwards through the command history:&lt;/p>
&lt;p>&lt;img src="images/search-commands-backwards-and-forwards-1.gif" alt="search commands backwards and forwards">&lt;/p>
&lt;p>As you type, your command history is searched, the most recent commands coming first. Use the arrow keys to edit the command, press enter to execute it, or &lt;code>Ctrl + g&lt;/code> to cancel the search.&lt;/p>
&lt;p>Here are the same commands applied to the original example:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Action&lt;/th>
&lt;th>Shortcut&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Search backwards / forwards&lt;/td>
&lt;td>&lt;code>Ctrl + r&lt;/code> / Ctrl + s&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-next.gif" target="_blank">&lt;img src="images/search-history-next.gif" alt="find next occurrence" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Run the command&lt;/td>
&lt;td>&lt;code>Enter&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-execute.gif" target="_blank">&lt;img src="images/search-history-execute.gif" alt="execute" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Edit the command&lt;/td>
&lt;td>&lt;code>Right Arrow&lt;/code> / &lt;code>Right Arrow&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-edit.gif" target="_blank">&lt;img src="images/search-history-edit.gif" alt="edit command" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Stop searching&lt;/td>
&lt;td>&lt;code>Ctrl + g&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-cancel.gif" target="_blank">&lt;img src="images/search-history-cancel.gif" alt="cancel search" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>&lt;/tbody>&lt;/table>
&lt;h2 id="editing-in-place">Editing In-Place&lt;/h2>
&lt;p>These tips and tricks are helpful, but if you are working with a really long or complex command, you might find it useful just to jump into your favourite editor.&lt;/p>
&lt;p>Use &lt;code>Ctrl + x , Ctrl + e&lt;/code> to edit-in place:&lt;/p>
&lt;p>&lt;img src="images/edit-in-place.gif" alt="edit in place">&lt;/p>
&lt;p>In a later article I'll talk a little more about how to configure the default editor.&lt;/p>
&lt;h2 id="clear-the-screen">Clear the Screen&lt;/h2>
&lt;p>Probably the shortcut I use the most is &lt;code>Ctrl + l&lt;/code>, which clears the screen without trashing your current command. Here's how it looks:&lt;/p>
&lt;p>&lt;img src="images/clear-screen-2.gif" alt="clear screen">&lt;/p>
&lt;h2 id="pro-tip-all-the-keys">Pro Tip: All The Keys!&lt;/h2>
&lt;p>You can use the &lt;code>bindkey&lt;/code> command to see a list of all keyboard shortcuts:&lt;/p>
&lt;pre>&lt;code>$ bindkey
&amp;quot;^@&amp;quot; set-mark-command
&amp;quot;^A&amp;quot; beginning-of-line
&amp;quot;^B&amp;quot; backward-char
&amp;quot;^D&amp;quot; delete-char-or-list
&amp;quot;^E&amp;quot; end-of-line
&amp;quot;^F&amp;quot; forward-char
&amp;quot;^G&amp;quot; send-break
&amp;quot;^H&amp;quot; backward-delete-char
&amp;quot;^I&amp;quot; expand-or-complete
&amp;quot;^J&amp;quot; accept-line
&amp;quot;^K&amp;quot; kill-line
&amp;quot;^L&amp;quot; clear-screen
...
&lt;/code>&lt;/pre>&lt;p>This is an extremely useful command to use if you forget the specific keyboard shortcuts, or just want to see the shortcuts which are available.&lt;/p>
&lt;h2 id="pro-tip-transposing">Pro Tip: Transposing!&lt;/h2>
&lt;p>If you've mastered all of the commands here and feel like adding something else to your repertoire, try this:&lt;/p>
&lt;p>&lt;img src="images/transpose-word.gif" alt="transpose-word">&lt;/p>
&lt;p>The &lt;code>Alt + t&lt;/code> shortcut will transpose the last two words. Use &lt;code>Ctrl + t&lt;/code> to transpose the last two letters:&lt;/p>
&lt;p>&lt;img src="images/transpose-letters.gif" alt="transpose-letters">&lt;/p>
&lt;p>These were new to me when I was researching for this article. I can't see myself ever being able to remember the commands more quickly than just deleting the last two words or characters and re-typing them, but there you go!&lt;/p>
&lt;h2 id="closing-thoughts">Closing Thoughts&lt;/h2>
&lt;p>If you are ever looking to go deeper, then search the web for &lt;em>GNU Readline&lt;/em>, which is the library used under the hood to handle the command line in many shells. You can actually configure lower level details of how all shells which use readline work, with the &lt;a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html">&lt;code>.inputrc&lt;/code>&lt;/a> configuration file.&lt;/p>
&lt;p>The great thing about learning these shortcuts is that they will work in any prompt which uses GNU Readline. This means everything you've learnt applies to:&lt;/p>
&lt;ol>
&lt;li>Bash&lt;/li>
&lt;li>zsh&lt;/li>
&lt;li>The Python REPL&lt;/li>
&lt;li>The Node.js REPL&lt;/li>
&lt;/ol>
&lt;p>And probably a whole bunch more&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>All of these shortcuts should be familiar to Emacs users. There is in fact a &amp;lsquo;Vi Mode&amp;rsquo; option for readline, which allows you to use vi commands to work with text. You can enter this mode with &lt;code>set -o vi&lt;/code>, I'll likely come back to this in detail in a later article.&lt;/p>
&lt;p>There's a great cheat sheet on emacs readline commands at &lt;a href="http://readline.kablamo.org/emacs.html">readline.kablamo.org/emacs&lt;/a>, which is a very useful reference if you want to dig deeper. For this article I've tried to focus on what I think are the most useful commands (and transpose just so you can show off!).&lt;/p>
&lt;p>Hope that was useful! GIFs were made with &lt;a href="http://www.cockos.com/licecap/">LICEcap&lt;/a>.&lt;/p>
&lt;hr>
&lt;h4 id="footnotes">Footnotes&lt;/h4>
&lt;h4 id="references">References&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/GNU_Readline">Wikipedia: GNU Readline&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html">GNU Org: Readline Init File&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://readline.kablamo.org/emacs.html">Kablamo.org: Readline Cheat Sheet&lt;/a>&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you know of any more, please let me know and I'll update the article! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>A utility to help you wait for ports to open</title><link>https://dwmkerr.com/a-utility-to-help-you-wait-for-ports-to-open/</link><pubDate>Thu, 25 May 2017 22:15:00 +0000</pubDate><guid>https://dwmkerr.com/a-utility-to-help-you-wait-for-ports-to-open/</guid><description>&lt;p>There are occasions where you might need to have scripts or commands which wait for TCP/IP ports to open before you continue.&lt;/p>
&lt;p>I've come across this need again and again when working with &lt;a href="https://dwmkerr.com/tag/microservices/">microservices&lt;/a>, to make my life easier I've created a little utility called &lt;a href="https://github.com/dwmkerr/wait-port">wait-port&lt;/a> which will wait for a port to open:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/wait-port">&lt;img src="images/wait-port.gif" alt="Wait Port Screenshot">&lt;/a>&lt;/p>
&lt;p>It's built in Node, the project is open source, open for contributions and ready to use:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/wait-port">github.com/dwmkerr/wait-port&lt;/a>&lt;/p>
&lt;p>Installation and usage is pretty straightforward:&lt;/p>
&lt;pre>&lt;code>$ npm install -g wait-port
wait-port@0.1.4
$ wait-port 8080
Waiting for localhost:8080.....
Connected!
&lt;/code>&lt;/pre>&lt;p>You can also install locally&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>This might be useful if you have a docker-compose workflow where you need to wait for a database to start up, want to run some automated tests against a server which can be slow to start, or have a complex set of interdependent services which need to start up in a specific order.&lt;/p>
&lt;p>I'd be interested to know of any cases where people find this useful, so please share in the comments and I can add a &amp;lsquo;use cases&amp;rsquo; section to the project showing others how they might be able to save some time and energy with the utility!&lt;/p>
&lt;h2 id="the-pure-shell-way">The Pure Shell Way&lt;/h2>
&lt;p>It is actually pretty easy to do this purely in bash. Here's how you can wait for a port to open in a shell script:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#66d9ef">until&lt;/span> nc -w 127.0.0.1 3000; &lt;span style="color:#66d9ef">do&lt;/span> sleep 1; &lt;span style="color:#66d9ef">done&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will be sufficient in many cases, the reason I created the utility is:&lt;/p>
&lt;ol>
&lt;li>I want something which is very readable in scripts (&lt;code>wait-port 3000&lt;/code> to me is more readable).&lt;/li>
&lt;li>I want to be able to specify an overall timeout (i.e. wait for up to 60 seconds) which requires adding more to the script.&lt;/li>
&lt;li>I need a different error code if the overall attempt to wait times out or fails for an unknown reason.&lt;/li>
&lt;li>I want to be able to optionally show some kind of progress (you can use the &lt;code>--output&lt;/code> flag to control the output from &lt;code>wait-port&lt;/code>).&lt;/li>
&lt;li>I know I need a few other features (being able to &amp;lsquo;snooze&amp;rsquo; after the port is opening, i.e. waiting for a little extra time, controllable intervals for trying the port etc, all of which can be easily added).&lt;/li>
&lt;/ol>
&lt;h2 id="testing-tip">Testing Tip!&lt;/h2>
&lt;p>One really useful tip which will be obvious to *nix pros but I wasn't aware of is that you can create a server listening on a port with &lt;code>netcat&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">nc -l &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is just the barest basics of what netcat can do, it's a very powerful tool. This tip makes it very easy to test the &lt;code>wait-port&lt;/code> behaviour.&lt;/p>
&lt;hr>
&lt;h3 id="footnotes">Footnotes&lt;/h3>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I hate installing things globally, if you are like me you'll prefer local usage with something like: npm install wait-port &amp;amp;&amp;amp; ./node_modules/.bin/wait-port :3000&lt;/code> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Tips and Tricks for Beautifully Simple Mobile App CI</title><link>https://dwmkerr.com/tips-and-tricks-for-beautifully-simple-mobile-app-ci/</link><pubDate>Mon, 03 Apr 2017 11:14:58 +0000</pubDate><guid>https://dwmkerr.com/tips-and-tricks-for-beautifully-simple-mobile-app-ci/</guid><description>&lt;p>In this article I'm going to demonstrate some simple tips and tricks which will help you build and maintain beautifully simple mobile build pipelines. These techniques can be applied to different mobile app technologies and integrated into almost any build system:&lt;/p>
&lt;p>&lt;img src="images/0-sample-index.png" alt="Sample App Index">&lt;/p>
&lt;p>Each tip is demonstrated in the sample apps in the &lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">dwmkerr/beautifully-simple-app-ci&lt;/a> repo.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="#TheChallengesOfMobileAppCI">The Challenges of Mobile App CI&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip1EmbraceMakefilesForConsistency">Tip 1 - Embrace Makefiles for Consistency&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip2ControlVersionNumbersWithATouchCommand">Tip 2 - Control Version Numbers with a &amp;lsquo;Touch&amp;rsquo; Command&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip3controlappiconswithalabelcommand">Tip 3 - Control App Icons with a &amp;lsquo;Label&amp;rsquo; Command&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip4SupportConfigurableAppIds">Tip 4 - Support Configurable App Ids&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip5DocumentDocumentDocument">Tip 5 - Document, Document, Document&lt;/a>&lt;/li>
&lt;li>&lt;a href="#/conclusion">Conclusion&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="the-challenges-of-mobile-app-ci">The Challenges of Mobile App CI&lt;/h2>
&lt;p>Conceptually, a mobile app CI pipeline is pretty simple:&lt;/p>
&lt;p>&lt;img src="images/1-basic-ci.png" alt="Basic CI Pipeline">&lt;/p>
&lt;p>We take our code, perform some kind of validation (such as testing, linting, whatever), generate our artifacts and then deploy them to some devices.&lt;/p>
&lt;p>Often though there's a bit more to it than that:&lt;/p>
&lt;p>&lt;img src="images/2-basic-not-basic-1.png" alt="Basic CI is not Basic">&lt;/p>
&lt;p>Our source code has some metadata associated with it at the point in time you create your binaries, such as:&lt;/p>
&lt;ul>
&lt;li>The SHA, which uniquely identifies your exact location in the source history.&lt;/li>
&lt;li>The branch, which may have some &lt;em>semantic&lt;/em> meaning for your project, for example &lt;code>master&lt;/code> meaning &amp;lsquo;production&amp;rsquo; or &lt;code>alpha&lt;/code> meaning your current unstable public build.&lt;/li>
&lt;li>A tag, which may represent something like a semver, or may have more project-specific meaning.&lt;/li>
&lt;li>A version, which might be in something like a &lt;code>package.json&lt;/code> or embedded in your project files for iOS or Android.&lt;/li>
&lt;/ul>
&lt;p>When we build we have to:&lt;/p>
&lt;ul>
&lt;li>Think about how we test and validate&lt;/li>
&lt;li>Think about how we sign&lt;/li>
&lt;li>Handle package names and bundle ids, which can cause headaches if you are going to install multiple &lt;em>versions&lt;/em> of an app (e.g. dev and UAT builds)&lt;/li>
&lt;li>Consider build numbers and version number&lt;/li>
&lt;/ul>
&lt;p>So even the &amp;lsquo;basic&amp;rsquo; CI isn't all that basic. The rest of this article is a set of tips and techniques which I have found useful when developing mobile apps.&lt;/p>
&lt;h2 id="tip-1---embrace-makefiles-for-consistency">Tip 1 - Embrace Makefiles for Consistency&lt;/h2>
&lt;p>There are a raft of platform and framework specific tools and interfaces we will have to use in mobile projects. XCode, Gradle, NPM, framework specific CLIs, tools such as Fastlane, etc etc.&lt;/p>
&lt;p>If you ensure that your main &amp;lsquo;entrypoint&amp;rsquo; to key operations is a recipe in a makefile, you can provide a degree of consistency to mobile projects. For example:&lt;/p>
&lt;ul>
&lt;li>&lt;code>make build&lt;/code> - Creates an IPA and APK, saving them to the &lt;code>./artifacts&lt;/code> folder.&lt;/li>
&lt;li>&lt;code>make test&lt;/code> - Runs all test suites.&lt;/li>
&lt;li>&lt;code>make deploy&lt;/code> - Deploys the binaries.&lt;/li>
&lt;/ul>
&lt;p>A &lt;code>makefile&lt;/code> for such commands might look like this:&lt;/p>
&lt;pre>&lt;code>test:
# Run all the tests.
npm test
build:
# Create the apk, copy to artifacts.
cd android &amp;amp;&amp;amp; ./gradlew assembleRelease &amp;amp;&amp;amp; cd ..
cp -f ./android/app/build/outputs/apk/myapp.apk ./artifacts
# Create the ipa, copy to artifacts.
cd ./ios; fastlane gym --scheme &amp;quot;app&amp;quot; --codesigning_identity &amp;quot;$(CODE_SIGNING_IDENTITY)&amp;quot;; cd ../;
cp -f ./ios/myapp.ipa ./artifacts
deploy:
# Push to TestFairy.
curl https://app.testfairy.com/api/upload \
-F api_key='$(API_KEY)' \
-F &amp;quot;file=@./artifacts/myapp.apk&amp;quot;
&lt;/code>&lt;/pre>&lt;p>This is a slightly shortened snippet, you can see a variety of working examples in the git repo:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">github.com/dwmkerr/beautifully-simple-app-ci&lt;/a>&lt;/p>
&lt;p>The first sample in the above repo demonstrates using makefiles to handle key commands for a React Native app. In the example, CircleCI is used to handle automatic builds on code changes, and the apps themselves are distributed automatically to testers&amp;rsquo; devices with TestFairy.&lt;/p>
&lt;p>The nice feature is that the bulk of the logic is in the main repo source, in the &lt;code>makefile&lt;/code> - the CI tool simply orchestrates it. Developers can run &lt;em>exactly&lt;/em> the same commands on their local machine.&lt;/p>
&lt;p>The &lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci/blob/master/1_react_native_app/README.md">&lt;code>README.md&lt;/code>&lt;/a> immediately draws attention to the makefile commands:&lt;/p>
&lt;p>&lt;img src="images/3-tip1-readme.png" alt="Screenshot of the README.md file">&lt;/p>
&lt;p>The makefiles do most of the work, that makes setting up CircleCI almost trivial. Here's a snippet of its config:&lt;/p>
&lt;pre>&lt;code># Tell Circle where we keep our artifacts.
general:
artifacts:
- ./artifacts
# When we test, we build the android app and test it.
test:
override:
- make build-android
- make test
# If there are any changes to the master branch, push a new version
# of the app.
deployment:
master:
branch: [master]
commands:
- make deploy-android
&lt;/code>&lt;/pre>&lt;p>Our commands are android specific at this stage as Circle don't support iOS builds on their free plan&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Later samples which use other build systems demonstrate Android &lt;em>and&lt;/em> iOS.&lt;/p>
&lt;p>The CI automatically tests and builds whenever we have new code commits:&lt;/p>
&lt;p>&lt;img src="images/4-tip1-circle.png" alt="Screenshot of CircleCI and the artifacts">&lt;/p>
&lt;p>Also, if a commit is made to the &lt;code>master&lt;/code> branch, our new app is automatically pushed to TestFairy, which can be configured to automatically update the test team:&lt;/p>
&lt;p>&lt;img src="images/5-tip1-testfairy.png" alt="Screenshot of TestFairy">&lt;/p>
&lt;p>Makefile syntax is close enough to shell scripting that simple operations are generally straightforward&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> to implement. The approach is also perfectly valid for server side code and almost any project.&lt;/p>
&lt;p>Teams with many projects can build consistent patterns and syntax for building. Take a look at the image below:&lt;/p>
&lt;p>&lt;img src="images/Simple-Docker-Image-CI.png" alt="Docker Workflow">&lt;/p>
&lt;p>This is from my article on &lt;a href="http://www.dwmkerr.com/simple-continuous-integration-for-docker-images/">Simple Continuous Integration for Docker Images&lt;/a> - where exactly the same principles are applied.&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Makefiles allow you to provide an entrypoint for common app CI tasks which is framework and toolkit agnostic&lt;/li>
&lt;li>Being able to run the individual &lt;em>steps&lt;/em> of a CI build on a local machine makes it easier for developers to work with the pipeline&lt;/li>
&lt;li>By having a CI platform only need to handle the orchestration of these simple steps, we are less tied to specific platforms and can reduce lock-in&lt;/li>
&lt;/ul>
&lt;p>We'll see more interesting makefile recipes as we get into the other tips.&lt;/p>
&lt;h2 id="tip-2---control-version-numbers-with-a-touch-command">Tip 2 - Control Version Numbers with a &amp;lsquo;Touch&amp;rsquo; command&lt;/h2>
&lt;p>iOS and Android apps have both a &lt;em>version number&lt;/em> and a &lt;em>build number&lt;/em>. We might have other files in our project with version numbers too (such as a &lt;code>package.json&lt;/code> file).&lt;/p>
&lt;p>It can be very useful to have a way of keeping these version numbers in sync. Again, we can use a makefile recipe:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make touch
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will vary in implementation depending on your platform. For example, this would be all that is needed for a Cordova based project:&lt;/p>
&lt;pre>&lt;code># The version in package.json is the 'master' version.
VERSION ?= $(shell cat package.json | jq --raw-output .version)
BUILD_NUM ?= 0
touch:
$(info &amp;quot;Touching to version $(VERSION) and build number $(BUILD_NUM).&amp;quot;)
sed -i &amp;quot;&amp;quot; -e 's/android-versionCode=\&amp;quot;[0-9]*\&amp;quot;/android-versionCode=\&amp;quot;$(BUILD_NUM)\&amp;quot;/g' ./config.xml
sed -i &amp;quot;&amp;quot; -e 's/ios-CFBundleVersion=\&amp;quot;[0-9]*\&amp;quot;/ios-CFBundleVersion=\&amp;quot;$(BUILD_NUM)\&amp;quot;/g' ./config.xml
sed -i &amp;quot;&amp;quot; -e 's/version=\&amp;quot;[.0-9a-zA-Z]*\&amp;quot;/version=\&amp;quot;$(VERSION)&amp;quot;/g' ./config.xml
&lt;/code>&lt;/pre>&lt;p>Notice we don't really need complex tools for a job like this, &lt;code>sed[^3]&lt;/code> is sufficient to quickly make changes to config files.&lt;/p>
&lt;p>This works very nicely with build systems, many of which provide a build number as an environment variable. For example, we can add a build number with TravisCI like so:&lt;/p>
&lt;pre>&lt;code>env:
- BUILD_NUM=$TRAVIS_BUILD_NUMBER
script:
- make touch
- make test
- make build-android
&lt;/code>&lt;/pre>&lt;p>To go into more detail, we'll look at the second sample in the git repo, which is a Cordova App. This sample will always set the build number in both apps and the build version to whatever is present in the &lt;code>package.json&lt;/code> file. That means you can do things like this:&lt;/p>
&lt;pre>&lt;code>$ npm version minor # Bump the version
v0.1.0
$ BUILD_NUM=3 make build &amp;amp;&amp;amp; make deploy # Build and deploy the apps
...
done
&lt;/code>&lt;/pre>&lt;p>And all of the version numbers and build numbers are updated and the apps are deployed. In this example project, they're deployed to HockeyApp:&lt;/p>
&lt;p>&lt;img src="images/6-hockey-app.png" alt="Screenshot of the newly versioned apps in HockeyApp">&lt;/p>
&lt;p>This build runs on TravisCI, so only builds the Android version. You can clone the code and build the iOS version (and deploy it) using the makefile.&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>There will come a point in your project development where you'll need to handle version numbers, having a command to explicitly deal with this adds rigour to this process&lt;/li>
&lt;li>Build numbers are just as important as version numbers during development, ensuring your CI build number is baked into your artifacts is critical for troubleshooting and control&lt;/li>
&lt;/ul>
&lt;h1 id="tip-3---control-app-icons-with-a-label-command">Tip 3 - Control App Icons with a &amp;lsquo;Label&amp;rsquo; Command&lt;/h1>
&lt;p>When you are working in a larger team, it can be very useful to label your app icon so that team members know exactly what version of the app they are using. This is often the case if you are working in a team where features or bugfixes are being deployed rapidly.&lt;/p>
&lt;p>You might label your icons with build numbers, SHAs, branch names, versions, tags, or even something custom such as &amp;lsquo;QA&amp;rsquo; or &amp;lsquo;UAT&amp;rsquo; for different versions of your app. Here are a few examples:&lt;/p>
&lt;p>&lt;img src="images/8-framed-labelled-icons.png" alt="Labelled Icons Screenshot">&lt;/p>
&lt;p>I've found this to be very useful, so created a command-line tool called &amp;lsquo;&lt;a href="github.com/dwmkerr/app-icon">app-icon&lt;/a>&amp;rsquo; to help with the task:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/app-icon">github.com/dwmkerr/app-icon&lt;/a>&lt;/p>
&lt;p>This tool has a &lt;code>label&lt;/code> command to add a label, and a &lt;code>generate&lt;/code> command to generate icons of all different sizes. This means you can add recipes like this to your &lt;code>makefile&lt;/code>:&lt;/p>
&lt;pre>&lt;code>VERSION ?= $(shell cat package.json | jq --raw-output .version)
BUILD_NUM ?= 0 # This might come from Circle, Travis or Whatever...
label:
$(info Labeling icon with '$(VERSION)' and '$(BUILD_NUM)'...)
app-icon label -i base-icon.png -o icon.png --top $(VERSION) --bottom $(BUILD_NUM)
app-icon generate -i icon.png
&lt;/code>&lt;/pre>&lt;p>Each sample app labels its icon in a different way:&lt;/p>
&lt;ol>
&lt;li>The &lt;a href="./1_react_native_app/">React Native App&lt;/a> puts the short Git SHA on the bottom of the icon.&lt;/li>
&lt;li>The &lt;a href="./2_ionic_app/">Ionic App&lt;/a> puts the &lt;code>package.json&lt;/code> version at the top of the icon.&lt;/li>
&lt;li>The &lt;a href="./3_native_app">Native App&lt;/a> puts an environment label at the top of the icon, and the build number at the bottom.&lt;/li>
&lt;li>The &lt;a href="./4_xamarinapp">Xamarin App&lt;/a> includes the configurable app environment (this is detailed in the next tip) and build number&lt;/li>
&lt;/ol>
&lt;p>There are references to each sample and the associated code in the &lt;code>README.md&lt;/code> at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">github.com/dwmkerr/beautifully-simple-app-ci&lt;/a>&lt;/p>
&lt;p>As a quick example, the Pure Native App runs this code prior to each build:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">BUILD_NUM&lt;span style="color:#f92672">=&lt;/span>BUDDYBUILD_BUILD_NUMBER make label
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This app uses BuddyBuild as a build system, meaning we can just drop this line in the &lt;a href="./buddybuild_postclone.sh">&lt;code>buddybuild_postclone.sh&lt;/code>&lt;/a> script. You can see the labeled icons directly in the BuddyBuild UI:&lt;/p>
&lt;p>&lt;img src="images/12-buddybuild-icons.png" alt="BuddyBuild Icons">&lt;/p>
&lt;p>The Android build is currently having some issues due to fonts being accessible by the labelling tool (which uses ImageMagick under the hood), with any luck this issue will be fixed soon. This seems to be an issue with the BuddyBuild ImageMagick installation rather than the labelling code itself, which is running fine on all of the other builds!&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>A little bit of time invested in managing your app icon can potentially save many hours if you are rapidly iterating on apps&lt;/li>
&lt;li>The &lt;a href="https://github.com/dwmkerr/app-icon">&lt;code>app-icon&lt;/code>&lt;/a> tool can help you quickly label and generate icons&lt;/li>
&lt;/ul>
&lt;h1 id="tip-4---support-configurable-app-ids">Tip 4 - Support Configurable App Ids&lt;/h1>
&lt;p>Another trick I've found useful is to have a command which automatically updates your iOS Bundle ID or Android Application ID. This can be handy when you have multiple versions of an app (such as a QA build, dev build, UAT build or whatever).&lt;/p>
&lt;p>If you have users who need to have different versions of your app on their phones then this is actually a necessary step (at least for iOS), as you cannot have multiple versions of an app with the same ID installed.&lt;/p>
&lt;p>Often, I will aim to have a standard &amp;lsquo;base id&amp;rsquo;, such as:&lt;/p>
&lt;pre>&lt;code>com.dwmkerr.myapp
&lt;/code>&lt;/pre>&lt;p>and then simply append whatever the &amp;lsquo;flavour&amp;rsquo; of my app is to the end of the id:&lt;/p>
&lt;pre>&lt;code>com.dwmkerr.myapp_qa # The QA build...
com.dwmkerr.myapp_uat # The UAT build...
&lt;/code>&lt;/pre>&lt;p>The base id is then reserved for the master build, which is what goes into production.&lt;/p>
&lt;p>Just like with all of the other tricks, I tend to use a recipe in the &lt;code>makefile&lt;/code> to do the heavy lifting, and then leave the build system to orchestrate the commands (we'll see more of this later). Here's how a recipe will typically look (this comes from the fourth sample, which is a Xamarin App):&lt;/p>
&lt;pre>&lt;code>ENV ?= production
# Set the app id, with the 'production' environment implying the unaltered 'base' id.
ifeq ($(ENV),production)
APP_ID=com.dwmkerr.xamarinapp
else
APP_ID=com.dwmkerr.xamarinapp_$(ENV)
endif
name:
$(info Naming app '$(APP_ID)'...)
sed -i.bak 's/com.dwmkerr.xamarinapp.*&amp;lt;/$(APP_ID)&amp;lt;/' iOS/Info.plist
sed -i.bak 's/com.dwmkerr.xamarinapp.*\&amp;quot;/$(APP_ID)\&amp;quot;/' Droid/Properties/AndroidManifest.xml
&lt;/code>&lt;/pre>&lt;p>This small recipe can be very useful in combination with other techniques. Ensuring your build respects the &lt;code>ENV&lt;/code> variable (or whatever you name your &amp;lsquo;flavour&amp;rsquo;) means that you can have different configurations for different environments, build multiple versions of the app, each with a distinct app icon, and distribute them to your team.&lt;/p>
&lt;p>In the screenshots below, you can see how the presence of the &lt;code>ENV&lt;/code> environment variable automatically updates the App ID (this is taken from the &lt;a href="./4_xamarinapp">Xamarin Sample&lt;/a>, which orchestrates builds with Bitrise&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/9-bitrise.png" alt="The ENV Environment variable in Bitrise">&lt;/p>
&lt;p>&lt;img src="images/10-bitrise-apps.png" alt="The built apps in Bitrise">&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Configurable App Ids allow you to maintain isolated builds of your app for specific environments, even on the same physical device&lt;/li>
&lt;li>This tip must be used with caution, some features (such as iOS push notifications) will not work if the bundle id is changed (it can also cause issues if your provisioning profile does not use a wildcard)&lt;/li>
&lt;/ul>
&lt;h2 id="tip-5---document-document-document">Tip 5 - Document, Document, Document&lt;/h2>
&lt;p>Even teams which are great at documenting complex application code can sometimes be a bit lax when it comes to documenting build related code.&lt;/p>
&lt;p>Unfortunately, build related code will often need &lt;em>more&lt;/em> documentation than usual. Why is this?&lt;/p>
&lt;ul>
&lt;li>It is often &lt;em>complex&lt;/em> (spend any time working with the XCode commandline or provisioning profiles and you'll likely agree)&lt;/li>
&lt;li>It is &lt;em>rarely changed&lt;/em> (often worked on heavily at the early stages of a project then not touched)&lt;/li>
&lt;li>It is &lt;em>critical&lt;/em> (when it breaks, teams are often blocked)&lt;/li>
&lt;/ul>
&lt;p>When something goes wrong with a build process, or needs to be changed, it is a real pain when only one person knows how the code works. Be rigorous with this code, make sure it is documented and reviewed, and share the knowledge around your team. I tend to like to have a table of commands as a quick index in the README.md file, and then heavily comment the code itself:&lt;/p>
&lt;p>&lt;img src="images/11-document.png" alt="TODO">&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Be rigorous with documentation, when things go wrong with CI code then people are often blocked&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Most of these tips are fairly explicit, there are detailed examples in the sample project. Familiarity with these patterns and techniques can be useful, but perhaps the most valuable takeaway would be to embrace the following principles:&lt;/p>
&lt;ul>
&lt;li>Developers should be able to run all of the key CI steps on their local machine, to be able to understand, adapt and improve the process&lt;/li>
&lt;li>When building more complex features, we should create small, simple units of work which can be composed into larger pipelines&lt;/li>
&lt;li>Complexity, if needed, should be in in code - not in &amp;lsquo;black box&amp;rsquo; CI tools (such as esoteric features for specific CI providers or Jenkins plugins). For example, CircleCI offers a Git Short SHA environment variable - but you can grab a short SHA with &lt;code>git log -1 --format=&amp;quot;%h&amp;quot;&lt;/code>, and the second approach works anywhere&lt;/li>
&lt;li>Use CI platforms to &lt;em>orchestrate&lt;/em> work, use makefiles and scripts to handle logic&lt;/li>
&lt;/ul>
&lt;p>I hope this article has been useful, any thoughts or comments are always welcome!&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I have successfully used this approach to build Android &lt;em>and&lt;/em> iOS from the same OSX build agent on their paid plan on a number of projects. The most straightforward way to do this is to have a single build run on OSX and create the Android app as well as the iOS app. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Perhaps straightforward is an overstatement, but getting those who are familiar with shell scripting will have few difficulties. Those who are not will find a learning curve, but it is &lt;em>very&lt;/em> useful to at least get the basics of shell scripting learnt. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Get up and running with OpenShift on AWS</title><link>https://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</link><pubDate>Thu, 02 Feb 2017 07:47:00 +0000</pubDate><guid>https://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</guid><description>&lt;p>&lt;a href="https://www.openshift.com/">OpenShift&lt;/a> is Red Hat's platform-as-a-service offering for hosting and scaling applications. It's built on top of Google's popular &lt;a href="https://kubernetes.io/">Kubernetes&lt;/a> system.&lt;/p>
&lt;p>Getting up and running with OpenShift Online is straightforward, as it is a cloud hosted solution. Setting up your own cluster is a little more complex, but in this article I'll show you how to make it fairly painless.&lt;/p>
&lt;p>&lt;img src="images/welcome.png" alt="OpenShift Login">&lt;/p>
&lt;p>The repo for this project is at: &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">github.com/dwmkerr/terraform-aws-openshift&lt;/a>.&lt;/p>
&lt;h2 id="creating-the-infrastructure">Creating the Infrastructure&lt;/h2>
&lt;p>OpenShift has some fairly specific requirements about what hardware it runs on&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. There's also DNS to set up, as well as internet access and so on.&lt;/p>
&lt;p>All in all, for a bare-bones setup, you'll need something like this:&lt;/p>
&lt;p>&lt;img src="images/network-diagram-2.png" alt="Network Diagram">&lt;/p>
&lt;p>Which is (deep breath):&lt;/p>
&lt;ol>
&lt;li>A network&lt;/li>
&lt;li>A public subnet, with internet access via a gateway&lt;/li>
&lt;li>A master host, which will run the OpenShift master&lt;/li>
&lt;li>A pair of node hosts, which will run additional OpenShift nodes&lt;/li>
&lt;li>A hosted zone, which allows us to configure DNS&lt;/li>
&lt;li>A bastion, which allows us to SSH onto hosts, without directly exposing them&lt;/li>
&lt;li>Some kind of basic log aggregation, which I'm using CloudWatch for&lt;/li>
&lt;/ol>
&lt;p>This is not a production grade setup, which requires redundant masters and so on, but it provides the basics.&lt;/p>
&lt;p>Rather than setting this infrastructure up by hand, this is all scripted with &lt;a href="https://www.terraform.io/">Terraform&lt;/a>. To set up the infrastructure, clone the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">github.com/dwmkerr/terraform-aws-openshift&lt;/a> repo:&lt;/p>
&lt;pre>&lt;code>$ git clone git@github.com:dwmkerr/terraform-aws-openshift
...
Resolving deltas: 100% (37/37), done.
&lt;/code>&lt;/pre>&lt;p>Then use the terraform CLI&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> to create the infrastructure:&lt;/p>
&lt;pre>&lt;code>$ cd terraform-aws-openshift/
$ terraform get &amp;amp;&amp;amp; terraform apply
&lt;/code>&lt;/pre>&lt;p>You'll be asked for a region, to deploy the network into, here I'm using &lt;code>us-west-1&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/Screenshot-at-Feb-02-21-16-44.png" alt="Enter Region">&lt;/p>
&lt;p>After a few minutes the infrastructure will be set up:&lt;/p>
&lt;p>&lt;img src="images/output.png" alt="Terraform complete">&lt;/p>
&lt;p>A quick glance at the AWS console shows the new hosts we've set up:&lt;/p>
&lt;p>&lt;img src="images/aws.png" alt="AWS Console">&lt;/p>
&lt;p>The next step is to install OpenShift.&lt;/p>
&lt;h2 id="installing-openshift">Installing OpenShift&lt;/h2>
&lt;p>There are a few different ways to install OpenShift, but the one we'll use is called the &amp;lsquo;advanced installation&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>'. This essentially involves:&lt;/p>
&lt;ol>
&lt;li>Creating an &amp;lsquo;inventory&amp;rsquo;, which specifies the hosts OpenShift will be installed on and the installation options&lt;/li>
&lt;li>Downloading the advanced installation code&lt;/li>
&lt;li>Running the advanced installation Ansible Playbook&lt;/li>
&lt;/ol>
&lt;p>To create the inventory, we just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sed &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">s/\${aws_instance.master.public_ip}/&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>terraform output master-public_ip&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">/&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> inventory.template.cfg &amp;gt; inventory.cfg
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This takes our &amp;lsquo;inventory template&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&amp;rsquo; and populates it with the public IP of our master node, which is recorded in a Terraform output variable.&lt;/p>
&lt;p>We can then copy the inventory to the bastion:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">ssh-add ~/.ssh/id_rsa
scp ./inventory.cfg ec2-user@&lt;span style="color:#66d9ef">$(&lt;/span>terraform output bastion-public_dns&lt;span style="color:#66d9ef">)&lt;/span>:~
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can again use the Terraform output variables, this time to get the bastion IP. Finally, we pipe our install script to the bastion host:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">cat install-from-bastion.sh | ssh -A ec2-user@&lt;span style="color:#66d9ef">$(&lt;/span>terraform output bastion-public_dns&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's a &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/issues/1">bug&lt;/a> which means you might see &lt;code>ansible-playbook: command not found&lt;/code>, if so, just run the script again. The install script clones the installation scripts and runs them, using the inventory we've provided:&lt;/p>
&lt;p>&lt;img src="images/ansible.png" alt="Ansible Output">&lt;/p>
&lt;p>This'll probably take about 10 minutes to run. And that's it, OpenShift is installed:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">open &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">https://&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>terraform output master-public_dns&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">:8443&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Hit &amp;lsquo;advanced&amp;rsquo; and continue, as we're using a self-signed certificate most browsers will complain:&lt;/p>
&lt;p>&lt;img src="images/console1.png" alt="Invalid Certificate">&lt;/p>
&lt;p>Enter any username and password (the system is configured to allow anyone to access it by default) and you'll be presented with the OpenShift console:&lt;/p>
&lt;p>&lt;img src="images/console2.png" alt="OpenShift console">&lt;/p>
&lt;p>As the setup requires three t2.large instances, which are not available on the free plan, you might want to clean up when you are done with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">terraform destroy
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>Hopefully you've found this useful, there are more details and references on the README of the github repo:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">https://github.com/dwmkerr/terraform-aws-openshift&lt;/a>&lt;/p>
&lt;p>Comments and feedback are always welcome!&lt;/p>
&lt;hr>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>See &lt;a href="https://docs.openshift.org/latest/install_config/install/prerequisites.html#system-requirements">https://docs.openshift.org/latest/install_config/install/prerequisites.html#system-requirements&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Use &amp;lsquo;brew install terraform&amp;rsquo;, full instructions in the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">README.md&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>See &lt;a href="https://docs.openshift.org/latest/install_config/install/advanced_install.html">https://docs.openshift.org/latest/install_config/install/advanced_install.html&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>See &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/blob/master/inventory.template.cfg">https://github.com/dwmkerr/terraform-aws-openshift/blob/master/inventory.template.cfg&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Creating a Resilient Consul Cluster for Docker Microservice Discovery with Terraform and AWS</title><link>https://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</link><pubDate>Mon, 09 Jan 2017 07:10:40 +0000</pubDate><guid>https://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</guid><description>&lt;p>In this article I'm going to show you how to create a resilient Consul cluster, using Terraform and AWS. We can use this cluster for microservice discovery and management. No prior knowledge of the technologies or patterns is required!&lt;/p>
&lt;p>The final code is at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster">github.com/dwmkerr/terraform-consul-cluster&lt;/a>. Note that it has evolved somewhat since the time of writing, see the Appendices at the end of the article for details.&lt;/p>
&lt;h2 id="consul-terraform--aws">Consul, Terraform &amp;amp; AWS&lt;/h2>
&lt;p>&lt;a href="https://www.consul.io/">Consul&lt;/a> is a technology which enables &lt;em>Service Discovery&lt;/em>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, a pattern which allows services to locate each other via a central authority.&lt;/p>
&lt;p>&lt;a href="https://www.terraform.io/">Terraform&lt;/a> is a technology which allows us to script the provisioning of infrastructure and systems. This allows us to practice the &lt;em>Infrastructure as Code&lt;/em> pattern. The rigour of code control (versioning, history, user access control, diffs, pull requests etc) can be applied to our systems.&lt;/p>
&lt;p>And why &lt;a href="https://aws.amazon.com/">AWS&lt;/a>? We need to create many servers and build a network to see this system in action. We can simulate parts of this locally with tools such as &lt;a href="https://www.vagrantup.com/">Vagrant&lt;/a>, but we can use the arguably most popular&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> IaaS platfom for this job at essentially zero cost, and learn some valuable skills which are readily applicable to other projects at the same time.&lt;/p>
&lt;p>A lot of what we will learn is not really AWS specific - and the Infrastructure as Code pattern which Terraform helps us apply allows us to apply these techniques easily with other providers.&lt;/p>
&lt;h2 id="the-goal">The Goal&lt;/h2>
&lt;p>The goal is to create a system like this:&lt;/p>
&lt;p>&lt;img src="images/img-0-goal.png" alt="Overall System Diagram">&lt;/p>
&lt;p>In a nutshell:&lt;/p>
&lt;ul>
&lt;li>We have a set of homogenous Consul nodes&lt;/li>
&lt;li>The nodes form a cluster and automatically elect a leader&lt;/li>
&lt;li>The nodes span more than one availability zone, meaning the system is redundant and can survive the failure of an entire availability zone (i.e. data centre)&lt;/li>
&lt;li>The Consul UI is available to view via a gateway&lt;/li>
&lt;li>We have two example microservices which register themselves on the cluster, so we can actually see some registered services in the console&lt;/li>
&lt;/ul>
&lt;p>As a quick caveat, in reality this setup would typically live in a private subnet, not directly accessible to the outside work except via public facing load balancers. This adds a bit more complexity to the Terraform setup but not much value to the walk-though. A network diagram of how it might look is below, I invite interested readers to try and move to this model as a great exercise to cement the concepts!&lt;/p>
&lt;h2 id="step-1---creating-our-network">Step 1 - Creating our Network&lt;/h2>
&lt;p>The first logical step is to create the network itself. This means:&lt;/p>
&lt;ul>
&lt;li>The network (in AWS terminology, this is a &lt;em>VPC&lt;/em> or &lt;em>Virtual Private Cloud&lt;/em>)&lt;/li>
&lt;li>The &amp;lsquo;public&amp;rsquo; subnet, which defines our IP ranges for hosts&lt;/li>
&lt;li>The internet gateway, which provides an entry/exit point for traffic from/to the internet&lt;/li>
&lt;li>The firewall rules, which define what traffic can come in and out of the network&lt;/li>
&lt;/ul>
&lt;p>All together, that's this:&lt;/p>
&lt;p>&lt;img src="images/img-1-network.png" alt="">&lt;/p>
&lt;p>Our solution will be made more resilient by ensuring we host our Consul nodes across multiple &lt;em>availability zones&lt;/em>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/p>
&lt;p>Creating a VPC and building a subnet is fairly trivial if you have done some network setup before or spent much time working with AWS, if not, you may be a little lost already. There's a good course on Udemy&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> which will take you through the process of setting up a VPC which I recommend if you are interested in this, as it is quite hands on. It'll also show you how to build a more &amp;lsquo;realistic&amp;rsquo; network, which also contains a private subnet and NAT, but that's beyond the scope of this write-up. Instead, I'll take you through the big parts.&lt;/p>
&lt;h3 id="the-network">The Network&lt;/h3>
&lt;p>We're using AWS, we need to create a VPC. A VPC is a Virtual Private Cloud. The key thing is that it is &lt;em>isolated&lt;/em>. Things you create in this network will be able to talk to each other if you let them, but cannot communicate with the outside world, unless you specifically create the parts needed for them to do so.&lt;/p>
&lt;p>A private network is probably something you regularly use if you work in a company&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. Most companies have their own internal network - when you use a computer on that network it can talk to other company computers (such as the company mail server). When you are off that network, you might not be able to access your company email (unless it is publicly available, like gmail, or over a VPN [and by accessing a VPN, you are actually &lt;em>joining&lt;/em> the network again, albeit remotely]).&lt;/p>
&lt;p>Perhaps the most immediately obvious part of a VPC is that &lt;em>you control the IP addresses&lt;/em>. You specify the &lt;em>range&lt;/em> of IP addresses which are available to give to machines on the network. When a machine joins, it is given an IP in that range. I'm not going to go into too much detail here, if you are interested let me know and I'll write up an article on VPCs in detail!&lt;/p>
&lt;p>&lt;img src="images/img-3-vpc.png" alt="">&lt;/p>
&lt;p>Here's how I'd suggest scripting AWS infrastructure with Terraform if you haven't done this before.&lt;/p>
&lt;ol>
&lt;li>Use the AWS console to create what you want&lt;/li>
&lt;li>Search the Terraform documentation for the entity you want to create (e.g. &lt;a href="https://www.terraform.io/docs/providers/aws/r/vpc.html">VPC&lt;/a>), &lt;em>script&lt;/em> the component and &lt;em>apply&lt;/em> the provisioning&lt;/li>
&lt;li>Compare the hand-made VPC to the script-made VPC, if the two are the same, you are done&lt;/li>
&lt;li>If the two are different, check the documentation and try again&lt;/li>
&lt;/ol>
&lt;p>Ensure you have an AWS account, and note your Secret Key and Access Key. We'll need these to remotely control it. Here's the terraform script to create a VPC:&lt;/p>
&lt;pre>&lt;code>// Setup the core provider information.
provider &amp;quot;aws&amp;quot; {
access_key = &amp;quot;${var.access_key}&amp;quot;
secret_key = &amp;quot;${var.secret_key}&amp;quot;
region = &amp;quot;${var.region}&amp;quot;
}
// Define the VPC.
resource &amp;quot;aws_vpc&amp;quot; &amp;quot;consul-cluster&amp;quot; {
cidr_block = &amp;quot;10.0.0.0/16&amp;quot; // i.e. 10.0.0.0 to 10.0.255.255
enable_dns_hostnames = true
tags {
Name = &amp;quot;Consul Cluster VPC&amp;quot;
Project = &amp;quot;consul-cluster&amp;quot;
}
}
&lt;/code>&lt;/pre>&lt;p>This script uses &lt;a href="https://www.terraform.io/docs/configuration/variables.html">Terraform Variables&lt;/a>, such as &lt;code>var.access_key&lt;/code>, which we keep in a &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/variables.tf">variables.tf&lt;/a> file. Terraform will use the default values defined in the file if they are present, or ask the user to supply them. Let's build the network:&lt;/p>
&lt;pre>&lt;code>terraform apply
&lt;/code>&lt;/pre>&lt;p>After supplying the values for the variables, Terraform will provision the network, using the AWS SDK internally.&lt;/p>
&lt;p>&lt;img src="images/img-2-terraform-apply.png" alt="">&lt;/p>
&lt;p>You'll see lots of info about what it is creating, then a success message.&lt;/p>
&lt;h3 id="the-public-subnet">The Public Subnet&lt;/h3>
&lt;p>You don't put hosts directly into a VPC, they need to go into a structure called a &amp;lsquo;subnet&amp;rsquo;, which is a &lt;em>part&lt;/em> of a VPC. Subnets get their own subset of the VPC's available IP addresses, which you specify.&lt;/p>
&lt;p>Subnets are used to build &lt;em>zones&lt;/em> in a network. Why would you need this? Typically it is to manage security. You might have a &amp;lsquo;public zone&amp;rsquo; in which all hosts can be accessed from the internet, and a &amp;lsquo;private zone&amp;rsquo; which is inaccessible directly (and therefore a better location for hosts with sensitive data). You might have an &amp;lsquo;operator&amp;rsquo; zone, which only sysadmins can access, but they can use to get diagnostic information.&lt;/p>
&lt;p>Here's a common subnet layout for multi-tiered applications:&lt;/p>
&lt;p>&lt;img src="images/img-4-subnets.png" alt="">&lt;/p>
&lt;p>The defining characteristics of zones is that they are used to create &lt;em>boundaries&lt;/em> to isolate hosts. These boundaries are normally secured by firewalls, traversed via gateways or NATs etc. We're going to create two public subnets, one in each of the availability zones&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>:&lt;/p>
&lt;pre>&lt;code>// Create a public subnet for each AZ.
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-a&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.consul-cluster.id}&amp;quot;
cidr_block = &amp;quot;10.0.1.0/24&amp;quot; // i.e. 10.0.1.0 to 10.0.1.255
availability_zone = &amp;quot;ap-southeast-1a&amp;quot;
map_public_ip_on_launch = true
}
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-b&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.consul-cluster.id}&amp;quot;
cidr_block = &amp;quot;10.0.2.0/24&amp;quot; // i.e. 10.0.2.0 to 10.0.1.255
availability_zone = &amp;quot;ap-southeast-1b&amp;quot;
map_public_ip_on_launch = true
}
&lt;/code>&lt;/pre>&lt;p>With Terraform, resources can depend on each other. In this case, the subnets need to reference the ID of the VPC we want to place them in (so we use &lt;code>aws_vpc.consul-cluster.id&lt;/code>).&lt;/p>
&lt;h3 id="the-internet-gateway-route-tables-and-security-groups">The Internet Gateway, Route Tables and Security Groups&lt;/h3>
&lt;p>The final parts of the network you can see in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/network.tf">./infrastructure/network.tf&lt;/a> script. These are the Internet Gateway, Route Table and Security Group resources. Essentially they are for controlling access between hosts and the internet. AWS have a &lt;a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html">good guide&lt;/a> if you are not familiar with these resources; they don't add much to the article so I'll leave you to explore on your own.&lt;/p>
&lt;p>That's it for the network, we now have the following structure:&lt;/p>
&lt;p>&lt;img src="images/img-1-network-1.png" alt="">&lt;/p>
&lt;p>If you want to see the code as it stands now, check the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-1">Step 1&lt;/a> branch. Now we need to look at creating the hosts to install Consul on.&lt;/p>
&lt;h2 id="step-2---creating-the-consul-hosts">Step 2 - Creating the Consul Hosts&lt;/h2>
&lt;p>The Consul documentation recommends running in a cluster or 3 or 5 nodes&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. We want to set up a system which is self-healing - if we lose a node, we want to create a new one.&lt;/p>
&lt;p>Enter &lt;a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html">Auto-Scaling Groups&lt;/a>. Auto-scaling groups allow us to define a template for an instance, and ask AWS to make sure there are always a certain number of these instances. If we lose an instance, a new one will be created to keep the group at the correct size&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>So we now need to create:&lt;/p>
&lt;ol>
&lt;li>A &amp;lsquo;Launch Configuration&amp;rsquo; which determines what instances our Auto-scaling Group creates&lt;/li>
&lt;li>A &amp;lsquo;user data script&amp;rsquo; which runs on newly created instances, which must install and start Consul&lt;/li>
&lt;li>An Auto-scaling group, configured to run five instances across the two public subnets&lt;/li>
&lt;li>A load balancer, configured to pass incoming requests for the Consul Admin console to the nodes&lt;/li>
&lt;/ol>
&lt;p>Or visually:&lt;/p>
&lt;p>&lt;img src="images/img-5-cluster-basic-2.png" alt="Basic Cluster Diagram">&lt;/p>
&lt;p>Let's get to it.&lt;/p>
&lt;h3 id="the-launch-configuration--auto-scaling-group">The Launch Configuration &amp;amp; Auto-scaling Group&lt;/h3>
&lt;p>The Launch Configuration will define the characteristics of our instances and the auto-scaling group determines the size of our cluster:&lt;/p>
&lt;pre>&lt;code>// Launch configuration for the consul cluster auto-scaling group.
resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
name_prefix = &amp;quot;consul-node-&amp;quot;
image_id = &amp;quot;${lookup(var.ami_ecs_optimised, var.region)}&amp;quot;
instance_type = &amp;quot;t2.micro&amp;quot;
security_groups = [&amp;quot;${aws_security_group.consul-cluster-vpc.id}&amp;quot;]
lifecycle {
create_before_destroy = true
}
}
// Auto-scaling group for our cluster.
resource &amp;quot;aws_autoscaling_group&amp;quot; &amp;quot;consul-cluster-asg&amp;quot; {
name = &amp;quot;consul-asg&amp;quot;
launch_configuration = &amp;quot;${aws_launch_configuration.consul-cluster-lc.name}&amp;quot;
min_size = 5
max_size = 5
vpc_zone_identifier = [
&amp;quot;${aws_subnet.public-a.id}&amp;quot;,
&amp;quot;${aws_subnet.public-b.id}&amp;quot;
]
lifecycle {
create_before_destroy = true
}
}
&lt;/code>&lt;/pre>&lt;p>A few key things to note:&lt;/p>
&lt;ol>
&lt;li>I have omitted the &lt;code>tag&lt;/code> properties in the scripts for brevity&lt;/li>
&lt;li>The &amp;lsquo;image&amp;rsquo; for the launch configuration is looked up based on the region we've specified - we're a basic linux image&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>&lt;/li>
&lt;li>We are using micro instances, which are free-tier eligible&lt;/li>
&lt;li>The auto-scaling group spans both availability zones.&lt;/li>
&lt;/ol>
&lt;p>Once we run &lt;code>terraform apply&lt;/code>, we'll see our auto-scaling group, which references the new launch configuration and works over multiple availability zones:&lt;/p>
&lt;p>&lt;img src="images/img-6-lc-asg.png" alt="Auto scaling group and launch configuration">&lt;/p>
&lt;p>We can also see the new instances:&lt;/p>
&lt;p>&lt;img src="images/img-7-instances.png" alt="Instances">&lt;/p>
&lt;p>These instances don't do much yet though, we've not installed Docker or Consul.&lt;/p>
&lt;h3 id="installing-consul-and-accessing-the-admin-interface">Installing Consul and Accessing the Admin Interface&lt;/h3>
&lt;p>To set up our instances we use a &amp;lsquo;userdata&amp;rsquo; script&amp;rsquo; A userdata runs once when an instance is created. We can create a script in our repository, and reference it in our Terraform files.&lt;/p>
&lt;p>We add a new file called &lt;code>consul-node.sh&lt;/code> to a &lt;code>files&lt;/code> folder. This script installs Docker and runs Consul:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">yum install -y docker
usermod -a -G docker ec2-user
service docker start
&lt;span style="color:#75715e"># Get my IP address.&lt;/span>
IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>curl http://169.254.169.254/latest/meta-data/local-ipv4&lt;span style="color:#66d9ef">)&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Instance IP is: &lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Start the Consul server.&lt;/span>
docker run -d --net&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name&lt;span style="color:#f92672">=&lt;/span>consul &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> consul agent -server -ui &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bind&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -client&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.0.0.0&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bootstrap-expect&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;1&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here's a breakdown of what we're doing:&lt;/p>
&lt;ol>
&lt;li>Install Docker. These scripts run as root, so we add the ec2-user to the Docker group, meaning when we log in later on via SSH, we can run Docker&lt;/li>
&lt;li>Get our IP address. AWS provide a magic address (169.254.169.254) which lets you query data about your instance, see &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance Metadata &amp;amp; User Metadata&lt;/a>&lt;/li>
&lt;li>Run the Consul docker image in server mode, with the UI enabled, expecting only one instance&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>The actual scripts contains more!&lt;/strong> Getting userdata scripts right, testing and debugging them is tricky. See how I do it in detail in &lt;a href="#Appendix-1-Logging">Appendix 1: Logging&lt;/a>.&lt;/p>
&lt;p>Now we need to tell Terraform to include this script as part of the instance metadata. Here's how we do that:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
/// ...add the line below....
user_data = &amp;quot;${file(&amp;quot;files/consul-node.sh&amp;quot;)}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>When Consul is running with the &lt;code>-ui&lt;/code> option, it provides an admin UI. You can try it by running Consul locally with &lt;code>docker run -p8500:8500 consul&lt;/code> and navigating to http://localhost:8500/ui.&lt;/p>
&lt;p>We can install a load balancer in front of our auto-scaling group, to automatically forward incoming traffic to a host. Here's the config:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_elb&amp;quot; &amp;quot;consul-lb&amp;quot; {
name = &amp;quot;consul-lb-a&amp;quot;
security_groups = [
&amp;quot;${aws_security_group.consul-cluster-vpc.id}&amp;quot;,
&amp;quot;${aws_security_group.web.id}&amp;quot;
]
subnets = [
&amp;quot;${aws_subnet.public-a.id}&amp;quot;,
&amp;quot;${aws_subnet.public-b.id}&amp;quot;
]
listener {
instance_port = 8500
instance_protocol = &amp;quot;http&amp;quot;
lb_port = 80
lb_protocol = &amp;quot;http&amp;quot;
}
health_check {
healthy_threshold = 2
unhealthy_threshold = 2
timeout = 3
target = &amp;quot;HTTP:8500/ui/&amp;quot;
interval = 30
}
}
&lt;/code>&lt;/pre>&lt;p>Blow-by-blow:&lt;/p>
&lt;ol>
&lt;li>Create a load balancer, with the same security groups as the rest of the VPC, but also a security group which allows web access&lt;/li>
&lt;li>Point to two subnets first subnet&lt;/li>
&lt;li>Forward HTTP 8500 traffic&lt;/li>
&lt;li>Configure a healthcheck&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>&lt;/li>
&lt;/ol>
&lt;p>The final change we make is to add an &lt;code>outputs.tf&lt;/code> file, which lists all of the properties Terraform knows about which we want to save. All it includes is:&lt;/p>
&lt;pre>&lt;code>output &amp;quot;consul-dns&amp;quot; {
value = &amp;quot;${aws_elb.consul-lb.dns_name}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>When we finally run &lt;code>terraform apply&lt;/code>, we see the public DNS of our load balancer:&lt;/p>
&lt;p>&lt;img src="images/img-8-cluster-dns.png" alt="Screenshot showing &amp;lsquo;terraform apply&amp;rsquo; output, indicating our newly generated ELB's public DNS">&lt;/p>
&lt;p>And running in a browser on port 8500 we see the Consul admin interface:&lt;/p>
&lt;p>&lt;img src="images/img-9-admin-ui.png" alt="Screenshot showing the Consul admin interface">&lt;/p>
&lt;p>Every time we refresh we will likely see a different node. We've actually created five clusters each of one node - what we now need to do is connect them all together into a single cluster of five nodes.&lt;/p>
&lt;p>If you want to see the code as it stands now, check the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-2">Step 2&lt;/a> branch.&lt;/p>
&lt;h2 id="step-3---creating-the-cluster">Step 3 - Creating the Cluster&lt;/h2>
&lt;p>Creating the cluster is now not too much of a challenge. We will update the userdata script to tell the consul process we are expecting 5 nodes (via the &lt;a href="https://www.consul.io/docs/agent/options.html#_bootstrap_expect">&lt;code>bootstrap-expect&lt;/code>&lt;/a> flag.&lt;/p>
&lt;p>Here's the updated script:&lt;/p>
&lt;pre>&lt;code># Get my IP address.
IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
echo &amp;quot;Instance IP is: $IP&amp;quot;
# Start the Consul server.
docker run -d --net=host \
--name=consul \
consul agent -server -ui \
-bind=&amp;quot;$IP&amp;quot; \
-client=&amp;quot;0.0.0.0&amp;quot; \
-bootstrap-expect=&amp;quot;5&amp;quot;
&lt;/code>&lt;/pre>&lt;p>The problem is &lt;strong>this won't work&lt;/strong>&amp;hellip; We need to tell each node the address of &lt;em>another&lt;/em> server in the cluster. For example, if we start five nodes, we should tell nodes 2-5 the address of node 1, so that the nodes can discover each other.&lt;/p>
&lt;p>The challenge is how do we get the IP of node 1? The IP addresses are determined by the network, we don't preset them so cannot hard code them. Also, we can expect nodes to occasionally die and get recreated, so the IP addresses of nodes will in fact change over time.&lt;/p>
&lt;h3 id="getting-the-ip-addresses-of-nodes-in-the-cluster">Getting the IP addresses of nodes in the cluster&lt;/h3>
&lt;p>There's a nice trick we can use here. We can ask AWS to give us the IP addresses of each host in the auto-scaling group. If we tell each node the addresses of the &lt;em>other nodes&lt;/em>, then they will elect a leader themselves&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;img src="images/img-12-choose-leader-1.png" alt="Diagram showing how we decide on a leader IP">&lt;/p>
&lt;p>There are a couple of things we need to do to get this right. First, update the userdata script to provide the IPs of other nodes when we're starting up, then update the &lt;strong>role&lt;/strong> of our nodes so that they have permissions to use the APIs we're going to call.&lt;/p>
&lt;h3 id="getting-the-cluster-ips">Getting the Cluster IPs&lt;/h3>
&lt;p>This is actually fairly straightforward. We update our userdata script to the below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># A few variables we will refer to later...&lt;/span>
ASG_NAME&lt;span style="color:#f92672">=&lt;/span>consul-asg
REGION&lt;span style="color:#f92672">=&lt;/span>ap-southeast-1
EXPECTED_SIZE&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>
&lt;span style="color:#75715e"># Return the id of each instance in the cluster.&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span> cluster-instance-ids &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Grab every line which contains &amp;#39;InstanceId&amp;#39;, cut on double quotes and grab the ID:&lt;/span>
&lt;span style="color:#75715e"># &amp;#34;InstanceId&amp;#34;: &amp;#34;i-example123&amp;#34;&lt;/span>
&lt;span style="color:#75715e">#....^..........^..^.....#4.....^...&lt;/span>
aws --region&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$REGION&lt;span style="color:#e6db74">&amp;#34;&lt;/span> autoscaling describe-auto-scaling-groups &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --auto-scaling-group-name $ASG_NAME &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | grep InstanceId &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | cut -d &lt;span style="color:#e6db74">&amp;#39;&amp;#34;&amp;#39;&lt;/span> -f4
&lt;span style="color:#f92672">}&lt;/span>
&lt;span style="color:#75715e"># Return the private IP of each instance in the cluster.&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span> cluster-ips &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#66d9ef">for&lt;/span> id in &lt;span style="color:#66d9ef">$(&lt;/span>cluster-instance-ids&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">do&lt;/span>
aws --region&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$REGION&lt;span style="color:#e6db74">&amp;#34;&lt;/span> ec2 describe-instances &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --query&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Reservations[].Instances[].[PrivateIpAddress]&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --instance-ids&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$id&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;span style="color:#f92672">}&lt;/span>
&lt;span style="color:#75715e"># Wait until we have as many cluster instances as we are expecting.&lt;/span>
&lt;span style="color:#66d9ef">while&lt;/span> COUNT&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>cluster-instance-ids | wc -l&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$COUNT&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -lt &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>
&lt;span style="color:#66d9ef">do&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$COUNT&lt;span style="color:#e6db74"> instances in the cluster, waiting for &lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74"> instances to warm up...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
sleep &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;span style="color:#75715e"># Get my IP address, all IPs in the cluster, then just the &amp;#39;other&amp;#39; IPs...&lt;/span>
IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>curl http://169.254.169.254/latest/meta-data/local-ipv4&lt;span style="color:#66d9ef">)&lt;/span>
mapfile -t ALL_IPS &amp;lt; &amp;lt;&lt;span style="color:#f92672">(&lt;/span>cluster-ips&lt;span style="color:#f92672">)&lt;/span>
OTHER_IPS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#f92672">(&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>ALL_IPS[@]/&lt;span style="color:#e6db74">${&lt;/span>IP&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>/&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">)&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Instance IP is: &lt;/span>$IP&lt;span style="color:#e6db74">, Cluster IPs are: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>CLUSTER_IPS[@]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">, Other IPs are: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[@]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Start the Consul server.&lt;/span>
docker run -d --net&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name&lt;span style="color:#f92672">=&lt;/span>consul &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> consul agent -server -ui &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bind&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[0]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[1]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[2]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[3]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bootstrap-expect&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Right, here's what's going on:&lt;/p>
&lt;ol>
&lt;li>We create a few variables we'll use repeatedly&lt;/li>
&lt;li>We create a &lt;code>cluster-instance-ids&lt;/code> function which returns the ID of each instance in the auto-scaling group&lt;/li>
&lt;li>We create a &lt;code>cluster-ips&lt;/code> function which returns the private IP address of each instance in the cluster.&lt;/li>
&lt;li>We wait until the auto-scaling group has our expected number of instances (it can take a while for them all to be created)&lt;/li>
&lt;li>We get the 5 IP addresses&lt;/li>
&lt;li>We remove our IP from the array, leaving us with the IPs of the &lt;em>other&lt;/em> nodes&lt;/li>
&lt;li>We start the Consul agent in server mode, expecting 5 nodes and offering the IP of each other agent&lt;/li>
&lt;/ol>
&lt;p>The problem is, if we try to run the script we will fail, because calling the AWS APIs requires some permissions we don't have. Let's fix that.&lt;/p>
&lt;h3 id="creating-a-role-for-our-nodes">Creating a Role for our nodes&lt;/h3>
&lt;p>Our nodes now have a few special requirements. They need to be able to query the details of an auto-scaling group and get the IP of an instance&lt;sup id="fnref:11">&lt;a href="#fn:11" class="footnote-ref" role="doc-noteref">11&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We will need to create a policy which describes the permissions we need, create a role, attach the policy to the role and then ensure our instances are assigned the correct role. This is &lt;code>consul-node-role.tf&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>// This policy allows an instance to discover a consul cluster leader.
resource &amp;quot;aws_iam_policy&amp;quot; &amp;quot;leader-discovery&amp;quot; {
name = &amp;quot;consul-node-leader-discovery&amp;quot;
path = &amp;quot;/&amp;quot;
policy = &amp;lt;&amp;lt;EOF
{
&amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
&amp;quot;Statement&amp;quot;: [
{
&amp;quot;Sid&amp;quot;: &amp;quot;Stmt1468377974000&amp;quot;,
&amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
&amp;quot;Action&amp;quot;: [
&amp;quot;autoscaling:DescribeAutoScalingInstances&amp;quot;,
&amp;quot;autoscaling:DescribeAutoScalingGroups&amp;quot;,
&amp;quot;ec2:DescribeInstances&amp;quot;
],
&amp;quot;Resource&amp;quot;: [
&amp;quot;*&amp;quot;
]
}
]
}
EOF
}
// Create a role which consul instances will assume.
// This role has a policy saying it can be assumed by ec2
// instances.
resource &amp;quot;aws_iam_role&amp;quot; &amp;quot;consul-instance-role&amp;quot; {
name = &amp;quot;consul-instance-role&amp;quot;
assume_role_policy = &amp;lt;&amp;lt;EOF
{
&amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
&amp;quot;Statement&amp;quot;: [
{
&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;,
&amp;quot;Principal&amp;quot;: {
&amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot;
},
&amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
&amp;quot;Sid&amp;quot;: &amp;quot;&amp;quot;
}
]
}
EOF
}
// Attach the policy to the role.
resource &amp;quot;aws_iam_policy_attachment&amp;quot; &amp;quot;consul-instance-leader-discovery&amp;quot; {
name = &amp;quot;consul-instance-leader-discovery&amp;quot;
roles = [&amp;quot;${aws_iam_role.consul-instance-role.name}&amp;quot;]
policy_arn = &amp;quot;${aws_iam_policy.leader-discovery.arn}&amp;quot;
}
// Create a instance profile for the role.
resource &amp;quot;aws_iam_instance_profile&amp;quot; &amp;quot;consul-instance-profile&amp;quot; {
name = &amp;quot;consul-instance-profile&amp;quot;
roles = [&amp;quot;${aws_iam_role.consul-instance-role.name}&amp;quot;]
}
&lt;/code>&lt;/pre>&lt;p>Terraform is a little verbose here! Finally, we update our launch configuration to ensure that the instances assume this role.&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
// Add this line!!
iam_instance_profile = &amp;quot;${aws_iam_instance_profile.consul-instance-profile.id}&amp;quot;
}
}
&lt;/code>&lt;/pre>&lt;p>Let's create the cluster again, with &lt;code>terraform apply&lt;/code>. When we log into the UI we should now see a cluster containing all five nodes:&lt;/p>
&lt;p>&lt;img src="images/img-13-cluster.png" alt="Screenshot of the Consul UI, showing that the Consul server is running on five nodes in the Datacenter">&lt;/p>
&lt;p>This code is all in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-3">Step 3&lt;/a> branch.&lt;/p>
&lt;p>If you are familiar with Consul, this may be all you need. If not, you might be interested in seeing how we actually create a new instance to host a service, register it with Consul and query its address.&lt;/p>
&lt;h2 id="step-4---adding-a-microservice">Step 4 - Adding a Microservice&lt;/h2>
&lt;p>I've created a docker image for as simple a microservice as you can get. It returns a quote from Futurama's Zapp Brannigan. The image is tagged as &lt;code>dwmkerr/zapp-service&lt;/code>.&lt;/p>
&lt;p>On a new EC2 instance, running in either subnet, with the same roles as the Consul nodes, we run the following commands:&lt;/p>
&lt;pre>&lt;code># Install Docker
sudo su
yum update -y
yum install -y docker
service docker start
# Get my IP and the IP of any node in the server cluster.
IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
NODE_ID=$(aws --region=&amp;quot;ap-southeast-1&amp;quot; autoscaling describe-auto-scaling-groups --auto-scaling-group-name &amp;quot;consul-asg&amp;quot; \
| grep InstanceId \
| cut -d '&amp;quot;' -f4 \
| head -1)
NODE_IP=$(aws --region=&amp;quot;ap-southeast-1&amp;quot; ec2 describe-instances \
--query=&amp;quot;Reservations[].Instances[].[PrivateIpAddress]&amp;quot; \
--output=&amp;quot;text&amp;quot; \
--instance-ids=&amp;quot;$NODE_ID&amp;quot;)
# Run the consul agent.
docker run -d --net=host \
consul agent \
-bind=&amp;quot;$IP&amp;quot; \
-join=$NODE_IP
# Run registrator - any Docker images will then be auto registered.
docker run -d \
--name=registrator \
--net=host \
--volume=/var/run/docker.sock:/tmp/docker.sock \
gliderlabs/registrator:latest \
consul://localhost:8500
# Run the example microservice - registrator will take care of letting consul know.
docker run -d -p 5000:5000 dwmkerr/zapp-service
&lt;/code>&lt;/pre>&lt;p>What's going on here?&lt;/p>
&lt;ol>
&lt;li>We grab our own IP address and the IP address of the first instance we find in the server cluster, using the same tricks as before&lt;/li>
&lt;li>We run the Consul agent - telling it the IP to use to join the cluster&lt;/li>
&lt;li>We run &lt;a href="https://github.com/gliderlabs/registrator">Registrator&lt;/a>, a handy utility which will automatically register any new services we run to Consul&lt;/li>
&lt;li>We run a goofy sample microservice (which registrator will register for us)&lt;/li>
&lt;/ol>
&lt;p>Now we can check the Consul UI:&lt;/p>
&lt;p>&lt;img src="images/img-15-sample-service.png" alt="The Consul UI showing a new service">&lt;/p>
&lt;p>And there we have it. Our new node joins the cluster (as a client), we can register a new service with Consul.&lt;/p>
&lt;p>We can call this service from any node in the subnet, seeing output like the below:&lt;/p>
&lt;p>&lt;img src="images/img-x-zapp.png" alt="Screenshot of the Zapp service">&lt;/p>
&lt;p>In this example, I used a DNS SRV query to ask where the &lt;code>zapp-service&lt;/code> is, was told it was at &lt;code>10.0.2.158&lt;/code> on port &lt;code>5000&lt;/code>, then called the service, receiving a response. I can discover any service using this method, from any node. As services are added, removed, moved etc, I can ask Consul for accurate information on where to find them.&lt;/p>
&lt;p>Check the &lt;a href="">Step 4&lt;/a> branch to see the code in its current state.&lt;/p>
&lt;h2 id="step-5---spanner-throwing">Step 5 - Spanner Throwing&lt;/h2>
&lt;p>We can now try to throw some spanners in the works, to see how resilient the system is.&lt;/p>
&lt;p>According to the &lt;a href="https://www.consul.io/docs/internals/consensus.html#deployment-table">Deployment Table&lt;/a> from the Consul documentation, a cluster of five nodes means we have a quorum of three nodes (i.e. a minimum of three nodes are needed for a working system). This means we can tolerate the failure of two nodes.&lt;/p>
&lt;p>The easiest way to test this is to simply manually kill two nodes:&lt;/p>
&lt;p>&lt;img src="images/img-16-terminate.png" alt="Screenshot showing two AWS instances being terminated">&lt;/p>
&lt;p>If we pick two random nodes, as above, and terminate them, we see the cluster determines that we have two failed nodes but will still function (if one was the leader, a new leader will be automatically elected):&lt;/p>
&lt;p>&lt;img src="images/img-17-node-failure.png" alt="Screenshot showing the cluster highlighting two failed nodes">&lt;/p>
&lt;p>What's nice about this setup is that no manual action is needed to recover. Our load balancer will notice the nodes are unhealthy and stop forwarding traffic. Our auto-scaling group will see the nodes have terminated and create two new ones, which will join the cluster in the same way as the original nodes. Once they join, the load balancer will find them healthy and bring them back into rotation.&lt;/p>
&lt;p>We can see from the load balancer monitoring that it notices we have unhealthy nodes and also notices when new ones come into service:&lt;/p>
&lt;p>&lt;img src="images/img-18-recovery-1.png" alt="Screenshot showing the load balancer monitoring">&lt;/p>
&lt;p>A quick check of the admin dashboard shows we now have a recovered system, with five healthy nodes:&lt;/p>
&lt;p>&lt;img src="images/img-18b-recovered.png" alt="Screenshot showing recovered system">&lt;/p>
&lt;p>The nodes which were terminated are still listed as failing. After 72 hours Consul will stop trying to periodically reconnect to these nodes and completely remove them&lt;sup id="fnref:12">&lt;a href="#fn:12" class="footnote-ref" role="doc-noteref">12&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>Hopefully this should provide a good starting point to think about building your own resilient and robust systems for services like Consul.&lt;/p>
&lt;p>Interesting areas to look into to extend the project would be:&lt;/p>
&lt;ol>
&lt;li>Setting up alerts so that if we lose more than one node, we are informed&lt;/li>
&lt;li>Automating resilience tests by programatically bringing down servers and monitoring how long it takes the system to return to five nodes&lt;/li>
&lt;li>Instead of using a userdata script to set up a node, bake it into a new custom AMI with &lt;a href="https://www.packer.io/">Packer&lt;/a>&lt;/li>
&lt;li>Adding alerts for if we lose three of more nodes, which always requires manual intervention (see &lt;a href="https://www.consul.io/docs/guides/outage.html">Outage Recovery&lt;/a>)&lt;/li>
&lt;/ol>
&lt;p>As always, any questions or comments are welcome! All code is available at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster">github.com/dwmkerr/terraform-consul-cluster&lt;/a>.&lt;/p>
&lt;hr>
&lt;h2 id="appendix-1-logging">Appendix 1: Logging&lt;/h2>
&lt;p>Small typos or mistakes in the userdata script are almost impossible to effectively diagnose. The scripts were actually built in the following way:&lt;/p>
&lt;ol>
&lt;li>Draft a script on my local machine which configures script logging and CloudWatch&lt;sup id="fnref:13">&lt;a href="#fn:13" class="footnote-ref" role="doc-noteref">13&lt;/a>&lt;/sup>&lt;/li>
&lt;li>Spin up a new EC2 instance manually&lt;/li>
&lt;li>SSH onto the instance, and run the script line by line until I'm sure it's right&lt;/li>
&lt;li>Ensure the logs are forwarded to CloudWatch, then add the more complex features and repeatedly test&lt;/li>
&lt;/ol>
&lt;p>I've included CloudWatch logging in the code. In this write-up I've omitted this code as it is purely for diagnostics and doesn't contribute to the main topic. The setup is in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/files/consul-node.sh">&lt;code>consul-node.sh&lt;/code>&lt;/a> and &lt;a href="%60https://github.com/dwmkerr/terraform-consul-cluster/blob/master/consul-node-role.tf">&lt;code>consul-node-role.tf&lt;/code>&lt;/a> files.&lt;/p>
&lt;p>If you want more details, let me know, or just check the code. I would heartily recommend setting up logging like this for all but the most straightforward projects:&lt;/p>
&lt;p>&lt;img src="images/img-19-cloudwatch-1.png" alt="Screenshot showing logs">&lt;/p>
&lt;p>Being able to diagnose issues like this is vital when working with distributed systems which may be generating many log files.&lt;/p>
&lt;h2 id="appendix-2-modularisaton">Appendix 2: Modularisaton&lt;/h2>
&lt;p>I got some a great PR from &lt;a href="https://github.com/arehmandev">arehmandev&lt;/a> which modularises the code. This makes it more reusable and cleans up the structure significantly. If you want to see the before/after, check the original PR at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/pull/4">https://github.com/dwmkerr/terraform-consul-cluster/pull/4&lt;/a>.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Further Reading&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://www.consul.io/docs/internals/consensus.html">Consul - Consensus Protocol&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://sitano.github.io/2015/10/06/abt-consul-outage/">What you have to know about Consul and how to beat the outage problem&lt;/a>, John Koepi&lt;/li>
&lt;/ol>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>This kind of pattern is critical in the world of microservices, where many small services will be running on a cluster. Services may die, due to errors or failing hosts, and be recreated on new hosts. Their IPs and ports may be ephemeral.It is essential that the system as a whole has a registry of where each service lives and how to access it. Such a registry must be &lt;em>resilient&lt;/em>, as it is an essential part of the system. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Most popular is a fairly loose term. Well ranked by Gartner and anecdotally with the largest infrastructure footprint. &lt;a href="https://www.gartner.com/doc/reprints?id=1-2G2O5FC&amp;amp;ct=150519&amp;amp;st=sb">https://www.gartner.com/doc/reprints?id=1-2G2O5FC&amp;amp;ct=150519&amp;amp;st=sb&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>This is AWS parlance again. An availabilty zone is an isolated datacenter. Theoretically, spreading nodes across AZs will increase resilience as it is less likely to have catastrophic failures or outages across multiple zones. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>I don't get money from Udemy or anyone else for writing anything on this blog. All opinions are purely my own and influenced by my own experience, not sponsorship. Your milage may vary (yada yada) but I found the course quite good: &lt;a href="https://www.udemy.com/aws-certified-solutions-architect-associate/">https://www.udemy.com/aws-certified-solutions-architect-associate/&lt;/a>. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>For more expert readers that may sound horribly patronising, I don't mean it to be. For many less experienced technologists the basics of networking might be more unfamiliar! &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>See &lt;a href="https://www.consul.io/docs/internals/consensus.html">https://www.consul.io/docs/internals/consensus.html&lt;/a>. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>A common pattern is to actually make the group size dynamic, responding to events. For example, we could have a group of servers which increases in size if the average CPU load of the hosts stays above 80% for five minutes, and scales down if it goes below 10% for ten minutes. This is more common for app and web servers and not needed for our system. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>Specifically, the current latest &lt;a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux AMI&lt;/a>. &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>Check the admin UI every 30 seconds, more than 3 seconds indicates a timeout and failure. Two failures in a row means an unhealthy host, which will be destroyed, two successes in a row for a new host means healthy, which means it will receive traffic. &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>This is a fairly sophisticated topic in itself, see &lt;a href="https://www.consul.io/docs/internals/consensus.html">Consul - Consensus Protocol&lt;/a> for details. &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:11" role="doc-endnote">
&lt;p>In fact, we actually have more permissions required, because in the &amp;lsquo;real&amp;rsquo; code we also have logs forwarded to CloudWatch. &lt;a href="#fnref:11" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:12" role="doc-endnote">
&lt;p>These nodes can be removed manually, see &lt;a href="https://www.consul.io/docs/commands/force-leave.html">Consul Force Leave&lt;/a>. &lt;a href="#fnref:12" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:13" role="doc-endnote">
&lt;p>Amazon's service for managing and aggregating logs &lt;a href="#fnref:13" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Using Slack for Server Development</title><link>https://dwmkerr.com/using-slack-for-server-development/</link><pubDate>Fri, 18 Nov 2016 01:25:00 +0000</pubDate><guid>https://dwmkerr.com/using-slack-for-server-development/</guid><description>&lt;p>I recently found a surprisingly helpful approach for server-side development which uses Slack in a creative way.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>The scenario can be roughly simplified to this:&lt;/p>
&lt;p>&lt;img src="images/0-problem.png" alt="Planned Architecture">&lt;/p>
&lt;p>We are building a mobile app and application server. This will take data from a user, transform it and then pass it to the enterprise system processing.&lt;/p>
&lt;p>The problem is that the enterprise system doesn't exist yet!&lt;/p>
&lt;p>Now this is not too much of a challenge, the first thing we did was build a simple mock of the enterprise system in Node.js, so that we can at least talk to &lt;em>something&lt;/em>:&lt;/p>
&lt;p>&lt;img src="images/0-problem-2.png" alt="The Mock System">&lt;/p>
&lt;p>So now we have the question - is our application server transforming the data correctly?&lt;/p>
&lt;p>Let's say that in our example we bring in three pieces of data from the UI - a first name, middle name and last name.&lt;/p>
&lt;p>Our enterprise system, in this case we'll say it is a CRM system, only accepts a first name and last name. So in our app server, we are going to concatenate the middle name and last name.&lt;/p>
&lt;p>Our testers want to make sure that the enterprise system will receive the right data - but at the moment it is only a mock, we cannot log in a check the middle and last names have been combined properly. What to do?&lt;/p>
&lt;h2 id="slack-to-the-rescue">Slack to the Rescue!&lt;/h2>
&lt;p>It's a trivial change to our mock server to send the received messages to Slack:&lt;/p>
&lt;p>&lt;img src="images/1-slack.png" alt="Slack Diagram">&lt;/p>
&lt;p>Now our testers can input data in the mobile app and then watch a slack channel to see the data our application server will actually send to the enterprise system. They can verify the logic has been implemented correctly.&lt;/p>
&lt;p>Here's how it might look - in the image below I am running my mock enterprise server, which has Swagger UI to show the mocked APIs and allow me to call them:&lt;/p>
&lt;p>&lt;img src="images/4-swagger.png" alt="Swagger UI">&lt;/p>
&lt;p>The message is received on the server, sent to slack and we can check the result:&lt;/p>
&lt;p>&lt;img src="images/5-slack.png" alt="Slack">&lt;/p>
&lt;p>Now this is obviously a trivial and contrived example, but Slack offers a lot of capabilities. Imagine you have a server which watermarks images, you could send an image file to render to the screen. There are a whole bunch of ways you can extend this use case.&lt;/p>
&lt;p>In the early stages of a project, where they may be many mocked systems, being able to see what they are doing can be really useful.&lt;/p>
&lt;h2 id="setting-it-up">Setting it up&lt;/h2>
&lt;p>I've created a super-simple demo setup here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/slack-backend">github.com/dwmkerr/slack-backend&lt;/a>&lt;/p>
&lt;p>Here's how you go about it.&lt;/p>
&lt;p>Step 1: Set up a webhook on slack&lt;/p>
&lt;p>&lt;img src="images/1-menu.png" alt="Menu">&lt;/p>
&lt;p>&lt;img src="images/1-incoming-webhook.png" alt="Webhook">&lt;/p>
&lt;p>&lt;img src="images/3-hook.png" alt="">&lt;/p>
&lt;p>Step 2: Use the HTTP APIs from Slack, or a client from your platform of choice to send the message:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">
&lt;span style="color:#75715e">// Create the Slack webhook based on our config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">slack&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Slack&lt;/span>();
&lt;span style="color:#a6e22e">slack&lt;/span>.&lt;span style="color:#a6e22e">setWebhook&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;https://hooks.slack.com/services/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&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Every time we&amp;#39;re about to handle a request, tell our friend Slack.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">ext&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;onPreHandler&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">request&lt;/span>, &lt;span style="color:#a6e22e">reply&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Never bother logging any requests to swagger UI.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/swaggerui\//&lt;/span>) &lt;span style="color:#f92672">||&lt;/span>
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/swagger.json/&lt;/span>) &lt;span style="color:#f92672">||&lt;/span>
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/$/&lt;/span>)) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reply&lt;/span>.&lt;span style="color:#66d9ef">continue&lt;/span>();
}
&lt;span style="color:#75715e">// Send the Slack message.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">slack&lt;/span>.&lt;span style="color:#a6e22e">webhook&lt;/span>({
&lt;span style="color:#a6e22e">text&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">Request *&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">*
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">method&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">payload&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
});
&lt;span style="color:#a6e22e">reply&lt;/span>.&lt;span style="color:#66d9ef">continue&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This approach was quick and easy to implement, hopefully others will find it useful!&lt;/p></description><category>CodeProject</category></item><item><title>Simple Continuous Integration for Docker Images</title><link>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</link><pubDate>Thu, 03 Nov 2016 05:14:35 +0000</pubDate><guid>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</guid><description>&lt;p>In this article I'm going to demonstrate a few tips and tricks which can make your life easier when you are building or maintaining Dockerfiles.&lt;/p>
&lt;h2 id="the-need-for-a-build-pipeline">The need for a Build Pipeline&lt;/h2>
&lt;p>Do we really need any kind of continuous integration or build pipeline for Dockerfiles?&lt;/p>
&lt;p>There will be cases when the answer is no. However, if the answer to any of the following questions is &amp;lsquo;yes&amp;rsquo;, it might be worth considering:&lt;/p>
&lt;ol>
&lt;li>Do you want others to be able to contribute to the Dockerfile, perhaps changing the image over time?&lt;/li>
&lt;li>Are there specific functionalities in your Dockerfiles which could break if altered?&lt;/li>
&lt;li>Do you expect to need to release updates to your Dockerfile?&lt;/li>
&lt;/ol>
&lt;p>Essentially, if we are looking at providing some kind of automated quality assurance and automation around building and releasing, then a build pipeline is not a bad idea.&lt;/p>
&lt;h2 id="a-simple-build-pipeline">A simple Build Pipeline&lt;/h2>
&lt;p>Here's what a simple build pipeline could look like. This example is for a Docker Image I just created for local DynamoDB development - &lt;a href="https://github.com/dwmkerr/docker-dynamodb">dwmkerr/docker-dynamodb&lt;/a>:&lt;/p>
&lt;p>&lt;img src="images/Simple-Docker-Image-CI.png" alt="Simple Continous Intergration Pipeline">&lt;/p>
&lt;p>Let's dissect what we've got here.&lt;/p>
&lt;h3 id="the-dockerfile">The Dockerfile&lt;/h3>
&lt;p>This is the main &amp;lsquo;code&amp;rsquo; of the project if you like. The &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/Dockerfile">Dockerfile&lt;/a> is the recipe for the image we create.&lt;/p>
&lt;h3 id="the-continuous-integration-service">The Continuous Integration Service&lt;/h3>
&lt;p>In this case, I am using &lt;a href="https://circleci.com/">CircleCI&lt;/a>, however the approach described would work fine with most CI systems (such as Jenkins, TravisCI and TeamCity). There &lt;em>is&lt;/em> an option to use the &lt;a href="https://docs.docker.com/docker-hub/builds/">Docker Hub Automated Builds&lt;/a>, but I've found this doesn't give the flexibility I need (see &lt;a href="#appendix1whynotdockerhubautomatedbuilds">Why not Docker Hub Automated Builds&lt;/a>).&lt;/p>
&lt;p>Essentially the CI service needs to offer the option to have three distinct steps in the pipeline, each of which must pass for process to proceed:&lt;/p>
&lt;ol>
&lt;li>Build&lt;/li>
&lt;li>Test&lt;/li>
&lt;li>Deploy&lt;/li>
&lt;/ol>
&lt;h3 id="the-build">The Build&lt;/h3>
&lt;p>We can build with tools, script files, whatever. At the moment, I am leaning towards &lt;a href="https://www.gnu.org/software/make/">makefiles&lt;/a>. Normally I only need a few lines of shell script to do a build - anything more complex and the makefile can call a shell script. See also &lt;a href="#appendix2whymakefiles">Why Makefiles?&lt;/a>&lt;/p>
&lt;p>Here's what it might look like:&lt;/p>
&lt;pre>&lt;code>build:
docker build -t dwmkerr/dynamodb:latest .
ifndef BUILD_NUM
$(warning No build number is defined, skipping build number tag.)
else
docker build -t dwmkerr/dynamodb:$(BUILD_NUM) .
endif
&lt;/code>&lt;/pre>&lt;p>This command just builds the &lt;code>Dockerfile&lt;/code> and tags it as &lt;code>dwmkerr/dynamodb:lastest&lt;/code>. If a &lt;code>BUILD_NUM&lt;/code> variable is present, we also create the tag &lt;code>dwmkerr/dynamodb:BUILD_NUM&lt;/code>. This means if we want to deploy to a service such as &lt;a href="https://aws.amazon.com/ecs/">Amazon ECS&lt;/a> we can push a specific build by referring to the image with that tag.&lt;/p>
&lt;h3 id="the-tests">The Tests&lt;/h3>
&lt;p>Again I'm relying on &lt;code>make&lt;/code>. I just want to be able to run &lt;code>make test&lt;/code> - if zero is returned I'm happy. If not, the pipeline should stop and I'll check the output. Here's my test command:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>Not a thing of beauty, but it works. These scripts I'll discuss a little bit later on, in the delightly titled &lt;a href="#appendix3whatarethesetestscripts">What are these test scripts&lt;/a> section.&lt;/p>
&lt;p>For CircleCI, this is enough to have the main part of our pipeline. Here's how the &lt;code>circle.yml&lt;/code> file looks at this stage:&lt;/p>
&lt;pre>&lt;code>machine:
services:
- docker
environment:
# Set the build number, used in makefiles.
BUILD_NUM: $CIRCLE_BUILD_NUM
test:
override:
- make test
&lt;/code>&lt;/pre>&lt;p>(Actually there's a couple of other bits but they're just to make sure circle uses the right version of Docker, &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/circle.yml">see the full circle.yml file here&lt;/a>).&lt;/p>
&lt;h3 id="the-deployments">The Deployments&lt;/h3>
&lt;p>Deployments are trivial as all we need to do is push to the Docker Hub. The &lt;code>make deploy&lt;/code> command looks-a like this:&lt;/p>
&lt;pre>&lt;code>deploy:
docker push dwmkerr/dynamodb:latest
ifndef BUILD_NUM
$(warning No build number is defined, skipping push of build number tag.)
else
docker push dwmkerr/dynamodb:$(BUILD_NUM)
endif
&lt;/code>&lt;/pre>&lt;p>We're pushing the &lt;code>latest&lt;/code> tag and &lt;code>BUILD_NUM&lt;/code> tag if present. To add this to the CircleCI pipeline, we just add the following to &lt;code>circle.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>deployment:
master:
branch: master
commands:
- docker login -e $DOCKER_EMAIL -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
- make deploy
&lt;/code>&lt;/pre>&lt;p>If we have a push to &lt;code>master&lt;/code>, we log in to Docker (using environment variables I configure in the CircleCI UI) and then run &lt;code>make deploy&lt;/code> to push our images.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>That's about it. This is a pretty simple approach, you can see it in action at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/docker-dynamodb">github.com/dwmkerr/docker-dynamodb&lt;/a>&lt;/p>
&lt;p>The rest of this post is a bit of a deep dive into some specific areas I found interesting.&lt;/p>
&lt;h2 id="appendix-1-why-not-docker-hub-automated-builds">Appendix 1: Why not Docker Hub Automated Builds?&lt;/h2>
&lt;p>There are automated builds available in the Docker Hub:&lt;/p>
&lt;p>&lt;img src="images/dockerhubbuilds.png" alt="Docker Hub Automated Builds">&lt;/p>
&lt;p>I'm not using this feauture at the moment, here's a brief roundup of what I think are the current pros and cons:&lt;/p>
&lt;p>Pros&lt;/p>
&lt;ul>
&lt;li>You don't have to goof around installing Docker on a CI platform.&lt;/li>
&lt;li>It allows you to update the description of your Docker image automatically, from the GitHub &lt;code>README.md&lt;/code>.&lt;/li>
&lt;li>It allows you to associate the image with a specific GitHub repo (rather than just linking from the image description).&lt;/li>
&lt;li>Branch management - allowing tags to be built for specific branches.&lt;/li>
&lt;/ul>
&lt;p>Cons&lt;/p>
&lt;ul>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of configurable gating, such as a running a test command prior to deploying.&lt;/li>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of triggering of downstream processes, such as updating environments, sending notifications or whatever.&lt;/li>
&lt;/ul>
&lt;p>The lack of ability to perform tests on the image before deploying it why I'm currently not using the service.&lt;/p>
&lt;p>By doing the testing in a CI system for every pull request and only merging PRs where the tests pass we could mitigate the risk here. This service is worth watching as I'm sure it will evolve quickly.&lt;/p>
&lt;h2 id="appendix-2-why-makefiles">Appendix 2: Why Makefiles?&lt;/h2>
&lt;p>I started coding with a commandline compiler in DOS. When I used my first GUI (Borland Turbo C++) it felt like a huge leap:&lt;/p>
&lt;p>&lt;img src="images/turbocpp.png" alt="Borland Turbo C++">&lt;/p>
&lt;p>Later on I moved onto Microsoft Visual C++ 4.2:&lt;/p>
&lt;p>&lt;img src="images/visualcpp.png" alt="Visual C++ 4.2">&lt;/p>
&lt;p>And you cannot imagine the excitement when I got my boxed edition of Visual Studio .NET:&lt;/p>
&lt;p>&lt;img src="images/visualstudiodotnet.jpg" alt="Visual Studio .NET">&lt;/p>
&lt;p>Wow!&lt;/p>
&lt;p>Anyway, I digress. GNU &lt;code>make&lt;/code> was invented by Leonardo Da Vinci in 1473 to allow you to build something from the commandline, using a fairly consistent syntax.&lt;/p>
&lt;p>It is near ubiquitous on *nix systems. I am increasingly using it as an &amp;lsquo;entry point&amp;rsquo; to builds, as I use variety of languages and platforms. Being able to know that most of the time:&lt;/p>
&lt;pre>&lt;code>make build
make test
&lt;/code>&lt;/pre>&lt;p>Will build and test something is convenient. Makefiles actually are not that great to work with (see &lt;a href="http://stackoverflow.com/questions/448910/makefile-variable-assignment">this&lt;/a>, &lt;a href="http://stackoverflow.com/questions/10121182/multiline-bash-commands-in-makefile">this&lt;/a> and &lt;a href="http://www.conifersystems.com/whitepapers/gnu-make/">this&lt;/a>). I've found as long as you keep the commands simple, they're OK. For anything really complex, I normally have a &lt;code>scripts/&lt;/code> folder, but call the scripts &lt;em>from&lt;/em> the makefile, so that there's still a simple entrypoint.&lt;/p>
&lt;p>I'm not entirely sold on makefiles, but they tend to be my default at the moment if I know I'm going to use the commandline for builds (for example, in Java projects I'll often write a makefile to call Maven or Gradle).&lt;/p>
&lt;p>For things like Node.js, where you have commands like &lt;code>npm test&lt;/code> or &lt;code>npm run xyz&lt;/code> I &lt;em>still&lt;/em> sometimes use makefiles, using &lt;code>npm&lt;/code> for day-to-day dev tests (&lt;code>npm start&lt;/code>) and &lt;code>make&lt;/code> if it's something more complex (e.g. &lt;code>make deploy-sit&lt;/code> to deploy to an SIT environment).&lt;/p>
&lt;h2 id="appendix-3-what-are-these-test-scripts">Appendix 3: What are these test scripts?&lt;/h2>
&lt;p>You may have noticed:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>What's going on here?&lt;/p>
&lt;p>My Docker image is just a wrapper around &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">Amazon's Local DynamoDB tool&lt;/a>. I don't really need to test that tool. But what I wanted to test was the capabilities which lie at the &lt;em>intersection&lt;/em> between &amp;lsquo;native&amp;rsquo; Docker and &amp;lsquo;native&amp;rsquo; DynamoDB.&lt;/p>
&lt;p>For example, I know Docker supports volume mapping. I know DynamoDB supports using a data directory, to allow persistent between runs. I want to test I can combine Docker volume mapping and the DynamoDB data directory features. I know Docker images should default to being ephemeral, I want to test this holds true by default for my image.&lt;/p>
&lt;p>Testing Docker is a little hard - I want to test that I can run containers, start, stop, check state before and after and so on. This is essentially an integration test, it can be tricky to make it truly isolated and deterministic.&lt;/p>
&lt;p>I've given it my best go with these scripts. Here's an example for the &amp;lsquo;ephemeral&amp;rsquo; test, where I'm trying to assert that if I run a container, create a table, stop the container and run a new one, I no longer have the table. Here's the test:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Bomb if anything fails.&lt;/span>
set -e
&lt;span style="color:#75715e"># Kill any running dynamodb containers.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Cleaning up old containers...&amp;#34;&lt;/span>
docker ps -a | grep dwmkerr/dynamodb | awk &lt;span style="color:#e6db74">&amp;#39;{print $1}&amp;#39;&lt;/span> | xargs docker rm -f &lt;span style="color:#f92672">||&lt;/span> true
&lt;span style="color:#75715e"># Run the container.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Checking we can run the container...&amp;#34;&lt;/span>
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># Create a table.&lt;/span>
aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> create-table &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --table-name Supervillains &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --attribute-definitions AttributeName&lt;span style="color:#f92672">=&lt;/span>name,AttributeType&lt;span style="color:#f92672">=&lt;/span>S &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --key-schema AttributeName&lt;span style="color:#f92672">=&lt;/span>name,KeyType&lt;span style="color:#f92672">=&lt;/span>HASH &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --provisioned-throughput ReadCapacityUnits&lt;span style="color:#f92672">=&lt;/span>1,WriteCapacityUnits&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Clean up the container. On CircleCI the FS is BTRFS, so this might fail...&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Stopping and restarting...&amp;#34;&lt;/span>
docker stop $ID &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm $ID &lt;span style="color:#f92672">||&lt;/span> true
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># List the tables - there shouldn&amp;#39;t be any!&lt;/span>
COUNT&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> list-tables &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | jq &lt;span style="color:#e6db74">&amp;#39;.TableNames | length&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> $COUNT -ne &lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Expected to find no tables, found &lt;/span>$COUNT&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>It's a bit dirty - it removes containers from the host, changes things and so on. But it works.&lt;/p>
&lt;p>I did experiment with running these tests &lt;em>in a container&lt;/em>, which has the benefit of giving you a clean host to start with, which you can throw away after each test.&lt;/p>
&lt;p>I had to give up after a little while due to time constraints, but will probably revisit this process. The benefits of running these integration tests in a container is that we get a degree of isolation from the host.&lt;/p>
&lt;p>If anyone is interested, my attempts so far are on this &lt;a href="https://github.com/dwmkerr/docker-dynamodb/pull/2">RFC Pull Request&lt;/a>. Feel free to jump in!&lt;/p></description><category>CodeProject</category></item><item><title>Run Amazon DynamoDB locally with Docker</title><link>https://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</link><pubDate>Thu, 27 Oct 2016 08:06:00 +0000</pubDate><guid>https://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</guid><description>&lt;p>&lt;strong>tl;dr:&lt;/strong> Run DynamoDB locally using Docker:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8000:8000 dwmkerr/dynamodb
&lt;/code>&lt;/pre>&lt;p>Try it out by opening the shell, &lt;a href="http://localhost:8000/shell">localhost:8000/shell&lt;/a>:&lt;/p>
&lt;p>&lt;img src="images/banner.jpg" alt="DynamoDB Shell">&lt;/p>
&lt;p>That's all there is to it!&lt;/p>
&lt;h2 id="dynamodb">DynamoDB&lt;/h2>
&lt;p>&lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html">Amazon DynamoDB&lt;/a> is a NoSQL database-as-a-service, which provides a flexible and convenient repository for your services.&lt;/p>
&lt;p>Building applications which use DynamoDB is straightforward, there are APIs and clients for many languages and platforms.&lt;/p>
&lt;p>One common requirement is to be able to run a local version of DynamoDB, for testing and development purposes. To do this, you need to:&lt;/p>
&lt;ol>
&lt;li>Hit the &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">DynamoDB Local&lt;/a> documentation page&lt;/li>
&lt;li>Download an archive&lt;/li>
&lt;li>Extract it to a sensible location&lt;/li>
&lt;li>Run the extracted JAR, perhaps passing in some options&lt;/li>
&lt;/ol>
&lt;p>This can be a little cumbersome if you regularly use DynamoDB, so here's a easier way:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker run -p 8000:8000 dwmkerr/dynamodb
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>dwmkerr/dynamodb&lt;/code> image runs the JAR in a container, exposing the database on port 8000 by default.&lt;/p>
&lt;p>You can see the &lt;a href="dockeri.co/image/dwmkerr/dynamodb">image on the Docker Hub&lt;/a> and the source code at &lt;a href="https://github.com/dwmkerr/docker-dynamodb">github.com/dwmkerr/docker-dynamodb&lt;/a>.&lt;/p>
&lt;h2 id="customising-dynamodb">Customising DynamoDB&lt;/h2>
&lt;p>You can pass any of &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">the documented commandline flags to DynamoDB&lt;/a>. There are instructions on the GitHub page. Here's an example of how you can pass in a data directory, which allows DynamoDB data to be persisted after restarting a container (the image is ephemeral by default, as per &lt;a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">Dockerfile best practices&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker run -d -p 8000:8000 -v /tmp/data:/data/ dwmkerr/dynamodb -dbPath /data/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Running DynamoDB in a container gives an extra degree of flexibility and can speed up your workflow too!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Node.js Debugging</title><link>https://dwmkerr.com/effective-node-js-debugging/</link><pubDate>Sat, 03 Sep 2016 01:36:09 +0000</pubDate><guid>https://dwmkerr.com/effective-node-js-debugging/</guid><description>&lt;p>If you are interested in improving your Node.js debugging skills, then check out my talk at the recent &lt;a href="">JSChannel 2016&lt;/a> conference in Bangalore:&lt;/p>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/-iCygy2wGpM" frameborder="0" allowfullscreen>&lt;/iframe>
&lt;p>Comments and observations are always welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Testing the Docker for Mac Beta</title><link>https://dwmkerr.com/testing-the-docker-for-mac-beta/</link><pubDate>Fri, 03 Jun 2016 10:45:24 +0000</pubDate><guid>https://dwmkerr.com/testing-the-docker-for-mac-beta/</guid><description>&lt;p>I've finally had a chance to install the new Docker for Mac Beta and give it a whirl. In this article I'm going to talk a bit about how Docker works, the challenges of running Docker on a Mac or Windows and how the new Beta helps.&lt;/p>
&lt;p>&lt;em>Below: The welcome message for the new Docker for Mac app&lt;/em>&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-20-33-20.png" alt="Docker for Mac Icon">&lt;/p>
&lt;h1 id="so-what-is-docker-for-mac">So What is Docker for Mac?&lt;/h1>
&lt;p>If you don't know what Docker is, check out my article &lt;a href="http://www.dwmkerr.com/learn-docker-by-building-a-microservice/">Learn Docker by Building a Microservice&lt;/a> or the lovely &lt;a href="https://www.docker.com/what-docker">What is Docker&lt;/a> page from the docs.&lt;/p>
&lt;p>You may be aware that Docker creates processes in isolated containers using some key Linux technologies which allow for low-level isolation (such as &lt;strong>namespaces&lt;/strong> and &lt;strong>cgroups&lt;/strong>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>).&lt;/p>
&lt;p>This is described in detail on the &lt;a href="https://docs.docker.com/engine/understanding-docker/">Understand the Docker Architecture&lt;/a> page, but essentially means we can do this:&lt;/p>
&lt;p>&lt;img src="images/Docker-on-Ubuntu.png" alt="Docker Running on Ubuntu">&lt;/p>
&lt;p>Here I have:&lt;/p>
&lt;ol>
&lt;li>My machine, called &lt;code>Dave-Ubuntu&lt;/code>, which is running Ubuntu&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, with a local IP 192.168.0.1.&lt;/li>
&lt;li>The &lt;code>docker&lt;/code> executable, which I use to issue commands to&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;the Docker Host, which runs the docker daemon, which actually does the work of starting/stopping/building containers and so on.&lt;/li>
&lt;li>Some containers in the Docker Host - one is based on a MySQL image and has a DB, one is based on a Node.js image and is running an app.&lt;/li>
&lt;/ol>
&lt;p>The Docker host is actually my machine - I can connect using the loopback IP 127.0.0.1 (i.e. localhost). The containers also have the IP of the host. If I want to create and connect to a MySQL DB from my machine, I just type:&lt;/p>
&lt;pre>&lt;code>docker run -d -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 mysql
mysql -uroot -p123 -h127.0.0.1
&amp;gt; show databases;
&amp;gt; ...etc...
&amp;gt; exit;
&lt;/code>&lt;/pre>&lt;p>The container was created on my machine (in the host) and addressable using my loopback IP.&lt;/p>
&lt;h2 id="so-what">So What?&lt;/h2>
&lt;p>This is all great, but things get a little harder on a Mac or Windows. MacOS and the Windows OS don't have the same kernel level support for process isolation, control groups and so on, so the Docker Host cannot run on these operating systems. Instead, an extra layer and component is introduced:&lt;/p>
&lt;p>&lt;img src="images/Docker-on-MacOS.png" alt="Docker on OSX">&lt;/p>
&lt;p>What's new?&lt;/p>
&lt;ol>
&lt;li>Oracle VirtualBox has been installed to create and manage virtual machines.&lt;/li>
&lt;li>A virtual machine running Linux (called in this case a &amp;lsquo;docker machine&amp;rsquo;) called &amp;lsquo;default&amp;rsquo; has been created (by convention with the IP 192.168.99.100).&lt;/li>
&lt;li>This virtual machine runs Linux, so can perfectly happily act as the docker host.&lt;/li>
&lt;li>The docker host is still addressable as 127.0.0.1 - &lt;em>from the virtual machine&lt;/em> - from the outside world (i.e. my Mac) I have to use the virtual machine IP.&lt;/li>
&lt;/ol>
&lt;p>So this is how Docker works on a Mac or on Windows. Things are made seemless where possible, for example, all of the required components are installed when you install the &lt;a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox&lt;/a>.&lt;/p>
&lt;h2 id="so-what-1">So What?&lt;/h2>
&lt;p>Well the problem here is that one of the big benefits of using docker is that it allows us to create development environments which are much closer to production environments (at least from a software point of view).&lt;/p>
&lt;p>This kind of breaks down if we are doing development on a Mac or on Windows - because we have introduced an additional component which is simply not going to be present in our production environment. What are the problems?&lt;/p>
&lt;h3 id="1-localhost-vs-docker-machine-ip">1. Localhost vs docker-machine IP&lt;/h3>
&lt;p>Docker helps us be a lot more agnostic to our development box, but if I'm writing about how to interact with docker containers there's a problem:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8080:8080 my-app-server
curl http://localhost:8080/some-api-call
&lt;/code>&lt;/pre>&lt;p>This works on a Linux machine - it does not work on a Mac or Windows. On a Mac I need to run something like:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8080:8080 my-app-server
curl http://$(docker-machine ip default)/some-api-call
&lt;/code>&lt;/pre>&lt;p>This will &lt;em>not&lt;/em> work on Linux or Windows.&lt;/p>
&lt;p>Is this a big deal? Actually, kind of. What if I have an integration test which spins up some containers and runs calls against them - the test has to know about the execution environment. That's a pain. An alternative is to run tests in a container and link them with something like docker-compose, but this is not ideal.&lt;/p>
&lt;h3 id="2-terminal-hassle">2. Terminal Hassle&lt;/h3>
&lt;p>If I open a terminal and check to see what containers are running:&lt;/p>
&lt;pre>&lt;code>docker ps
&lt;/code>&lt;/pre>&lt;p>I'll see nothing. If I try to run a container:&lt;/p>
&lt;pre>&lt;code>docker run -it mongo
&lt;/code>&lt;/pre>&lt;p>I'll get an error - because my docker instance cannot communicate with the host. I need to use a specially set up terminal to tell it to connect to the VM.&lt;/p>
&lt;p>Again, the Docker Toolkit is set up to try and make things easy. If I install the toolkit I can run an app called Docker Quickstart Terminal:&lt;/p>
&lt;p>&lt;img src="images/Quickstart.jpg" alt="Docker Quickstart Terminal">&lt;/p>
&lt;p>And this will open a terminal where I &lt;em>can&lt;/em> use these commands. It will also start the docker machine VM if it has to. It's even smart enough to recognise if I have multiple terminal apps, such as iTerm, and ask which one I want to use.&lt;/p>
&lt;p>This problem is - this doesn't always work smoothly. Sometimes it will seem that the machine has started but will still not accept commands. Typically a restart is needed in this scenario.&lt;/p>
&lt;p>Also, it's an interruption. If you are running a terminal already and want to issue a quick command, it will fail, unless it was a terminal started with the Docker Quickstart app.&lt;/p>
&lt;h3 id="3-inotify---in-container-development">3. inotify - In Container Development&lt;/h3>
&lt;p>If you recognise the term, you probably know the issue. If not, a little explanation is necessary.&lt;/p>
&lt;p>As you get more and more familiar with Docker, you will probably find that you are spending more and more time testing, building then running your image in a container. In fact, you might be changing a single code file and using the container as the dev test server on your machine.&lt;/p>
&lt;p>This fast gets painful - the container image takes time to build and slows down the development cycle. There's a great technique in this scenario: &lt;strong>In Container Development&lt;/strong>.&lt;/p>
&lt;p>In container development is pretty much what it sounds like. Instead of editing your code on your machine, building an image and creating a container to debug, you simply create the container with what you need, &lt;strong>mount your code&lt;/strong> in to the container and run all of your development tooling from inside the container:&lt;/p>
&lt;p>&lt;img src="images/In-Container-Development.png" alt="Docker In Container Development">&lt;/p>
&lt;p>In this diagram, I have my code locally on my machine. I have built a container which runs &lt;code>nodemon&lt;/code>, watching a directory on the container. That directory is actually just a volume containing my code which I have mounted into my container.&lt;/p>
&lt;p>This is a really nice technique - I can still code locally, but as I make changes, &lt;code>nodemon&lt;/code> serves up my new content.&lt;/p>
&lt;p>This specific example applies to Node.js, but can be applied to many scenarios.&lt;/p>
&lt;p>The problem is that many watcher tools like &lt;code>nodemon&lt;/code> use a kernel subsystem called &lt;code>inotify&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> to get notifications when files change. But &lt;code>inotify&lt;/code> doesn't work on virtualbox&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>. This means that this technique isn't supported for Mac or Windows. There are however some tools which try and work around this with polling.&lt;/p>
&lt;p>So now we have another issue. The develop/test process might be nice on Linux, but for devs on other platforms the process is more clunky.&lt;/p>
&lt;h1 id="docker-for-mac-and-windows-to-the-rescue">Docker for Mac and Windows to the rescue&lt;/h1>
&lt;p>The issues I've mentioned so far are the big ones which cause me problems personally, I'm sure there are others (please comment and let me know!).&lt;/p>
&lt;p>This is why there was rather a lot of interest in the new Docker Beta - one of the big features is that the Docker Machine is going away. In theory, we can use Docker on a Mac or Windows and have the same experience as on Linux.&lt;/p>
&lt;h2 id="so-how">So how?&lt;/h2>
&lt;p>Virtualbox is gone. We still need a VM, but this VM is now a very lightweight Alpine Linux based image which runs on xhyve for MacOS and Hyper-V for Windows. All management of this VM is handled &lt;em>by the docker executable&lt;/em>.&lt;/p>
&lt;p>If these are not familiar terms, &lt;a href="https://en.wikipedia.org/wiki/Alpine_Linux">Alpine Linux&lt;/a> is an &lt;em>extreeeemely&lt;/em> lightweight Linux distro originally design to fit on a floppy disk (I think it clocks at around 5 MB now). &lt;a href="https://github.com/mist64/xhyve">xhyve&lt;/a> is an &lt;em>extremely&lt;/em> lightweight hypervisor which allows FreeBSD and some other distros on OSX. &lt;a href="https://en.wikipedia.org/wiki/Hyper-V">Hyper-V&lt;/a> is a native hypervisor for Windows Server which can run on Windows 8 onwards&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Using tools specifically designed for each platform (and with the help of both Apple and Microsoft), Docker have been able to make the experience much more seamless and smooth.&lt;/p>
&lt;h1 id="trying-it-out">Trying It Out&lt;/h1>
&lt;p>Removing the three pain points discussed and a clean and simple setup process is what I'm looking at today, and here's the results.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Piece of cake. Download the beta, install, run, enter the beta key and pop, there's the new docker:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-20-33-20-1.png" alt="Docker Welcome Message">&lt;/p>
&lt;p>The new status bar icon gives me a way to quickly see the status of the machine. Some of the commands hint at features to come, others offer the instructions needed. Settings are fairly basic, but I'm not sure what else you'd need:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-09-56.png" alt="Status Bar Screenshot 1">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-10-07.png" alt="Status Bar Screenshot 2">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-10-23.png" alt="Status Bar Screenshot 3">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-44-04.png" alt="Status Bar Screenshot 4">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-44-12.png" alt="Status Bar Screenshot 5">&lt;/p>
&lt;h3 id="1-localhost-vs-docker-machine-ip-1">1. Localhost vs docker-machine IP&lt;/h3>
&lt;p>Quickly bashing out the commands below shows that the virtual machine IP address issue is gone:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123 mysql
mysql -uroot -p123 -h127.0.0.1
&amp;gt; show databases;
&lt;/code>&lt;/pre>&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-23-37-39.png" alt="Localhost Screenshot">&lt;/p>
&lt;p>Great news!&lt;/p>
&lt;p>How this works under the hood is a mystery to me. If anyone knows, I'd be interested and would like to update this writeup!&lt;/p>
&lt;h3 id="2-terminal-hassle-1">2. Terminal Hassle&lt;/h3>
&lt;p>Quick and easy to test - running any terminal any way I like lets me access containers using the &lt;code>docker&lt;/code> executable - no magic needed:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-23-46-57.png" alt="Shells">&lt;/p>
&lt;p>Here's a screenshot of iTerm3, the Terminal App and the Terminal App running &lt;code>zsh&lt;/code>, all of which are happily communicating with the docker deamon through the &lt;code>docker&lt;/code> app.&lt;/p>
&lt;h3 id="3-in-container-development">3. In Container Development&lt;/h3>
&lt;p>I've not thrashed this one too hard, but gone for a quick sanity check. Throwing together probably my best ever node.js app&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;strong>main.js&lt;/strong>&lt;/p>
&lt;pre>&lt;code>setInterval(function() {
console.log(&amp;quot;Goodbye, cruel world!&amp;quot;);
}, 1000);
&lt;/code>&lt;/pre>&lt;p>and a simple dockerfile:&lt;/p>
&lt;p>&lt;strong>Dockerfile&lt;/strong>&lt;/p>
&lt;pre>&lt;code>FROM node:6
WORKDIR src/
ADD package.json .
RUN npm install
CMD npm start
&lt;/code>&lt;/pre>&lt;p>is enough to test this. I can build then run the container, mounting the working directory into the &lt;code>src&lt;/code> volume on the container:&lt;/p>
&lt;pre>&lt;code>docker build -t incontainerdev .
docker run -it -v `pwd`:/src incontainerdev]
&lt;/code>&lt;/pre>&lt;p>Immediately, I open a new window and change the source code and save (on my local Mac, not in the container). Voila:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-03-23.png" alt="Live Reloading">&lt;/p>
&lt;p>Live reloading works without a hitch! &lt;code>nodemon&lt;/code> picks up my changes, using &lt;code>inotify&lt;/code> from the VM (all through a lightweight userspace hypervisor).&lt;/p>
&lt;p>You know what is cool&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>? &lt;strong>I don't even need Node.js installed to build this Node app!&lt;/strong> The runtime is in the container, all of the execution happens in the container.&lt;/p>
&lt;h1 id="thats-a-wrap">That's a Wrap&lt;/h1>
&lt;p>That's it for my initial impressions. From this point onwards I'm going to be using Docker for Mac heavily as I'll do all of my work with it installed, so from time to time I may update this article with other observations.&lt;/p>
&lt;p>The key takeaway is: at the moment, Docker for Mac just &lt;em>works&lt;/em>. I'm using it in the same way I would on Ubuntu with no messing around. This is great, it seems like a simple thing but I'm guessing it was a lot of effort from the guys and girls at Docker, Microsoft and Apple.&lt;/p>
&lt;p>This is still a Beta, there'll be bugs and they'll be fixed. I can't wait for the Beta to go fully into the wild, and see what exciting things people can do with it.&lt;/p>
&lt;p>As usual, any comments or observations are welcome!&lt;/p>
&lt;p>&lt;strong>References&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Further Reading&lt;/strong>&lt;/p>
&lt;p>Namespaces: &lt;a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">http://man7.org/linux/man-pages/man7/namespaces.7.html&lt;/a>
cgroups: &lt;a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">http://man7.org/linux/man-pages/man7/cgroups.7.html&lt;/a>
Docker Execution Drivers: &lt;a href="https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/">https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/&lt;/a>
inotify: &lt;a href="http://man7.org/linux/man-pages/man7/inotify.7.html">http://man7.org/linux/man-pages/man7/inotify.7.html&lt;/a>
The challenges of in-container development on OSX: &lt;a href="http://hharnisc.github.io/2015/09/16/developing-inside-docker-containers-with-osx.html">http://hharnisc.github.io/2015/09/16/developing-inside-docker-containers-with-osx.html&lt;/a>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Read up on namespaces &lt;a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">here&lt;/a> and cgroups &lt;a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">here&lt;/a>. Docker can also use &lt;a href="https://en.wikipedia.org/wiki/LXC">LXC&lt;/a> but no longer &lt;em>has&lt;/em> to, there's a great write-up &lt;a href="https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/">here&lt;/a>. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Surprise! &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Read up on inotify &lt;a href="http://man7.org/linux/man-pages/man7/inotify.7.html">here&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>The issue will not be resolved: &lt;a href="https://www.virtualbox.org/ticket/10660">https://www.virtualbox.org/ticket/10660&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>I've not used the Docker for Windows Beta yet so have not got first hand experience of it. I've also not looked into compatibility, from memory Hyper-V isn't available on Home versions of Windows, but I might be wrong. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>Inspired by my first programming book, the excellent &lt;a href="http://www.amazon.com/C-Dummies-Dan-Gookin/dp/0764570684">C for Dummies&lt;/a> by Dan Gookin. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>For a given definition of cool. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Is it worth persevering with Golang?</title><link>https://dwmkerr.com/is-it-worth-persevering-with-golang/</link><pubDate>Wed, 01 Jun 2016 22:10:40 +0000</pubDate><guid>https://dwmkerr.com/is-it-worth-persevering-with-golang/</guid><description>&lt;p>I recently decided to try out &lt;a href="https://golang.org/">the Go Programming Language&lt;/a>, by building a little project called &lt;a href="http://www.github.com/dwmkerr/google-it">google-it&lt;/a> which let's me run a google search from a terminal:&lt;/p>
&lt;p>&lt;img src="images/google-it.gif" alt="google-it screenshot">&lt;/p>
&lt;p>The idea behind the project is simple - avoid jumping into a browser if you need to quickly look up something which you can find in the first line of a Google search result. The idea is to try and stay in the zone. For example, forgotten how to split panes in tmux?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">google-it &lt;span style="color:#e6db74">&amp;#34;split pane tmux&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Would probably show enough information to get going without leaving the terminal.&lt;/p>
&lt;p>Anyway, the project itself is not that useful&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> but it seemed like an ideal project to use as a learning exercise for a new language. After perhaps 10-20 hours of learning, coding and messing around, I'm wondering - is it worth persevering with Golang?&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> If you are learning too, check the &lt;a href="#tipsfornoobs">Tips for Noobs&lt;/a> section at the end of the article, great tips from members of the community!&lt;/p>
&lt;h2 id="why-go2">Why Go&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>?&lt;/h2>
&lt;p>The decision to choose Go for this learning exercise was fairly arbitrary. For the last few years I've been using mainly interpretted languages or languages which use a platform (.NET, Node.js, Java etc) and the idea of going back to something which compiles into in good ol&amp;rsquo; binaries seemed appealing. I'd also heard a lot of good things about Go in general, mostly relating to simplicity, ease of use and concurrency.&lt;/p>
&lt;h2 id="why-persevere">Why Persevere?&lt;/h2>
&lt;p>That's where I'm looking for guidance. I've collected some of my observations so far, and my overall experience with the language is uninspiring. Anyone who can comment on what makes Go great, or whether my ambivalence is justified will help me decide whether to build my next mess-around project in Go or move on to something else.&lt;/p>
&lt;h2 id="frustrations-so-far">Frustrations So Far&lt;/h2>
&lt;p>Before I upset anyone, this is all just the opinion of a total Go noob with maybe 15 hours of coding time in Go. But I've been developing using a few different languages and platforms for while.&lt;/p>
&lt;h3 id="folder-structure-is-way-too-opinionated">Folder structure is way too opinionated&lt;/h3>
&lt;p>Setup itself is easy, at least on unix or a Mac. But like many coders, I'm anal-retentive about how I like to organise things:&lt;/p>
&lt;pre>&lt;code>~
└───repositories
├───github.com
├───dwmkerr
├───project1
├───etc
├───organisation1
├───etc
├───bitbucket.com
├───etc
&lt;/code>&lt;/pre>&lt;p>This is how I structure my projects on all my machines, and it works for me.&lt;/p>
&lt;p>Go forces me to put all of my Go projects in the &lt;code>$GOPATH&lt;/code>, so now I have:&lt;/p>
&lt;pre>&lt;code>└───repositories
├───github.com
├───etc
├───go
├───src
├───github.com
├───dwmkerr
├───goproject1
&lt;/code>&lt;/pre>&lt;p>Which unnecessarily spreads out my projects. Other thoughts:&lt;/p>
&lt;ol>
&lt;li>My &lt;code>src&lt;/code> folder is increasingly cluttered with dependent modules, making it harder to find my own work.&lt;/li>
&lt;li>Even within the project folder, I have little flexibility. I'd like to have a &lt;code>src&lt;/code> folder to keep my code in, with just the &lt;code>README.md&lt;/code> at the root (leaving space for a &lt;code>docs&lt;/code> folder and others if necessary) - this cannot be done, so &lt;a href="https://github.com/dwmkerr/google-it">my root folder is cluttered&lt;/a>.&lt;/li>
&lt;li>Again, in the project folder itself, &lt;a href="https://www.reddit.com/r/golang/comments/2lq3it/is_there_a_way_to_arrange_go_code_into_multiple/">I cannot use sub-folders for code&lt;/a>. Some might argue if you need subfolders you have too much code in one project.&lt;/li>
&lt;/ol>
&lt;p>All in all it feels like there are a lot of constraints for structure and organisation, with little benefit.&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> Steve Francia has rightly pointed out that points 2 and 3 are actually wrong, a project can be simply a &lt;code>main.go&lt;/code> file in the root and a set of submodules, see &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2708416211">this comment&lt;/a> for details.&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> A very nice way to separate internal and external go modules is described in &lt;a href="https://www.reddit.com/r/golang/comments/4m5it3/is_it_worth_persevering_with_golang/d3ssyts">this reddit thread&lt;/a>.&lt;/p>
&lt;h3 id="the-idiomatic-approach-to-error-handling-is-flawed">The idiomatic approach to error handling is flawed&lt;/h3>
&lt;p>This is likely to prove contentious.&lt;/p>
&lt;p>My code contains sections like this:&lt;/p>
&lt;pre>&lt;code>func LoadSettings() (Settings, error) {
var s Settings
exists, err := exists(GetSettingsPath())
if err != nil {
return s, err
}
if !exists {
return CreateDefaultSettings(), nil
}
raw, err := ioutil.ReadFile(GetSettingsPath())
if err != nil {
return s, err
}
json.Unmarshal(raw, &amp;amp;s)
return s, err
}
&lt;/code>&lt;/pre>&lt;p>I see smells:&lt;/p>
&lt;ol>
&lt;li>The &lt;code>s&lt;/code> structure is created even though I may not need it.&lt;/li>
&lt;li>Even worse, it is &lt;strong>returned uninitialised&lt;/strong> in error conditions.&lt;/li>
&lt;li>Repetitive code for dealing with error conditions for calls.&lt;/li>
&lt;/ol>
&lt;p>Now I could avoid the first smell by returning a pointer to the structure, but that incures unnecessary complexity and heap allocations. Here I feel the language is forcing me to do something awful (return a structure I know is invalid) and expect the caller to deal with it.&lt;/p>
&lt;p>Even worse - the calling code now does this:&lt;/p>
&lt;pre>&lt;code>settings, err := LoadSettings()
if err != nil {
color.Red(&amp;quot;Error loading settings: &amp;quot;, err)
os.Exit(1)
}
&lt;/code>&lt;/pre>&lt;p>I've seen this in many places - nested calls passing the same error around, with little extra context, and eventually terminating.&lt;/p>
&lt;p>&lt;strong>This is what exceptions are for.&lt;/strong>&lt;/p>
&lt;p>Native exceptions in languages handle this for you, giving stack information and killing the process by default.&lt;/p>
&lt;p>The &amp;lsquo;pass the error on to the caller approach&amp;rsquo; may not be the right way to go, but the Go blog suggests exactly this:&lt;/p>
&lt;p>&lt;a href="https://blog.golang.org/error-handling-and-go">https://blog.golang.org/error-handling-and-go&lt;/a>&lt;/p>
&lt;p>And to me it stinks a bit. If this is the truly desired idomatic approach, then why not supported it natively by the language? Here's the same pseudo-code in F#:&lt;/p>
&lt;pre>&lt;code>let loadSettings =
let path = getSettingsPath()
match exists path with
| true -&amp;gt; path |&amp;gt; readFile |&amp;gt; readSettings
| _ -&amp;gt; createDefaultSettings
match loadSettings with
| Some settings -&amp;gt; // ..whatever
| None -&amp;gt; // ..deal with errors
&lt;/code>&lt;/pre>&lt;p>If &lt;code>loadSettings&lt;/code> can't return settings, it doesn't return settings. If the caller doesn't handle the &amp;lsquo;no settings&amp;rsquo; scenario explicitly, the compiler will complain that there's a case missing. In this case we have an approach which will warn the coder if they miss something.&lt;/p>
&lt;h3 id="inconsistent-syntax">Inconsistent Syntax&lt;/h3>
&lt;p>A small one, but when I'm defining a structure I can do this:&lt;/p>
&lt;pre>&lt;code>type Link struct {
Id string
Uri string
}
&lt;/code>&lt;/pre>&lt;p>but when I'm returning a structure, I need commas:&lt;/p>
&lt;pre>&lt;code>return Link{
Id: strconv.Itoa(linkNumber),
Uri: item.Link,
}
&lt;/code>&lt;/pre>&lt;p>I can see the benefit of &lt;strong>allowing&lt;/strong> a comma on the last line, to support quick refactoring, but &lt;strong>forcing&lt;/strong> it seems odd. Why commas for some constructs and not others&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>?&lt;/p>
&lt;p>Also, some more &amp;lsquo;unusual&amp;rsquo; syntax (depending on your background) is present, I assume to save space:&lt;/p>
&lt;pre>&lt;code>something := createAndAssign()
// rather than
var something SomeType
something = assign()
&lt;/code>&lt;/pre>&lt;p>But some space saving constructs such as ternary operators are missing:&lt;/p>
&lt;pre>&lt;code>// easy- c++, c#, java style
something := condition ? case1() : case2()
// easy- python style
something := case1() if condition else case2() // python
// hard - go style
var something SomeType
if condition {
something = case1()
} else {
something = case2()
}
&lt;/code>&lt;/pre>&lt;h3 id="difficult-debugging">Difficult Debugging&lt;/h3>
&lt;p>For C, C++, .NET, Java and many other languages, debugging is pretty straightforward. For Node.js, you can just use the excellent Chrome debugging tools. For Go, it seems like it's &lt;strong>much&lt;/strong> harder.&lt;/p>
&lt;p>In my limited time using the language, I avoided &lt;code>gdb&lt;/code> because it looked like a lot of work:&lt;/p>
&lt;p>&lt;a href="https://golang.org/doc/gdb">https://golang.org/doc/gdb&lt;/a>&lt;/p>
&lt;p>I did see some projects like &lt;a href="https://github.com/mailgun/godebug">godebug&lt;/a> which may ease the process but I was initially surprised by the effort needed to get into debugging.&lt;/p>
&lt;p>Commenter Sotirios Mantziaris &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2707804888">mentioned that delve provides a nice experience as a debugger&lt;/a>, so this would be worth exploring.&lt;/p>
&lt;h2 id="delights-so-far">Delights So Far&lt;/h2>
&lt;p>It's also worth talking about what I've liked or loved about Go so far.&lt;/p>
&lt;h3 id="simple-tooling">Simple Tooling&lt;/h3>
&lt;p>A project can be nothing more than a single file, go knows how to build and install it. Compare that to Java, where you have a lot of &amp;lsquo;project&amp;rsquo; related stuff - Gradle stuff, Ant stuff, Maven stuff, xml project files stuff and it feels much cleaner.&lt;/p>
&lt;p>The tooling is intuitive, fast and works well if you are happy living in a terminal.&lt;/p>
&lt;h3 id="fantastic-community">Fantastic Community&lt;/h3>
&lt;p>I've added this observation just recently, since writing the article I've had a &lt;strong>huge&lt;/strong> amount of positive input, describing how to improve my code, better understand Go idioms and where its sweet spots like.&lt;/p>
&lt;p>For someone new to a language, the community support is great and will really help people just getting into Go get advice and guidance.&lt;/p>
&lt;h3 id="testing-as-a-first-class-citizen">Testing as a First Class Citizen&lt;/h3>
&lt;p>Testing is built in, which is great. Knowing that you can run &lt;code>go test&lt;/code> on a project and have a standard way of executing tests is really quite nice. I love &lt;code>npm test&lt;/code> for Node.js projects as it has helped standardise testing as a practice (checkout &lt;code>npm install&lt;/code> then &lt;code>npm test&lt;/code>).&lt;/p>
&lt;p>However, I did have to rely on a library, &lt;a href="https://github.com/smartystreets/goconvey">goconvey&lt;/a>, to allow me to write tests in the more BBD structured style which I prefer:&lt;/p>
&lt;pre>&lt;code>func TestSpec(t *testing.T) {
Convey(&amp;quot;The param loader&amp;quot;, t, func() {
Convey(&amp;quot;Should handle no params&amp;quot;, func() {
params, err := ParseParams([]string{})
So(params.ShowHelp.Present, ShouldEqual, false)
So(params.Results.Present, ShouldEqual, false)
So(params.Open.Present, ShouldEqual, false)
So(err, ShouldEqual, nil)
})
&lt;/code>&lt;/pre>&lt;p>But that's a totally personal thing and I'm sure many others will prefer more &amp;lsquo;vanilla&amp;rsquo; tests.&lt;/p>
&lt;h3 id="great-documentation">Great Documentation&lt;/h3>
&lt;p>I've found everything I've needed so far on &lt;a href="https://golang.org/doc/">Go's own documentation&lt;/a>. The documentation is clean, accessible and seems fairly complete from my limited interactions with it.&lt;/p>
&lt;h3 id="delightful-vim-development-experience">Delightful Vim Development Experience&lt;/h3>
&lt;p>OK - this is not a language feature. But if you are a noob like me moving from this:&lt;/p>
&lt;p>&lt;img src="images/VimGoVanilla-1.jpg" alt="Vim vanilla">&lt;/p>
&lt;p>to this:&lt;/p>
&lt;p>&lt;img src="images/VimWithVimGo.jpg" alt="Vim with vim-go plugin screenshot">&lt;/p>
&lt;p>made a big difference. The excellent &lt;a href="https://github.com/fatih/vim-go">vim-go&lt;/a> plugin gives syntax highlighting and supports some really useful commands. As a learner, regularly running &lt;code>:GoLint&lt;/code> is really helping me write more &amp;lsquo;conventional&amp;rsquo; Go.&lt;/p>
&lt;h2 id="what-am-i-missing">What am I missing?&lt;/h2>
&lt;p>There are some things I know I haven't had a chance to look at which may really be demonstrating the best parts of Go:&lt;/p>
&lt;ol>
&lt;li>Concurrency patterns&lt;/li>
&lt;li>Performance&lt;/li>
&lt;li>Writing web servers&lt;/li>
&lt;li>Godoc&lt;/li>
&lt;li>Debugging with Delve&lt;/li>
&lt;/ol>
&lt;h2 id="should-i-continue">Should I continue?&lt;/h2>
&lt;p>At this stage I'm leaning towards moving on and trying something different, hoping that I'll come back to Go later. Should I persevere with Go for my next project, would Go enthusiasts suggest so and what sort of project hits the &amp;lsquo;sweet spot&amp;rsquo; where Go is a really effective choice?&lt;/p>
&lt;p>An interesting comment by a colleague was: &amp;ldquo;I would say the usual &amp;lsquo;does it change the way you think about programming?', if yes then persevere, if no then are you going to really leverage Go’s strengths (and find out weaknesses) in your project? If no then either change language or project.&amp;rdquo; was rather insightful.&lt;/p>
&lt;p>Any comments are welcome!&lt;/p>
&lt;h2 id="can-you-help-me-get-better">Can you help me get better?&lt;/h2>
&lt;p>Any pull requests to my project or comments which show where I've gone wrong and what I could do to improve my experience and code would be welcome at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/google-it">https://github.com/dwmkerr/google-it&lt;/a>&lt;/p>
&lt;p>Thanks!&lt;/p>
&lt;h2 id="tips-for-noobs">Tips for Noobs!&lt;/h2>
&lt;p>Since publishing this article I've collected some useful tips from people who've commented or got in touch.&lt;/p>
&lt;h4 id="use-gofmt-and-lint">Use gofmt and lint&lt;/h4>
&lt;p>The tool &lt;code>gofmt&lt;/code> will update your code to format it in a conventional go style. This'll help you keep your code consistent with others&amp;rsquo;. Using a linter will also help you stay conventional - if you are using &lt;a href="https://github.com/fatih/vim-go">vim-go&lt;/a> you can run it from vim with &lt;code>:GoLint&lt;/code>. Thanks @snoproblem!&lt;/p>
&lt;h4 id="understand-where-go-is-a-ferrari">Understand where Go is a Ferrari&lt;/h4>
&lt;p>This I am still working on, and it's certainly tricky for a noob. But commenter devdungeon pointed out that a project like mine is not a great use case for Go - Go excels at speed and concurrency. Projects where that is key are going to be more inspiring. See &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2708265044">this comment&lt;/a> for more.&lt;/p>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Mainly because you have to sign up for the Google Cloud Platform to get an API key so you can perform searches, as Google have deprecated the free and easy search API. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>&lt;a href="https://www.youtube.com/watch?v=DvijZuvEiQo">https://www.youtube.com/watch?v=DvijZuvEiQo&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>SnoProblem describes why in &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2707767852">this comment&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Quick Tip: Sending Newlines with cURL</title><link>https://dwmkerr.com/quick-tip-sending-newlines-with-curl/</link><pubDate>Tue, 03 May 2016 22:12:28 +0000</pubDate><guid>https://dwmkerr.com/quick-tip-sending-newlines-with-curl/</guid><description>&lt;p>Yikes, this took far too long to figure out!&lt;/p>
&lt;p>I have a service which takes plain text multi-line input and outputs an object for each line, something like this:&lt;/p>
&lt;p>&lt;strong>Input&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Line 1
Line 2
Line 3
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Output&lt;/strong>&lt;/p>
&lt;pre>&lt;code>[
{line: &amp;quot;Line 1&amp;quot;},
{line: &amp;quot;Line 2&amp;quot;},
{line: &amp;quot;Line 3&amp;quot;}
]
&lt;/code>&lt;/pre>&lt;p>There's a bit more to it than that, but that's the gist.&lt;/p>
&lt;p>I want to test my service with cURL, trying:&lt;/p>
&lt;pre>&lt;code>curl --data &amp;quot;Line 1\nLine 2\nLine 3&amp;quot; \
-H &amp;quot;Content-Type: text/plain&amp;quot; localhost:3000/parse
&lt;/code>&lt;/pre>&lt;p>This did not work. Nor did some alternatives. And I really didn't want to have to write the text to a file and load it in.&lt;/p>
&lt;p>Turns out there's a nice little shell trick to let you use escape characters C style, use &lt;code>$'some\ncontent'&lt;/code> to use ANSI C escaping. Now you can cURL with newlines!&lt;/p>
&lt;pre>&lt;code>curl --data $'Line 1\nLine 2\nLine 3' \
-H &amp;quot;Content-Type: text/plain&amp;quot; localhost:3000/parse
&lt;/code>&lt;/pre>&lt;p>Enjoy!&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/ANSI_002dC-Quoting.html">GNU Bash ANSI C Quoting&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://stackoverflow.com/questions/8467424/echo-newline-in-bash-prints-literal-n">Stack Overflow - Echo Newline Bash Prints \n&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://stackoverflow.com/questions/3872427/how-to-send-line-break-with-curl">Stack Overflow - How to send line break with cURL&lt;/a>&lt;/li>
&lt;/ol></description><category>CodeProject</category></item><item><title>Moving from React + Redux to Angular 2</title><link>https://dwmkerr.com/moving-from-react-redux-to-angular-2/</link><pubDate>Mon, 25 Apr 2016 09:45:00 +0000</pubDate><guid>https://dwmkerr.com/moving-from-react-redux-to-angular-2/</guid><description>&lt;p>I've just finished working on a very large project written in React and Redux. The whole team were new to both and we loved them.&lt;/p>
&lt;p>I'm going to share my experiences of experimenting in Angular 2 with you, from the point of view of someone who needs a pretty compelling reason to move away from my JSX and reducers.&lt;/p>
&lt;h1 id="the-journey-so-far">The Journey So Far&lt;/h1>
&lt;p>Let me highlight a few key moments in my UI development experiences, to give a bit of context to my ramblings.&lt;/p>
&lt;p>&lt;img src="images/Journey.jpg" alt="The Journey So Far">&lt;/p>
&lt;p>Reading about redux was a lightbulb moment for me - rather than a complex framework it's a simply library to help apply a few common sense functional programming principles - state is immutable, functions apply predictable transformations to data to produce new data.&lt;/p>
&lt;p>Learning React took a little bit of getting used to, but not too much, it was quite a bit more simple than Angular anyway.&lt;/p>
&lt;p>Long story short, simple React components and rigorous state management has so far resulted in the most manageable and well written very large scale UIs I've worked on so far - can Angular 2 compete with this?&lt;/p>
&lt;h1 id="first-step-with-angular-2---folder-structure-typescript-sublime-text">First Step with Angular 2 - Folder Structure, Typescript, Sublime Text&lt;/h1>
&lt;p>I checked out &lt;a href="https://angular.io/docs/ts/latest/quickstart.html">the pretty neat &amp;lsquo;Getting Started&amp;rsquo; guide from Angular&lt;/a> which promised to get me started in five minutes.&lt;/p>
&lt;p>It didn't take five minutes, there's a few gotchas, so I'm going to give a condensed guide here.&lt;/p>
&lt;h2 id="step-1-the-folder-structure">Step 1: The Folder Structure&lt;/h2>
&lt;p>The first few steps of the angular guide creates the following folder structure:&lt;/p>
&lt;pre>&lt;code>|-- angular2-starter
|-- tsconfig.json
|-- typings.json
|-- package.json
&lt;/code>&lt;/pre>&lt;p>This is the standard &lt;code>package.json&lt;/code> with some scripts ready to go. We also have &lt;code>tsconfig.json&lt;/code> to configure the typescript compiler and &lt;code>typings.json&lt;/code> to provide info to the compiler on where to get type information.&lt;/p>
&lt;p>You can check the code at this stage here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step1">https://github.com/dwmkerr/angular2-starter/tree/step1&lt;/a>&lt;/p>
&lt;p>&lt;img src="images/Step1.png" alt="Step 1 GitHub Screenshot">&lt;/p>
&lt;h2 id="node--npm-issues">Node &amp;amp; NPM Issues&lt;/h2>
&lt;p>At this stage the quickstart says you can run &lt;code>npm install&lt;/code> and all will be well:&lt;/p>
&lt;p>&lt;img src="images/npm-install.png" alt="npm install screenshot">&lt;/p>
&lt;pre>&lt;code>npm ERR! cb() never called!
&lt;/code>&lt;/pre>&lt;p>Not so good! For the record I'm using NPM 3.7.3 installed via homebrew. This looks like a bug in Beta 15 (see &lt;a href="https://github.com/angular/angular/issues/8053">Issue #8053&lt;/a>).&lt;/p>
&lt;p>I fixed this by using &lt;em>n&lt;/em> to upgrade my node version:&lt;/p>
&lt;pre>&lt;code>$ node -v
v5.9.0
$ npm install -g n # install 'n' node version manager
$ sudo n latest
installed : v5.11.0
$ node -v
v5.11.0
&lt;/code>&lt;/pre>&lt;p>Now it &lt;code>npm install&lt;/code> runs OK.&lt;/p>
&lt;h2 id="step-2-adding-components-and-configuring-sublime">Step 2: Adding Components and Configuring Sublime&lt;/h2>
&lt;p>The next steps of the walkthrough take us through adding an app component, a &lt;code>main.ts&lt;/code> file to bootstrap the application and an index file. You can check the updates here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step2">https://github.com/dwmkerr/angular2-starter/tree/step2&lt;/a>&lt;/p>
&lt;p>Essentially we now have:&lt;/p>
&lt;pre>&lt;code>|-- angular2-starter
|-- tsconfig.json
|-- typings.json
|-- package.json
|-- index.html
|-- styles.css
|-- app
|-- main.ts
|-- app.component.ts
&lt;/code>&lt;/pre>&lt;p>At this stage, running &lt;code>npm start&lt;/code> gives us a browerserified app to play with:&lt;/p>
&lt;p>&lt;img src="images/Step2.png" alt="Step 2 Screenshot">&lt;/p>
&lt;p>Clear enough so far, although the code in Sublime is not looking so pretty:&lt;/p>
&lt;p>&lt;img src="images/Step2Sublime.png" alt="Step 2 Sublime Text Screenshot">&lt;/p>
&lt;p>Quickly installing the &lt;a href="https://github.com/Microsoft/TypeScript-Sublime-Plugin">TypeScript plugin&lt;/a> from Microsoft[^n] seems to do the trick:&lt;/p>
&lt;p>&lt;img src="images/Step2SublimeFormatted.png" alt="Step 2 Sublime Text with TypeScript plugin">&lt;/p>
&lt;p>If you need more details, here's a gist with the full setup for Sublime 3, assuming you've got nothing installed.&lt;/p>
&lt;p>&lt;a href="https://gist.github.com/dwmkerr/04fa8b8c15d049d0381e7798a79bcc45">https://gist.github.com/dwmkerr/04fa8b8c15d049d0381e7798a79bcc45&lt;/a>&lt;/p>
&lt;p>At this stage the app will run, we can see the basics of the Angular 2 syntax and start experimenting.&lt;/p>
&lt;h2 id="step-3-adding-some-components">Step 3: Adding some components&lt;/h2>
&lt;p>At this stage the quick started guide starts going into more detail, guiding you through the process of creating multiple components. I decided to go off on my own here, with the rough plan of being able to write a set of goals for the day and turn it into a check-list[^n].&lt;/p>
&lt;p>Within not much time I had the some basic components, input and output, bindings and so on. Some screenshots:&lt;/p>
&lt;p>&lt;img src="images/Goals-Screenshot-1.png" alt="Goals Screenshot 1">&lt;/p>
&lt;p>&lt;img src="images/Goals-Screenshot-2-1.png" alt="Goals Screenshot 2">&lt;/p>
&lt;p>You can take a look at the code at this stage by checking out the &amp;lsquo;step3&amp;rsquo; branch:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step3">github.com/dwmkerr/angular2-starter/tree/step3&lt;/a>&lt;/p>
&lt;h1 id="thoughts-so-far">Thoughts so far&lt;/h1>
&lt;p>For now, that's all I've got time for. I've had a chance to get a feel for Angular 2, I'm going to come back to this in a few weeks and integrate Redux, maybe swap out System.JS for Webpack and do some experimenting.&lt;/p>
&lt;p>Opinions[^n] so far?&lt;/p>
&lt;h3 id="not-sold-on-typescript">Not Sold on TypeScript&lt;/h3>
&lt;p>I've used TypeScript in my mess around, rather than plain &amp;lsquo;ol JavaScript, to keep the experience authentic to the angular team's goals of using TypeScript to help.&lt;/p>
&lt;p>So far, I'm not seeing an enormous benefit. Some of the extra information available to auto-completion in nice, but this is a tooling thing.&lt;/p>
&lt;p>JavaScript is not a static language, the TypeScript annotations I find slowing me down a little.&lt;/p>
&lt;blockquote>
&lt;p>There's so much extra domain specific &lt;em>stuff&lt;/em> in Angular 2 that people might be lost without it. But if your stuff is so complex you need to adapt the base language, is it &lt;strong>too&lt;/strong> complex?&lt;/p>
&lt;/blockquote>
&lt;h3 id="explicit-component-surface-areas-are-a-nice-idea">Explicit Component Surface Areas are a Nice Idea&lt;/h3>
&lt;p>When defining a component, you specify explicitly what comes &lt;em>in&lt;/em> (data) and what goes &lt;em>out&lt;/em> (events).&lt;/p>
&lt;p>This means that the surface area of a component (i.e. the part you touch if you interact with it programmatically) is well defined. This is a good thing.&lt;/p>
&lt;p>However, this is all handled with some pretty framework-specific stuff[^n]:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// e.g.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">GoalsBoxComponent&lt;/span> {
&lt;span style="color:#75715e">// Event we fire when the goals change.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">@&lt;/span>&lt;span style="color:#a6e22e">Output&lt;/span>() &lt;span style="color:#a6e22e">goalsChanged&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">EventEmitter&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Goal&lt;/span>[]&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">EventEmitter&lt;/span>();
}
&lt;span style="color:#75715e">// e.g.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">GoalListComponent&lt;/span> {
&lt;span style="color:#75715e">// Input is a set of goals to render.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">@&lt;/span>&lt;span style="color:#a6e22e">Input&lt;/span>() &lt;span style="color:#a6e22e">goals&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">Goal&lt;/span>[] &lt;span style="color:#f92672">=&lt;/span> [];
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In a nutshell&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Explicit component surface area is a cool idea.&lt;/p>
&lt;/blockquote>
&lt;p>React does this too with the optional &lt;code>propTypes&lt;/code>, but it is not enforced. &lt;em>However&lt;/em>, how this is done in Angular has already gone through a few radical changes with some &lt;a href="https://github.com/angular/angular/pull/4435#issuecomment-144789359">lively debate&lt;/a>.&lt;/p>
&lt;h3 id="not-ready-for-production-yet">Not ready for production&amp;hellip; yet&lt;/h3>
&lt;p>There's no standardised, documented way to test a component - nuff said. But things are evolving quickly.&lt;/p>
&lt;h3 id="framework-fatigue">Framework Fatigue&lt;/h3>
&lt;p>Comparing React to Angular is unfair, one is a view library, one is a framework. But it's worth pointing out this is a pretty complex framework. There's a &lt;strong>lot&lt;/strong> of very domain specific stuff. See this documentation for an example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">li&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">ngFor&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;#hero of heroes&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>From &lt;a href="https://angular.io/docs/ts/latest/tutorial/toh-pt2.html">the documentation&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>The (*) prefix to ngFor indicates that the &lt;code>&amp;lt;li&amp;gt;&lt;/code> element and its children constitute a master template.&lt;/p>
&lt;p>&amp;hellip;&lt;/p>
&lt;p>The # prefix before &amp;ldquo;hero&amp;rdquo; identifies the hero as a local template variable. We can reference this variable within the template to access a hero’s properties.&lt;/p>
&lt;/blockquote>
&lt;p>You'll get used to it (if you have to), but I think it's harder to &lt;em>reason&lt;/em> about than:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">render&lt;/span> () {
&lt;span style="color:#66d9ef">return&lt;/span> (
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">div&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
{&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">props&lt;/span>.&lt;span style="color:#a6e22e">goals&lt;/span>.&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">goal&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">li&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>{&lt;span style="color:#a6e22e">goal&lt;/span>.&lt;span style="color:#a6e22e">title&lt;/span>}&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">l&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">d&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">v&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">)&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>OK fair enough, JSX is very specific, but the &lt;strong>logic&lt;/strong> (mapping an iterable) is JavaScript.&lt;/p>
&lt;h1 id="wrapping-up">Wrapping Up&lt;/h1>
&lt;p>That's it, for now. Next steps are to experiment more, see if it will play nice with Redux and share the next set of opinions.&lt;/p>
&lt;p>I'd love to hear what you think, so drop your comments below!&lt;/p>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p></description><category>CodeProject</category></item><item><title>Learn Docker by building a Microservice</title><link>https://dwmkerr.com/learn-docker-by-building-a-microservice/</link><pubDate>Tue, 19 Apr 2016 08:54:39 +0000</pubDate><guid>https://dwmkerr.com/learn-docker-by-building-a-microservice/</guid><description>&lt;p>If you are looking to get your hands dirty and learn all about &lt;a href="https://docker.com">Docker&lt;/a>, then look no further!&lt;/p>
&lt;p>In this article I'm going to show you how Docker works, what all the fuss is about, and how Docker can help with a basic development task - building a microservice.&lt;/p>
&lt;p>We'll use a simple Node.js service with a MySQL backend as an example, going from code running locally to containers running a microservice and database.&lt;/p>
&lt;p align="center">
&lt;img src="images/Article.png" />
&lt;/p>
&lt;p>Once you've read the article, you can find the source code here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h2 id="what-is-docker">What is Docker?&lt;/h2>
&lt;p>At its heart, Docker is software which lets you create an &lt;em>image&lt;/em> (which is a lot like a template for a virtual machine) and then run instances of that image in a &lt;em>container&lt;/em>.&lt;/p>
&lt;p>Docker maintains a vast repository of images, called the &lt;a href="https://hub.docker.com">Docker Hub&lt;/a> which you can use as starting points or as free storage for your own images. You can install Docker, choose an image you'd like to use, then run an instance of it in a container.&lt;/p>
&lt;p>We're going to build images, create containers from images and more in this article.&lt;/p>
&lt;h3 id="install-docker">Install Docker&lt;/h3>
&lt;p>To follow along and use this article, you'll need Docker.&lt;/p>
&lt;p>Check the installation guide for your platform, &lt;a href="https://docs.docker.com/engine/installation/">docs.docker.com/engine/installation&lt;/a>.&lt;/p>
&lt;p>If you are on Mac or Windows, consider using a Virtual Machine. I use Parallels on Mac OS X to run an Ubuntu machine for most development activities. Being able to take snapshots, break things and then revert back is very handy when experimenting.&lt;/p>
&lt;h3 id="try-it-out">Try It Out&lt;/h3>
&lt;p>Enter this command:&lt;/p>
&lt;pre>&lt;code>docker run -it ubuntu
&lt;/code>&lt;/pre>&lt;p>After a bit of spinning, you'll see a prompt like this:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/#
&lt;/code>&lt;/pre>&lt;p>Try out a few commands and then exit the container:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/# lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 14.04.4 LTS
Release: 14.04
Codename: trusty
root@719059da250d:/# exit
&lt;/code>&lt;/pre>&lt;p>This doesn't look like much, but a lot has happened!&lt;/p>
&lt;p>What you are seeing is the bash shell of an &lt;em>isolated&lt;/em> container running Ubuntu, on your machine. It's yours to place with - you can install things on it, run software, whatever you want.&lt;/p>
&lt;p>Here's a diagram and breakdown of what just happened (the digram is from the &lt;a href="https://docs.docker.com/v1.8/introduction/understanding-docker/">&amp;lsquo;Understanding the Architecture&amp;rsquo; Docker Documentation&lt;/a>, which is great):&lt;/p>
&lt;p>&lt;img src="images/Flow.png" alt="Docker Run Flow">&lt;/p>
&lt;ol>
&lt;li>We issue a docker command:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;code>docker&lt;/code>: run the docker client&lt;/li>
&lt;li>&lt;code>run&lt;/code>: the command to run a new container&lt;/li>
&lt;li>&lt;code>-it&lt;/code>: option to give the container an interactive terminal&lt;/li>
&lt;li>&lt;code>ubuntu&lt;/code>: the image to base the container on&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>The docker service running on the host (our machine) checks to see if we have a copy of the requested image locally- which there isn't.&lt;/li>
&lt;li>The docker service checks the public registry (the docker hub) to see if there's an image named &lt;code>ubuntu&lt;/code> available- which there is.&lt;/li>
&lt;li>The docker service downloads the image and stores it in its local cache of images (ready for next time).&lt;/li>
&lt;li>The docker service creates a new container, based on the &lt;code>ubuntu&lt;/code> image.&lt;/li>
&lt;/ol>
&lt;p>Try any of these:&lt;/p>
&lt;pre>&lt;code>docker run -it haskell
docker run -it java
docker run -it python
&lt;/code>&lt;/pre>&lt;p>We're not going to use &lt;a href="https://xkcd.com/1312/">Haskell&lt;/a> today, but you can see, running an environment is very easy.&lt;/p>
&lt;p>It's a snap to build images of our own, with our apps or services on them, databases, whatever we need. We can then run them on any machine with Docker installed - and the image will run in the same, predictable way. We can build our software &lt;em>and the environment it runs on&lt;/em> as code and deploy easily.&lt;/p>
&lt;p>Let's look into a simple microservice as an example.&lt;/p>
&lt;h2 id="the-brief">The Brief&lt;/h2>
&lt;p>We're going to build a microservice which lets us manage a directory of email addresses to phone numbers, using Node.js and MySQL.&lt;/p>
&lt;h2 id="getting-started">Getting Started&lt;/h2>
&lt;p>For doing local development we'll need to install MySQL and create a test database for us to&amp;hellip;&lt;/p>
&lt;p>&amp;hellip;nope.&lt;/p>
&lt;p>Creating a local database and running scripts on it is an easy start, but can get messy. Lots of uncontrolled stuff going on. It might work, we could even control it with some shell scripts checked in to our repo, but what if other developers already have MySQL installed? What if they have a database already with the creative name &amp;lsquo;users&amp;rsquo; which we want to create?&lt;/p>
&lt;h3 id="step-1-creating-a-test-database-server---in-docker">Step 1: Creating a Test Database Server - in Docker&lt;/h3>
&lt;p>This is a great Docker use case. We might not want to run our production database in Docker (perhaps we'll just use Amazon RDS for example), but we can spin up a clean MySQL database in no time as a Docker container for development - leaving our development machine clean and keeping everything we do controlled and repeatable.&lt;/p>
&lt;p>Run the following command:&lt;/p>
&lt;pre>&lt;code>docker run --name db -d -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 mysql:latest
&lt;/code>&lt;/pre>&lt;p>This starts a MySQL instance running, allowing access through port 3306 using the root password 123.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> tells the engine we want to run an image (the image comes at the end, &lt;a href="https://hub.docker.com/_/mysql/">mysql:vlatest&lt;/a>&lt;/li>
&lt;li>&lt;code>--name db&lt;/code> names this container &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-d&lt;/code> (or &lt;code>--detach&lt;/code>) detach - i.e. run the container in the background.&lt;/li>
&lt;li>&lt;code>-e MYSQL_ROOT_PASSWORD=123&lt;/code> (or &lt;code>--env&lt;/code>) environment variables - tells docker we want to provide an environment variable. The variable following it is what the MySQL image checks for setting the default root password.&lt;/li>
&lt;li>&lt;code>-p 3306:3306&lt;/code> (or &lt;code>--publish&lt;/code> tells the engine that we want to map the port 3306 from inside the container to out port 3306.&lt;/li>
&lt;/ol>
&lt;p>The last part is really important - even though that's the MySQL default port, if we don't tell docker explicitly we want to map it, it will block access through that port (because containers are isolated until you tell them you want access).&lt;/p>
&lt;p>The return value of this function is the &lt;em>container id&lt;/em>, a reference to the container which you can use to stop it, restart it, issue commands on it and so on. Let's see which containers are running:&lt;/p>
&lt;pre>&lt;code>$ docker ps
CONTAINER ID IMAGE ... NAMES
36e68b966fd0 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>The key information is the container ID, image and name. Let's connect to this image and see what's there:&lt;/p>
&lt;pre>&lt;code>$ docker exec -it db /bin/bash
root@36e68b966fd0:/# mysql -uroot -p123
mysql&amp;gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
+--------------------+
1 rows in set (0.01 sec)
mysql&amp;gt; exit
Bye
root@36e68b966fd0:/# exit
&lt;/code>&lt;/pre>&lt;p>This is pretty clever too:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker exec -it db&lt;/code> tells docker we want to execute a command on the container named &lt;code>db&lt;/code> (we could also use the id, or just the first few letters of the id). &lt;code>-it&lt;/code> ensures we have an interactive terminal.&lt;/li>
&lt;li>&lt;code>mysql -uroot -p123&lt;/code> the command we actually run as a process in the container, which in this case is just the mysql client.&lt;/li>
&lt;/ol>
&lt;p>We can create databases, tables, users, whatever we need.&lt;/p>
&lt;h3 id="wrapping-up-the-test-database">Wrapping up the Test Database&lt;/h3>
&lt;p>Running MySQL inside a container has already introduced a few Docker tricks, but let's pause here and move onto the service. For now, we'll have create a &lt;code>test-database&lt;/code> folder with a script to start the database, stop the database and setup test data:&lt;/p>
&lt;pre>&lt;code>test-database\setup.sql
test-database\start.sh
test-database\stop.sh
&lt;/code>&lt;/pre>&lt;p>Start is simple:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Run the MySQL container, with a database named &amp;#39;users&amp;#39; and credentials&lt;/span>
&lt;span style="color:#75715e"># for a users-service user which can access it.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Starting DB...&amp;#34;&lt;/span>
docker run --name db -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_ROOT_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_DATABASE&lt;span style="color:#f92672">=&lt;/span>users -e MYSQL_USER&lt;span style="color:#f92672">=&lt;/span>users_service -e MYSQL_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -p 3306:3306 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> mysql:latest
&lt;span style="color:#75715e"># Wait for the database service to start up.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Waiting for DB to start up...&amp;#34;&lt;/span>
docker exec db mysqladmin --silent --wait&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">30&lt;/span> -uusers_service -p123 ping &lt;span style="color:#f92672">||&lt;/span> exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Run the setup script.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Setting up initial data...&amp;#34;&lt;/span>
docker exec -i db mysql -uusers_service -p123 users &amp;lt; setup.sql
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This script runs the database image in a detached container (i.e. in the background), with a user set up to access a &lt;code>users&lt;/code> database, then waits for the database server to start up, then runs a &lt;code>setup.sql&lt;/code> script to set initial data.&lt;/p>
&lt;p>&lt;code>setup.sql&lt;/code> is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">
&lt;span style="color:#66d9ef">create&lt;/span> &lt;span style="color:#66d9ef">table&lt;/span> directory (user_id INT &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> AUTO_INCREMENT &lt;span style="color:#66d9ef">PRIMARY&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span>, email TEXT, phone_number TEXT);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">homer@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1111&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">marge@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1112&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">maggie@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1113&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">lisa@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1114&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">bart@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1115&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>stop.sh&lt;/code> script will stop the container and remove it (containers are left around by docker by default so that they can be restared quickly, we don't really need that feature for this example):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Stop the db and remove the container.&lt;/span>
docker stop db &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm db
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We're going to make this even more slick later on, simplifying this further. Check the code at this stage by looking at the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step1">step1&lt;/a> branch of the repo.&lt;/p>
&lt;h3 id="step-2-creating-a-microservice-in-nodejs">Step 2: Creating a Microservice in Node.js&lt;/h3>
&lt;p>This article is really focused on learning Docker, so I'm not going to spend ages on the Node.js microservice. Instead, I'll highlight the areas and takeaways.&lt;/p>
&lt;pre>&lt;code>test-database/ # contains the code seen in Step 1
users-service/ # root of our node.js microservice
- package.json # dependencies, metadata
- index.js # main entrypoint of the app
- api/ # our apis and api tests
- config/ # config for the app
- repository/ # abstraction over our db
- server/ # server setup code
&lt;/code>&lt;/pre>&lt;p>Let's take this apart bit by bit. The first section to look at is &lt;code>repository&lt;/code>. It can be useful to wrap your database access in some kind of class or abstraction, to allow to mock it for testing purposes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// repository.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Exposes a single function - &amp;#39;connect&amp;#39;, which returns
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// a connected repository. Call &amp;#39;disconnect&amp;#39; on this object when you&amp;#39;re done.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">mysql&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;mysql&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Class which holds an open connection to a repository
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// and exposes some simple functions for accessing data.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span> {
&lt;span style="color:#a6e22e">constructor&lt;/span>(&lt;span style="color:#a6e22e">connection&lt;/span>) {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">connection&lt;/span>;
}
&lt;span style="color:#a6e22e">getUsers&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the users: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#a6e22e">resolve&lt;/span>((&lt;span style="color:#a6e22e">results&lt;/span> &lt;span style="color:#f92672">||&lt;/span> []).&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
});
});
}
&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Fetch the customer.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory WHERE email = ?&amp;#39;&lt;/span>, [&lt;span style="color:#a6e22e">email&lt;/span>], (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the user: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">results&lt;/span>.&lt;span style="color:#a6e22e">length&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">undefined&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">resolve&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
});
});
}
&lt;span style="color:#a6e22e">disconnect&lt;/span>() {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">end&lt;/span>();
}
}
&lt;span style="color:#75715e">// One and only exported function, returns a connected repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">connectionSettings&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A host must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A user must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A password must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A port must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span>(&lt;span style="color:#a6e22e">mysql&lt;/span>.&lt;span style="color:#a6e22e">createConnection&lt;/span>(&lt;span style="color:#a6e22e">connectionSettings&lt;/span>)));
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's probably a lot of better ways to do this! But basically we can create a &lt;code>Repository&lt;/code> object like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;127.0.0.1&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users_service&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;123&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>);
});
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;homer@thesimpsons.com&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">user&lt;/span>);
})
&lt;span style="color:#75715e">// ...when you are done...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's also a set of unit tests in the &lt;code>repository/repository.spec.js&lt;/code> file. Now that we've got a repo, we can create a server. This is &lt;code>server/server.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// server.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;express&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">morgan&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;morgan&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Make sure we have a repository and port provided.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a connected repository.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a port.&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Create the app, add some logging.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span>();
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">use&lt;/span>(&lt;span style="color:#a6e22e">morgan&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;dev&amp;#39;&lt;/span>));
&lt;span style="color:#75715e">// Add the APIs to the app.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;../api/users&amp;#39;&lt;/span>)(&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>);
&lt;span style="color:#75715e">// Start the app, creating a running server which we return.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">listen&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">server&lt;/span>);
});
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This module exposes a &lt;code>start&lt;/code> function, which we can use like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server);
&lt;/span>&lt;span style="color:#e6db74">server.start({port: 8080, repo: repository}).then((svr) =&amp;gt; {
&lt;/span>&lt;span style="color:#e6db74"> // we&amp;#39;&lt;/span>&lt;span style="color:#a6e22e">ve&lt;/span> &lt;span style="color:#a6e22e">got&lt;/span> &lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#a6e22e">running&lt;/span> &lt;span style="color:#a6e22e">http&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">:&lt;/span>)
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice that &lt;code>server.js&lt;/code> uses &lt;code>api/users/js&lt;/code>? Here it is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// users.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Defines the users api. Add to a server by calling:
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// require(&amp;#39;./users&amp;#39;)
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#75715e">// Only export - adds the API to the app with the given options.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/users&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>, &lt;span style="color:#a6e22e">next&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>.&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; { &lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Get the email.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">email&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;When searching for a user, the email must be specified, e.g: &amp;#39;/search?email=homer@thesimpsons.com&amp;#39;.&amp;#34;&lt;/span>);
}
&lt;span style="color:#75715e">// Get the user from the repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">user&lt;/span>) {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">404&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;User not found.&amp;#39;&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Both of these files have unit tests adjacent to the source.&lt;/p>
&lt;p>We'll need config. Rather than using a specialised library, a simple file will do the trick - &lt;code>config/config.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can &lt;code>require&lt;/code> config as needed. Currently, most config is hard coded, but as you can see from &lt;code>port&lt;/code> it's easy to add environment variables as an option.&lt;/p>
&lt;p>Final step - stringing it together with an &lt;code>index.js&lt;/code> file which composes everything:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// index.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Entrypoint to the application. Opens a repository to the MySQL
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// server and starts the server.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">repository&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./repository/repository&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./config/config&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Lots of verbose logging when we&amp;#39;re starting up...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;--- Customer Service---&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to customer repository...&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Log unhandled exceptions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;uncaughtException&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Exception&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;unhandledRejection&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">promise&lt;/span>){
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Rejection&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">database&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connected. Starting server...&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span>({
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>,
&lt;span style="color:#a6e22e">repository&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>
});
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">app&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Server started successfully, running on port &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;close&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a little error handling and beyond that we're just loading config, creating a repo and starting our server.&lt;/p>
&lt;p>That's the microservice. It allows us to get all users, or search a user:&lt;/p>
&lt;pre>&lt;code>HTTP GET /users # gets all users
HTTP GET /search?email=homer@thesimpons.com # searches by email
&lt;/code>&lt;/pre>&lt;p>If you checkout the code, you'll see that there's a few commands available for you:&lt;/p>
&lt;pre>&lt;code>cd ./users-service
npm install # setup everything
npm test # unit test - no need for a test database running
npm start # run the server - you must have a test database running
npm run debug # run the server in debug mode, opens a browser with the inspector
npm run lint # check to see if the code is beautiful
&lt;/code>&lt;/pre>&lt;p>Asides from the code you've seen we have:&lt;/p>
&lt;ol>
&lt;li>Node Inspector for debugging&lt;/li>
&lt;li>Mocha/shoud/supertest for unit tests&lt;/li>
&lt;li>ESLint for linting&lt;/li>
&lt;/ol>
&lt;p>That's it!&lt;/p>
&lt;p>Run the test database with:&lt;/p>
&lt;pre>&lt;code>cd test-database/
./start.sh
&lt;/code>&lt;/pre>&lt;p>Then the service with:&lt;/p>
&lt;pre>&lt;code>cd ../users-service/
npm start
&lt;/code>&lt;/pre>&lt;p>You can point your browser to &lt;a href="http://localhost:8123/users">localhost:8123/users&lt;/a> and see it in action. If you are using Docker Machine (i.e. you're on Mac or Windows) then &lt;code>localhost&lt;/code> won't work, you need the IP of the docker machine instead. You can use &lt;code>docker-machine ip&lt;/code> to get it.&lt;/p>
&lt;p>We've whipped through building the service quickly. If you'd like to see this code before we continue, check the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step2">step2&lt;/a> branch.&lt;/p>
&lt;h1 id="step-3-dockerising-our-microservice">Step 3: Dockerising our Microservice&lt;/h1>
&lt;p>OK now it gets fun!&lt;/p>
&lt;p>So we have a microservice which we can run on a dev box, as long as it has a compatible version of Node.js installed. What we'd like to do is set up our service so that we can create a &lt;em>Docker Image&lt;/em> from it, allowing us to deploy our service anywhere which supports docker.&lt;/p>
&lt;p>The way we do this is create a &lt;em>Dockerfile&lt;/em>. A Dockerfile is a recipe that tells the Docker engine how to build your image. We'll create a simple Dockerfile in our &lt;code>users-service&lt;/code> directory and start to explore how we can adapt it to our needs.&lt;/p>
&lt;h2 id="creating-the-dockerfile">Creating the Dockerfile&lt;/h2>
&lt;p>Create a new text file called &lt;code>Dockerfile&lt;/code> at &lt;code>users-service/&lt;/code> with the content below:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Run node
CMD [&amp;quot;node&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>Now run the commands below to build the image and run the a container from it:&lt;/p>
&lt;pre>&lt;code>docker build -t node4 . # Builds a new image
docker run -it node4 # Run a container with this image, interactive
&lt;/code>&lt;/pre>&lt;p>Let's look at the build command first.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker build&lt;/code> tell the engine we want to create a new image.&lt;/li>
&lt;li>&lt;code>-t node4&lt;/code> tag this image with the tag &lt;code>node4&lt;/code>. We can refer to this image by tag from now on.&lt;/li>
&lt;li>&lt;code>.&lt;/code> use the current directory to find the &lt;code>Dockerfile&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>After some console output you'll see we have a new image created. You can see all images on your system with &lt;code>docker images&lt;/code>. The next command should be fairly familiar from what we've done so far:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> run a new container from an image.&lt;/li>
&lt;li>&lt;code>-it&lt;/code> use an interactive terminal.&lt;/li>
&lt;li>&lt;code>node4&lt;/code> the tag of the image we want to use in the container.&lt;/li>
&lt;/ol>
&lt;p>When we run this image, we get a node repl, check the current version like so:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">version&lt;/span>
&lt;span style="color:#e6db74">&amp;#39;v4.4.0&amp;#39;&lt;/span>
&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">exit&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is potentially different to the node version on your current machine.&lt;/p>
&lt;h2 id="examining-the-dockerfile">Examining the Dockerfile&lt;/h2>
&lt;p>Looking at the dockerfile we can see quite easily what is going on:&lt;/p>
&lt;ol>
&lt;li>&lt;code>FROM node:4&lt;/code> the first thing we specify in a Dockerfile is the base image. A quick google finds the &lt;a href="https://hub.docker.com/_/node/">node organisation page on the docker hub&lt;/a> showing all of the available images. This is essentially bare bones ubuntu with node installed.&lt;/li>
&lt;li>&lt;code>CMD [&amp;quot;node&amp;quot;]&lt;/code> the &lt;code>CMD&lt;/code> command tells docker that this image should run the node executable. When the executable terminates, the container shuts down.&lt;/li>
&lt;/ol>
&lt;p>With the addition of a few more commands, we can update our Dockerfile so that it runs our service:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Add everything in the current directory to our image, in the 'app' folder.
ADD . /app
# Install dependencies
RUN cd /app; \
npm install --production
# Expose our server port.
EXPOSE 8123
# Run our app.
CMD [&amp;quot;node&amp;quot;, &amp;quot;/app/index.js&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>The only addition here is that we use the &lt;code>ADD&lt;/code> command to copy everything&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> in the current directory to a folder in the container called &lt;code>app/&lt;/code> . We then use &lt;code>RUN&lt;/code> to run a command in the image, which installs our modules. Finally, we &lt;code>EXPOSE&lt;/code> the server port, telling docker we intend to support inbound connections on &lt;code>8123&lt;/code>, then run our server code.&lt;/p>
&lt;p>Ensure the test-database service is running, then build and run the image again:&lt;/p>
&lt;pre>&lt;code>docker build -t users-service .
docker run -it -p 8123:8123 users-service
&lt;/code>&lt;/pre>&lt;p>If you navigate to &lt;code>localhost:8123/users&lt;/code> in a browser you should see an error, checking the console shows our container is reporting some issues:&lt;/p>
&lt;pre>&lt;code>--- Customer Service---
Connecting to customer repository...
Connected. Starting server...
Server started successfully, running on port 8123.
GET /users 500 23.958 ms - 582
Error: An error occured getting the users: Error: connect ECONNREFUSED 127.0.0.1:3306
at Query._callback (/app/repository/repository.js:21:25)
at Query.Sequence.end (/app/node_modules/mysql/lib/protocol/sequences/Sequence.js:96:24)
at /app/node_modules/mysql/lib/protocol/Protocol.js:399:18
at Array.forEach (native)
at /app/node_modules/mysql/lib/protocol/Protocol.js:398:13
at nextTickCallbackWith0Args (node.js:420:9)
at process._tickCallback (node.js:349:13)
&lt;/code>&lt;/pre>&lt;p>Yikes! So the connection from our &lt;code>users-service&lt;/code> container to the &lt;code>test-database&lt;/code> container is being refused. We might try running &lt;code>docker ps&lt;/code> to see all containers running:&lt;/p>
&lt;pre>&lt;code>CONTAINER ID IMAGE PORTS NAMES
a97958850c66 users-service 0.0.0.0:8123-&amp;gt;8123/tcp kickass_perlman
47f91343db01 mysql:latest 0.0.0.0:3306-&amp;gt;3306/tcp db
&lt;/code>&lt;/pre>&lt;p>They're both there, so what is going on?&lt;/p>
&lt;h2 id="linking-containers">Linking Containers&lt;/h2>
&lt;p>The issue we've seen is actually to be expected. Docker containers are supposed to be isolated, so it wouldn't make much sense if we could create connections between containers without us explicitly allowing it.&lt;/p>
&lt;p>Yes, we can connect from our machine (the host) to a container, because we've opened ports for that (using the &lt;code>-p 8123:8123&lt;/code> argument for example). If we allowed containers to talk to each other in the same way, then two containers running on the same machine would be able to communicate, even if the developers didn't intend it, and that's a recipe for disaster, especially when we might have a cluster of machines whos job it is to run containers from different applications.&lt;/p>
&lt;p>If we're going to connect from one container to another, we need to &lt;em>link&lt;/em> them, which tells docker that we explicitly want to allow communication between the two. There are two ways of doing this, the first is the &amp;lsquo;old fasioned&amp;rsquo; but quite simple way, the second we'll see a little later.&lt;/p>
&lt;h3 id="linking-containers-with-the-link-parameter">Linking Containers with the &amp;lsquo;link&amp;rsquo; parameter&lt;/h3>
&lt;p>When we run a container, we can tell docker that we intend to connect to another container using the &lt;code>link&lt;/code> parameter. In our case, we can run our service correctly like this:&lt;/p>
&lt;pre>&lt;code>docker run -it -p 8123:8123 --link db:db -e DATABASE_HOST=DB users-service
&lt;/code>&lt;/pre>&lt;ol>
&lt;li>&lt;code>docker run -it&lt;/code> run a docker image in a container, with an interactive terminal.&lt;/li>
&lt;li>&lt;code>-p 8123:8123&lt;/code> map the host port 8123 to the container port 8123.&lt;/li>
&lt;li>&lt;code>link db:db&lt;/code> link to the container named &lt;code>db&lt;/code> and refer to it as &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-e DATABASE_HOST=db&lt;/code> set the &lt;code>DATABASE_HOST&lt;/code> environment variable to &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>users-service&lt;/code> the name of the image to run in our container.&lt;/li>
&lt;/ol>
&lt;p>Now when we go to &lt;code>localhost:8123/users&lt;/code> everything works.&lt;/p>
&lt;h4 id="how-it-works">How it works&lt;/h4>
&lt;p>Remember our config file for the service? It allowed us to specify a database host with an environment variable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>When we run the container, we set this environment variable to &lt;code>DB&lt;/code>, which means we're connecting to a host called &lt;code>DB&lt;/code>. This is &lt;em>automatically&lt;/em> set up for us by the docker engine when we link to a container.&lt;/p>
&lt;p>To see this in action, try running &lt;code>docker ps&lt;/code> to list all running containers. Look up the name of the container running the &lt;code>users-service&lt;/code>, which will be a random name such as &lt;code>trusting_jang&lt;/code>:&lt;/p>
&lt;pre>&lt;code>docker ps
CONTAINER ID IMAGE ... NAMES
ac9449d3d552 users-service ... trusting_jang
47f91343db01 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>Now we can look at the hosts available on our container:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 db 47f91343db01 # linking magic!!
172.17.0.3 ac9449d3d552
&lt;/code>&lt;/pre>&lt;p>Remember how &lt;code>docker exec&lt;/code> works? Choose a container name and then whatever follows is the command you'll execute on the container, in our case &lt;code>cat /etc/hosts&lt;/code>.&lt;/p>
&lt;p>OK the hosts file doesn't have the &lt;code># linking magic!!&lt;/code> comment, that's so you can see - docker has added &lt;code>db&lt;/code> to our hosts file so we can refer to the linked container by hostname. This is one consequence of linking. Here's the other:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang printenv | grep DB
DB_PORT=tcp://172.17.0.2:3306
DB_PORT_3306_TCP=tcp://172.17.0.2:3306
DB_PORT_3306_TCP_ADDR=172.17.0.2
DB_PORT_3306_TCP_PORT=3306
DB_PORT_3306_TCP_PROTO=tcp
DB_NAME=/trusting_jang/db
&lt;/code>&lt;/pre>&lt;p>From this command we can also see that when docker links a container, it also provides a set of environment variables with some helpful information. We know the host, tcp port and container name.&lt;/p>
&lt;p>That's step 3 complete - we have a MySQL database running happily in a container, we have a node.js microservice which we can run locally or in a container of its own, and we know how to link them together.&lt;/p>
&lt;p>You can check out how the code looks at this stage by going to the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step3">step3&lt;/a> branch.&lt;/p>
&lt;h1 id="step-4-integration-testing-the-environment">Step 4: Integration Testing the Environment&lt;/h1>
&lt;p>We can now write an integration test which calls the actual server, running as a docker container, calling the containerised test database.&lt;/p>
&lt;p>Writing the integration test can be done in whatever language or on whatever platform you want, within reason, but to keep things simple I'm using Node.js as we've already seen Mocha and Supertest in our project.&lt;/p>
&lt;p>In a new folder, called &lt;code>integration-tests&lt;/code> we've got a single &lt;code>index.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;supertest&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">should&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;should&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">describe&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;users-service&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">api&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;http://localhost:8123&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">it&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;returns a 200 for a known user&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">done&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">api&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search?email=homer@thesimpsons.com&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">expect&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>, &lt;span style="color:#a6e22e">done&lt;/span>);
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will check an API call and show the results of the test&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>As long as your &lt;code>users-service&lt;/code> and &lt;code>test-database&lt;/code> are running, the tests will pass. However, at this stage the services are getting a little harder to handle:&lt;/p>
&lt;ol>
&lt;li>We have to use a shell script to start and stop the database&lt;/li>
&lt;li>We have to remember a sequence of commands to start the users service against the database&lt;/li>
&lt;li>We have to use node directly to run the integration tests&lt;/li>
&lt;/ol>
&lt;p>Now that we're a little more familiar with Docker we can fix these issues.&lt;/p>
&lt;h3 id="simplifiying-the-test-database">Simplifiying the Test Database&lt;/h3>
&lt;p>Currently we have the following files for the test database:&lt;/p>
&lt;pre>&lt;code>/test-database/start.sh
/test-database/stop.sh
/test-database/setup.sql
&lt;/code>&lt;/pre>&lt;p>Now that we're more familar with Docker, we can improve on this. Looking into the &lt;a href="https://hub.docker.com/_/mysql/">mysql image documentation&lt;/a> on Docker Hub there's a note which tells us any &lt;code>.sql&lt;/code> or &lt;code>.sh&lt;/code> file added to the image's &lt;code>/docker-entrypoint-initdb.d&lt;/code> folder will be executed when setting up the DB.&lt;/p>
&lt;p>This means we can replace our &lt;code>start.sh&lt;/code> and &lt;code>stop.sh&lt;/code> scripts with a &lt;code>Dockerfile&lt;/code>:&lt;/p>
&lt;pre>&lt;code>FROM mysql:5
ENV MYSQL_ROOT_PASSWORD 123
ENV MYSQL_DATABASE users
ENV MYSQL_USER users_service
ENV MYSQL_PASSWORD 123
ADD setup.sql /docker-entrypoint-initdb.d
&lt;/code>&lt;/pre>&lt;p>Now to run our test database it is just:&lt;/p>
&lt;pre>&lt;code>docker build -t test-database .
docker run --name db test-database
&lt;/code>&lt;/pre>&lt;h3 id="composing">Composing&lt;/h3>
&lt;p>Building and running each container is still somewhat time consuming. We can take things a step further with the &lt;a href="https://docs.docker.com/compose/">Docker Compose&lt;/a> tool.&lt;/p>
&lt;p>Docker Compose lets you create a file which defines each container in your system, the relationships between them, and build or run them all.&lt;/p>
&lt;p>First, &lt;a href="https://docs.docker.com/compose/install/">install Docker Compose&lt;/a>. Now create a new file in the root of your project called &lt;code>docker-compose.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>Now check this out:&lt;/p>
&lt;pre>&lt;code>docker-compose build
docker-compose up
&lt;/code>&lt;/pre>&lt;p>Docker Compose has built all of the images needed for our application, created containers fromthem, run them in the correct order and started the whole stack!&lt;/p>
&lt;p>The &lt;code>docker-compose build&lt;/code> command builds each image which is listed in the &lt;code>docker-compose.yml&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>The &lt;code>build&lt;/code> value for each of our services tells docker where to go to find the &lt;code>Dockerfile&lt;/code>. When we run &lt;code>docker-compose up&lt;/code>, docker starts all of our services. Notice from the &lt;code>Dockerfile&lt;/code> we can specify ports and dependencies. Actually, there's a whole bunch of config we can change here.&lt;/p>
&lt;p>In another terminal, run &lt;code>docker compose down&lt;/code> to gracefully shut down the containers.&lt;/p>
&lt;h1 id="winding-up">Winding Up&lt;/h1>
&lt;p>We've seen a lot of docker in this article, but there's a lot more to it. I hope this has shown some of the interesting and useful things that you can use docker for in your workflow.&lt;/p>
&lt;p>As usual, questions and comments are welcomed! I'd also strongly recommend the document &lt;a href="https://docs.docker.com/engine/understanding-docker/">Understanding Docker&lt;/a> to get a deeper understanding of how docker works.&lt;/p>
&lt;p>You can see the final source code for the project built in this article at &lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h1 id="notes">Notes&lt;/h1>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Copying everything is actually a bad idea, because we will also copy the node_modules folder. Generally it is a better idea explicitly list the files or folders you want to copy, or use a .dockerignore file, which works just like the .gitignore file. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If the server isn't running, it will actually show a rather annoying exception, due to a bug in supertest, see &lt;a href="https://github.com/visionmedia/supertest/issues/314">github.com/visionmedia/supertest/issues/314&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Getting Started with React &amp; ES6</title><link>https://dwmkerr.com/getting-started-with-react/</link><pubDate>Mon, 07 Sep 2015 19:44:54 +0000</pubDate><guid>https://dwmkerr.com/getting-started-with-react/</guid><description>&lt;p>Feeling like having a go with Facebook's hugely popular &lt;a href="http://facebook.github.io/react/">React&lt;/a> framework but not sure where to start?&lt;/p>
&lt;p>In this post I'm going to build a simple React application from scratch - using &lt;a href="http://es6-features.org/">ECMAScript 6&lt;/a>.&lt;/p>
&lt;p>We'll put together the bare minimum skeleton of a site and keep the folder structure free of noise and clutter so that you can focus on the app code and not the tooling!&lt;/p>
&lt;p>The simple app we'll build is at &lt;a href="https://github.com/dwmkerr/react-es6-starter">github.com/dwmkerr/react-es6-starter&lt;/a>, or see &lt;a href="https://react-es6-starter.herokuapp.com">it live&lt;/a>.&lt;/p>
&lt;h2 id="building-the-code">Building the Code&lt;/h2>
&lt;p>Our goal will be to have a single &lt;code>index.html&lt;/code> file which includes our Javascript files. We're aiming for something like this:&lt;/p>
&lt;p>&lt;img src="images/Build-Process.png" alt="Build Process 1">&lt;/p>
&lt;p>But browsers don't handle ES6 yet. So our loose files, which reference each other, are going to have to be transpiled into ES5 and bundled into a single file. We need a build process:&lt;/p>
&lt;p>&lt;img src="images/Build-Process-2.png" alt="Build Process 2">&lt;/p>
&lt;p>&lt;a href="webpack.github.io">Webpack&lt;/a> can handle all of this for us. Given an entrypoint file, webpack will traverse all of the &lt;code>require&lt;/code> and &lt;code>import&lt;/code> statements and build a single bundle file. It also allows us to configure &amp;lsquo;loaders&amp;rsquo;, which let us pass these files through other tools:&lt;/p>
&lt;p>&lt;img src="images/Build-Process-3.png" alt="Build Process 3">&lt;/p>
&lt;p>We'll need the following libraries:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="webpack.github.io">Webpack&lt;/a> - the tool that handles the build process.&lt;/li>
&lt;li>&lt;a href="babeljs.io">Babel&lt;/a> - an excellent ES6/ES7/JSX to ES5 transpiler.&lt;/li>
&lt;li>&lt;a href="github.com/babel/babel-loader">Babel Loader&lt;/a> - the component which integrates Babel into our Webpack build.&lt;/li>
&lt;li>&lt;a href="github.com/ampedandwired/html-webpack-plugin">Html Webpack Plugin&lt;/a> - a simple Webpack plugin which will copy our index file to our build folder and add a link to our Webpack bundle.&lt;/li>
&lt;/ol>
&lt;p>Let's install these modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save webpack babel babel-loader html-webpack-plugin
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll also need a webpack config file. By default webpack expects a file named &lt;code>webpack.config.js&lt;/code> to be in the root of the project. But every tool under the sun wants to stick its config file in the root of our project, and most of the time they're just in the way.&lt;/p>
&lt;p>So let's put everything to do with our tooling in a &lt;code>tooling&lt;/code> folder instead. Create the file &lt;code>webpack.config.js&lt;/code> in a &lt;code>tooling&lt;/code> folder in the root of the project:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;path&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#75715e">// Defines the entrypoint of our application.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">entry&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src/app.js&amp;#39;&lt;/span>),
&lt;span style="color:#75715e">// Bundle to a ./build/public/bundle.js file.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">output&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">path&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../build/public&amp;#39;&lt;/span>),
&lt;span style="color:#a6e22e">filename&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;bundle.js&amp;#39;&lt;/span>
},
&lt;span style="color:#75715e">// Use babel for anything that is *.js or *.jsx.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">loaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;babel-loader&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">include&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src&amp;#39;&lt;/span>)
}
]
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>First we define our entry point - the first file which will actually be run if we run the final bundled script. This is the &lt;code>app.js&lt;/code> file we'll create shortly. If &lt;code>app.js&lt;/code> includes other modules, Webpack will pick them up, if those modules include other modules, they will be picked up and so on.&lt;/p>
&lt;p>Next we specify that everything should be bundled into a &lt;code>./build/public/bundle.js&lt;/code> file (we're going to use the convention that everything we can produce with our tools goes into &lt;code>./build&lt;/code>).&lt;/p>
&lt;p>Finally, we specify that every file in &lt;code>src&lt;/code> which matches the &lt;code>\.jsx?$&lt;/code> regex will go through the babel loader.&lt;/p>
&lt;h3 id="using-es6">Using ES6!&lt;/h3>
&lt;p>We've actually got enough now to use ES6. Create a file in &lt;code>src&lt;/code> called &lt;code>index.html&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&lt;span style="color:#75715e">&amp;lt;!DOCTYPE html&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then create a &lt;code>src/app.js&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">PI&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3.14&lt;/span>;
&lt;span style="color:#66d9ef">let&lt;/span> &lt;span style="color:#a6e22e">vals&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>].&lt;span style="color:#a6e22e">map&lt;/span>(&lt;span style="color:#a6e22e">x&lt;/span> =&amp;gt; &lt;span style="color:#a6e22e">x&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>);
document.&lt;span style="color:#a6e22e">body&lt;/span>.&lt;span style="color:#a6e22e">innerText&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Pi is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">3.14&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and vals is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">vals&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run the command &lt;code>./node_modules/.bin/webpack --config ./tooling/webpack.config.js&lt;/code> and our code is built, transpiled an moved to the build folder.&lt;/p>
&lt;p>Now we could serve this folder using any basic webserver. We are already using webpack, so the webpack dev server will do the trick. It uses exactly the same config file as the webpack tool:&lt;/p>
&lt;pre>&lt;code>npm install --save-dev webpack-dev-server
./node_modules/.bin/webpack-dev-server --config ./tooling/webpack.config --inline
&lt;/code>&lt;/pre>&lt;p>The inline reloads the page when the source changes. We don't need to tell the server where the files are, it knows that from the webpack config.&lt;/p>
&lt;p>Let's stick these commands in our &lt;code>package.json&lt;/code> for convenience:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">{
...
&lt;span style="color:#e6db74">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#34;start&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;webpack-dev-server --config ./tooling/webpack.config.js --inline --quiet&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">&amp;#34;webpack&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;webpack --config tooling/webpack.config.js&amp;#34;&lt;/span>
...
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we can manually build with &lt;code>npm run webpack&lt;/code> and start our dev server with &lt;code>npm start&lt;/code>.&lt;/p>
&lt;h3 id="adding-some-react">Adding some React&lt;/h3>
&lt;p>Let's add a React component. Create a folder under &lt;code>app&lt;/code> called &lt;code>home&lt;/code> and add a &lt;code>home.js&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">default&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#66d9ef">extends&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">Component&lt;/span> {
&lt;span style="color:#a6e22e">render&lt;/span> () {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">div&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">h1&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>&lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">ES6&lt;/span> &lt;span style="color:#a6e22e">Starter&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">h&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">1&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">p&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>&lt;span style="color:#a6e22e">Welcome&lt;/span> &lt;span style="color:#a6e22e">to&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">ES6&lt;/span> &lt;span style="color:#a6e22e">Starter&lt;/span> &lt;span style="color:#a6e22e">home&lt;/span> &lt;span style="color:#a6e22e">page&lt;/span>&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">p&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">d&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">v&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is our first react component, which does nothing more than render some basic markup. We'll use this as the starting point for our application.&lt;/p>
&lt;p>We can now take our &lt;code>app.js&lt;/code> file and render our Home component into the div. Here's &lt;code>app.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react/addons&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;./home/home&amp;#39;&lt;/span>;
&lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">render&lt;/span>(&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>, document.&lt;span style="color:#a6e22e">body&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>That's all there is to it! We've got a clean and simple starting point to begin playing with React. Before we look into things like state management and routing, let's look into testing what we have so far.&lt;/p>
&lt;h3 id="testing">Testing&lt;/h3>
&lt;p>Even the most simple app would be incomplete without looking into how we will deal with the testing.&lt;/p>
&lt;p>Many will recommend the &lt;a href="https://facebook.github.io/jest/">Jest&lt;/a> framework to test React applications. However, it's a bit more to learn and has some problems with NodeJS v0.12, so until we get Node v4 I'm going to keep things simple.&lt;/p>
&lt;p>First, we'll install &lt;a href="http://karma-runner.github.io/">Karma&lt;/a> as a test runner. We'll use &lt;a href="http://jasmine.github.io/">Jasmine&lt;/a> as as framework to write test cases and &lt;a href="http://phantomjs.org/">PhantomJS&lt;/a> as a headless browser in which our tests will run. This means we'll need to add some more dev dependencies:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev karma jasmine karma-webpack karma-jasmine karma-phantomjs-launcher
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can now create a &lt;code>karma.config.js&lt;/code> file in our &lt;code>tooling&lt;/code> folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;path&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>) {
&lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">set&lt;/span>({
&lt;span style="color:#a6e22e">browsers&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;PhantomJS&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">files&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
&lt;span style="color:#75715e">// We need to polyfill as PhantomJS doesn&amp;#39;t support &amp;#39;bind&amp;#39;.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#e6db74">&amp;#39;../node_modules/babel-core/browser-polyfill.js&amp;#39;&lt;/span>,
&lt;span style="color:#e6db74">&amp;#39;../**/*.spec.js&amp;#39;&lt;/span>
],
&lt;span style="color:#a6e22e">frameworks&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;jasmine&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">preprocessors&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#39;../**/*.spec.js&amp;#39;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;webpack&amp;#39;&lt;/span>],
},
&lt;span style="color:#a6e22e">reporters&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;progress&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">singleRun&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;span style="color:#a6e22e">webpack&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">loaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;babel-loader&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">include&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src&amp;#39;&lt;/span>)
}
],
}
},
&lt;span style="color:#a6e22e">webpackServer&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">noInfo&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>
}
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So here we are:&lt;/p>
&lt;ol>
&lt;li>Loading a polyfill from babel core (sorry guys, one more &lt;code>npm install --save-dev babel-core&lt;/code>) which gives PhantomJS the &lt;code>bind&lt;/code> function (along with some others). This is needed as some of the testing code in the browser needs these features.&lt;/li>
&lt;li>Specifying that anything that ends in &lt;code>.spec.js&lt;/code> should be loaded.&lt;/li>
&lt;li>Running anything that ends in &lt;code>.spec.js&lt;/code> through webpack.&lt;/li>
&lt;li>Telling webpack to use babel.&lt;/li>
&lt;/ol>
&lt;p>Quite a bit of config, but we're re-using the same webpack tooling as before. We run the code through webpack, which sends it through babel and builds ES5 we can test in the browser.&lt;/p>
&lt;p>With this in place, we can write a spec. Add &lt;code>home.spec.js&lt;/code> to the &lt;code>home&lt;/code> folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">$&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;jquery&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;./home.js&amp;#39;&lt;/span>;
&lt;span style="color:#a6e22e">describe&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Home&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">it&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;should render to the DOM&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// Create the &amp;lt;Home /&amp;gt; react component.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">component&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">render&lt;/span>(&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>, document.&lt;span style="color:#a6e22e">body&lt;/span>);
&lt;span style="color:#75715e">// Find the DOM element for the created component.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">node&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">findDOMNode&lt;/span>(&lt;span style="color:#a6e22e">component&lt;/span>);
&lt;span style="color:#75715e">// Check the DOM looks how we&amp;#39;d expect it to.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">expect&lt;/span>(&lt;span style="color:#a6e22e">$&lt;/span>(&lt;span style="color:#a6e22e">node&lt;/span>).&lt;span style="color:#a6e22e">children&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;h1&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">text&lt;/span>()).&lt;span style="color:#a6e22e">toEqual&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;React Redux Starter&amp;#34;&lt;/span>);
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>What's going on here? We just ask React to render our Home component directly into the DOM. We get a component back from this call. We can then ask React to give us the DOM associatefd with the component and use familiar tools (jQuery!) to test the shape of the generated DOM.&lt;/p>
&lt;p>All that's missing is the last of the dev dependencies we've missed:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev jquery phantomjs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can run tests directly on a Mac or Unix with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">./node_modules/.bin/karma start ./tooling/karma.config.js
&lt;/code>&lt;/pre>&lt;/div>&lt;p>For Windows use:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">node_modules&lt;span style="color:#ae81ff">\.&lt;/span>bin&lt;span style="color:#ae81ff">\k&lt;/span>arma start tooling&lt;span style="color:#ae81ff">\k&lt;/span>arma.config.js
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, we'll update our &lt;code>package.json&lt;/code> scripts so that this is the &lt;code>test&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#e6db74">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#34;test&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;./node_modules/.bin/karma start ./tooling/karma.config.js&amp;#34;&lt;/span>,
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! This means we can run tests on any platform with NodeJS&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> using the same command - &lt;code>npm test&lt;/code>.&lt;/p>
&lt;p>We now have a very simple setup which allows us to run tests. You can build on this - perhaps adding Jest later or a more sophisticated or React specific set of tools.&lt;/p>
&lt;h3 id="adding-code-coverage">Adding Code Coverage&lt;/h3>
&lt;p>You might want to add some code coverage information to your project. This can be a little tricky when using ES6, as we need to make sure we report coverage of the original ES6 code, rather than the actual transpiled code which is instrumented.&lt;/p>
&lt;p>Fortunately, with the clean and simple setup we have built, adding code coverage is a snap.&lt;/p>
&lt;p>Our test runner, Karma, is built to quickly integrate with the code coverage tool &lt;a href="https://github.com/gotwarlost/istanbul">Istanbul&lt;/a>, we just need to use the &lt;a href="https://github.com/karma-runner/karma-coverage">Karma Coverage&lt;/a> plugin. Let's install the two modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev istanbul karma-coverage
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now with a small addition to our &lt;code>karma.config.js&lt;/code> file we will get a nice HTML coverage report. We need to update our &lt;code>reporters&lt;/code> config to include &lt;code>coverage&lt;/code> and specify coverage options in the &lt;code>coverageReporter&lt;/code> config.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript"> &lt;span style="color:#a6e22e">reporters&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;progress&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;coverage&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">coverageReporter&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">dir&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;../build/coverage/&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;html&amp;#39;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you run &lt;code>npm test&lt;/code> now, you'll get an HTML coverage report generated. The only problem is that it is for the transpiled code, which makes it almost useless. A customer instrumenter called isparta will help us here. We use isparta to get a report of the coverage of the original ES6 code. Two more modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev isparta isparta-instrumenter-loader
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then in our karma config we pass the orignal code through the insrtrumenter, before babel transpiles it:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">webpack&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">preLoaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">exclude&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">/node_modules/&lt;/span>, &lt;span style="color:#e6db74">/\.spec\.js/&lt;/span>],
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;isparta-instrumenter-loader&amp;#39;&lt;/span>
},
],
&lt;span style="color:#75715e">// everything else stays the same...
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Anything that is not a spec or from &lt;code>node_modules&lt;/code> gets instrumented. Now we have a ES6 code coverage report:&lt;/p>
&lt;p>&lt;img src="images/CapturFiles_8.png" alt="Code Coverage Report">&lt;/p>
&lt;p>With this in place, you can go even further and integrate with other CI or publish to code quality systems (for example this repo integrates to &lt;a href="https://coveralls.io">coveralls.io&lt;/a>). This is often used to show badges for repos:&lt;/p>
&lt;p>&lt;a href="https://coveralls.io/github/dwmkerr/react-es6-starter?branch=master">&lt;img src="images/badge.svg" alt="Coverage Status">&lt;/a>&lt;/p>
&lt;p>Another use case is to gate checkins unless they maintain a certain code coverage threshhold.&lt;/p>
&lt;h3 id="wrapping-up">Wrapping Up&lt;/h3>
&lt;p>This provides a very lean starting point for learning React. There's no moving parts at the moment - no state management. We'll get into that in later articles but right now you have a playground.&lt;/p>
&lt;p>You can set up CI in a flash, just sign up for a &lt;a href="https://travis-ci.org/">Travis&lt;/a> account and use a &lt;code>travis.yml&lt;/code> like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yml" data-lang="yml">language: node_js
node_js:
- &lt;span style="color:#e6db74">&amp;#34;0.12&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This repo is all ready to push to &lt;a href="todo">Heroku&lt;/a>, no Procfile is needed. Check out &lt;a href="todo">react-es6-starter.herokuapp.com&lt;/a> to see the code in action.&lt;/p>
&lt;p>I hope you've found this article useful! Next time we'll be getting into the details of managing state in React.&lt;/p>
&lt;p>Please fork the repo and have a play, let me know of any suggestions or improvements!&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/react-es6-starter">github.com/dwmkerr/react-es6-starter&lt;/a>&lt;/p>
&lt;h3 id="glossary-of-conventions">Glossary of Conventions&lt;/h3>
&lt;p>There are a few conventions that I personally use in most Javascript projects. The conventions used in this article which I think are valuable to consider using in many projects are:&lt;/p>
&lt;h4 id="always-support-installteststart">Always support install/test/start&lt;/h4>
&lt;p>Everyone should always be able to checkout, install, test and run the code with the following commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install &lt;span style="color:#75715e"># installs everything needed&lt;/span>
npm test &lt;span style="color:#75715e"># lets the user know the code works right on their system!&lt;/span>
npm start &lt;span style="color:#75715e"># starts the code, lets the user know what to do next&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Install should setup everything, and if code needs to be built to be testable, this should be a post-install hook.&lt;/p>
&lt;p>Test should be run next, as a user should be able to verify that the code works as expected on their system.&lt;/p>
&lt;p>Finally, when the user runs start, a dev server (as convention dictates we are in a dev mode by default (and production mode is set with a flag or environment variable) the server should start and a console message should show the user where to browse to.&lt;/p>
&lt;hr>
&lt;h5 id="footnotes">Footnotes&lt;/h5>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://www-03.ibm.com/press/us/en/pressrelease/47474.wss">IBM Mainframes&lt;/a> anyone? &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Manipulating JSON Web Tokens (JWTs)</title><link>https://dwmkerr.com/modifying-a-jwt-in-a-node-application/</link><pubDate>Tue, 24 Mar 2015 14:45:02 +0000</pubDate><guid>https://dwmkerr.com/modifying-a-jwt-in-a-node-application/</guid><description>&lt;p>I've been writing a couple of web services lately that use &lt;a href="https://auth0.com/">Auth0&lt;/a> for identity management. It's a great platform that makes working with different identity providers a breeze.&lt;/p>
&lt;p>One thing that I couldn't work out how to do at first was to quickly build a new JWT&lt;sup>&lt;a href="#fn1" id="ref1">1&lt;/a>&lt;/sup> from an existing token. I wanted to take my current token, add some more data to it and return it to the user. So here's a &amp;lsquo;why&amp;rsquo; and &amp;lsquo;how&amp;rsquo;.&lt;/p>
&lt;h2 id="why">Why?&lt;/h2>
&lt;p>Why would you want to do this? A use case would be when you want to associate your a session with some data. For example, imagine a library gateway which offers access to a whole bunch of University libraries. First we authenticate. Then we ask for all of the libraries in the system. Then we ask for authorisation to use a specific library. We could put the library name in the token and pass it for every call onwards.&lt;/p>
&lt;p>It might look like this:&lt;/p>
&lt;h4 id="1-authenticate">1. Authenticate&lt;/h4>
&lt;p>First, we authenticate, perhaps with a username and password.&lt;/p>
&lt;pre>&lt;code>POST libraries.com/api/authenticate
{&amp;quot;usename&amp;quot;:&amp;quot;calculon&amp;quot;,&amp;quot;password&amp;quot;:&amp;quot;dramatic...pause&amp;quot;}
&lt;/code>&lt;/pre>&lt;p>Then we can return a JWT if all is well:&lt;/p>
&lt;pre>&lt;code>{&amp;quot;jwt&amp;quot;:&amp;quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJjYWxjdWxvbiJ9.VWkAafAMCxazY7uBlPTJoQwCBdUIy3T1d-C4TfxhAZQ&amp;quot;}
&lt;/code>&lt;/pre>&lt;h4 id="2-work-with-the-service">2. Work with the Service&lt;/h4>
&lt;p>We can put this JWT in an &lt;code>Authorization&lt;/code> header and start asking for protected resources:&lt;/p>
&lt;pre>&lt;code>GET libraries.com/api/libraries
Authorization: Bearer eyJhb...AZQ
&lt;/code>&lt;/pre>&lt;p>giving us:&lt;/p>
&lt;pre>&lt;code>[
{&amp;quot;name&amp;quot;: &amp;quot;Mars University Libary&amp;quot;, &amp;quot;slug&amp;quot;:&amp;quot;mul&amp;quot;},
{&amp;quot;name&amp;quot;: &amp;quot;Coney Island State Library&amp;quot;, &amp;quot;slug&amp;quot;:&amp;quot;cis&amp;quot;}
]
&lt;/code>&lt;/pre>&lt;p>Two libraries we can choose from. Now I want to present this choice to a user, but once they've made their choice I don't want to change the libary again. I want to work with only one library in a session.&lt;/p>
&lt;h4 id="3-add-data-to-the-token">3. Add Data to the Token&lt;/h4>
&lt;p>A nice thing we can do here is just create &lt;em>another&lt;/em> authentication method, which attempts to see if we are authorised to use the given library:&lt;/p>
&lt;pre>&lt;code>POST libraries.com/api/libraries/mul/authorise
Authorization: Bearer eyJhb...AZQ
&lt;/code>&lt;/pre>&lt;p>If the token is valid, we can check to see if the user is allowed to use this library. If so, we can return a &lt;em>new&lt;/em> token, which is associated with a &lt;em>specific&lt;/em> library:&lt;/p>
&lt;pre>&lt;code>HTTP/1.1 200 OK
{&amp;quot;jwt&amp;quot;: &amp;quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJjYWxjdWxvbiIsImxpYnJhcnkiOiJtdWwifQ.NM2pqRMkIp65u9unZnGIoyxK6v2A18730lPwSMrK93Q&amp;quot;}
&lt;/code>&lt;/pre>&lt;p>This is a new token. Paste it into &lt;a href="https://jwt.io">jwt.io&lt;/a>, you'll see there's a library code in the payload.&lt;/p>
&lt;h4 id="4-work-with-the-service">4. Work with the service&lt;/h4>
&lt;p>Now I can call APIs like:&lt;/p>
&lt;pre>&lt;code>GET libaries.com/api/books
&lt;/code>&lt;/pre>&lt;p>And my server can check the library in my token. If I have one, I return books from the given library, otherwise I return a 401.&lt;/p>
&lt;h4 id="is-this-useful">Is this useful?&lt;/h4>
&lt;p>This specific example might not appeal, but you may well find as you write more complex services you want to at times add data to your token.&lt;/p>
&lt;p>The case above also shows how you can associate a session with a set of resources (in this case, a single library). This is useful if we know we'll only work with a subset of resources. I want to choose a library once and work with that only. If you need to work with multiple libraries, it wouldn't make sense.&lt;/p>
&lt;h2 id="how">How?&lt;/h2>
&lt;p>If we are using Auth0, then we almost certainly have our token generated for us. The helper library &lt;a href="https://github.com/auth0/express-jwt">express-jwt&lt;/a> will certainly let us make sure the token is valid, and put the payload of data on the &lt;code>request.user&lt;/code> object, but how can we create a new token &lt;em>from the existing one&lt;/em>?&lt;/p>
&lt;p>It turns out it's really pretty easy, as we would expect as we are using open standards. Here's the code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;jsonwebtoken&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">extendToken&lt;/span>(&lt;span style="color:#a6e22e">secret&lt;/span>, &lt;span style="color:#a6e22e">payload&lt;/span>, &lt;span style="color:#a6e22e">extend&lt;/span>) {
&lt;span style="color:#75715e">// Clone and extend the payload.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">body&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">parse&lt;/span>(&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>));
&lt;span style="color:#66d9ef">for&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">prop&lt;/span> &lt;span style="color:#66d9ef">in&lt;/span> &lt;span style="color:#a6e22e">extend&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#a6e22e">extend&lt;/span>.&lt;span style="color:#a6e22e">hasOwnProperty&lt;/span>(&lt;span style="color:#a6e22e">prop&lt;/span>)) {
&lt;span style="color:#a6e22e">body&lt;/span>[&lt;span style="color:#a6e22e">prop&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">extend&lt;/span>[&lt;span style="color:#a6e22e">prop&lt;/span>];
}
}
&lt;span style="color:#75715e">// Sign the new token with our secret.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">sign&lt;/span>(&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">body&lt;/span>), &lt;span style="color:#a6e22e">secret&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a function which takes a secret, the payload of an existing token, an object containing data to extend and that's it. Here's how you could use it:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">expressJwt&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;express-jwt&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">mySecret&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Buffer&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;walkinonsunshine&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;base64&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Middleware for protecting routes...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">requireAuth&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">expressJwt&lt;/span>({&lt;span style="color:#a6e22e">secret&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">mySecret&lt;/span>});
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">post&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/libraries/:lib/authorise&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">requireAuth&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>, &lt;span style="color:#a6e22e">next&lt;/span>) {
&lt;span style="color:#75715e">// get the library, check the user has access...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">lib&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">params&lt;/span>.&lt;span style="color:#a6e22e">lib&lt;/span>;
&lt;span style="color:#a6e22e">checkLib&lt;/span>(&lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">sub&lt;/span>, &lt;span style="color:#a6e22e">lib&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">ok&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">next&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">ok&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">401&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Access Denied.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>({&lt;span style="color:#a6e22e">jwt&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">extendToken&lt;/span>(&lt;span style="color:#a6e22e">mySecret&lt;/span>, &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>, {&lt;span style="color:#a6e22e">library&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">lib&lt;/span>})});
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've extended the original token with some new data, resigned it and passed it back to the user. Future requests will automatically have the &lt;code>req.user.lib&lt;/code> field set (as the entire token payload is put by default on the &lt;code>req.user&lt;/code> object with the express-js middleware.&lt;/p>
&lt;p>Hopefully that'll be of some use if you ever need to extend the payload of a JWT token in a Node app.&lt;/p>
&lt;hr>
&lt;p>&lt;sup id="fn1">1. Json Web Token, read more at &lt;a href="http://jwt.io/">jwt.io&lt;/a>. &lt;a href="#ref1">↩&lt;/a>&lt;/sup>&lt;/p></description><category>CodeProject</category></item><item><title>The Best Module System for AngularJS Applications</title><link>https://dwmkerr.com/the-best-module-system-for-angularjs-applications/</link><pubDate>Wed, 18 Mar 2015 14:47:10 +0000</pubDate><guid>https://dwmkerr.com/the-best-module-system-for-angularjs-applications/</guid><description>&lt;p>I was working on a small and simple application built with AngularJS the other day. As with most applications like this, I start with a single JavaScript file caled &lt;code>app.js&lt;/code> and no module system.&lt;/p>
&lt;p>In the past I've used RequireJS with AngularJS. It's an awful mistake. It leads to a big jump in complexity with no benefts. Angular apps don't work well with AMDs, so really your are using RequireJS to combine files into one big file.&lt;/p>
&lt;p>I'm sure there's a good analogy with hammers and nails. Something like:&lt;/p>
&lt;blockquote>
&lt;p>It's like banging nails into your face with a hammer.&lt;/p>
&lt;/blockquote>
&lt;p>Maybe a bit extreme. But those who've used the two together may well be nodding sagely.&lt;/p>
&lt;p>I've also used Browserify. I prefer this approach, the syntax is cleaner. But it's still a pain.&lt;/p>
&lt;p>Ideally, I'd like to use ECMA6 modules. So another approach is to just use ECMA6 module syntax and then compile your code with something like Traceur. But that requires quite a bit of tooling, slows down your pipeline and you're still not &lt;em>really&lt;/em> using modules.&lt;/p>
&lt;p>I think the best approach is this one from &lt;a href="https://medium.com/@dickeyxxx">Jeff Dicky&lt;/a> on his post &lt;a href="https://medium.com/@dickeyxxx/best-practices-for-building-angular-js-apps-266c1a4a6917">Best Practices for Building Angular.js Apps&lt;/a>. Just forget all of the module stuff and concatenate only.&lt;/p>
&lt;p>Start with this:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Or whatever your preferred structure is. Then stick your main file in &lt;code>app/&lt;/code>:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- app.js
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Your &lt;code>app.js&lt;/code> file should define your main Angular module:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>, []);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now just go ahead and concatenate everything in your &lt;code>app/&lt;/code> folder. Structure it however you want:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- components/
- home/
- profile/
- app.js
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Concat will put everything in the top level folder (i.e. &lt;code>app.js&lt;/code>) first. As long as you don't put anything else in your top level folder (that comes before &amp;lsquo;a&amp;rsquo; alphabetically) then it doesn't matter where you put your other files, as long as you define them without referencing any globals. So define your components like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SomeController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// something
&lt;/span>&lt;span style="color:#75715e">&lt;/span>});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>No fuss no muss. No requires, no exports.&lt;/p>
&lt;p>If you need a new service, write it and save it. Same for directives or controllers or filters. Add the source file and it's included, no messing around.&lt;/p>
&lt;p>Keep it simple, don't force another module system on top of angular's, you don't get much benenfit. And wait patiently until ECMA6 moves more into the mainstream and we can start using native modules. There's less and less point in investing in some super-sophisticated complex fancy module system for a framework which in vNext will throw it all away and for a language which will finally get native modules.&lt;/p>
&lt;h3 id="words-for-gulpers">Words for Gulpers&lt;/h3>
&lt;p>If you are a gulp user, here's how a pipeline might look to concat your JavaScript:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">gulp&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">jshint&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-jshint&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">stylish&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;jshint-stylish&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">uglify&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-uglify&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">rename&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-rename&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">sourcemaps&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-sourcemaps&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">concat&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-concat&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">ngAnnotate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-ng-annotate&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Hints and builds all JavaScript.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">task&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;js&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">src&lt;/span>([&lt;span style="color:#e6db74">&amp;#39;./client/app/**/*.js&amp;#39;&lt;/span>])
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>.&lt;span style="color:#a6e22e">reporter&lt;/span>(&lt;span style="color:#a6e22e">stylish&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>.&lt;span style="color:#a6e22e">reporter&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;fail&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">sourcemaps&lt;/span>.&lt;span style="color:#a6e22e">init&lt;/span>({&lt;span style="color:#a6e22e">loadMaps&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>}))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">concat&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app.js&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">dest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./client/dist&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">ngAnnotate&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">uglify&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">rename&lt;/span>({&lt;span style="color:#a6e22e">suffix&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;.min&amp;#39;&lt;/span>}))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">sourcemaps&lt;/span>.&lt;span style="color:#a6e22e">write&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">dest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./client/dist/&amp;#39;&lt;/span>));
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Watch your app javascript folder and when it changes, you'll hint everything, concat into a single distribution folder, annotate and uglify, as well as building full sourcemaps.&lt;/p>
&lt;h3 id="what-about-other-stuff">What about other stuff?&lt;/h3>
&lt;p>For vendor code (jQuery, Bootstrap, whatever), don't bother trying to be smart and require or import it. Just include it in your app with script tags. I wouldn't go to the effort at trying to force some kind of smart module system on a language that doesn't really support it - uf you can get away with avoiding it, do so.&lt;/p>
&lt;p>This is not an encouragement to be sloppy, this is just the easiest way to deal with the issue. The number of hours I've wasted tracking down &amp;lsquo;bugs&amp;rsquo; which were subtle issues to do with require.js or type-os has definitely made the approach above my preferred approach.&lt;/p></description><category>CodeProject</category></item><item><title>Fixing Memory Leaks in AngularJS and other JavaScript Applications</title><link>https://dwmkerr.com/fixing-memory-leaks-in-angularjs-applications/</link><pubDate>Tue, 03 Mar 2015 14:35:36 +0000</pubDate><guid>https://dwmkerr.com/fixing-memory-leaks-in-angularjs-applications/</guid><description>&lt;p>Dealing with memory leaks in JavaScript applications can be a complex process. In this article I'm going to show you how to identify whether you have memory leaks, analyse them and ultimately resolve them.&lt;/p>
&lt;p>I'm using an AngularJS application to demonstrate the concepts and approaches, but much of this material applies to any JavaScript application.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="#understandingmemoryleaks">Understanding Memory Leaks&lt;/a>
&lt;ul>
&lt;li>What is a Memory Leak?&lt;/li>
&lt;li>Why is a Memory Leak Bad?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#identifyingmemoryleaks">Identifying Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Method 1: The Wrong Way&lt;/li>
&lt;li>Method 2: The Timeline&lt;/li>
&lt;li>Method 3: Recording Heap Allocations&lt;/li>
&lt;li>Method 4: Heap Snapshots&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#analysingmemoryleaks">Analysing Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Analysing the leak in Scenario 2&lt;/li>
&lt;li>More on Graphs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#fixingmemoryleaks">Fixing Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Three golden rules&lt;/li>
&lt;li>Anti-patterns to avoid&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#thefuture">The Future&lt;/a>
&lt;ul>
&lt;li>Weak Maps&lt;/li>
&lt;li>AngularJS 2&lt;/li>
&lt;li>Even Better Browsers&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#appendices">Appendices&lt;/a>
&lt;ul>
&lt;li>Thanks&lt;/li>
&lt;li>Mysteries&lt;/li>
&lt;li>Futher Reading&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="understanding-memory-leaks">Understanding Memory Leaks&lt;/h2>
&lt;p>If you've dealt with memory leaks before, or the patterns of memory usage we sometimes call memory leaks in memory managed applications, then you can probably skip to &lt;a href="#identifyingmemoryleaks">Identifying Memory Leaks&lt;/a>.&lt;/p>
&lt;p>If not let's start with some theory.&lt;/p>
&lt;h3 id="what-is-a-memory-leak">What is a Memory Leak?&lt;/h3>
&lt;p>A memory leak, at least in the world of unmanaged applications, is what occurs when you allocate memory and forget to free it. In pseudo-code&lt;sup>&lt;a href="#fn1" id="ref1">1&lt;/a>&lt;/sup>:&lt;/p>
&lt;pre>&lt;code>void leaky()
{
void* memory;
memory = malloc(1000);
/* malloc just gave us some memory, use it! */
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>memory&lt;/code> will hold the address of the memory we've allocate. We use the memory, then the function ends. &lt;code>memory&lt;/code> goes out of scope and whatever address it held is lost - but we didn't free the memory! Not only that, we've lost the address of it so can't ever free it in the future - it's &lt;em>leaked&lt;/em>.&lt;/p>
&lt;p>This memory is lost to the application - we can't release it. Only terminating the process will release it back to the operating system.&lt;/p>
&lt;blockquote>
&lt;p>When we allocate memory and don't release it when we are done, we have &amp;lsquo;leaked&amp;rsquo; that memory.&lt;/p>
&lt;/blockquote>
&lt;p>So how do we get memory leaks in JavaScript applications? We don't allocate memory directly, the engine does it for us, and it cleans it up afterwards as well&lt;sup>&lt;a href="#fn2" id="ref2">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>If we hold on to objects longer than we need to, that will give us similar results. Let's look at some code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">ChessManager&lt;/span>() {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">moves&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [];
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">makeMove&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">move&lt;/span>) {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">moves&lt;/span>.&lt;span style="color:#a6e22e">push&lt;/span>(&lt;span style="color:#a6e22e">move&lt;/span>);
};
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">newGame&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">moves&lt;/span>.&lt;span style="color:#a6e22e">clear&lt;/span>();
};
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we've got a bug - the &lt;code>newGame&lt;/code> function doesn't clear the &lt;code>ChessManager&lt;/code>'s moves, it just throws a null reference exception. But we could use this class in our code. In theory if we keep on calling &lt;code>makeMove&lt;/code> we'll just grow and grow the &lt;code>moves&lt;/code> array. This is a bug leading to memory that can't be freed, even though we don't need it.&lt;/p>
&lt;p>That's a contrived example of a JavaScript memory leak.&lt;/p>
&lt;blockquote>
&lt;p>When we are finished with memory but don't allow the garbage collector to clean it up, that's a memory leak.&lt;/p>
&lt;/blockquote>
&lt;p>At least for the purposes of this discussion. We'll see it's a very easy thing to do.&lt;/p>
&lt;h3 id="why-is-a-memory-leak-bad">Why is a Memory Leak bad?&lt;/h3>
&lt;p>It might seem obvious but let's just make sure we're explicit with everything. As we said in the initial definition, we allocate memory but don't deallocate it.&lt;/p>
&lt;p>In &lt;em>some&lt;/em> circumstances, this is not necessarily a disaster, if we don't leak too much too often, but there are circumstances where this is very serious.&lt;/p>
&lt;p>Memory leaks cause performance problems, slow down applications and can lead to a process terminating. There are some times when that's really not good.&lt;/p>
&lt;p>Servers and high performance applications shouldn't leak, especially as many should be expected to run for long periods of time. Mobile apps or apps for embedded systems will need to deal with fewer resources and will suffer if they leak. Any application an end user is expecting to use for a long time will cause a lot of frustration if it leaks.&lt;/p>
&lt;p>That's enough theory, let's actually start looking at identifying memory leaks in the context of an AngularJS application.&lt;/p>
&lt;h2 id="identifying-memory-leaks">Identifying Memory Leaks&lt;/h2>
&lt;p>I've created a sample app for showing photo albums which is leaky in parts. The app is at:&lt;/p>
&lt;p>&lt;a href="http://dwmkerr.github.io/angular-memory-leaks/">dwmkerr.github.io/angular-memory-leaks&lt;/a>&lt;/p>
&lt;p>It's a very basic app with a fairly common set of components; Bootstrap, jQuery and AngularJS. We're going to take a look at how we can identify whether this app suffers from memory leaks.&lt;/p>
&lt;p>You can run the app in your browser, or run it locally with the commands:&lt;/p>
&lt;pre>&lt;code>git clone https://github.com/dwmkerr/angular-memory-leaks.git
cd angular-memory-leaks
npm install &amp;amp;&amp;amp; bower install
gulp
&lt;/code>&lt;/pre>&lt;p>Running gulp will serve the app, lint, and reload the browser when you change the code. The project page is at &lt;a href="https://github.com/dwmkerr/angular-memory-leaks">github.com/dwmkerr/angular-memory-leaks&lt;/a>.&lt;/p>
&lt;h3 id="method-1-the-wrong-way">Method 1: The Wrong Way&lt;/h3>
&lt;p>First, just be aware that the wrong way to look for leaks is by examing the memory usage of the Chrome process. While an increasing amount of memory usage &lt;em>can&lt;/em> indicate a leak, it is not reliable. Why?&lt;/p>
&lt;p>Well browsers can allocate memory and use it how they want to. A page it is rendering may no longer need as much memory as it needed before, but that doesn't mean the browser needs to release it to the OS. It may just keep it to avoid having to re-allocate it later on.&lt;/p>
&lt;h3 id="method-2-the-timeline">Method 2: The Timeline&lt;/h3>
&lt;p>Open the Chrome developer tools. Go to &amp;lsquo;Timeline&amp;rsquo; select &amp;lsquo;Memory&amp;rsquo; and hit &amp;lsquo;Record&amp;rsquo;.&lt;/p>
&lt;p>&lt;img src="images/StartRecording.png" alt="Start Recording">&lt;/p>
&lt;p>Now start using your application. After you are done, stop recording. You'll see a graph of memory usage.&lt;/p>
&lt;p>&lt;img src="images/MemoryUsage.png" alt="Memory Usage">&lt;/p>
&lt;p>This is &lt;strong>almost&lt;/strong> exactly what we need. I'll explain the almost shortly, but lets take a look at this graph.&lt;/p>
&lt;ol>
&lt;li>We see a &lt;em>Used JS Heap&lt;/em> in blue. &lt;em>Used&lt;/em> is important here - Chrome is telling us that there may be more heap usage than shown in its actual process, but what we are seeing here is what is actually used by the page.&lt;/li>
&lt;li>We see documents (in this case a steady value of one document).&lt;/li>
&lt;li>We see DOM nodes. As I use the app the nodes increase, up until a certain point and then they drop.&lt;/li>
&lt;li>We see Listeners (i.e. even handlers). Again, these increase as I use the app and then drop.&lt;/li>
&lt;/ol>
&lt;p>So what should we be looking for in this graph? That depends on what our app is doing. But let's imagine the we are navigating through different photo albums in the albums app. We'll need more memory to see each album, but once we leave an album we don't need that memory any more. So we should get a healthy saw-tooth pattern&lt;sup>&lt;a href="#fn3" id="ref3">3&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/TimelineSawtooth.png" alt="Timeline Sawtooth">&lt;/p>
&lt;p>Here we see that we use more and more memory, up until the point that Chrome garbage collects, then goes back to where we started. This is repeated again and again. This is a good sign - when Chrome garbage collects we go back to the same place we started, a strong indication we are not leaking much memory.&lt;/p>
&lt;p>If we are doing some work which simply needs more and more memory, and we don't release it, we would expect to see steps instead&lt;sup>&lt;a href="#fn4" id="ref4">4&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/TimelineSteps-1.png" alt="Timeline Steps">&lt;/p>
&lt;p>An example of this might be an infinite scroll situation. I'm looking through a vast photo album, and when I get to the bottom of the screen I load more images automatically. The ones I've loaded are still in the DOM so cannot be released. We see no saw-tooth because there's no release of memory. However, this is not a memory leak - it's just increasing memory usage. It does mean that if we allow the user to scroll too much we may run out of resources though.&lt;/p>
&lt;p>The &lt;strong>dangerous&lt;/strong> case is the one below:&lt;/p>
&lt;p>&lt;img src="images/TimelineLeakySawtooth.png" alt="Leaky Sawtooth">&lt;/p>
&lt;p>Let's imaging we're using the application, navigating through albums, returning the the home page, looking through some more albums and so on. We keep using memory, and Chrome keeps on garbage collecting, but we never quite get back to where we started. We are trending towards increasing memory usage. This indicates we &lt;em>might&lt;/em> be leaking memory.&lt;/p>
&lt;p>&lt;em>Might&lt;/em> is not going to cut the mustard, we need to know categorically what is going on and whether we have a leak.&lt;/p>
&lt;blockquote>
&lt;p>You said this is &amp;lsquo;almost&amp;rsquo; exactly what we need?&lt;/p>
&lt;/blockquote>
&lt;p>Unfortunately, you cannot always trust this graph. See Mystery 1 for the ugly details. Suffice to say that what we're seeing here is an indicator only, but for more detail we need to look at Method 3.&lt;/p>
&lt;h3 id="method-3-recording-heap-allocations">Method 3: Recording Heap Allocations&lt;/h3>
&lt;p>Let's look at a different way of seeing if we've got a leak, the &amp;lsquo;Heap Allocations&amp;rsquo; view. In the developer tools, go to &amp;lsquo;Profiles&amp;rsquo; and &amp;lsquo;Record Heap Allocations&amp;rsquo;:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocations.png" alt="Record Heap Allocations">&lt;/p>
&lt;p>When we record heap allocations we get a chart showing us spikes as we allocate memory. These spikes are initially blue (meaning Chrome is using the memory), then change to grey once the memory is freed. If we see spikes or sections of spikes that remain blue, we may have a problem.&lt;/p>
&lt;p>Try this, go to the Ablums app and start recording. Click on the &amp;lsquo;India&amp;rsquo; album, then go back to the home page. You should see a chart like this:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx1.png" alt="Heap Allocations Example 1">&lt;/p>
&lt;p>So we start recording and nothing is being allocated. Then we click on the &amp;lsquo;India&amp;rsquo; album (point 1) and we get a few spikes, as chrome allocates memory needed for the content in the new page. Then we click back on the home page (point 2). Some of the memory used in the India album is released (it looks like about half). One spike of memory used for the home page is still in use (what we'd expect) and another spike or two seem to be freed. These other spikes might be memory used for the actual transition, for example in logic in the router.&lt;/p>
&lt;p>So this looks like we may have a problem in the album page. In fact, we can drag a selection box around those first three spikes and see what is &lt;em>still&lt;/em> in memory (i.e. what might be a potential leak) in the view below:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx2.png" alt="Heap Allocations Example 2">&lt;/p>
&lt;p>Dissecting this view we have:&lt;/p>
&lt;ol>
&lt;li>A subset of the data, the blue spike from the album page which is still in use.&lt;/li>
&lt;li>The &amp;lsquo;Heap View&amp;rsquo;, which shows us different &lt;em>types&lt;/em> of data in memory. Don't worry, we'll see a lot more on this later.&lt;/li>
&lt;li>An instance of a specific type of data, in this case an instance of a JavaScript object.&lt;/li>
&lt;li>The retainers graph for the specific object.&lt;/li>
&lt;/ol>
&lt;p>We're going to look into what all of this means in a lot of detail as we go through the article. For now, I'll simply state what we're seeing, by the end of the article you'll be able to analyse this (and much more) yourself.&lt;/p>
&lt;p>In this snapshot we see a small amount of data still in use. A quick look through the data reveils we have data still in use which relats to the AngularJS template cache.&lt;/p>
&lt;p>This is good! It means this is probably not a leak. When I first visit the album page AngularJS is caching the template used to render it, so of course it stays in memory.&lt;/p>
&lt;blockquote>
&lt;p>When analysing memory usage remember that caching, preloading and other optimisation techniques may cause some noise.&lt;/p>
&lt;/blockquote>
&lt;p>So if we have the albums page in a cache, in theory the next time we visit the page and then return to the home page, we should free a lot more of the memory (because the &lt;em>new&lt;/em> memory we allocate will be just for the page itself, not the cache which is already set up). Let's try it. We'll record going to the album page, back to the homepage, then the album page and back again:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx3.png" alt="Heap Allocations Example 3">&lt;/p>
&lt;p>This is looking good.&lt;/p>
&lt;ol>
&lt;li>We go to the &amp;lsquo;India&amp;rsquo; album. Some memory used is now freed, but much is still in use. As we saw, at least some of that is the template cache.&lt;/li>
&lt;li>We go back to the home page, lots of memory is used but by the time we're done recording it's almost entirely freed.&lt;/li>
&lt;li>We visit the India album a second time, requiring some memory almost all of which is freed.&lt;/li>
&lt;li>We go back to the home page. Some memory is used during the transition and to render the page, some of that is still in use (which is expected as the page is still open).&lt;/li>
&lt;/ol>
&lt;p>The heap allocations chart is exceptionally useful in identifying memory leaks, it has already led to some insights:&lt;/p>
&lt;ol>
&lt;li>Initial loading of pages increases our &amp;lsquo;baseline&amp;rsquo; memory footprint due to data being added to caches (such as the AngularJS template cache).&lt;/li>
&lt;li>Subsequent loading of pages requires memory, but the vast majority of it is freed.&lt;/li>
&lt;/ol>
&lt;p>One thing we noticed from this brief analysis was that the initial result was slightly misleading. With the heap allocations view repeated operations can help you identify trends. In the Albums application I've actually set up part of the app to run repeated operations, so we can try to consistently test scenarions. The &amp;lsquo;scenarios&amp;rsquo; menu lets us run them. Let's try running scenario 1.&lt;/p>
&lt;p>&lt;img src="images/Scenario1.png" alt="Scenario 1">&lt;/p>
&lt;p>This scenario will navigate from &lt;code>/&lt;/code> (the home page) to &lt;code>/nowhere&lt;/code> ten times. &lt;code>/nowhere&lt;/code> isn't matched by the router so takes us back to the home page. This has the effect of reloading the home page 20 times (just reloading doesn't work, the router is smart enough to realise we're staying on the same page).&lt;/p>
&lt;p>&lt;img src="images/Scneario1HeapAllocations.png" alt="Scenario 1 Heap Allocations">&lt;/p>
&lt;p>While you are recording the chart you can see peaks go from blue to grey as memory is freed. Let's see what we've got.&lt;/p>
&lt;ol>
&lt;li>Shows our first navigation, some memory is not freed. Everything before this is setup code.&lt;/li>
&lt;li>Our last navigation. Some memory still in use (as expected).&lt;/li>
&lt;li>A glance at memory in use shows some compiled code and system data (more on this later). At this stage we don't need to worry, Chrome will allocate data like this when it needs to.&lt;/li>
&lt;li>It looks like the 11th page load didn't free all of it's memory. This is potential cause for worry.&lt;/li>
&lt;/ol>
&lt;p>Altogether this a very healthy looking scenario. The huge majority of what we allocate is freed, as we would hope. Small amounts of memory stay in use (mostly used under the hood by Chrome) and a small amount of memory after the 11th reload is not freed (a quick look suggests a timing issue, definitely something we'd want to investigate further in a real-world app). Our allocations are in the 50 KB to 100 KB range and we're looking good.&lt;/p>
&lt;p>Before we say goodbye to the Heap Allocations view (for now) let's do the same for Scenario 2 (moving from the home page to the top rated page 10 times).&lt;/p>
&lt;p>&lt;img src="images/Scenario2HeapAllocations.png" alt="Scenario 2 Heap Allocations">&lt;/p>
&lt;p>We are not going to analyse this issue (yet!) but this is an example of a much less healthy chart. In this chart we seem to be allocating memory for each page view and not releasing it. This kind of chart definitely indicates that there could be problems.&lt;/p>
&lt;p>So we've seen the Heap Allocations view, which is a bit more sophisticated than the memory usage graph. Let's look at the last way to analyse memory leaks - snapshots.&lt;/p>
&lt;h3 id="method-4-heap-snapshots">Method 4: Heap Snapshots&lt;/h3>
&lt;p>The final method of identifying memory leaks is the most sophisticated and finely controlled. We will take snapshots at specific points in time and analyse the differences between them. To take a snapshot, we go to the Profiles view and choose &amp;lsquo;Take Heap Snapshot&amp;rsquo;:&lt;/p>
&lt;p>&lt;img src="images/TakeHeapSnapshot.png" alt="Take Heap Snapshot">&lt;/p>
&lt;p>When we take a heap snapshot Chrome simply records the details of all memory allocated.&lt;/p>
&lt;blockquote>
&lt;p>Remember: Taking a Snapshot &lt;strong>always&lt;/strong> runs garbage collection first.&lt;/p>
&lt;/blockquote>
&lt;p>A heap snapshot shows you exactly the same kind of data you get in the Heap Allocations view, except that you are seeing ALL memory in use, not just objects which were allocated and are still alive:&lt;/p>
&lt;p>&lt;img src="images/HeapSnapshot1.png" alt="A Heap Snapshot">&lt;/p>
&lt;p>This view is very complete but not necessarily very useful. There's some extra ways to see the data (if you change from &amp;lsquo;Summary&amp;rsquo; to another view or change &amp;lsquo;All Objects&amp;rsquo; but we'll see that later).&lt;/p>
&lt;p>Staying on topic, we'll not yet look in detail at what the data is that we are seeing, we'll first look into identifying whether there are memory leaks - then we'll look into tracking them down.&lt;/p>
&lt;p>Indivdiual snapshots are not so helpful for checking for leaks, but what is very helpful is the ability to compare memory used between snapshots.&lt;/p>
&lt;p>Let's take some snapshots, try this:&lt;/p>
&lt;ol>
&lt;li>Open the app.&lt;/li>
&lt;li>Navigate to the top rated page (caches should now be set up).&lt;/li>
&lt;li>Navigate to the home page. Take a snapshot.&lt;/li>
&lt;li>Navigate to the top rated page. Take a snapshot.&lt;/li>
&lt;li>Navigate to the home page. Take a snapshot.&lt;/li>
&lt;/ol>
&lt;p>Now we can do something really cool. Select snapshot 3, and choose to view data allocated between snapshot 1 and 2. This means we're seeing data allocated for the top rated page, which is &lt;em>still&lt;/em> in use when we go back to the home page, i.e. probably leaked.&lt;/p>
&lt;p>&lt;img src="images/SnapshotComparison.png" alt="Snapshot Comparison">&lt;/p>
&lt;p>So what are we seeing now?&lt;/p>
&lt;ol>
&lt;li>We have three snapshots. The size of each one is shown. &lt;em>Sometimes&lt;/em> the very first one seems overly high. See Mystery 2. We have selected the 3rd snapshot and are therefore only able to see data still present in this snapshot.&lt;/li>
&lt;li>We are chosing to show only objects allocated between Snapshot 1 and 2, i.e. objects allocated to present the page. But we're &lt;strong>in&lt;/strong> snapshot 3, so we're seeing those objects which were allocated and are still present.&lt;/li>
&lt;li>Objects allocated are looking suspicious - we've got DOM elements. This doesn't look good!&lt;/li>
&lt;/ol>
&lt;p>This is the best way to identify memory leaks. So now that we've seen how to identify whether we have memory leaks, or at least that we have a potential problem to analyse we can move onto step 2 - Analysing Memory Leaks.&lt;/p>
&lt;h2 id="analysing-memory-leaks">Analysing Memory Leaks&lt;/h2>
&lt;p>If we think we have a memory leak, we need to be able to look at the heap data and see what's going on. Whether we are seeing heap data from a selection of allocations from the Heap Allocations view or from the Heap Snapshots, we see the same kind of information:&lt;/p>
&lt;p>&lt;img src="images/HeapData.png" alt="Heap Data">&lt;/p>
&lt;p>Starting from the left we have the &amp;lsquo;Constructor&amp;rsquo; column. This is the type of object we have. Some of these objects we can see are JavaScript classes (constructed with a &lt;code>new&lt;/code> call to a function), such as &lt;code>Scope&lt;/code>. As well as our own classes, we have some special classes of data:&lt;/p>
&lt;ul>
&lt;li>(compiled code): Represents JavaScript code compiled by Chrome. Consider this internal - we have no control over it.&lt;/li>
&lt;li>(array): Internally used array object. Again, internal.&lt;/li>
&lt;li>Array: A JavaScript array. Often we have a &lt;em>lot&lt;/em> of data in arrays.&lt;/li>
&lt;li>Object: A plain old JavaScript object.&lt;/li>
&lt;li>(closure): A closure.&lt;/li>
&lt;li>system / Context: The underlying data require to call a function, for example the actual data used by a closure.&lt;/li>
&lt;li>system: Internally used data.&lt;/li>
&lt;/ul>
&lt;p>There are also plenty of objects that are created by Chrome, such as &lt;code>HTMLDivElement&lt;/code>, which is a wrapper around the internally used (native) DOM object.&lt;/p>
&lt;p>Let's dissect some of these objects in detail. Running &lt;strong>Scenario 3&lt;/strong> allocates some data and puts it on the &lt;code>window&lt;/code> object. This is really trivial data but shows a lot. You can use the Heap Allocations View or Heap Snapshots to see the data. I've taken three snapshots (once before pressing OK, once after the data is allocated, and the final one when the last modal is closed):&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis2.png" alt="Heap Data Analysis Part 1">&lt;/p>
&lt;p>This data has come from the code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// Create a class which will hold heap data. Makes it easier
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to find the data in Chrome.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">HeapData&lt;/span>() {}
&lt;span style="color:#75715e">// Create a heap data object.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">HeapData&lt;/span>();
&lt;span style="color:#75715e">// Create a function that multiplies two numbers.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">multiply&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>, &lt;span style="color:#a6e22e">b&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#a6e22e">b&lt;/span>;
}
&lt;span style="color:#75715e">// Create a &amp;#39;multiply by&amp;#39; function, which curries the above
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to generate a function which multiplies by a constant. This
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// will involve closures.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">b&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">multiply&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>, &lt;span style="color:#a6e22e">b&lt;/span>);
}
};
&lt;span style="color:#75715e">// Add some data to our heap data object.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">fry&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Philip J. Fry&amp;#34;&lt;/span>;
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">zoidberb&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;John &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Zoidberg&amp;#34;&lt;/span>;
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">character&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">firstName&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Amy&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">secondName&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Wong&amp;#34;&lt;/span>
};
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#66d9ef">double&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span>(&lt;span style="color:#ae81ff">2&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multiplyBy100&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span>(&lt;span style="color:#ae81ff">100&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">doubledNumber&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#66d9ef">double&lt;/span>(&lt;span style="color:#ae81ff">18&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multipliedNumber&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multiplyBy100&lt;/span>(&lt;span style="color:#ae81ff">15&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">div&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">createElement&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;div&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Put the heap data on the window, it is now pinned to a GC root.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>window.&lt;span style="color:#a6e22e">heapData&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've got a little bit of everything here, some code, some closures, some objects and a DOM element.&lt;/p>
&lt;p>As we've put most of this data on the &lt;code>heapData&lt;/code> object, which is an instance of &lt;code>HeapData&lt;/code> we can easily find the object:&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis3.png" alt="Heap Data Analysis 3">&lt;/p>
&lt;p>So we can see the &lt;code>HeapData&lt;/code> constructor, expanding it we see an &lt;em>instance&lt;/em> of &lt;code>HeapData&lt;/code>. The &lt;code>@420269&lt;/code> is a unique ID assigned by Chrome. If we have lots of heap data objects, we can use this to distinguish between them when we're looking at other parts of the snapshot. What else do we see?&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Distance&lt;/strong>. How far the instance is from a GC Root. A GC root is anything that can &amp;lsquo;pin&amp;rsquo; objects, for example the &lt;code>window&lt;/code> object which holds globals. If put something on &lt;code>window&lt;/code> it will never be freed, this is what makes it a GC root. Our distance is 2 as we have &lt;code>HeapData&lt;/code> (constructor) to &lt;code>heapData&lt;/code> (instance) to &lt;code>window&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Objects count&lt;/strong>. Only valid for the top level nodes, this shows us how many objects of the specified type we have. We have 1 &lt;code>HeapData&lt;/code> object.&lt;/li>
&lt;li>&lt;strong>Shallow Size&lt;/strong>. The size of the data that is directly allocated for the object. Compare this to &lt;em>Retained Size&lt;/em>.&lt;/li>
&lt;li>&lt;strong>Retained Size&lt;/strong>. The size of data this object is retaining. For example, out &lt;code>heapData&lt;/code> instance holds a reference to an object which contains two fields &lt;code>firstName&lt;/code> and &lt;code>secondName&lt;/code>. Our shallow size includes enough data for the reference, the retained size includes the full retained size of the retained object.&lt;/li>
&lt;/ol>
&lt;p>Notice that our instance of &lt;code>HeapData&lt;/code> is highlighted in yellow? That's a convenience from Chrome, it's showing us objects which are &lt;strong>directly accessible&lt;/strong> from JavaScript. Our object can be accessed via &lt;code>window.heapData&lt;/code>, therefore it's directly accessible. Other objects we've created might not be (for example, a variable used in a closure exists and is on the heap, but not directly accessible).&lt;/p>
&lt;p>Let's see some other data we allocated:&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis4-1.png" alt="Heap Data Analysis 4">&lt;/p>
&lt;p>Now we're looking at closures. We have two closures in yellow next to each other, clicking on one shows the retainer graph. What is going on here?&lt;/p>
&lt;ol>
&lt;li>Our closure is not a simple thing. It has code (of course), which takes up memory. We won't look into this in detail. It has shared function data (again, internally used and not worth looking into). We also have a reference to a &lt;code>__proto__&lt;/code> (a function object has a prototype!). Finally, we have the context, which contains enough data to call the function. If we look in to the context we will not see much, as our function contains numbers which Chrome can simply store in the code. However, if we use references in closures we'll actually see them in the context.&lt;/li>
&lt;li>We also have the retainers. Our closure is referenced via a variable called &lt;code>multiplyBy100&lt;/code>, which itself is referenced by &lt;code>heapData&lt;/code>, which if referenced by the &lt;code>window&lt;/code> GC root.&lt;/li>
&lt;li>The &lt;code>multiplyBy100&lt;/code> variable is &lt;em>also&lt;/em> dominated by the second element of an array with id &lt;code>@227339&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>The last thing we'll look at in this snapshot is the div element.&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis5.png" alt="Heap Data Analyis 5">&lt;/p>
&lt;p>We can see the div element is retained by the &lt;code>div&lt;/code> variable in the &lt;code>heapData&lt;/code> object. We can also see it is made up of a prototype and some native object. The native object shows no size - don't be fooled. That just means its taking up no JavaScript heap memory. It is still using memory (just in V8 engine not the JavaScript code).&lt;/p>
&lt;p>What's important to note here is that the element is shown in red. This means it's &lt;strong>detached&lt;/strong>. So it exists, is referenced (and therefore cannot be garbage collected) but is not in the DOM. This is not necessarily a problem, but lots of detached DOM elements is often a bad sign, especially if the number is increasing.&lt;/p>
&lt;p>The rest of the data you can look through yourself. You'll notice some interesting things, such as how concatenated strings work, but the important stuff we've now seen.&lt;/p>
&lt;p>Let's move on to analyising the first potential memory leak we discovered - the transition to the Top Rated page of the albums app.&lt;/p>
&lt;h3 id="analysing-the-leak-in-scenario-2">Analysing the leak in Scenario 2&lt;/h3>
&lt;p>We saw that &lt;strong>Scenario 2&lt;/strong> (switching to and from the &amp;lsquo;top rated&amp;rsquo; view) seemed to leak memory. Let's use the heap snapshot comparison view to analyse this further. The steps are:&lt;/p>
&lt;ol>
&lt;li>Navigate to the home page.&lt;/li>
&lt;li>Navigate to the top rated page (setting up the cache).&lt;/li>
&lt;li>Navigate to the home page, take a snapshot.&lt;/li>
&lt;li>Navigate to the top rated page, take a snapshot.&lt;/li>
&lt;li>Navigate to the home page, take a snapshot.&lt;/li>
&lt;/ol>
&lt;p>We can now look at the memory allocated between 1 and 2 which is present in 3 (i.e. what we allocated for the top rated view and potentially leaked):&lt;/p>
&lt;p>&lt;img src="images/Scenario2Snapshot1.png" alt="Scenario 2 Snapshot 1">&lt;/p>
&lt;p>Some things jump out immediately:&lt;/p>
&lt;ol>
&lt;li>We have gone from 7.5 to 8.4 to 8.5 MB. We are changing from one view to another - and ending in the same place that we started. We &lt;strong>should&lt;/strong> be going back to 7.5 MB.&lt;/li>
&lt;li>We've got a lot of objects still hanging around, not just system data like compiled code, but HTML elements, detached DOM elements, &lt;code>Promise&lt;/code> objects, &lt;code>n.fn.init&lt;/code> objects and so on.&lt;/li>
&lt;/ol>
&lt;p>This looks like a classic leak situation. Let's start by looking at some objects we recognise. There are some &lt;code>Scope&lt;/code> objects near the top of the chart, let's look at those.&lt;/p>
&lt;p>&lt;img src="images/Scenario1Part2.png" alt="Scenario 2 Part 2">&lt;/p>
&lt;p>We've got some &lt;code>Scope&lt;/code> objects, three in fact. These objects contain the usual AngularJS fields such as &lt;code>$parent&lt;/code>, the only field which distinguishes this scope is the &lt;code>album&lt;/code> field. If we look at out &lt;code>aml-rated-album&lt;/code> directive it looks like it could be the isolated scope for this directive:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">.&lt;span style="color:#a6e22e">directive&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;amlRatedAlbum&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">restrict&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;E&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">album&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;=&amp;#34;&lt;/span>
} &lt;span style="color:#75715e">// etc
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This scope has an &lt;code>album&lt;/code> field. There are three albums so it looks likely these are the three albums in the top rated page, the scopes stil in memory. What retains them?&lt;/p>
&lt;p>Looking at the retainers (at &lt;strong>2&lt;/strong>) we don't see much. We're retained by a &lt;code>$$ChildScope&lt;/code>, which also retained by a &lt;code>$$ChildScope&lt;/code> object. In fact we have quite a complex graph of objects.&lt;/p>
&lt;blockquote>
&lt;p>When we leak a scope in AngularJS, we leak a huge graph of objects.&lt;/p>
&lt;/blockquote>
&lt;p>Scopes know about their parents. They also know about their children, and siblings. If we inadvertantly pin a scope to a GC root, we &lt;strong>will probably leak almost all of the scopes in the page&lt;/strong>.&lt;/p>
&lt;p>Why? The graph below should show why. I &amp;lsquo;leak&amp;rsquo; a scope, and by doing so I retain all of the other scopes, because they are connected. Having a connected graph of scopes is required for angular to work, but it means that we we are extremely susceptible to leaking a &lt;strong>lot&lt;/strong> of data.&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph1.png" alt="Scope leak graph">&lt;/p>
&lt;p>This graph shows &lt;code>$parent&lt;/code> retained relationships, but don't forget scopes also know about their children and their siblings, so real graph is even more highly connected.&lt;/p>
&lt;p>So just grabbing a specific scope is not good enough. We need to try and be a little bit more specific. Let's try starting from an element instead. Here we take a look at a div element and its retainers:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part3.png" alt="Scenario 2 Part 3">&lt;/p>
&lt;p>Resting the mouse over the instance of a leaked &lt;code>HTMLElement&lt;/code> shows a bit of data about it, it's a &lt;code>aml-rated-album&lt;/code> and it is detached. Definitely a symptom of our leak. Let's see the retainers:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part4-1.png" alt="Scenario 2 Part 4">&lt;/p>
&lt;p>Ouch. This is nasty. Again, we are not seeing much that is particularly useful. We have a long graph of retainers starting with the &lt;code>compileNode&lt;/code> function, we also have an array in a &lt;code>n.fn.init&lt;/code> function. To cut a long story short, we're are not going to easily find the root cause here. But I will share some hints.&lt;/p>
&lt;blockquote>
&lt;p>jQuery isn't leaking.&lt;/p>
&lt;/blockquote>
&lt;p>We will end up seeing so much jQuery stuff it is natural to wonder whether jQuery is leaking. Almost certainly not. In the graph about &lt;code>n.fn.init&lt;/code> is just a jQuery selector, held onto by &lt;code>$$element&lt;/code>. No surprise - all angular elements are jQuery or jQuery light objects. We've leaked an element, it just happens to be wrapped in a jQuery selector. (You might see a different type of graph, probably due to the jQuery 1 + AngularJS 1.2 combination, we'll see it later).&lt;/p>
&lt;p>You may see low level arrays containing data associated with a scope in jQuery, again, don't worry. It's the jQuery data cache (which we'll also see later), which is associating elements to scopes.&lt;/p>
&lt;p>We can try and work through this graph, but let's try another tack.&lt;/p>
&lt;p>It looks like we're probably leaking the whole of the top rated view. We're probably leaking the main scope for the view, created by the &lt;code>TopRatedController&lt;/code>. Let's see if we can find it.&lt;/p>
&lt;blockquote>
&lt;p>You can find objects you think are leaking by tagging them with classes!&lt;/p>
&lt;/blockquote>
&lt;p>This is a neat trick. Let's add a couple of lines to our top rated controller:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;TopRatedController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$interval&lt;/span>) {
&lt;span style="color:#75715e">// Create a class, assign it to the scope. This&amp;#39;ll help us
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// see if $scope is leaked.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">TopRatedControllerTag&lt;/span>() {}
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">__tag&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">TopRatedControllerTag&lt;/span>();
&lt;span style="color:#75715e">// etc...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now when we run the analysis again, we can search in the snapshot for &lt;code>TopRatedControllerTag&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part5.png" alt="Scenario 2 Part 5">&lt;/p>
&lt;ol>
&lt;li>We search for &amp;lsquo;Tag&amp;rsquo;, finding one instance of the &lt;code>TopRatedControllerTag&lt;/code>.&lt;/li>
&lt;li>Bingo - it is retained by a Scope, with id &lt;code>@534851&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>Let's look at this scope in more detail. Right click on it and choose &amp;lsquo;Review in Summary View&amp;rsquo;, so we can see what is retaining it:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part6.png" alt="Scenario 2 Part 6">&lt;/p>
&lt;ol>
&lt;li>We can now see the root scope for the actual view.&lt;/li>
&lt;li>We can see the usual pattern of &lt;code>$$ChildScope&lt;/code> and &lt;code>$parent&lt;/code> properties, but what else have we got?&lt;/li>
&lt;/ol>
&lt;p>Intestingly we can see that our scope is also retained by a &lt;strong>context variable called $scope&lt;/strong>. How do I know it is a context variable? It's in blue, part of the colour coding (see Mystery 3).&lt;/p>
&lt;p>What is a context variable?&lt;/p>
&lt;blockquote>
&lt;p>A &lt;strong>closure&lt;/strong> is a function which refers to a variable outside of its definition. A &lt;strong>context variable&lt;/strong> is the variable stored in a function context. A &lt;strong>function context&lt;/strong> contains the environment for a closure, which is the data required to execute it.&lt;/p>
&lt;/blockquote>
&lt;p>So basically we have a closure which refers to a variable called &lt;code>$scope&lt;/code>, which is the root scope of our view. We can see in detail the closure:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part7.png" alt="Scenario 2 Part 7">&lt;/p>
&lt;ol>
&lt;li>&lt;code>$scope&lt;/code> is retained by a &lt;code>context&lt;/code> for a closure.&lt;/li>
&lt;li>The closure is in the &lt;code>refresh&lt;/code> function (this is why the &lt;code>context&lt;/code> is retained by &lt;code>refresh&lt;/code>).&lt;/li>
&lt;/ol>
&lt;p>We can open the function and examine it for issues. There's an &lt;code>$http.get&lt;/code> which has as closure which uses &lt;code>$scope&lt;/code>, but alarmingly there is an &lt;code>$interval&lt;/code> registered to run every 10 seconds, which is never deregistered. The interval callback uses another &lt;code>$http.get&lt;/code>, with a closure that uses &lt;code>$scope&lt;/code>. This is the problem.&lt;/p>
&lt;p>A simple timeout we forgot to deregister has a closure on &lt;code>$scope&lt;/code>. &lt;code>$scope&lt;/code> can therefore never be cleaned up, because it is retained by a context.&lt;/p>
&lt;p>Some important takeaways:&lt;/p>
&lt;ol>
&lt;li>The framework hides implementation details. Often useful, but in this case it made finding the leak a problem.&lt;/li>
&lt;li>This example seems contrived, but how how often do you have a closure using &lt;code>$scope&lt;/code> in a controller? In real world apps all of the time time, callbacks to ajax requests, event handlers, promise functions etc.&lt;/li>
&lt;li>A leak of a small object that contains the &lt;strong>data&lt;/strong> for three albums has leaked a &lt;strong>large graph&lt;/strong> of other objects, and even &lt;strong>DOM elements&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Leaks are not incremental. You don't get an accumulation of small leaks, one small leak can retain a huge graph.&lt;/p>
&lt;/blockquote>
&lt;p>Let's talk about this a bit more.&lt;/p>
&lt;h3 id="dealing-with-object-graphs">Dealing with Object Graphs&lt;/h3>
&lt;p>We saw before that a chain of retainers can pin an object, such as a scope, to a GC root. We also saw that AngularJS scopes are part of a highly connected graph, meaning that if we leak part of it, we probably leak it all:&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph1-1.png" alt="Scope Leak Graph 1">&lt;/p>
&lt;p>However, things can get worse. Remember how in an angular app you can get the scope for an element with &lt;code>$(selector).scope()&lt;/code>? This connection between a scope an an element is maintained in the jQuery data cache. This lets us associate arbitrary data with an element. This introduces another layer of connectivity:&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph2.png" alt="Scope Leak Graph 2">&lt;/p>
&lt;p>In this graph, we see the jQuery data cache entries (in grey) associating DOM elements to scopes, introducing more connectivity.&lt;/p>
&lt;p>We can see here an alarming increase in the size and potential complexity of the graph. We've got DOM elements in play now. The chances are that if you are reading this you are dealing with a memory leak in your app, if it's noticable enough for you to deal with it, you probably have a non-trivial graph.&lt;/p>
&lt;p>So how do we fix memory leaks? I'll show three general approaches and how to use each one.&lt;/p>
&lt;h2 id="fixing-memory-leaks">Fixing Memory Leaks&lt;/h2>
&lt;p>Fixing memory leaks is hard. As we have seen our problem is highly connected graphs. If we have a part of the graph we want to free for garbage collection (such as a scope and all of it's children, such as a view or directive) then we must not retain that graph of objects. This means if you have (for example) three problems that lead to retaining a graph, you have to fix &lt;strong>all of the problems&lt;/strong> before the leak goes away.&lt;/p>
&lt;p>Let's generalise the best practices first into three rules, see patterns we should follow for each of them and then look at anti-patterns to avoid.&lt;/p>
&lt;h3 id="three-golden-rules">Three Golden Rules&lt;/h3>
&lt;blockquote>
&lt;p>Rule 1: Understand the framework and lifecycle.&lt;/p>
&lt;/blockquote>
&lt;p>If you are using a framework like AngularJS, you &lt;strong>must&lt;/strong> understand the lifecycle of the objects you are dealing with. Unless you understand how the framework tries to clean up, you may make mistakes that stop it from working.&lt;/p>
&lt;blockquote>
&lt;p>Rule 2: Be careful at the interface between short and long lived objects.&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you see an interface between a short and long lived object, be extra careful. For example, if you have a directive talking to a service, make sure the service cannot retain the directive through closures, callbacks or any references. Services will last for the lifetime of the application, so they are the sort of object which can inadvertantly retain short lived objects.&lt;/p>
&lt;p>Other long lived objects exist but may be more subtle, the interface between AngularJS and other libraries can be a risky area, if other libraries maintain long lived state.&lt;/p>
&lt;p>Finally, consider this. The isolated scope for a directive (for example) may inadvertantly be long lived - if it is leaked. That leads us to Rule 3.&lt;/p>
&lt;blockquote>
&lt;p>Rule 3: Disconnect the graph.&lt;/p>
&lt;/blockquote>
&lt;p>You can be defensive by manually disconnecting graphs of objects. This can aid if you have a memory leak you cannot resolve. By disconnecting the graph, the garbage collector will at least be able to attempt to clean up parts of it.&lt;/p>
&lt;p>AngularJS should attempt to do this for you, for example when scopes are destroyed the links to other scopes are severed. But you can also do this yourself. Disconnecting the graph is not always as simple as emptying arrays or nulling objects, it can mean nulling closures and context variables too&lt;sup>&lt;a href="#fn5" id="ref5">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>The anti-patterns which follow are all violations of these rules.&lt;/p>
&lt;h3 id="anti-patterns-to-avoid">Anti-Patterns to Avoid&lt;/h3>
&lt;p>Whether or not your app is suffering from memory leaks, avoid these patterns.&lt;/p>
&lt;h4 id="poorly-managed-event-handlers">Poorly Managed Event Handlers&lt;/h4>
&lt;p>Consider a trivial example in a directive link:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">scope&lt;/span>, &lt;span style="color:#a6e22e">element&lt;/span>, &lt;span style="color:#a6e22e">attrs&lt;/span>) {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;click&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">selected&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
});
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We register an event handler. We've now built a closure which will have a context, which retains the &lt;code>scope&lt;/code>. If we don't deregister this event handler, we retain the closure, the context, the scope, and then basically everything in the universe.&lt;/p>
&lt;p>&lt;strong>The Fix&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">scope&lt;/span>, &lt;span style="color:#a6e22e">element&lt;/span>, &lt;span style="color:#a6e22e">attrs&lt;/span>) {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;click&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">selected&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
});
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;$destroy&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">off&lt;/span>(); &lt;span style="color:#75715e">// deregister all event handlers
&lt;/span>&lt;span style="color:#75715e">&lt;/span> })&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>Note:&lt;/em> Angular &lt;em>should&lt;/em> handle this. It is supposed to deregister event handlers on elements it manages. In my experience this isn't always the case, although it seems cases when this doesn't happen are fewer and fewer as bugs get fixed in the framework. Anyway, Rule 3 - disconnect.&lt;/p>
&lt;h4 id="poorly-managed-watchers">Poorly Managed Watchers&lt;/h4>
&lt;p>Watchers or angular event handlers, basically the same as above.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;someEvent&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">refresh&lt;/span>();
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, Angular should clean this up if you forget to, but the advice is always do it yourself. Angular watchers return a deregister function.&lt;/p>
&lt;p>&lt;strong>The Fix&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">cleanup&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;someEvent&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">refresh&lt;/span>();
});
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;$destroy&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">cleanup&lt;/span>();
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Rule 1 - know the framework and how lifecycle is handled. &lt;code>$destroy&lt;/code> is sent to a scope specifically to allow it to be cleaned up.&lt;/p>
&lt;h4 id="callback-functions-on-services">Callback Functions on Services&lt;/h4>
&lt;p>Services (or other long lived objects) should typically not take callback functions. Imagine a &amp;lsquo;user service&amp;rsquo;, allowing a scope to discover if the user has changed their name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">UserService&lt;/span>.&lt;span style="color:#a6e22e">onNameChange&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">newName&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">userName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">newName&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the service (a long lived object) takes a closure with a context to a short lived object, the scope. Unless the service is written absolutely correctly, we run the risk of the service retaining the scope. Remember, services are singletons and as such the interface between services and scopes is one that requires careful management.&lt;/p>
&lt;p>There are two fixes I would suggest.&lt;/p>
&lt;p>&lt;strong>Fix 1: For a one-off operation, use a promise&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// change and name and wait for the result
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">UserService&lt;/span>.&lt;span style="color:#a6e22e">changeName&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Fry&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">newName&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">newName&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The notification service returns a promise (a short lived object) which holds the closure. If we get things wrong, we are less likely to leak the scope. Plus, promises are typically easy to work with once you've got the hang of them&lt;sup>&lt;a href="#fn6" id="ref6">6&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;strong>Fix 2: For notifications, use broadcasts&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// more like our original example
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NotificationService:ChangeName&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">data&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">data&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Some will say to not overuse broadcasts as they can be expensive. They can, so use them judiciously. But remember, they're provided by the framework, typically lead to fairly loose coupling and are probably managing clean up as well or better than a hand-rolled mechanism in a service. Rule 2 - don't tie short lived objects to long lived objects.&lt;/p>
&lt;h2 id="the-future">The Future&lt;/h2>
&lt;p>That's a wrap. Hopefully this article will grow and improve with feedback from the community. To wind up, lets look at a few things that are on their way which will touch on these issues.&lt;/p>
&lt;h3 id="weak-maps">Weak Maps&lt;/h3>
&lt;p>Finally, in ECMAScript 6 we will get a WeakMap&lt;sup>&lt;a href="#fn7" id="ref7">7&lt;/a>&lt;/sup> object. This is &lt;em>ideal&lt;/em> for something like the jQuery data cache. A weak map uses weak references (not natively supported in JavaScript). This means that we can map a DOM element to a scope in a weak map, but the map entry doesn't retain the element or scope. If the element or scope is cleaned up, the map entry is removed. This means internal structures to aid with frameworks don't need to necessarily retain object graphs.&lt;/p>
&lt;h3 id="angularjs-2">AngularJS 2&lt;/h3>
&lt;p>Simplifications to the framework in 2.0 and usage of native features like web components mean less complex framework code and less scope for issues. Consider even the usage of classes in Angular 2.0. We don't decorate a scope object (of type &lt;code>Object&lt;/code>) we create an instance of a class. Easier to see in the heap view.&lt;/p>
&lt;h3 id="even-better-browsers">Even Better Browsers&lt;/h3>
&lt;p>SPA frameworks are driving improvements to browsers. Frameworks like Angular lead to more SPAs. More SPAs mean we find more bugs and edge cases in browsers. Many memory leak issues in AngularJS have led to fixes in V8.&lt;/p>
&lt;h2 id="appendices">Appendices&lt;/h2>
&lt;p>Beware any write up long enough to need appendices.&lt;/p>
&lt;h3 id="thanks">Thanks&lt;/h3>
&lt;p>Much of my understanding here came from working with others on real-world issues. I would like to thank the following people for their advice and insights:&lt;/p>
&lt;p>James Denning, Shaun Bohannon, Arnaud Rebts, Colin Montgomery, Jon Hamshaw, Christian Lilley, Maarten De Wilde&lt;/p>
&lt;p>There are others I have worked on with in this area, if I have forgotten to mention you please let me know.&lt;/p>
&lt;h3 id="mysteries">Mysteries&lt;/h3>
&lt;p>After a large amount of time spent investigating memory leaks, there are still some things which to me are a mystery. If anyone can shed some light, I'd be interested to know.&lt;/p>
&lt;p>&lt;strong>Mystery 1: False Charts&lt;/strong>&lt;/p>
&lt;p>As mentioned earlier we cannot always trust the timeline, it is not uncommon to see the memory usage in the timeline increase, even though the size of snapshots seems to be staying constant. This may be related to AngularJS Issue &lt;a href="https://github.com/angular/angular.js/issues/4864">DOM Nodes Leaking&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Mystery 2: Odd Snapshot Sizes&lt;/strong>&lt;/p>
&lt;p>It is not uncommon for the first snapshot to be large, and then subsequent snapshots to all be a bit smaller (even without any state changes). Why this is the case I do not know. To test, run an angular app and take some snapshots without doing anything in between. You'll normally see (for example) 9 MB, 9MB, 9MB. However, it is not uncommon to see 15 MB, 9MB, 9MB.&lt;/p>
&lt;p>&lt;strong>Mystery 3: Where's the colour coding documentation?&lt;/strong>&lt;/p>
&lt;p>The Chrome documentation states that the colour coding key for elements in the heap snapshot is available in the tool. I can't find it anywhere, so had to research to find the details.&lt;/p>
&lt;h3 id="further-reading">Further Reading&lt;/h3>
&lt;p>Still not had enough? Try these.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/heap-profiling#basics">Profiling Memory Performance&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/memory-analysis-101">Memory Analysis 101&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/heap-profiling-containment">Heap profile containment&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/tips-and-tricks">Dev tools tips &amp;amp; tricks&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/javascript-memory-profiling">JavaScript Memory Profiling&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management">Memory Management&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://addyosmani.com/blog/taming-the-unicorn-easing-javascript-memory-profiling-in-devtools/">Taming the Unicorn&lt;/a>&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>&lt;sup id="fn1">1. This is C actually, but the syntax isn't important, just the logic of what we're doing.&lt;a href="#ref1">↩&lt;/a>&lt;/sup>
&lt;sup id="fn2">2. In JavaScript as in most managed languages, the mechanism by which this happens is reference counting and garbage collection. There's a superb description at &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management">JavaScript Memory Management&lt;/a>.&lt;a href="#ref2">↩&lt;/a>&lt;/sup>
&lt;sup id="fn3">3. Try it yourself with this &lt;a href="http://jsfiddle.net/dwmkerr/2LzxgLb4/">fiddle for a sawtooth pattern&lt;/a>.&lt;a href="#ref3">↩&lt;/a>&lt;/sup>
&lt;sup id="fn4">4. Try it yourself with this &lt;a href="http://jsfiddle.net/dwmkerr/9dmpp5te/">fiddle for a &amp;lsquo;steps&amp;rsquo; pattern&lt;/a>.&lt;a href="#ref4">↩&lt;/a>&lt;/sup>
&lt;sup id="fn5">5. See &lt;a href="https://github.com/dwmkerr/angular-modal-service/commit/79998ca98101798608bdb914aecbd44f3ccbaa7a">this commit&lt;/a> in my Angular Modal Service for an example of how nulling context variables (i.e. disconnecting the graph) solved a memory leak. This is a good example of how are it can be, after large amounts of analysis I still haven't discovered &lt;strong>why&lt;/strong> this was needed, but it solved the problem. It may relate to Mystery 4.&lt;a href="#ref5">↩&lt;/a>&lt;/sup>
&lt;sup id="fn6">6. See my article &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">Promises in AngularJS - The Definitive Guide&lt;/a> if you are not sure how to use them.&lt;a href="#ref6">↩&lt;/a>&lt;/sup>
&lt;sup id="fn7">7. More details at &lt;a href="https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/WeakMap">https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/WeakMap&lt;/a>&lt;a href="#ref7">↩&lt;/a>&lt;/sup>&lt;/p></description><category>CodeProject</category></item><item><title>The Only AngularJS Modal Service You'll Ever Need</title><link>https://dwmkerr.com/the-only-angularjs-modal-service-youll-ever-need/</link><pubDate>Mon, 16 Jun 2014 00:48:12 +0000</pubDate><guid>https://dwmkerr.com/the-only-angularjs-modal-service-youll-ever-need/</guid><description>&lt;p>If you need modals in an AngularJS application, look no further. I'll show you how to use the &lt;a href="https://github.com/dwmkerr/angular-modal-service">Angular Modal Service&lt;/a> to add Bootstrap Modals or your own custom modals to your application.&lt;/p>
&lt;p>&lt;a href="http://jsfiddle.net/dwmkerr/8MVLJ/">See it in a fiddle&lt;/a> or check out &lt;a href="http://dwmkerr.github.io/angular-modal-service">a full set of samples online&lt;/a>.&lt;/p>
&lt;h4 id="contents">Contents&lt;/h4>
&lt;ol>
&lt;li>[Using the Angular Modal Service](#UsingTheAngular ModalService)&lt;/li>
&lt;li>&lt;a href="#AQuickExample">A Quick Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="#DesignGoals">Design Goals&lt;/a>&lt;/li>
&lt;li>&lt;a href="#HowItWorks">How It Works&lt;/a>&lt;/li>
&lt;li>&lt;a href="#WrappingUp">Wrapping Up&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="using-the-angular-modal-service">Using the Angular Modal Service&lt;/h2>
&lt;p>Here's how you can use the Angular Modal Service to add a bootstrap modal to your application.&lt;/p>
&lt;h4 id="step-1-install-with-bower">Step 1: Install with Bower&lt;/h4>
&lt;p>Install the service with bower:&lt;/p>
&lt;pre>&lt;code>bower install angular-modal-service --save
&lt;/code>&lt;/pre>&lt;p>If you don't use bower, just get the source directly from the &lt;a href="https://github.com/dwmkerr/angular-modal-service/tree/master/dst">&lt;code>dst&lt;/code>&lt;/a> folder of the repo.&lt;/p>
&lt;h4 id="step-2-include-the-javascript">Step 2: Include the JavaScript&lt;/h4>
&lt;p>Include the JavaScript from the &lt;code>dst&lt;/code> folder or require it with require.js:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;bower_components\angular-modal-service\dst\angular-modal-service.min.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="step-3-add-it-as-a-dependency">Step 3: Add it as a dependency&lt;/h4>
&lt;p>Make sure the &lt;code>angularModalService&lt;/code> module is listed as a required module for your application:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;myApp&amp;#39;&lt;/span>, [&lt;span style="color:#e6db74">&amp;#39;angularModalService&amp;#39;&lt;/span>]);
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="step-4-show-the-modal">Step 4: Show the Modal&lt;/h4>
&lt;p>Inject &lt;code>ModalService&lt;/code> into any controller, directive or service and call the &lt;code>showModal&lt;/code> function to show a modal:&lt;/p>
&lt;pre>&lt;code class="language-language" data-lang="language">app.controller('SampleController', function($scope, ModalService) {
ModalService.showModal({
templateUrl: &amp;quot;template.html&amp;quot;,
controller: &amp;quot;ModalController&amp;quot;
}).then(function(modal) {
//it's a bootstrap element, use 'modal' to show it
modal.element.modal();
modal.close.then(function(result) {
console.log(result);
});
});
);
&lt;/code>&lt;/pre>&lt;p>This code loads the HTML from &lt;code>template.html&lt;/code>, adds it to the DOM, creates a scope for it and creates an instance of a &lt;code>ModalController&lt;/code>.&lt;/p>
&lt;p>When this is done, the promise returned by the &lt;code>showModal&lt;/code> function resolves and you get a &lt;code>modal&lt;/code> object. This object contains the element created. If it's a Bootstrap modal just call &lt;code>modal&lt;/code> to show it, if it's a custom one you can show it by changing its CSS styles or using whatever APIs are provided. There's an example ofa custom modal in &lt;a href="http://dwmkerr.github.io/angular-modal-service/">the samples&lt;/a>.&lt;/p>
&lt;h4 id="step-5-close-the-modal">Step 5: Close the Modal&lt;/h4>
&lt;p>The controller that is created always has one extra parameter injected into it - a function called &lt;code>close&lt;/code>. Call this function to close the modal, anything you pass to it is passed to the caller as the &lt;code>result&lt;/code> object.&lt;/p>
&lt;pre>&lt;code class="language-language" data-lang="language">app.controller('ModalController', function($scope, close) {
// when you need to close the modal, call close
close(&amp;quot;Success!&amp;quot;);
});
&lt;/code>&lt;/pre>&lt;p>You can pass a number of milliseconds to wait before destroying the DOM element as an optional second parameter to &lt;code>close&lt;/code> - this is useful if the closing of the modal is animated and you don't want it to disappear before the animation completes.&lt;/p>
&lt;h2 id="a-quick-example">A Quick Example&lt;/h2>
&lt;p>Here's a fiddle of the modal service in action:&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/8MVLJ/embedded/result,js,html" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>One thing to note in this examples is that the template is just declared in the DOM - this works fine because the service always checks the template cache before attempting to load it from the server.&lt;/p>
&lt;p>There are more examples at &lt;a href="http://dwmkerr.github.io/angular-modal-service/">dwmkerr.github.io/angular-modal-service&lt;/a>.&lt;/p>
&lt;h2 id="design-goals">Design Goals&lt;/h2>
&lt;p>There are some other services for handling modals out there, notably &lt;a href="https://github.com/Fundoo-Solutions/angularjs-modal-service">Fundoo's Modal Service&lt;/a> and a few others. However, the design goals for my service were slightly different:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>No link to bootstrap&lt;/strong>. Bootstrap modals are complex with lots of options - if you want to use them then that's great, the service should work with them, but the complexity of the options for Bootstrap Modals should not increase the complexity of the service.&lt;/li>
&lt;li>&lt;strong>Extremely simple code&lt;/strong>. It's rare you'll write something that it will suit everyone's need. Rather than trying to please everyone, I want a service that is simple enough to understand so that it can be easily adapted by others.&lt;/li>
&lt;/ol>
&lt;p>So the core goal here is simplicity - if others can understand the code, then they can more effectively decide whether it's what they need, or build upon it.&lt;/p>
&lt;p>With these design goals in mind I built the angular modal service.&lt;/p>
&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>I'm going to walk through a slightly simplified version of the code because it actually illustrates quite a few important concepts when working with AngularJS.&lt;/p>
&lt;p>One of the things that's useful to know is that this service creates a DOM element, builds a scope for it and instantiates a controller for it - what we're doing is &lt;em>very&lt;/em> similar to what AngularJS does behind the scenes when a directive is created.&lt;/p>
&lt;p>So let's dive in. We're going to define a service, so we need a module.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">module&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;angularModalService&amp;#39;&lt;/span>, []);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we have our module, we can define our service. I tend to write services in the form of classes, but this is a personal choice - it's just as valid to return a javascript object that contains functions and data.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ModalService&amp;#39;&lt;/span>, [&lt;span style="color:#e6db74">&amp;#39;$document&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$compile&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$controller&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$http&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$rootScope&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$q&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$timeout&amp;#39;&lt;/span>,
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$document&lt;/span>, &lt;span style="color:#a6e22e">$compile&lt;/span>, &lt;span style="color:#a6e22e">$controller&lt;/span>, &lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$rootScope&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>, &lt;span style="color:#a6e22e">$timeout&lt;/span>) {
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I need a lot of injected components, we'll see why as we continue. I also use the explicit form of the function which takes the parameters as strings - this is the only safe way to write an injected function if you are minifying code.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">body&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$document&lt;/span>.&lt;span style="color:#a6e22e">find&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;body&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">ModalService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I use the &lt;code>$document&lt;/code> object to get the body element, which the modal will be appended to. I then create a class function and record &lt;code>this&lt;/code> as self, so that I can refer to the class instance in callbacks and so on.&lt;/p>
&lt;p>The next part of the code creates a function that will return the template, given either a raw template string or a template url. The reason we wrap this function like this is that the operation will either be synchronous or asynchronous, and I don't want the caller to care. So we use promises to wrap the logic.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">getTemplate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>, &lt;span style="color:#a6e22e">templateUrl&lt;/span>) {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">templateUrl&lt;/span>) {
&lt;span style="color:#a6e22e">$http&lt;/span>({&lt;span style="color:#a6e22e">method&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;GET&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">url&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">templateUrl&lt;/span>, &lt;span style="color:#a6e22e">cache&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>);
});
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;No template or templateUrl has been specified.&amp;#34;&lt;/span>);
}
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If any of this seems confusing, check out my article &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">AngularJS Promises - The Definitive Guide&lt;/a>.&lt;/p>
&lt;p>Now to the main function.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">showModal&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>) {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>showModal&lt;/code> function is going to have to do all sorts of async work - loading the template from the server and so on. So we are going to create a &lt;code>deferred&lt;/code> object and build a promise to return to the caller.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">controller&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">controller&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;No controller has been specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we validate that a controller has been passed in as part of the options. Notice how just like in &lt;code>getTemplate&lt;/code> we use the &lt;code>reject&lt;/code> function to deal with error cases. Again, if error handling with promises seems unfamiliar, check out &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">AngularJS Promises - The Definitive Guide&lt;/a>.&lt;/p>
&lt;p>Next we deal with the template.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">getTemplate&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">template&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">templateUrl&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>) {
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've used the &lt;code>getTemplate&lt;/code> function to get the template, sync or async it doesn't matter, our logic is the same.&lt;/p>
&lt;p>Now we can build a new scope for our modal.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$rootScope&lt;/span>.&lt;span style="color:#a6e22e">$new&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll refer to this a lot later on. Now for some cleverness.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">closeDeferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">inputs&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">$scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span>,
&lt;span style="color:#a6e22e">close&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>, &lt;span style="color:#a6e22e">delay&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#66d9ef">undefined&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>) &lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;span style="color:#a6e22e">$timeout&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span> () {
&lt;span style="color:#a6e22e">closeDeferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>);
}, &lt;span style="color:#a6e22e">delay&lt;/span>);
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This requires some explanation. First, we create a new &lt;code>deferred&lt;/code> object. This is going to be used to build a promise that is resolved when the modal closes.&lt;/p>
&lt;p>Now we build an &lt;code>input&lt;/code> object. This contains parameters we want to inject to the controller we're going to create. Any parameters the controller needs, such as &lt;code>$element&lt;/code>, &lt;code>$timeout&lt;/code> or whatever will be injected by angular. We're just going to make sure that the &lt;code>$scope&lt;/code> that is injected is the one we've just created, and that we also inject a function called &amp;lsquo;close&amp;rsquo;. This function simply resolves the promise we've created after a specified timeout.&lt;/p>
&lt;p>This means that any controller for a modal can take &lt;code>close&lt;/code> as a parameter, and we'll inject the function that resolves the promise. This promise is returned to the consumer so that they can take action when the modal closes. We also allow the controller to pass a variable to &lt;code>close&lt;/code> which is passed to the &lt;code>resolve&lt;/code> function as well.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>) {
&lt;span style="color:#66d9ef">for&lt;/span>(&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">inputName&lt;/span> &lt;span style="color:#66d9ef">in&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>) {
&lt;span style="color:#a6e22e">inputs&lt;/span>[&lt;span style="color:#a6e22e">inputName&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>[&lt;span style="color:#a6e22e">inputName&lt;/span>];
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Without the this code, the service is close to useless. What we do here is allow the caller to provide extra inputs to the controller. Imagine we have a list of items, maybe books for a library program, and when the use clicks on one we want to show a modal. The code that shows the modal needs to pass the selected book to the modal controller - by adding it to the &lt;code>inputs&lt;/code> object, the book can be injected into the controller. This allows to client to pass data &lt;strong>to&lt;/strong> the controller, with the parameter of the &lt;code>close&lt;/code> function used to return data &lt;strong>from&lt;/strong> the controller.&lt;/p>
&lt;p>Ready for some lower level Angular?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalController&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$controller&lt;/span>(&lt;span style="color:#a6e22e">controller&lt;/span>, &lt;span style="color:#a6e22e">inputs&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalElementTemplate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">element&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">linkFn&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$compile&lt;/span>(&lt;span style="color:#a6e22e">modalElementTemplate&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalElement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">linkFn&lt;/span>(&lt;span style="color:#a6e22e">modalScope&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Four innocuous lines that are actually quite complex.&lt;/p>
&lt;ol>
&lt;li>First, we create an instance of the controller with name &lt;code>controller&lt;/code>. Regardless of what AngularJS injects, we provide &lt;code>inputs&lt;/code> to be injected as well.&lt;/li>
&lt;li>Now we turn our raw template html into an AngularJS DOM element. AngularJS always works with jQuery or jQuery Lite elements, the &lt;code>angular.element&lt;/code> function takes raw HTML and turns it into a DOM element we can work with.&lt;/li>
&lt;li>Now we &lt;code>$compile&lt;/code> the element. This step goes over the DOM and expands all directives. We're turning raw DOM elements into elements that are expanded into directives, but we haven't yet linked this set of elements into a scope. This is the first step of the compile/link process.&lt;/li>
&lt;li>Finally, we can link the element. The &lt;code>$compile&lt;/code> function returns a link function which we call with a scope to link the DOM elements (fully expanded) to the specified scope.&lt;/li>
&lt;/ol>
&lt;p>This is very similar to AngularJS actually handles directives itself - creating a scope, loading a template, turning it into an element, compiling it and linking it.&lt;/p>
&lt;p>Why are compile and link separate steps? Think of it like this, the work that is done in compile is actually identical for each instance of a directive (or modal in our case). It's not related to an &lt;em>instance&lt;/em> of a directive or modal, it's just expanding the elements and directives. So this work can be done once only, saving a lot of time - then we just call link to create an &lt;em>instance&lt;/em> of our element, bound to a specific scope. So link logic is always per instance (you have a scope, you can &lt;code>$watch&lt;/code> and so on) whereas compile logic is per &lt;em>type&lt;/em> of directive.&lt;/p>
&lt;p>Based on this, we could in fact cache the results of the compile function on a per-template basis, as they can be reused and linked to a scope as necessary. However this is an optimisation that is currently left out.&lt;/p>
&lt;p>Now we can add the fully built element to the DOM and build our return object.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">body&lt;/span>.&lt;span style="color:#a6e22e">append&lt;/span>(&lt;span style="color:#a6e22e">modalElement&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modal&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalController&lt;/span>,
&lt;span style="color:#a6e22e">scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span>,
&lt;span style="color:#a6e22e">element&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalElement&lt;/span>,
&lt;span style="color:#a6e22e">close&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">closeDeferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We return the four things the caller might need - the controller, scope, element and close promise. When the close promise is resolved, we also want to clean up:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">modal&lt;/span>.&lt;span style="color:#a6e22e">close&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">modalScope&lt;/span>.&lt;span style="color:#a6e22e">$destroy&lt;/span>();
&lt;span style="color:#a6e22e">modalElement&lt;/span>.&lt;span style="color:#a6e22e">remove&lt;/span>();
});
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">modal&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So when &lt;code>close&lt;/code> is resolved, whatever happens we'll destroy the scope and clean up the DOM. Now we can resolve our promise with the &lt;code>modal&lt;/code> object we've built&amp;hellip;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> .&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip;and we can pass errors that occured during &lt;code>getTemplate&lt;/code> to the caller and finally return the promise we've built.&lt;/p>
&lt;p>That's it! With this design we handle errors correctly, can pass data to and from the modal, clean up after ourselves and make sure that units of asynchronous work are handled with the standard pattern of promises.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>I hope you've found the service and some of the details of the code useful, as always comments are welcome, fork the code and have a play - let me know if you think of improvements or have questions,&lt;/p></description><category>CodeProject</category></item><item><title>AngularJS Promises - The Definitive Guide</title><link>https://dwmkerr.com/promises-in-angularjs-the-definitive-guide/</link><pubDate>Wed, 07 May 2014 12:06:55 +0000</pubDate><guid>https://dwmkerr.com/promises-in-angularjs-the-definitive-guide/</guid><description>&lt;p>Promises are a core feature of AngularJS - whether you understand them or not, if you use AngularJS you've almost certainly been using them for a while.&lt;/p>
&lt;p>In this post I'm going to explain what promises are, how they work, where they're used and finally how to use them effectively.&lt;/p>
&lt;p>Once we've got the core understanding of promises, we'll look at some more advanced functionality - chaining and resolving promises when routing.&lt;/p>
&lt;h4 id="contents">Contents&lt;/h4>
&lt;ol>
&lt;li>&lt;a href="#whatarepromises">What are Promises?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#howdopromiseswork">How do Promises Work?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#arealworldexample">A Real World Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="#promisessuccesserrorthen">Promises - Success, Error, Then&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromiseschaining">Advanced Promises - Chaining&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromisesrouting">Advanced Promises - Routing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromisestipstricks">Advanced Promises - Tips &amp;amp; Tricks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thefutureofpromises">The Future of Promises&lt;/a>&lt;/li>
&lt;li>&lt;a href="#wrappingup">Wrapping Up&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="what-are-promises">What are Promises?&lt;/h2>
&lt;p>I'm going to try and be as succinct as possible - if anyone has a shorter, clearer description, let me know!&lt;/p>
&lt;blockquote>
&lt;p>A promise represents the eventual result of an operation. You can use a promise to specify what to do when an operation eventually succeeds or fails.&lt;/p>
&lt;/blockquote>
&lt;p>So let's see this in action. Look at the code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code uses the &lt;code>$http&lt;/code> service to perform an HTTP GET on the url &amp;lsquo;/api/my/name&amp;rsquo;. Let's say that this is an api we've implemented on our server that returns the name of the logged in user.&lt;/p>
&lt;p>Now a common mistake for JavaScript newcomers might be to assume that the function returns the name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// The WRONG way!
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>It doesn't - and in fact it can't. An HTTP request has to be executed, it'll take a while before it returns - it might not return at all if there are errors. Remember, when we make requests in JavaScript we're using &lt;strong>ajax&lt;/strong> which is &lt;em>&lt;strong>asynchronous&lt;/strong> javascript and xml&lt;/em>. The key word here is asynchronous - we return control to the browser, let it make a request and give it a function to call when the request completes.&lt;/p>
&lt;p>So let's see how you actually make the request.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
});
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we use the promise object to specify what to do when the request succeeds, or when it fails. Remember, the functions we pass to &lt;code>success&lt;/code> or &lt;code>error&lt;/code> will be called later - when this block is finished executing we don't have the name, we've just specified what to do when we &lt;em>do&lt;/em> eventually get it - or what to do if we fail to get it.&lt;/p>
&lt;p>As a convenience, the &lt;code>success&lt;/code> and &lt;code>error&lt;/code> functions actually just return the promise, so we can simplify the code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, &lt;code>success&lt;/code> and &lt;code>error&lt;/code> are special functions added to a promise by &lt;code>$http&lt;/code> - normally with promises we just use &lt;code>then&lt;/code>, which takes the success function as the first parameter and the error function as the second:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(
&lt;span style="color:#75715e">/* success */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
},
&lt;span style="color:#75715e">/* failure */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll see more about the difference between &lt;code>success&lt;/code>, &lt;code>error&lt;/code> and &lt;code>then&lt;/code> later.&lt;/p>
&lt;p>That's all there is to it - a promise lets us specify what to do as the result of an operation.&lt;/p>
&lt;h2 id="how-do-promises-work">How do Promises Work?&lt;/h2>
&lt;p>Promises are not actually complicated, they're objects that contain a reference to functions to call when something fails or succeeds.&lt;/p>
&lt;p>Under the hood, AngularJS actually wires up a promise for an HTTP request in a way a bit like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">request&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">XMLHttpRequest&lt;/span>();
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">addEventListener&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;load&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// complete the promise
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}, &lt;span style="color:#66d9ef">false&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">addEventListener&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;error&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// fail the promise
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}, &lt;span style="color:#66d9ef">false&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">open&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;GET&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">true&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">send&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>this is pseudo-code, but the idea is that its the browser that calls us back, via the event listeners, then AngularJS can just call the appropriate method on the promise.&lt;/p>
&lt;p>Now in AngularJS, the promises are created with the &lt;code>$q&lt;/code> service (we'll see exactly how to do this shortly), but why &lt;code>$q&lt;/code>?&lt;/p>
&lt;p>The reason the service is named &lt;code>$q&lt;/code> is that AngularJS&amp;rsquo; promise implementation is based on Kris Kowal's promise mechanism, which is called &amp;lsquo;Q&amp;rsquo;. You can see the library at &lt;a href="https://github.com/kriskowal/q">github.com/kristkowal/q&lt;/a>.&lt;/p>
&lt;p>This was a deliberate decision, as the Q library is widely used and well understood by the community. We're going to see a little bit later what the future of promises is in AngularJS and actually in ECMAScript 6.&lt;/p>
&lt;h3 id="a-real-world-example">A Real World Example&lt;/h3>
&lt;p>In this example we'll create a service that gets the user's name, just like in our examples. However, to make it interesting, we'll set our service up so that the first time we get the name from the server, and then afterwards we'll return a cached copy.&lt;/p>
&lt;p>This means we'll have to build our code to deal with the asynchronous case (the first one) and the more trivial synchronous case (getting the name from the cache).&lt;/p>
&lt;p>Let's look at a pure asynchronous implementation.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NameService&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>) {
&lt;span style="color:#75715e">// Create a class that represents our name service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;span style="color:#75715e">// getName returns a promise which when
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// fulfilled returns the name.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/my/name&amp;#39;&lt;/span>);
};
}
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here's how it looks in a fiddle - just click &amp;lsquo;Result&amp;rsquo; to see it working. You can click on &amp;lsquo;Update&amp;rsquo; name to get the name, but each time it sends a request. This is what we'll change next.&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/4GjtR/embedded/js,html,result" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>Now let's update our service so that we hit the server only if we haven't already cached the name. I'll build the service blow by blow, then we can see a fiddle of it working.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NameService&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>) {
&lt;span style="color:#75715e">// Create a class that represents our name service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;span style="color:#75715e">// Initially the name is unknown....
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>so first we create a service which is in the form of a class. It has a name field which is initially null.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// Create a deferred operation.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now in the &lt;code>getName&lt;/code> function we start by creating a &lt;code>deferred&lt;/code> object, using the &lt;code>$q&lt;/code> service. This object contains the promise we'll return, and has some helper functions to let us build the promise.&lt;/p>
&lt;p>We create a deferred object because whether we use ajax or not, we want the consumer to use the promise - even if we &lt;em>can&lt;/em> return straightaway in some circumstances (when we have the name) we can't in all - so the caller must always expect a promise.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">!==&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; (from Cache!)&amp;#34;&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If we already have the name, we can just &lt;code>resolve&lt;/code> the deferred object immediately - this is the easy case. I've added &amp;lsquo;from cache&amp;rsquo; to the name so we can see when it comes from the cache compared to the server.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Tip:&lt;/strong> You can resolve a promise even before you return it. It still works fine for the consumer.&lt;/p>
&lt;/blockquote>
&lt;p>Finally, we can handle the case if we don't already have the name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#75715e">// Get the name from the server.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/my/name/&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; (from Server!)&amp;#34;&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>);
});
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So if we get success from the server, we can &lt;code>resolve&lt;/code> the promise. Otherwise, we &lt;code>reject&lt;/code> it, which means failure.&lt;/p>
&lt;blockquote>
&lt;p>Call &lt;code>resolve&lt;/code> on a deferred object to complete it successfully, call &lt;code>reject&lt;/code> to fail it with an error.&lt;/p>
&lt;/blockquote>
&lt;p>Finally, we just return the promise we've built with &lt;code>deferred&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And that's it! You can see it in action below, press &amp;lsquo;Update Name&amp;rsquo; a few times and you'll see it uses the cache.&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/LeZU4/embedded/result,html,js" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>How do we use this? We'll it's simple, here's a controller that uses the service we've built:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> (&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#75715e">// We have a name on the code, but it&amp;#39;s initially empty...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>;
&lt;span style="color:#75715e">// We have a function on the scope that can update the name.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">updateName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>()
.&lt;span style="color:#a6e22e">then&lt;/span>(
&lt;span style="color:#75715e">/* success function */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
},
&lt;span style="color:#75715e">/* error function */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Failed to get the name, result is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">result&lt;/span>);
});
};
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now there's something different here. Before, we might have used the &lt;code>error&lt;/code> or &lt;code>success&lt;/code> function of the promise. But here we use &lt;code>then&lt;/code>. Why is that?&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>success&lt;/code> and &lt;code>error&lt;/code> are functions on a promise that AngularJS adds for us when using &lt;code>$http&lt;/code> or &lt;code>$resource&lt;/code>. They're not standard, you won't find them on other promises.&lt;/p>
&lt;/blockquote>
&lt;p>So we've seen how promises work, what they are and so on, now we'll look into this success/error/then stuff.&lt;/p>
&lt;h2 id="promises---success-error-then">Promises - Success, Error, Then&lt;/h2>
&lt;p>Now we know that &lt;code>$http&lt;/code> returns a promise, and we know that we can call &lt;code>success&lt;/code> or &lt;code>error&lt;/code> on that promise. It would be sensible to think that these functions are a standard part of promise - but they're not!&lt;/p>
&lt;p>When you are using a promise, the function you should call is &lt;code>then&lt;/code>. &lt;code>then&lt;/code> takes two parameters - a callback function for success and a callback function for failure. Taking a look at our original &lt;code>$http&lt;/code> example, we can rewrite it to use this function.
So this code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>becomes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
}, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">result&lt;/span>);
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We &lt;strong>can&lt;/strong> use &lt;code>success&lt;/code> or &lt;code>error&lt;/code> when using &lt;code>$http&lt;/code> - it's convenient. For one thing, the &lt;code>error&lt;/code> function gives us a response and status (and more) and the &lt;code>success&lt;/code> function gives us the response data (rather than the full response object).&lt;/p>
&lt;p>But remember that it's not a standard part of a promise. You can can add your own versions of these functions to promises you build yourself if you want:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">success&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">fn&lt;/span>) {
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">fn&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">headers&lt;/span>, &lt;span style="color:#a6e22e">config&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">fn&lt;/span>) {
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">null&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">fn&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">headers&lt;/span>, &lt;span style="color:#a6e22e">config&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>this is exactly how angular does it.&lt;/p>
&lt;p>So what's the advice?&lt;/p>
&lt;blockquote>
&lt;p>Use &lt;code>success&lt;/code> or &lt;code>error&lt;/code> with &lt;code>$http&lt;/code> promises if you want to - just remember they're not standard, and the parameters are different to those for &lt;code>that&lt;/code> callbacks.&lt;/p>
&lt;/blockquote>
&lt;p>So if you change your code so that your promise is not returned from &lt;code>$http&lt;/code>, as we did in the earlier example when we load data from a cache, your code will break if you expect &lt;code>success&lt;/code> or &lt;code>error&lt;/code> to be there.&lt;/p>
&lt;p>A safe approach is to use &lt;code>then&lt;/code> wherever possible.&lt;/p>
&lt;h2 id="advanced-promises---chaining">Advanced Promises - Chaining&lt;/h2>
&lt;p>If you've had your fill of promises for now, you can skip to &lt;a href="#thefutureofpromises">The Future of Promises&lt;/a> or &lt;a href="#wrappingup">Wrapping Up&lt;/a>.&lt;/p>
&lt;p>One useful aspect of promises is that the &lt;code>then&lt;/code> function returns the promise itself. This means that you can actually &lt;em>chain&lt;/em> promises, to create conscise blocks of logic that are executed at the appropriate times, without lots of nesting.&lt;/p>
&lt;p>Let's consider an example where we need to fetch the user's name from the backend, but we have to use separate requests to get their profile information and then their application permissions.&lt;/p>
&lt;p>Here's an example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span> {
&lt;span style="color:#a6e22e">username&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>,
&lt;span style="color:#a6e22e">profile&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>,
&lt;span style="color:#a6e22e">permissions&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>
};
&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/user/name&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the username, get the profile.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/profile/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the profile, now get the permissions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">profile&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/security/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the permissions
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">permissions&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The full user details are: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">details&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we have a series of asynchronous calls that we can coordinate without having lots of nested callbacks.&lt;/p>
&lt;p>We can also greatly simplify error handling - let's see the example again, with an exception thrown in:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/user/name&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the username, get the profile.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/profile/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the profile, now get the permissions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">profile&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Oh no! Something failed!&amp;#34;&lt;/span>;
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the permissions
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">permissions&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The full user details are: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">details&lt;/span>);
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;An error occured: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can use &lt;code>catch(callback)&lt;/code> - which is actually just shorthand for &lt;code>then(null, callback)&lt;/code>. There's even a &lt;code>finally&lt;/code> - which is executed whether or not the operations fail or succeed.&lt;/p>
&lt;blockquote>
&lt;p>Use &lt;code>catch&lt;/code> and for error handling with promises - and use &lt;code>finally&lt;/code> for logic that's executed after success OR failure.&lt;/p>
&lt;/blockquote>
&lt;p>The composition of promises can simplify complicated code - particularly when you add in error handling!&lt;/p>
&lt;p>One final point to make which is not quite related to chaining but does relate to multiple promises is &lt;code>$q.all&lt;/code>. &lt;code>all&lt;/code> can be used to build a single promise from a set of promises.&lt;/p>
&lt;p>You can pass an array of promises to &lt;code>all&lt;/code> and you get back a single promise - which is resolved when all of the promises it contains resolve. This can be useful if you are building complex methods that may have to perform multiple asynchronous tasks - such as multiple ajax calls.&lt;/p>
&lt;h2 id="advanced-promises---routing">Advanced Promises - Routing&lt;/h2>
&lt;p>There's a particular area of AngularJS that uses promises to great effect, and that's the router.&lt;/p>
&lt;p>Let's imagine we have a router like the following:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;home.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>
})
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we have two routes. The home route takes us to the home page, with the &lt;code>MainController&lt;/code>, and the profile route takes us to the user's profile page.&lt;/p>
&lt;p>Our ProfileController uses our funky name service:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The problem is, &lt;strong>until the name service gets the name from the backend, the name is null&lt;/strong>. This means if our view binds to the name, it'll flicker - first it's empty then its set.&lt;/p>
&lt;p>What we'd like to do is actully say to the router - &amp;ldquo;I'm going to go to this view, but only when you can tell me my name&amp;rdquo;.&lt;/p>
&lt;p>We can do this with the &lt;em>resolves&lt;/em> in the router, here's how it works:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// Create a function that uses the NameService
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to return the getName promise.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>();
};
&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/home.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>
})
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>,
&lt;span style="color:#75715e">/* only navigate when we&amp;#39;ve resolved these promises */&lt;/span>
&lt;span style="color:#a6e22e">resolve&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">name&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span>
}
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>so now we have a &lt;em>resolve&lt;/em> on the route - when we go to the profile page the router will wait until the promise returned by &lt;code>getName&lt;/code> resolves, then it will pass the result into the controller, as the parameter called &lt;code>name&lt;/code>. Now our controller looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Much better! And also &lt;strong>much&lt;/strong> more testable.&lt;/p>
&lt;p>One thing you may wonder - why do I use &lt;code>getName&lt;/code> as the resolve function instead of just using &lt;code>NameService.getName&lt;/code> directly?&lt;/p>
&lt;p>That's because the route is set up in a &lt;code>config&lt;/code> function - and that function cannot have services injected. However, a resolve function &lt;strong>can&lt;/strong>, so we just use a function and let AngularJS inject the &lt;code>NameService&lt;/code> for us.&lt;/p>
&lt;p>Now for an important statement:&lt;/p>
&lt;blockquote>
&lt;p>If the first thing your controller does is fetch data from the server, it's probably wrong.&lt;/p>
&lt;/blockquote>
&lt;p>Why? Because if your controller needs data, inject it - let the router ensure the data is ready. Then you don't have controllers in an invalid state as they're loading - and your controllers become easier to test.&lt;/p>
&lt;p>Be aware of &lt;code>resolve&lt;/code> for routes - it's a great way to handle loading of required data, authentication and other things that you might be putting into the wrong place.&lt;/p>
&lt;p>You can see the example above in action here:&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/m29pe/embedded/result,js,html" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>What's cool is we can also see our caching logic by going to and from the Home and Profile pages. The promises are keeping our code clean and testable.&lt;/p>
&lt;p>As a final note on promises when routing, you can specify multiple resolves if you need to:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>,
&lt;span style="color:#75715e">/* only navigate when we&amp;#39;ve resolved these promises */&lt;/span>
&lt;span style="color:#a6e22e">resolve&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">name&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span>,
&lt;span style="color:#a6e22e">profile&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getProfile&lt;/span>,
&lt;span style="color:#a6e22e">anythingElse&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getAnythingElse&lt;/span>
}
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>in this case each resolve is injected into the controller.&lt;/p>
&lt;h2 id="advanced-promises---tips--tricks">Advanced Promises - Tips &amp;amp; Tricks&lt;/h2>
&lt;p>This section just contains some tips and tricks you might find useful when working with promises.&lt;/p>
&lt;ol>
&lt;li>Promises in directives are not resolved automatically since AngularJS 1.2. Previously, if you passed a promise to a directive with an &amp;lsquo;=&amp;rsquo; binding, AngularJS would resolve the promise for you, this is no longer the case.&lt;/li>
&lt;/ol>
&lt;h2 id="the-future-of-promises">The Future of Promises&lt;/h2>
&lt;p>So promises are a core part of AngularJS and to use the framework effectively, you must understand how to use them and how they work. But what is the future of promises?&lt;/p>
&lt;p>It's almost certain that promises are going to become a &lt;strong>native&lt;/strong> feature of JavaScript, they are part of the proposed ECMAScript 6 specification.&lt;/p>
&lt;p>The functionality of the &lt;code>q&lt;/code> library and AngularJS&amp;rsquo; implementation of promises are very similar indeed to the proposed specification, but be aware that when promises become standard, AngularJS is most likely to adapt their own promises to work like native promises.&lt;/p>
&lt;p>You can read more at &lt;a href="http://www.html5rocks.com/en/tutorials/es6/promises/">html5rocks.com/en/tutorials/es6/promises/&lt;/a>.&lt;/p>
&lt;p>Just be aware that you'll see promises more and more, in other frameworks and in vanilla JavaScript.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>I hope this post has been useful to understanding promises. Any feedback is always good, so let me know if anything is unclear or could be improved. To finish this article, here are some useful links:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>The Q library&lt;/strong> &lt;a href="https://github.com/kriskowal/q">github.com/kriskowal/q&lt;/a>&lt;/li>
&lt;li>&lt;strong>The AngularJS &lt;code>$q&lt;/code> Service&lt;/strong> &lt;a href="https://docs.angularjs.org/api/ng/service/$q">docs.angularjs.org/api/ng/service/$q&lt;/a>&lt;/li>
&lt;li>&lt;strong>Promises in ECMAScript 6&lt;/strong> &lt;a href="http://www.html5rocks.com/en/tutorials/es6/promises/">html5rocks.com/en/tutorials/es6/promises/&lt;/a>&lt;/li>
&lt;li>&lt;strong>XmlHttpRequest, which we used in an example&lt;/strong> &lt;a href="https://developer.mozilla.org/en/docs/Web/API/XMLHttpRequest">developer.mozilla.org/en/docs/Web/API/XMLHttpRequest&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>And also some interesting discussions:&lt;/p>
&lt;p>&lt;a href="http://spion.github.io/posts/why-i-am-switching-to-promises.html">Why I am switching to promises&lt;/a> - Written by Gorgi Kosev, great article describing why a switch from callbacks to promises can be a very good thing in NodeJS applications.&lt;/p>
&lt;p>&lt;a href="http://blog.ometer.com/2011/07/24/callbacks-synchronous-and-asynchronous/">Callbacks, sychronous and asynchronous&lt;/a> - From Havoc, this post contains many useful points for API writers who are using callbacks or promises. One key takeaway is to &lt;strong>never&lt;/strong> do what a sample in this article does which is resolve a promise either synchronously or asynchronously, as it leads to code which can be difficult to reason about. I'll be mentioning this more in a later update which will explain the problem and solution.&lt;/p>
&lt;p>&lt;a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Designing for Asynchrony&lt;/a> - Written by Isaac Z. Schlueter, this post is another great one for API designers that takes a look into asynchrony.&lt;/p></description><category>CodeProject</category></item><item><title>Better Specifications</title><link>https://dwmkerr.com/better-specifications/</link><pubDate>Mon, 05 May 2014 14:58:43 +0000</pubDate><guid>https://dwmkerr.com/better-specifications/</guid><description>&lt;p>Specifications are absolutely key to the success of a project.&lt;/p>
&lt;p>Unless you have a good definition of what your project is &lt;em>supposed to be&lt;/em>, there's no way you can deliver it. A specification is the contract between you and the client, the basis for technical designs, quality assurance test plans, operational readiness, and much more.&lt;/p>
&lt;p>I'm not going to talk about how different teams do specs, what works and what doesn't work. I'm going to make the statement that &lt;strong>the better that specifications are handled, understood and controlled, the better for everyone&lt;/strong> - Project Managers, developers, testers, operational teams and customers.&lt;/p>
&lt;p>If there's anyone who's on the fence about whether specifications are important or not, &lt;a href="http://www.joelonsoftware.com/articles/fog0000000036.html">Joel Spolsky's series on Painless Specifications&lt;/a> is a must read, he makes the point exceedingly well and I'd definitely recommend reading the articles.&lt;/p>
&lt;p>I'm going to describe an approach to functional specifications that I think has a lot going for it. To developers it should look very familiar and (hopefully) appealing. To non-developers, the approach may not be so familiar, but the potential benefits should speak for themselves.&lt;/p>
&lt;h3 id="specs-right-now">Specs Right Now&lt;/h3>
&lt;p>OK - the introductions have been made. So how do we represent specs at the moment? Here are some common ways.&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Text files&lt;/strong>. Specs are text? Well, sometimes. They might also be images, sometimes diagrams help too. But text can work.&lt;/li>
&lt;li>&lt;strong>Word documents&lt;/strong>. A little like the above, but with the facility to use tables and images and so on.&lt;/li>
&lt;li>&lt;strong>Web Pages&lt;/strong>. Perhaps more common nowadays, specs can be written on online systems like Sharepoint (just documents really, but with better multi-user support), Google Docs or Bug Tracking/Wiki type systems.&lt;/li>
&lt;li>&lt;strong>BDD Tools&lt;/strong>. Whether using tools or not, BDD specs are files that state functionality in a more strongly defined format.&lt;/li>
&lt;li>&lt;strong>Tests&lt;/strong>. Kind of similar to the above - depending on what you're writing or the tech expertise of team members, some teams opt for the bulk of their specs in the form of tests.&lt;/li>
&lt;/ol>
&lt;p>All of these systems have pros and cons. Some have many more cons, and some balance out better on different types of projects.&lt;/p>
&lt;h2 id="a-better-way">A Better Way&lt;/h2>
&lt;p>So here's a suggestion of a better way.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Specs are markdown files in a repository. That's it.&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;p>Now I'm going to show you why this is a good idea.&lt;/p>
&lt;h3 id="specs-are-text-ish">Specs are text. Ish.&lt;/h3>
&lt;p>Pure plain text is a bit hard for specs - it can be helpful to have bullet points, headings and so on. But word processing tools are not always the best answer - you're tied to a specific tool, and unless you're working with people who all know how styles, track changes or the specifics of the tool work, you can spend more time messing around with formatting than you'd like.&lt;/p>
&lt;p>Try comparing and rationalising two versions of a complex document that have gone out of sync, it's a nightmare.&lt;/p>
&lt;p>Here's a snippet of a markdown spec:&lt;/p>
&lt;pre>&lt;code>Overview
--------
This spec is for the login screen of the application. The overall design of
the screen is in the file 'mockup.png'.
The Controls
------------
* The 'username' box accepts alphanumeric characters.
* The limit of the 'username' box is 120 characters.
* The tooltip for the username box is 'Enter Username'.
* The password box accepts any characters and is limited to 120 characters.
* The tooltip for the password box is 'Enter password'.
&lt;/code>&lt;/pre>&lt;p>It's readable in it's raw form. This is how it looks on GitHub:&lt;/p>
&lt;p>&lt;img src="images/LoginScreenSpec.png" alt="Login Screen Spec">&lt;/p>
&lt;p>See the real thing at &lt;a href="https://github.com/dwmkerr/better-specs/blob/master/login/login.md">github.com/dwmkerr/better-specs/blob/master/login/login.md&lt;/a>.&lt;/p>
&lt;p>(These specs are just made up ones for this article).&lt;/p>
&lt;p>The formatting is readable even in plain text mode, but many modern day tools understand how to show markdown in a slightly nicer way (I'm writing this post in markdown - &lt;a href="https://ghost.org/">Ghost&lt;/a> uses markdown for blog posts). You can print it and understand it, email it to recipients in plain text mode, and importantly there's no fiddling with formatting.&lt;/p>
&lt;p>If you haven't used markdown before, give it a try on &lt;a href="https://stackedit.io/">StackEdit&lt;/a>, it's an online markdown editor - you can have a play with it.&lt;/p>
&lt;h3 id="specs-are-version-controlled">Specs are Version Controlled&lt;/h3>
&lt;p>Specs need to be version controlled. You need to be able to see a history of a spec, who changed it, when they changed it and what the change was.&lt;/p>
&lt;p>Even more useful - you should be able to diff specs - what changed between two versions? This is hard to do with programs like word, with version control systems like git, it's a piece of cake. Take a look:&lt;/p>
&lt;p>&lt;img src="images/LoginScreenDiff.png" alt="">&lt;/p>
&lt;p>We can see easily who changed this spec and when, we can compare revisions.&lt;/p>
&lt;p>This not just a powerful feature - it's a required one. Developers and testers can see what has been added, removed or modified. So can project managers.&lt;/p>
&lt;p>This is a diff that developers will understand - the red and green make it clear for non-devs too. Modern systems like GitHub can take it further:&lt;/p>
&lt;p>&lt;img src="images/LoginNiceDiff.png" alt="">&lt;/p>
&lt;p>Pretty clear what's going on.&lt;/p>
&lt;h3 id="pull-requests">Pull Requests&lt;/h3>
&lt;p>Let's take the version control aspect further. A spec should have one owner, one person who can press the button and say &amp;lsquo;yes, this is in&amp;rsquo;. There needs to be one owner, because a change to a spec is like a change to a contract - it could represent hours of developer time, cost increases, release date issues and more. There's impact, there are consequences.&lt;/p>
&lt;p>So using services like GitHub or Bitbucket can help here. Anyone can make changes to a spec, but a single approver has to review those changes and decide whether to bring them in.&lt;/p>
&lt;p>&lt;img src="images/LockoutLogic.png" alt="">&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/better-specs/pull/1/files?short_path=d645d03#diff-d645d03c7459b43c1e030eeb13d1245b">See this pull request on GitHub&lt;/a>&lt;/p>
&lt;p>Pull requests support comments, discussions, diffs and all sorts of useful things. No one can get something into the spec until the approver has OK'd it.&lt;/p>
&lt;p>It also gives the approver a single point where they can action the changes, perhaps raising a task for a developer to work on the changes.&lt;/p>
&lt;p>That pull request can also be &lt;em>linked to&lt;/em> later - in the bug tracking or feature management system, an issue to implement the changes in the pull request can be made - and the implementer always has a link to the &lt;em>exact&lt;/em> change.&lt;/p>
&lt;blockquote>
&lt;p>Don't put the change to a spec in a work item. A work item &lt;em>refers&lt;/em> to a change in the spec.&lt;/p>
&lt;/blockquote>
&lt;p>This is very useful. In the pull request shown (which you can &lt;a href="https://github.com/dwmkerr/better-specs/pull/1/files?short_path=d645d03#diff-d645d03c7459b43c1e030eeb13d1245b">see here&lt;/a>) has one innocuous extra line (which we see in green) stating that the user is locked out after three failed password attempts. This isn't in the spec, not until we accept the pull request. And in this case instead we can comment to the person who raised it:&lt;/p>
&lt;p>&lt;img src="images/LoginPullReqComments.png" alt="">&lt;/p>
&lt;p>I had to make a contrived example and fake a discussion between myself and myself, but I think seeing how this looks helps make the point.&lt;/p>
&lt;h3 id="branches">Branches&lt;/h3>
&lt;p>Another great thing about keeping specs as plain text and using a version control system is that you can take advantage of branching. This means that different people can be working on proposed changes to specs or new features in their own isolated branches - the work they're doing won't be interfered with by others.&lt;/p>
&lt;p>When the time comes to bring the proposal into the spec, again a pull request can be made and the coordinator can deal with any conflicts that may have arisen since the branch was made.&lt;/p>
&lt;p>At the time the BA or whoever it might be is working on their specs, they still have full version control, a history and so on, but are not interfering with the &amp;lsquo;master&amp;rsquo; version of the specs that others in the project see.&lt;/p>
&lt;h3 id="what-about-rich-media">What About Rich Media?&lt;/h3>
&lt;p>Keep your rich media. Keep images, tables and diagrams - just check them in alongside the spec and link to them from the spec. You still get version control, pull requests and a history. Depending on the media you might even get a nice diff representation - check out this commit:&lt;/p>
&lt;p>&lt;img src="images/LoginImageDiff.png" alt="">&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/better-specs/commit/8a1224812db2ae4909dfb5a30f8483b1ca96ed18?diff-0=0-100">See the actual commit here&lt;/a>&lt;/p>
&lt;p>You can see the image before, after or even use the slider to see what has changed. The rich media is &lt;em>supporting&lt;/em> media - it's still the spec that's boss.&lt;/p>
&lt;p>Don't throw away your powerpoint presentations, visio files or anything else, but make the spec king and these files support it. Got a big table of information? Do it in excel or google sheets, that's the right tool for the job - but version control it with the spec.&lt;/p>
&lt;h3 id="persuading-others">Persuading Others&lt;/h3>
&lt;p>The hard thing about this approach might be persuading those who are not used to it to use it.&lt;/p>
&lt;p>To developers, I imagine this approach has immediate appeal. We know that an email chain of timestamped word documents or powerpoint presentations is a nightmare to maintain as it evolves, and that versin control systems are critical to managing shared work.&lt;/p>
&lt;p>To business people who are not used to version control or markdown, it might seem like a nerdy, inefficient way of doing things. But the points above are quite compelling. If you have strong arguments for or against, comment and I'll update the article.&lt;/p>
&lt;h3 id="useful-resources">Useful Resources&lt;/h3>
&lt;p>It's worth pulling together some useful further reading.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.joelonsoftware.com/articles/fog0000000036.html">Joel Spolsky's series on Painless Specifications&lt;/a> - A well written series on why specs are so important.&lt;/li>
&lt;li>&lt;a href="http://daringfireball.net/projects/markdown/">Markdown&lt;/a> - The official homepage&lt;/li>
&lt;li>&lt;a href="https://stackedit.io/">StackEdit&lt;/a> - Have a play writing markdown and see it rendered.&lt;/li>
&lt;/ul>
&lt;h2 id="final-thoughts">Final Thoughts&lt;/h2>
&lt;p>I've never used this approach in a team - I am writing specs for a side project like this at the moment, but this is a one-man project (for now).&lt;/p>
&lt;p>Have you tried this approach? Any success stories or experiences of it failing? I'd love to know, so comment if you've got some experience on this one.&lt;/p>
&lt;p>P.S. - This page was written with markdown!&lt;/p></description><category>CodeProject</category></item><item><title>CodeProject MVP</title><link>https://dwmkerr.com/codeproject-mvp/</link><pubDate>Tue, 17 Jan 2012 07:25:00 +0000</pubDate><guid>https://dwmkerr.com/codeproject-mvp/</guid><description>&lt;p>As a great start to the new year I have been made a CodeProject MVP!&lt;/p>
&lt;p>Have a look at my index of articles below:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528">&lt;a href="http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528">http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528&lt;/a>&lt;/a>&lt;/p>
&lt;p>Any suggestions for future articles are more than appreciated.&lt;/p></description><category>CodeProject</category></item><item><title>CodeProject Competition</title><link>https://dwmkerr.com/codeproject-competition/</link><pubDate>Thu, 06 Oct 2011 07:30:00 +0000</pubDate><guid>https://dwmkerr.com/codeproject-competition/</guid><description>&lt;p>My Solitaire and Spider Solitaire in WPF article is in two CodeProject competitions this month. The article is at:&lt;/p>
&lt;p>&lt;a href="https://www.codeproject.com/Articles/252152/Solitaire-and-Spider-Solitaire-for-WPF">https://www.codeproject.com/Articles/252152/Solitaire-and-Spider-Solitaire-for-WPF&lt;/a>&lt;/p>
&lt;p>If you think the article is worthy of a vote, then please go to the voting page for either of the two competitions!&lt;/p>
&lt;p>Best C# Article: &lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209">&lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209">http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209&lt;/a>&lt;/a>&lt;/p>
&lt;p>Best Overall Article: &lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212">&lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212">http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212&lt;/a>&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Solitaire and Spider Solitaire on the CodeProject</title><link>https://dwmkerr.com/solitaire-and-spider-solitaire-on-the-codeproject/</link><pubDate>Mon, 12 Sep 2011 06:01:00 +0000</pubDate><guid>https://dwmkerr.com/solitaire-and-spider-solitaire-on-the-codeproject/</guid><description>&lt;p>I have uploaded a new article on the CodeProject, a step by step tutorial showing how to create Solitaire and Spider Solitaire for WPF with the help of Apex.&lt;/p>
&lt;p>The article is available at: &lt;a href="http://www.codeproject.com/KB/WPF/solitaire.aspx">http://www.codeproject.com/KB/WPF/solitaire.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item></channel></rss>