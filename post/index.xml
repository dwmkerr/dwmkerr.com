<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on dwmkerr.com</title><link>https://dwmkerr.com/post/</link><description>Recent content in Posts on dwmkerr.com</description><generator>Hugo -- gohugo.io</generator><language>en-uk</language><copyright>Copright &amp;copy; Dave Kerr</copyright><lastBuildDate>Fri, 23 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://dwmkerr.com/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework</title><link>https://dwmkerr.com/building-least-privilege-permissions-aws/</link><pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/building-least-privilege-permissions-aws/</guid><description>&lt;p>In this article I'm going to give a brief overview of some techniques to build &amp;lsquo;least privilege&amp;rsquo; roles in AWS. This assumes a basic knowledge of AWS and Identity and Access Management. It uses the (at time of writing) &lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/iam-access-analyzer-easier-implement-least-privilege-permissions-generating-iam-policies-access-activity/">newly announced features in the AWS IAM Access Analyser&lt;/a>&lt;/p>
&lt;p>I'll be demoing the techniques using a project built on &lt;a href="https://www.serverless.com/">The Serverless Framework&lt;/a> but you don't need to know anything about how this framework works to follow the article - it is just used to demonstrate the concepts. You should be able to apply these techniques to almost any process which accesses or manages AWS resources.&lt;/p>
&lt;p>Let's get into it!&lt;/p>
&lt;hr>
&lt;h2 id="updates-to-the-aws-iam-access-analyser">Updates to the AWS IAM Access Analyser&lt;/h2>
&lt;p>AWS recently announced some new features to the IAM Access Analyser, which are designed to help build &amp;lsquo;least privilege&amp;rsquo; policies for your AWS solutions. As I have been deploying a number of solutions based on &lt;a href="https://www.serverless.com/">The Serverless Application Framework&lt;/a> I thought this would be a great time to try out these new features.&lt;/p>
&lt;p>The Serverless Application Framework is a useful framework if you want to rapidly create serverless applications. You can rapidly create lambda functions, deploy to AWS, test locally, debug and so on.&lt;/p>
&lt;h2 id="our-use-case---a-serverless-framework-deployment-process">Our Use Case - A Serverless Framework Deployment Process&lt;/h2>
&lt;p>When you use the Serverless Framework, a common pattern for deployment is to let the framework itself deploy resources.&lt;/p>
&lt;p>A deploy command would look like this:&lt;/p>
&lt;pre>&lt;code>serverless deploy --stack uat
&lt;/code>&lt;/pre>&lt;p>Under the hood, this will do a few things:&lt;/p>
&lt;ol>
&lt;li>Create a CloudFormation template which defines an application stack&lt;/li>
&lt;li>Upload the template to an S3 bucket on a specified AWS account&lt;/li>
&lt;li>Deploy the stack&lt;/li>
&lt;/ol>
&lt;p>Now what is deployed is very dependent on what you decide to use in your application, but common resources would be things like:&lt;/p>
&lt;ul>
&lt;li>CloudFormation Stacks&lt;/li>
&lt;li>Lambda Functions&lt;/li>
&lt;li>API Gateway resources&lt;/li>
&lt;li>DynamoDB tables&lt;/li>
&lt;li>SQS Queues&lt;/li>
&lt;li>&amp;hellip;and many more!&lt;/li>
&lt;/ul>
&lt;p>This raises some interesting questions - how should we secure this provisioning process?&lt;/p>
&lt;h2 id="fundamental-principles---isolation-and-least-privilege">Fundamental Principles - Isolation and Least-Privilege&lt;/h2>
&lt;p>There are two fundamental principles&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> which make sense to consider when thinking about how to integrate the Serverless Framework into your stack:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Isolation of Resources&lt;/strong>: Can we make sure that the stack resources are logically isolated from &lt;em>other&lt;/em> resources we are managing? This can reduce the impact of incidents - if the stack is compromised, it should only compromise specific resources, not all resources in your estate&lt;/li>
&lt;li>&lt;strong>Least Privilege&lt;/strong>: Can we make sure that when the &lt;code>serverless&lt;/code> binary deploys resources, it has the least permissions required to do its work, again reducing the impact of a potential incident&lt;/li>
&lt;/ol>
&lt;p>Isolation of resources can be handled in a number of ways - my preferred approach is to create separate AWS accounts for each application (and in fact, each environment, such as &amp;lsquo;dev&amp;rsquo;, &amp;lsquo;test&amp;rsquo; and so on). This is not something I will discuss in this article. What I would like to focus on is the second point - least privilege.&lt;/p>
&lt;h2 id="least-privilege-in-aws">Least Privilege in AWS&lt;/h2>
&lt;p>We don't quite know what the Serverless Framework does when it provisions resources. I don't mean this in a bad way. We &lt;em>could&lt;/em> investigate and read in detail exactly what happens, but part of the benefit of the framework is that it takes care of this for you. In the early stages of a project this is probably a great time saver - in the later stages it represents a potential vulnerability.&lt;/p>
&lt;p>We understand that it creates a CloudFormation stack, but some of the details are not necessarily readily discoverable from the documentation.&lt;/p>
&lt;p>If we wanted to create a policy which represents the permissions which the Serverless we could try a few approaches:&lt;/p>
&lt;ul>
&lt;li>Give the process full access to an environment, with wide permissions to create any resources&lt;/li>
&lt;li>Give the process limited access to an environment, run the provisioning process, see the permissions issues which arise, then iteratively add more permissions&lt;/li>
&lt;/ul>
&lt;p>You might think that the first instinct of a security team might be that a &amp;lsquo;full access&amp;rsquo; approach is fundamentally wrong. But great security experts balance risk, agility, cost all the time. They don't want to stop experimentation - just make sure that it is done in a safe way.&lt;/p>
&lt;p>The first approach is perfectly fine in low sensitivity environments. If you want to move fast and try out the technology, you could lose valuable time trying to get the permissions just right. If you have a solid approach to &lt;em>isolation&lt;/em>, then you should be able to run your proof of concepts in an isolated sandbox environment, which has no access to sensitive resources.&lt;/p>
&lt;p>You can also add Billing Alerts, or even automate the &lt;em>destruction&lt;/em> of resources at a certain point, so that you automatically &amp;lsquo;clean up&amp;rsquo;. This is great security practice - provide teams with a way to experiment &lt;em>safely&lt;/em>. Give teams full access to their own self-serve sandbox environments, with automated guardrails to mitigate the risk of incidents&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="beyond-the-sandbox">Beyond the Sandbox&lt;/h2>
&lt;p>The &amp;lsquo;sandbox environment&amp;rsquo; approach &lt;em>can&lt;/em> be valid. But there will likely come a stage when this is no longer appropriate.&lt;/p>
&lt;p>When you want to deploy into an environment which has other resources, sensitive data, is accessible to the public, runs production workloads and so on. There will likely come a point where you cannot fully isolate your application - at this stage we should be looking at improving our security.&lt;/p>
&lt;p>Specifically, at this point we really should try to make sure that we limit the permissions of the process which runs the &lt;code>serverless deploy&lt;/code> command.&lt;/p>
&lt;p>Limiting the permissions has the benefit of reducing the &amp;lsquo;blast radius&amp;rsquo; of an attack. If the process is compromised it can do fewer things. It also has the benefit of &lt;em>increasing transparency&lt;/em> - we will explicitly document &lt;em>what we expect the process to do&lt;/em>. This is highly useful when performing security checks.&lt;/p>
&lt;h2 id="the-challenges-of-limiting-permissions">The Challenges of Limiting Permissions&lt;/h2>
&lt;p>The process of working out the specific permissions required for a process can be challenging. It might involve looking through lots of documentation, trying to build a policy, seeing if the process works, adding permissions, changing permissions and so on.&lt;/p>
&lt;p>Just this month AWS released some updates to the IAM Access Manager, adding some features to help build &amp;lsquo;least permission&amp;rsquo; policies:&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/about-aws/whats-new/2021/04/iam-access-analyzer-easier-implement-least-privilege-permissions-generating-iam-policies-access-activity/">https://aws.amazon.com/about-aws/whats-new/2021/04/iam-access-analyzer-easier-implement-least-privilege-permissions-generating-iam-policies-access-activity/&lt;/a>&lt;/p>
&lt;p>These features immediately caught my eye as I'm very interesting in security practices. We're going to take a look at these features in detail for the rest of the article and see how we can use them to improve the security of a process like our &amp;lsquo;serverless deployment&amp;rsquo;.&lt;/p>
&lt;h2 id="using-the-iam-access-analyser-to-build-fine-grained-policies">Using the IAM Access Analyser to Build Fine-Grained Policies&lt;/h2>
&lt;p>The process for generating fine grained policies with the IAM Access Analyser is quite simple:&lt;/p>
&lt;ol>
&lt;li>Ensure you are using CloudTrail to track access to resources&lt;/li>
&lt;li>Create an Access Analyser&lt;/li>
&lt;li>Run the process you want to create fine-grained permissions for, initially with wide permissions&lt;/li>
&lt;li>Use the Access Analyser to generate a policy based on the events in CloudTrail&lt;/li>
&lt;li>Refine the policy&lt;/li>
&lt;li>Document, document, document&lt;/li>
&lt;/ol>
&lt;p>I'm going to demonstrate this end-to-end with a &amp;lsquo;serverless framework deployment&amp;rsquo; process. Please keep an eye out for an article I'll be writing soon on how to build a REST application with the Serverless Framework - for now don't worry about the application itself too much, this could be any kind of deployment or operational process we're running.&lt;/p>
&lt;h3 id="step-1-enable-cloudtrail">Step 1: Enable CloudTrail&lt;/h3>
&lt;p>We need to enable CloudTrail so that we have a log of API calls which Access Advisor can analyse.&lt;/p>
&lt;p>&lt;strong>Warning&lt;/strong>: if you trying these features out please be aware that they may fall outside of the &lt;a href="https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&amp;amp;all-free-tier.sort-order=asc&amp;amp;awsf.Free%20Tier%20Types=*all&amp;amp;awsf.Free%20Tier%20Categories=*all">AWS Free Tier&lt;/a> and so may incur a cost. Please be aware of this if you are testing these features.&lt;/p>
&lt;p>Open the CloudTrail portal and ensure that you have a trail setup which logs API calls. Once this is setup you should see something like this:&lt;/p>
&lt;img src="./images/cloudtrail.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/cloudtrail.png" class="img-zoomable">
&lt;p>You can use the code below as an example of how to create a trail:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">aws cloudtrail create-trail &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name management-events &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --s3-bucket-name cloudtrail-account123-management-events-bucket &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --is-multi-region-trail
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note that if you don't use the &lt;code>--is-multi-region-trail&lt;/code> flag then the trail is created for the current region only.&lt;/p>
&lt;p>You can read more about this command on the &lt;a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-and-update-a-trail-by-using-the-aws-cli-create-trail.html">Using create-trail&lt;/a> documentation page.&lt;/p>
&lt;h3 id="step-2-create-the-access-analyser">Step 2: Create the Access Analyser&lt;/h3>
&lt;p>You should be able to find the Access Analyser tool in the IAM page:&lt;/p>
&lt;img src="./images/access-analyser.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/access-analyser.png" class="img-zoomable">
&lt;p>You can now choose to create an analyser. Some things to note:&lt;/p>
&lt;ul>
&lt;li>Analysers are region specific - if you have many regions, you need many analysers&lt;/li>
&lt;li>You can provide a name, not surprising, but it might be useful to be highly descriptive here&lt;/li>
&lt;li>You have an option to specify the &amp;lsquo;zone of trust&amp;rsquo; - this might be an account or an entire organisation&lt;/li>
&lt;/ul>
&lt;p>Choose &amp;lsquo;Create Analyser&amp;rsquo; to create the access analyser.&lt;/p>
&lt;p>You'll shortly see the created access analyser and likely some &amp;lsquo;findings&amp;rsquo; as well:&lt;/p>
&lt;img src="./images/access-analyser-created.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/access-analyser-created.png" class="img-zoomable">
&lt;p>&amp;lsquo;Findings&amp;rsquo; are the descriptions of the policies that grant access to a resource to a principal which is &lt;em>outside of your zone of trust&lt;/em>. This is a quite complex topic, there are more details on the &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access-analyzer-findings.html">Access Analyser findings&lt;/a> documentation. But we are essentially seeing that my policies are set up in a which is exposing my resources to principals outside of the defined zone of trust - these findings are entirely correct, as I have set up &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html">Cross Account Access&lt;/a> in this environment.&lt;/p>
&lt;p>Feel free to read more about findings - these findings can potentially be very useful for a security team to be aware. For now we'll leave these findings alone and move onto the next step in creating fine grained policies, which is to run the process we want to secure.&lt;/p>
&lt;h3 id="step-3-run-your-process">Step 3: Run your process&lt;/h3>
&lt;p>Now you should run the process you want to create fine grained permissions for. To save rework, try and make sure you run &lt;em>all&lt;/em> part of the process which will be needed. For example, my Serverless Framework policy should cover creation of the stack, updating of the stack as well as deleting.&lt;/p>
&lt;p>To exercise this, I just need to run the following commands from my local project:&lt;/p>
&lt;pre>&lt;code># This command deploys a new stack...
serverless --stage dev deploy
# This command makes a change to a file, allowing us to update the stack...
echo &amp;quot;// testing a change to the stack...&amp;quot; &amp;gt;&amp;gt;&amp;gt; lambda_functions/my_function.js
serverless --stage dev deploy # this will update the stack
# This command deletes the stack, we then reset the changes to the file.
serverless --stage dev remove # this will destroy the stack
git checkout lambda_functions/my_function.js
&lt;/code>&lt;/pre>&lt;p>At this point you can run any process your want to secure. As CloudTrail is enable, API calls will be recorded.&lt;/p>
&lt;h3 id="step-4-create-a-policy-based-on-access-advisor">Step 4: Create a Policy based on Access Advisor&lt;/h3>
&lt;p>Now we get to the interesting part. Open the Roles view in AWS, select the role which is used when running your process and choose &amp;lsquo;Generate Policy&amp;rsquo;. Here's how this will look in the portal:&lt;/p>
&lt;img src="./images/generate-policy.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/generate-policy.png" class="img-zoomable">
&lt;p>Note that this screenshot shows &lt;em>exactly why&lt;/em> fine grained permissions are so important. I have run the Serverless Framework deployment from my local machine using the &amp;lsquo;Cross Account Administrator&amp;rsquo; role. This is an extremely high-privilege role which is used when I administer AWS accounts which are part of my organisation. This is &lt;em>not&lt;/em> an appropriate role for the Serverless Framework binary to assume outside of a sandbox or proof of concept context. However - remember at this stage we want to use a high-privilege role so that the process runs to completion, so that we can see the permissions needed and then create a more refined role.&lt;/p>
&lt;p>When you choose to generate a policy, you'll have the option of specifying which trail to use and which region. You can also choose a date range for events to analyse. It will be a lot easier to build an appropriate policy if you make this window as short as possible - so try and run the entire process you want to create a policy for and then immediately generate the policy.&lt;/p>
&lt;p>It can take a few minutes to generate the policy. When it is complete, you'll see the option to view the generated policy:&lt;/p>
&lt;img src="./images/view-generated-policy.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/view-generated-policy.png" class="img-zoomable">
&lt;p>Opening it up, you'll see the services and actions used, as well as options to add more actions:&lt;/p>
&lt;img src="./images/generated-policy.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/generated-policy.png" class="img-zoomable">
&lt;p>When you move to the next screen you'll get the option to customise the permissions:&lt;/p>
&lt;img src="./images/customise-permissions.png" alt="Building Least Privilege Policies with the AWS Policy Advisor - and a Demo with the Serverless Application Framework ./images/customise-permissions.png" class="img-zoomable">
&lt;p>At this stage I would suggest copying the policy, saving it to a local file and then moving onto the next step - refining the policy.&lt;/p>
&lt;h3 id="step-5-refine-the-policy">Step 5: Refine the Policy&lt;/h3>
&lt;p>The generated policy will likely not be suitable for use yet. It might to too specific - limiting access to the specific resources which were used. You will also have services and actions listed for &lt;em>any&lt;/em> calls which have been made using the role - which might also include calls used for &lt;em>other&lt;/em> processes than just the one you tested earlier. For example, my policy has some permissions to list analyzers. That is &lt;em>not&lt;/em> needed by serverless - that has been included because I was using the same cross-account administrator role to create the analyzer earlier on, and this has been picked up.&lt;/p>
&lt;p>This also highlights the importance of using separate roles for separate processes - if you use a small number of roles to do a lot of different things, it can be very hard to understand why certain actions were taken. Again, for a quick test it might be OK to use the same role that you access the portal with, but it is good to get into the habit of quickly creating roles for specific purposes.&lt;/p>
&lt;p>This is where I would suggest going through the policy in detail and using it as a template for the &amp;lsquo;final&amp;rsquo; policy. This is what we'll discus in the final step.&lt;/p>
&lt;h3 id="step-6-document-document-document">Step 6: Document, Document, Document&lt;/h3>
&lt;p>The final policy we create should be clearly documented. It is really important to explain &lt;em>why&lt;/em> certain permissions are needed. If people cannot reason about why a policy is set up in a specific way, then it will be very hard for them to maintain it over time or decide whether the permissions are appropriate or not.&lt;/p>
&lt;p>Even more so than with &amp;lsquo;normal&amp;rsquo; code, code which relates to security has to be comprehensible by others (or yourself when you come back to it). If you cannot understand why a policy grants a certain permission, then when you review the policy you don't know whether the remove the permissions or leave them in (this is an example of &lt;a href="https://github.com/dwmkerr/hacker-laws#chestertons-fence">Chesterton's Fence&lt;/a>.&lt;/p>
&lt;p>Whether you document this policy by saving it in a file, adding comments and checking it into source control, or turning it into a re-usable Terraform module, or using Pulimi to define the policy, or some other solution, is not too important. What &lt;em>is&lt;/em> important is documenting the policy and making this documentation transparent to others - and ideally making sure that others can maintain it over time.&lt;/p>
&lt;p>As an example, this is how I might define the S3 permissions in a Terraform file:&lt;/p>
&lt;pre>&lt;code># This statement allows the creation and management of buckets, which are used
# by serverless for CloudFormation files. Because the bucket name is
# non-deterministic we have to allow the creation of _any_ bucket.
statement {
sid = &amp;quot;ServerlessFrameworkS3&amp;quot;
effect = &amp;quot;Allow&amp;quot;
actions = [
&amp;quot;s3:CreateBucket&amp;quot;,
&amp;quot;s3:DeleteBucket&amp;quot;,
&amp;quot;s3:DeleteBucketPolicy&amp;quot;,
&amp;quot;s3:GetBucketAcl&amp;quot;,
&amp;quot;s3:GetBucketPolicy&amp;quot;,
&amp;quot;s3:GetBucketPolicyStatus&amp;quot;,
&amp;quot;s3:GetBucketPublicAccessBlock&amp;quot;,
&amp;quot;s3:GetEncryptionConfiguration&amp;quot;,
&amp;quot;s3:GetObject&amp;quot;,
&amp;quot;s3:ListBucket&amp;quot;,
&amp;quot;s3:PutBucketPolicy&amp;quot;,
&amp;quot;s3:PutBucketPublicAccessBlock&amp;quot;,
&amp;quot;s3:PutBucketTagging&amp;quot;,
&amp;quot;s3:PutEncryptionConfiguration&amp;quot;,
&amp;quot;s3:PutObject&amp;quot;,
&amp;quot;s3:SetBucketEncryption&amp;quot;,
]
resources = [
&amp;quot;arn:aws:s3:::*&amp;quot;
]
}
&lt;/code>&lt;/pre>&lt;p>I'm being very explicit with my comments, giving the statement id a meaningful value and creating separate statements for &lt;em>each service&lt;/em>.&lt;/p>
&lt;p>How you structure your policies will depend on the tools you use and your own preferred processes but the principle will remain the same - document carefully!&lt;/p>
&lt;h2 id="thats-it">That's It!&lt;/h2>
&lt;p>The IAM Access Advisor is a powerful feature and should be of interest to anyone managing sensitive environments in the cloud.&lt;/p>
&lt;p>It is not limited to creating fine grained permissions - it can also help identify &lt;em>external access&lt;/em> to resources. This means it can be used to identify when resources such as S3 buckets are accessed via processes such as Cross-Account access.&lt;/p>
&lt;p>There are a lot of exciting features here and it will be interesting to see how the Access Advisor works over time!&lt;/p>
&lt;p>As usual, please do share any comments, suggestions or observations!&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Of course this is only a tiny part of the world of security best practices. To learn more I highly recommend &lt;a href="https://github.com/veeral-patel/how-to-secure-anything">Veeral Patel's amazing &amp;lsquo;How to secure anything&amp;rsquo; project&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>This is a great way to get engineers to think more about security - let them experiment with it and learn about it safely. Sandbox environments &lt;em>still&lt;/em> need certain protections. For example, you don't want someone to inadvertently install a component which spins up a bunch of EC2 instances which start bitcoin mining, but AWS has a raft of features to help you build these kinds of guardrails, without limiting the ability of engineers to test and learn. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Unit Testing the Windows Registry</title><link>https://dwmkerr.com/unit-testing-the-windows-registry/</link><pubDate>Sat, 05 Sep 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/unit-testing-the-windows-registry/</guid><description>&lt;p>I've been updating some of my .NET projects recently (read more about this in &lt;a href="https://dwmkerr.com/modernising-dotnet-projects/">Modernising .NET projects for .NET Core and beyond!&lt;/a>). In one of these projects I have to work with the &lt;a href="https://en.wikipedia.org/wiki/Windows_Registry">Windows Registry&lt;/a> - which can be quite painful, particularly if you want to make your code unit test friendly.&lt;/p>
&lt;p>In this article I'm going to introduce a simple approach to make testing the registry a little easier. If you are just interested in the code and not so much the story behind it, you can skip straight to the project at &lt;a href="https://github.com/dwmkerr/dotnet-windows-registry">github.com/dwmkerr/dotnet-windows-registry&lt;/a>.&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#why-bother-testing">Why Bother Testing?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#why-bother-testing-the-registry">Why Bother Testing the Registry?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#talk-is-cheap-show-me-the-code">Talk is cheap, show me the code&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-registry-is-not-easily-testable">The Registry is not easily testable&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-testable-registry">The Testable Registry&lt;/a>&lt;/li>
&lt;li>&lt;a href="#go-forth-and-test">Go forth and test&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h1 id="why-bother-testing">Why Bother Testing?&lt;/h1>
&lt;p>There is a wealth of material available on the subject of testing. The value different of different types of tests has been discussed at length and is a constant source of debate. If you are interested in reading about testing in more detail, I recommend &lt;a href="https://martinfowler.com/testing/">Martin Fowler's Software Testing Guide&lt;/a>.&lt;/p>
&lt;p>I'm not going to weigh in on the debate of the value of different tests. Instead, here are the specific issues I faced when working on my &lt;a href="https://github.com/dwmkerr/sharpshell">SharpShell&lt;/a> project (which is where my registry testing project originated):&lt;/p>
&lt;ol>
&lt;li>This is an open source project with a number of users, who would be inconvenienced if things broke from one release to another&lt;/li>
&lt;li>There are a number of scenarios in the project which involve extensive modification of the registry&lt;/li>
&lt;li>Even very small mistakes in the way the registry is accessed can break the code&lt;/li>
&lt;li>Manually testing these scenarios is &lt;em>very&lt;/em> time consuming&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;and I have very limited time to work on this project&lt;/li>
&lt;li>I want to encourage others to contribute, but have confidence their changes will not cause unexpected failures&lt;/li>
&lt;/ol>
&lt;p>In &lt;em>this&lt;/em> project, being able to test the changes my code is going to make to the registry has been valuable. Whether it is for your own projects will depend on your own circumstances.&lt;/p>
&lt;h1 id="why-bother-testing-the-registry">Why Bother Testing the Registry?&lt;/h1>
&lt;p>The Registry is essentially a database. A problematic database. It has a complex schema, which has evolved over time. The schema for certain features (such as Windows Shell Extensions) has changed considerably over the years. It is often messy - many programs will write to it and programs can overwrite values.&lt;/p>
&lt;p>One thing I have discovered over my years maintaining the SharpShell project is that registry access is one of the most &lt;em>brittle&lt;/em> elements of the code. It is risky, it can have unexpected consequences.&lt;/p>
&lt;p>There are a few things which should cause anyone working with the registry to seriously consider testing:&lt;/p>
&lt;ul>
&lt;li>What do you do if the keys you are accessing have been modified by other programs?&lt;/li>
&lt;li>What if your own programs have written incorrect data?&lt;/li>
&lt;li>Is your code going to run on different versions of Windows, which might use the registry in different ways?&lt;/li>
&lt;li>Registry access is &lt;em>security sensitive&lt;/em> - does your code run with the appropriate permissions to access what it needs to access?&lt;/li>
&lt;/ul>
&lt;p>The registry is a database, but it is not an ACID database, meaning you can quite easily end up writing data in an inconsistent format (for example, if your program crashes before it has written all of the data it needs to). It has very limited access control - there is no way to limit other privileged programs overwriting or corrupting your data.&lt;/p>
&lt;p>Hopefully covers some of the reasons it is worth testing the registry. Now lets see some code.&lt;/p>
&lt;h1 id="talk-is-cheap-show-me-the-code">Talk is cheap, show me the code&lt;/h1>
&lt;p>Here's an example of what I want to be able to do:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#a6e22e">[Test]&lt;/span>
&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Register_Server_Associations_Uses_Appropriate_Class_Id_For_Class_Of_Extension()
{
&lt;span style="color:#75715e">// Pretty important test. Given we have a file extension in the registry, assert that we
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// register an extension with the appropriate ProgID.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e">// Prime the registry with a progid for *.exe files.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> _registry.AddStructure(RegistryView.Registry64, &lt;span style="color:#66d9ef">string&lt;/span>.Join(Environment.NewLine,
&lt;span style="color:#e6db74">@&amp;#34;HKEY_CLASSES_ROOT&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; .exe&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; (Default) = exefile&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; Content Type = application/x-msdownload&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; exefile&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; (Default) = Application&amp;#34;&lt;/span>
));
&lt;span style="color:#75715e">// Register a context menu with an *.exe association.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> clsid = &lt;span style="color:#66d9ef">new&lt;/span> Guid(&lt;span style="color:#e6db74">&amp;#34;00000000-1111-2222-3333-444444444444&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> serverType = ServerType.ShellContextMenu;
&lt;span style="color:#66d9ef">var&lt;/span> serverName = &lt;span style="color:#e6db74">&amp;#34;TestContextMenu&amp;#34;&lt;/span>;
&lt;span style="color:#66d9ef">var&lt;/span> associations = &lt;span style="color:#66d9ef">new&lt;/span>[] { &lt;span style="color:#66d9ef">new&lt;/span> COMServerAssociationAttribute(AssociationType.ClassOfExtension, &lt;span style="color:#e6db74">&amp;#34;.exe&amp;#34;&lt;/span>) };
&lt;span style="color:#66d9ef">var&lt;/span> registrationType = RegistrationType.OS64Bit;
ServerRegistrationManager.RegisterServerAssociations(clsid, serverType, serverName, associations, registrationType);
&lt;span style="color:#75715e">// Assert we have the new extention.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> print = _registry.Print(RegistryView.Registry64);
Assert.That(print, Is.EqualTo(&lt;span style="color:#66d9ef">string&lt;/span>.Join(Environment.NewLine,
&lt;span style="color:#e6db74">@&amp;#34;HKEY_CLASSES_ROOT&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; .exe&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; (Default) = exefile&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; Content Type = application/x-msdownload&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; exefile&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; (Default) = Application&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; ShellEx&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; ContextMenuHandlers&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; TestContextMenu&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; (Default) = {00000000-1111-2222-3333-444444444444}&amp;#34;&lt;/span>)
));
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This test looks a little complex, but the details don't matter. What matters is the &lt;em>flow&lt;/em>, which is just:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Given&lt;/strong> a particular existing structure in the registry&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;&lt;strong>when&lt;/strong> I call a certain API&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;&lt;strong>then&lt;/strong> I expect a certain set of changes to have been made&lt;/li>
&lt;/ol>
&lt;p>Should be easy right? Unfortunately, it's not as easy as this.&lt;/p>
&lt;h1 id="the-registry-is-not-easily-testable">The Registry is not easily testable&lt;/h1>
&lt;p>The &lt;a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.win32.registrykey">.NET Framework Registry classes&lt;/a> are not written with testing in mind. This is not surprising - they are just wrappers around the &lt;a href="https://docs.microsoft.com/en-us/windows/win32/sysinfo/registry-functions">Win32 Registry APIs&lt;/a>. These are APIs which have been around for a while, they have a very well-defined goal, which is to provide access to the registry. They were not written with unit testing in mind.&lt;/p>
&lt;p>There are in general two approaches which can be taken to testing &lt;a href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">&lt;em>side effects&lt;/em>&lt;/a>. Side effects are changes to state &lt;em>outside&lt;/em> of your function or code's state - such as the file system, databases and so on. These approaches are:&lt;/p>
&lt;ul>
&lt;li>Test the System: We allow our tests to change the external system, making sure to prepare it in advance, read the changes, then clean up afterwards&lt;/li>
&lt;li>Mocks the System: We make sure our code doesn't touch the external system when it is testing, we test a mock only and assert that the mocked code makes the expected changes&lt;/li>
&lt;/ul>
&lt;p>The first approach is arguably better - you are &lt;em>really&lt;/em> asserting that the expected changes have been made. But it is also complex - you have to clean up after yourself, you run the risk of your tests actually changing (or even breaking your system) and you make it harder to have other developers easily run the tests. Some systems can mitigate this - for example, with some databases you could test in the context of a transaction which you never commit. But the registry offers no such capabilities.&lt;/p>
&lt;p>The second approach is more common and in general a little easier. It doesn't cause side effects, but still allows us to at least ensure we are going to attempt to make the expected changes.&lt;/p>
&lt;p>To mock a service under test in .NET, we generally need to be calling functions on an &lt;em>interface&lt;/em>. There are some ways around this (fakes, modified assemblies, etc) but they are problematic. However, the .NET Registry classes are not exposed as interfaces. This is not a failure of the framework, arguably adding interfaces without a specific need is an anti-pattern. But it does make mocking the registry hard.&lt;/p>
&lt;p>The easiest way around this problem (at least in my opinion) is to wrap the registry access in an interface, then provide two implementations. One which uses the standard registry access methods, and one which mocks the changes to the registry in an isolated and testable fashion. In my SharpShell code this was the approach I took, and I have just extracted this code into its own library to help others who might want to use the same approach.&lt;/p>
&lt;h1 id="the-testable-registry">The Testable Registry&lt;/h1>
&lt;p>The solution I've used is fairly simple. You can see the code at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/dotnet-windows-registry">github.com/dwmkerr/dotnet-windows-registry&lt;/a>&lt;/p>
&lt;p>Instead of making calls to &lt;code>Regsitry&lt;/code> or &lt;code>RegistryKey&lt;/code>, you make calls to &lt;code>IRegsitry&lt;/code> or &lt;code>IRegsitryKey&lt;/code>. Then use the appropriate implementation. There are examples in the project documentation, but here's how it looks in a nutshell.&lt;/p>
&lt;p>First, make sure the code you have which access the registry does it via the &lt;code>IRegistry&lt;/code> interface:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Greeter&lt;/span>
{
&lt;span style="color:#66d9ef">public&lt;/span> Greeter(IRegistry _registry)
{
_registry = registry;
}
&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Greet(&lt;span style="color:#66d9ef">string&lt;/span> name, &lt;span style="color:#66d9ef">string&lt;/span> greeting)
{
&lt;span style="color:#66d9ef">using&lt;/span> var key = registry.OpenBaseKey(RegistryHive.CurrentUser, RegistryView.Registry64);
&lt;span style="color:#66d9ef">using&lt;/span> var subkey = key.OpenSubKey(&lt;span style="color:#e6db74">&amp;#34;Greetings&amp;#34;&lt;/span>);
subkey.SetValue(name, &lt;span style="color:#e6db74">$&amp;#34;{greeting}, {name}!&amp;#34;&lt;/span>);
}
&lt;span style="color:#66d9ef">private&lt;/span> IRegsitry _registry;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now in your program, create your class and provide it with a &lt;code>WindowsRegistry&lt;/code> class:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#66d9ef">var&lt;/span> greeter = &lt;span style="color:#66d9ef">new&lt;/span> Greeter(&lt;span style="color:#66d9ef">new&lt;/span> WindowsRegistry());
greeter.Greet(&lt;span style="color:#e6db74">&amp;#34;Billy&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;Howdy&amp;#34;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And you can test your code like so:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#66d9ef">var&lt;/span> registry = &lt;span style="color:#66d9ef">new&lt;/span> InMemoryRegistry();
&lt;span style="color:#66d9ef">var&lt;/span> greeter = &lt;span style="color:#66d9ef">new&lt;/span> Greeter(registry);
&lt;span style="color:#66d9ef">var&lt;/span> print = _registry.Print(RegistryView.Registry64);
Assert.That(print, Is.EqualTo(&lt;span style="color:#66d9ef">string&lt;/span>.Join(Environment.NewLine,
&lt;span style="color:#e6db74">@&amp;#34;HKEY_CURRENT_USER&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; Greetings&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">@&amp;#34; Billy = Howdy, Billy!&amp;#34;&lt;/span>)));
&lt;/code>&lt;/pre>&lt;/div>&lt;p>That's the basics.&lt;/p>
&lt;h1 id="go-forth-and-test">Go forth and test&lt;/h1>
&lt;p>There is a degree of inconvenience in having to use the interface rather than using the out-of-the-box implementation. This is a trade-off you will have to make to allow your code to be testable, and whether it is a worthwhile trade will depend on your project.&lt;/p>
&lt;p>The pattern of not relying on concrete implementations and instead providing interfaces to classes is known as &lt;a href="https://en.wikipedia.org/wiki/Dependency_injection">Dependency Injection&lt;/a>. There are technologies which attempt to assist with this pattern, known as Inversion of Control Containers - whether they make life easier to simply move complexity around (see &lt;a href="https://github.com/dwmkerr/hacker-laws#the-law-of-conservation-of-complexity-teslers-law">The Law of Conservation of Complexity&lt;/a>). But if you are &lt;em>already using&lt;/em> an IoC container then adopting this library and pattern will be trivial.&lt;/p>
&lt;p>That's it - the code has been internal to the SharpShell project for years and I have only just extracted it into its own library. I'll be using it in my &lt;a href="https://github.com/dwmkerr/dotnet-com-admin">ComAdmin&lt;/a> project (which is also being extracted from SharpShell). Given that it is new it might change a bit, and I'd love any feedback:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/dotnet-windows-registry">https://github.com/dwmkerr/dotnet-windows-registry&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Modernising .NET projects for .NET Core and beyond!</title><link>https://dwmkerr.com/modernising-dotnet-projects/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/modernising-dotnet-projects/</guid><description>&lt;p>The world of .NET is going through a transformation. The .NET Framework is reaching end of life, &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">.NET Core&lt;/a> is an increasingly feature rich and robust platform to develop solutions which target Linux, MacOS, embedded devices, containers and more. There's also the .NET Standard.&lt;/p>
&lt;p>But what does this mean for .NET &lt;em>Framework&lt;/em> projects? In this article I'll describe how to modernise your .NET Framework projects for .NET Core, the .NET Standard and .NET 5, which is planned to be released this year. I'll also explain the high level differences between the platforms and what the consequences of upgrading are for consumers, developers and maintainers.&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#the-net-framework-net-core-and-the-future">The .NET Framework, .NET Core and the Future&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-challenge-modernisation-and-compatibility">The Challenge: Modernisation and Compatibility&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-modernisation-process---introducing-our-two-villains">The Modernisation Process - Introducing our two Villains&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#step-1---understand-the-domain">Step 1 - Understand the Domain&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-2---understand-the-goal---multi-platform-builds">Step 2 - Understand the Goal - Multi-Platform Builds&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-3---migrate-projects-leaf-wise">Step 3 - Migrate Projects &amp;ldquo;Leaf-wise&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-4---refactor-rinse-repeat">Step 4 - Refactor, Rinse, Repeat&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-5---update-your-builds">Step 5 - Update Your Builds&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-6---simplify">Step 6 - Simplify!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-7---test-test-test">Step 7 - Test, Test, Test&lt;/a>&lt;/li>
&lt;li>&lt;a href="#step-8---document-compatibility">Step 8 - Document Compatibility&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-key-learnings">The Key Learnings&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h1 id="the-net-framework-net-core-and-the-future">The .NET Framework, .NET Core and the Future&lt;/h1>
&lt;p>There's a lot which has been written on this topic, but it can still be a little overwhelming to understand just how all of these things fit together.&lt;/p>
&lt;p>Here's a simple visual I've created to try and put things into context:&lt;/p>
&lt;p>&lt;img src="images/dotnet-timeline.png" alt="Diagram: .NET Timeline">&lt;/p>
&lt;p>I'm only going to cover the bare essentials - but there are links to further reading on each topic if you want to go deeper. This article is mainly going to be focused on the practicality and consequence of migration and re-targeting.&lt;/p>
&lt;p>First, the &lt;strong>.NET Framework&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>The .NET Framework was created in 2002 as set of unified tools and standards to allow developers on the Microsoft Platform to more quickly build solutions, provide interoperability between languages and more. &lt;a href="https://dotnet.microsoft.com/learn/dotnet/what-is-dotnet-framework">Read more about the .NET Framework&lt;/a>.&lt;/li>
&lt;li>The .NET Framework rapidly gained popularity, partly due to the convenience of developing in C# rather than Basic or C/C++. C# provided a more developer friendly language than C or C++ for many use cases, and was heavily inspired by Java. &lt;a href="https://docs.microsoft.com/en-us/dotnet/csharp/">Read more about C#&lt;/a>.&lt;/li>
&lt;li>With the increase in popularity, the .NET Framework started to have more frequent releases and became a standard part of the Windows operating system, installed out of the box rather than on-demand if needed.&lt;/li>
&lt;li>However - the .NET Framework only functioned on Microsoft Windows, which greatly limited its potential uses cases, even as more and more engineers used it for Web, Client Applications and mobile.&lt;/li>
&lt;/ul>
&lt;p>Enter &lt;strong>.NET Core&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Microsoft signaled a &lt;em>radical&lt;/em> switch in their strategy with the appointment of &lt;a href="https://en.wikipedia.org/wiki/Satya_Nadella">Satya Nadella&lt;/a>, becoming increasingly focused on open source, and more importantly, deciding that the Microsoft development toolchain should not &lt;em>force&lt;/em> users to use Windows as their execution environment&lt;/li>
&lt;li>.NET Core was developed as a lightweight version of the .NET Framework, which could run on multiple platforms - including Linux and MacOS. &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">Read more about .NET Core&lt;/a>.&lt;/li>
&lt;li>In a short period of time .NET Core became more and more feature rich, providing a lot of capabilities for web developers and front-end application developers.&lt;/li>
&lt;/ul>
&lt;p>The challenges of &lt;strong>divergence&lt;/strong> and the &lt;strong>.NET Standard&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>As .NET Core became more feature rich, the API became closer to the .NET Framework - but they are still fundamentally different runtimes. A binary compiled for the .NET Core does not run on the .NET Framework and vice-versa.&lt;/li>
&lt;li>To deal with this issue, Microsoft developed the &lt;strong>.NET Standard&lt;/strong> - a specification of a set of APIs. If a runtime offered these APIs, then solutions built on &lt;em>any runtime which meets the standard&lt;/em> could run on any compliant platform.&lt;/li>
&lt;/ul>
&lt;p>What does this mean? Basically, the table below shows the consequences of this. If you build on .NET Core 2.0 (for example), you can also run on the .NET Framework 4.6.1. Mono 5.4, Unity 2018.1 and more, because all of these runtimes implement the &lt;em>.NET Standard 2.0&lt;/em>.&lt;/p>
&lt;p>Of course, some features are always going to be very platform specific, so the standard started out small but has grown over time.&lt;/p>
&lt;p>Moving to &lt;strong>convergence&lt;/strong> and &lt;strong>.NET&lt;/strong>.&lt;/p>
&lt;ul>
&lt;li>Given that the later versions of the .NET Framework and .NET Core actually follow the same standard, the platforms are actually starting to become more and more similar.&lt;/li>
&lt;li>They are becoming &lt;em>so&lt;/em> similar that it no longer makes sense to maintain them separately. The next major version of &lt;em>both&lt;/em> platforms is &lt;strong>.NET 5&lt;/strong>. This is a new runtime which is the next version of .NET Core &lt;em>and&lt;/em> the .NET Framework.&lt;/li>
&lt;/ul>
&lt;p>This means that the .NET Framework and .NET Core are going to converge into a single platform, which will be wonderful for developers and simplify a complex landscape.&lt;/p>
&lt;p>But what does this mean if you have .NET Framework projects? How do we modernise, and do we have to make trade-offs around compatibility?&lt;/p>
&lt;h1 id="the-challenge-modernisation-and-compatibility">The Challenge: Modernisation and Compatibility&lt;/h1>
&lt;p>I have a number of projects which target the .NET Framework. On &lt;em>all&lt;/em> of these projects I have had multiple requests to migrate to the .NET Core, but I have had to hold off on this work until I could really understand in detail a few things:&lt;/p>
&lt;ol>
&lt;li>What would this mean for &lt;em>consumers&lt;/em> of the libraries? Would they have to change the platform they use? Could this break things for them?&lt;/li>
&lt;li>What would this mean for &lt;em>developers&lt;/em> on the platform? Would they need to change their development environment? Would this cause problems?&lt;/li>
&lt;li>What would this mean for &lt;em>maintainers&lt;/em> of the libraries? Would this greatly increase build and deployment complexity?&lt;/li>
&lt;/ol>
&lt;p>Finally I have found the time to be able to start to address these issues in detail - hopefully the learnings will be useful to anyone who is maintaining a .NET codebase and thinking about the future.&lt;/p>
&lt;h1 id="the-modernisation-process---introducing-our-two-villains">The Modernisation Process - Introducing our two Villains&lt;/h1>
&lt;p>There are two key projects I wanted to modernise. They are both reasonably well used, complex, and have some potentially serious complexities for multi-platform builds.&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/sharpgl">&lt;strong>SharpGL&lt;/strong>&lt;/a> is a library that allows developers to use &lt;a href="https://www.opengl.org/">OpenGL&lt;/a> in .NET applications. The big challenge? OpenGL is cross platform, but SharpGL &lt;em>specifically&lt;/em> provides an interface to the &lt;em>Windows&lt;/em> version of OpenGL. Can this possibly be made more future-proof? Could it ever target other platforms?&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/sharpshell">&lt;strong>SharpShell&lt;/strong>&lt;/a> is a library that allows developers to build &amp;lsquo;Shell Extensions&amp;rsquo; for Windows. Shell extensions are customisations to the Windows user interface, so would not be portable across platforms, but I still want to ensure that the project is future proof.&lt;/p>
&lt;p>What would be the experience with these two projects? I have other .NET projects, but they are far less popular and much more simple, my instinct is that if I can work through the process with &lt;em>these&lt;/em> projects, the others should be more straightforward.&lt;/p>
&lt;p>These are the steps I've followed to modernise. I'll finish the article with a summary of the key learnings.&lt;/p>
&lt;h2 id="step-1---understand-the-domain">Step 1 - Understand the Domain&lt;/h2>
&lt;p>I cannot stress this enough. In all meaningful technology work, &lt;em>understand the domain&lt;/em> you are dealing with. A quick Google on how to migrate, or following the formal migration guide was not enough for me. I knew I had to actually understand, at a reasonably detailed level, the differences in the runtime, the trade-offs, the process, the complexity.&lt;/p>
&lt;p>This article is the result of that work - sometimes writing about a topic is the best way to force yourself to learn it.&lt;/p>
&lt;p>Making changes rapidly and waiting to see what the consequences are can often work for small projects, internal tools and so on, but for a library which is relied upon by others is not good for the community. The last thing I wanted to do was make changes which had unintended consequences for users. So making sure that I learnt about this space, how things work under the hood, and what the expected changes in the future are was critical.&lt;/p>
&lt;p>Hopefully for others the process of understanding the domain will be a little easier with this article to cover the high level topics. During my actual process of writing and migrating, I went a lot deeper than this article goes.&lt;/p>
&lt;p>The key document to follow to actually &lt;em>execute&lt;/em> the migration is the excellent official &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">.NET Framework to .NET Core Porting Guide&lt;/a>.&lt;/p>
&lt;h2 id="step-2---understand-the-goal---multi-platform-builds">Step 2 - Understand the Goal - Multi-Platform Builds&lt;/h2>
&lt;p>Given the understanding of the domain, it made it much easier to understand what the required steps would be. Essentially, all that would be needed would be to target a version of the .NET Framework which adheres to a recent version of the .NET Standard. Once this was done, in theory the project could be built for the .NET Framework &lt;em>and&lt;/em> for .NET Core, and also be ready for the upcoming .NET 5 release.&lt;/p>
&lt;p>Multi-platform builds are supported in Visual Studio 2019. These builds allow us to have a single codebase, but build libraries for multiple platforms (i.e. the .NET Framework and .NET Core). The resulting binaries can be packed as a single package, and when consumers install the package, the appropriate library is installed.&lt;/p>
&lt;p>This introduces the first of the significant consequences - modernising your project means you must migrate it to Visual Studio 2019.&lt;/p>
&lt;p>In the past, this might have been more of an issue, licenses for Visual Studio were expensive, and many organisations were locked onto specific versions for compatibility issues (or because they were slow to upgrade). This seems to be the case less often nowadays, but is still an important consideration.&lt;/p>
&lt;p>My projects were using Visual Studio 2017. This is how the project properties looked:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-target-framework-2017.png" alt="Screenshot: SharpGL Target Framework Properties for Visual Studio 2017">&lt;/p>
&lt;p>Unsurprisingly the .NET Standard isn't mentioned. Time to upgrade to 2019. While I installed it I could reminisce about the excitement of buying Visual C++ .NET Learning Edition:&lt;/p>
&lt;p>&lt;img src="./images/visual-cpp-dotnet-learning-edition.jpg" alt="Photo: Visual C++ .NET 2003 Learning Edition">&lt;/p>
&lt;p>And try and remember what is was like to be a 15 years old. I wonder if that box set is still kicking around somewhere, I want to see it again. So much has changed. But long install processes for Visual Studio haven't, at least they kept that:&lt;/p>
&lt;p>&lt;img src="./images/install-visual-studio-2019.png" alt="Screenshot: Visual Studio 2019 Installer">&lt;/p>
&lt;p>When installing, remember to enable the .NET Core features.&lt;/p>
&lt;h2 id="step-3---migrate-projects-leaf-wise">Step 3 - Migrate Projects &amp;ldquo;Leaf-wise&amp;rdquo;&lt;/h2>
&lt;p>As per the &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Porting Guide&lt;/a>, we need to migrate each of the projects which make up the solution, starting with the &amp;lsquo;leaves&amp;rsquo; (projects which don't depend on other projects) and then moving up the tree to the &amp;lsquo;root&amp;rsquo; projects (projects which are depended on by others).&lt;/p>
&lt;p>Visually, for a solution like SharpGL, that would mean the projects will need to be converted in the following order:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-project-structure.png" alt="Diagram: SharpGL Project Dependency Graph">&lt;/p>
&lt;p>I was expecting each project to have quite different experiences:&lt;/p>
&lt;ul>
&lt;li>&lt;code>SharpGL.Serialization&lt;/code> is just a set of classes which load data from files. In theory, this library should become completely portable.&lt;/li>
&lt;li>&lt;code>SharpGL.WPF&lt;/code> and &lt;code>SharpGL.WinForms&lt;/code> are &lt;em>specifically&lt;/em> for Windows front-end technologies. I expected these to be able to be ported, but don't expect them to work on other platforms (in the future there might be &lt;code>SharpGL.OSx&lt;/code>, or &lt;code>SharpGL.Gnome&lt;/code>, who knows)&lt;/li>
&lt;li>&lt;code>SharpGL.SceneGraph&lt;/code> is a set of classes which represent 3D scenes - things like lights, cameras, materials and so on. I expect &lt;em>some&lt;/em> of this to &amp;lsquo;just work&amp;rsquo;, but things like image loading to perhaps need some tweaking.&lt;/li>
&lt;li>&lt;code>SharpGL&lt;/code> is just a wrapper around the Windows &lt;code>opengl32.dll&lt;/code> library. I can't imagine this &lt;em>working&lt;/em> anywhere but Windows, but how would the project structure porting go and would it build?&lt;/li>
&lt;/ul>
&lt;p>The details on &lt;em>how&lt;/em> to migrate a project are in the &lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Porting Guide&lt;/a>, but the general approach will be:&lt;/p>
&lt;ol>
&lt;li>Attempt to convert to the latest project format with the &lt;code>try-convert&lt;/code> tool&lt;/li>
&lt;li>Re-target the project to the .NET Framework 4.7.2 (the first version which supports the .NET standard)&lt;/li>
&lt;li>Repeat for projects which this project depends on, walking the tree of projects to the root&lt;/li>
&lt;li>Run the Portability Analysis tool to see if there are APIs which are not available on certain platforms&lt;/li>
&lt;/ol>
&lt;p>This is how you project might look after migration, having run the &lt;code>try-convert&lt;/code>:&lt;/p>
&lt;p>&lt;img src="./images/migrate-project.png" alt="Screenshot: Ported Visual Studio Project">&lt;/p>
&lt;p>Now we just need to edit the project files and change the line:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;TargetFramework&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>4.7.2&lt;span style="color:#f92672">&amp;lt;/TargetFramework&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;TargetFrameworks&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>netcoreapp2.0;netcoreapp3.0;netcoreapp3.1;net40;net45;net472&lt;span style="color:#f92672">&amp;lt;/TargetFrameworks&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The targets you will choose will depend on the APIs you want to use. There is an Portability Analysis extension available which can build a portability report, here's what one looks like:&lt;/p>
&lt;p>&lt;img src="./images/portability-report-summary.png" alt="Screenshot: Portability Report Summary">&lt;/p>
&lt;p>This will also show the &lt;em>specific&lt;/em> APIs which are not compatible with specific targets:&lt;/p>
&lt;p>&lt;img src="./images/portability-report.png" alt="Screenshot: Portability Report Details">&lt;/p>
&lt;p>Now it's time to move to the next step.&lt;/p>
&lt;h2 id="step-4---refactor-rinse-repeat">Step 4 - Refactor, Rinse, Repeat&lt;/h2>
&lt;p>This is the tricky part. You'll now need to work out whether you want to &lt;em>remove&lt;/em> API calls which are not portable, try and use alternatives, or conditionally compile the code for different platforms.&lt;/p>
&lt;p>If you are using non-portable APIs you may need to use conditional blocks to execute different code depending on the framework used. The &lt;a href="https://docs.microsoft.com/en-us/dotnet/standard/frameworks#how-to-specify-target-frameworks">Target frameworks in SDK-style projects&lt;/a> guide shows how to do this.&lt;/p>
&lt;p>You may also have to manually edit the project file to ensure that certain dependencies are &lt;em>only&lt;/em> used for certain targets. You solution file and dependencies may end up looking something like this:&lt;/p>
&lt;p>&lt;img src="./images/conditional-dependencies.png" alt="Screenshot: Conditional Dependencies">&lt;/p>
&lt;p>Once you have reloaded the project you'll see your dependencies can now be specified on a per-framework basis, and a build generates assemblies for each of the targets:&lt;/p>
&lt;p>&lt;img src="./images/generated-assemblies.png" alt="Screenshot: Generated Assemblies">&lt;/p>
&lt;p>This process might be simple, or complex, depending on the nuances of your project. For me it was fairly iterative - starting by targeting only &lt;code>net40&lt;/code> (the original target framework which I'd used), then adding more and more targets.&lt;/p>
&lt;p>Some targets will simply not be possible - for example .NET Core only supports WinForms and WPF from .NET Core 3.0 onwards; you won't be able to build a WinForms or WPF assembly which targets a lower version, the framework doesn't support it.&lt;/p>
&lt;h2 id="step-5---update-your-builds">Step 5 - Update Your Builds&lt;/h2>
&lt;p>At this stage, having fixed compatibility issues, you should have code which builds in Visual Studio.&lt;/p>
&lt;p>Now I would recommend porting all of your build code to use the &lt;code>dotnet&lt;/code> build system. This is going to maximise the portability and future-proof your project, you'll be able to run the builds on multiple platforms and are using the preferred standard tool (&lt;code>msbuild&lt;/code> will essentially become legacy).&lt;/p>
&lt;p>The way I like to structure things personally is have a set of scripts which you can run to build, test and package the code locally. You can then call these scripts from you CI tool of choice to automate things, but still keep the logic in your own code, rather than hidden away in a build system.&lt;/p>
&lt;p>For example, in my SharpGL project I have the following scripts:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Script&lt;/th>
&lt;th>Usage&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>config.ps1&lt;/code>&lt;/td>
&lt;td>Ensure your machine can run builds by installing necessary components such as &lt;code>nunit&lt;/code>. Should only need to be run once.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>build.ps1&lt;/code>&lt;/td>
&lt;td>Build all solutions.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>test.ps1&lt;/code>&lt;/td>
&lt;td>Run all tests, including those in samples.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>coverage.ps1&lt;/code>&lt;/td>
&lt;td>Create a coverage report. Reports are written to &lt;code>./artifacts/coverage&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>pack.ps1&lt;/code>&lt;/td>
&lt;td>Create all of the SharpGL NuGet packages, which are copied to &lt;code>./artifacts/packages&lt;/code>.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>I updated my scripts to use the &lt;code>dotnet&lt;/code> tool. For example, the &amp;lsquo;build&amp;rsquo; script looks something like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-ps" data-lang="ps">&lt;span style="color:#a6e22e">#&lt;/span> &lt;span style="color:#a6e22e">Run&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">build,&lt;/span> &lt;span style="color:#a6e22e">hiding&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">documentation&lt;/span> &lt;span style="color:#a6e22e">warnings&lt;/span> &lt;span style="color:#a6e22e">for&lt;/span> &lt;span style="color:#a6e22e">pinvoke&lt;/span> &lt;span style="color:#a6e22e">code.&lt;/span>
&lt;span style="color:#a6e22e">$buildCommand&lt;/span> &lt;span style="color:#a6e22e">=&amp;#34;dotnet&lt;/span> &lt;span style="color:#a6e22e">msbuild&lt;/span> &lt;span style="color:#a6e22e">$PSScriptRoot\SharpGL.sln&lt;/span> &lt;span style="color:#a6e22e">-noWarn:CS1591&lt;/span> &lt;span style="color:#a6e22e">-noWarn:CS1573&lt;/span> &lt;span style="color:#a6e22e">-t:Rebuild&lt;/span> &lt;span style="color:#a6e22e">-p:Configuration=Release&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">Write-Host&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;Running:&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;&amp;#34;$buildCommand&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">Invoke-Expression&lt;/span> &lt;span style="color:#a6e22e">$buildCommand&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And the &amp;lsquo;pack&amp;rsquo; script looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-ps" data-lang="ps">&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL/SharpGL.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.SceneGraph/SharpGL.SceneGraph.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.Serialization/SharpGL.Serialization.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.WinForms/SharpGL.WinForms.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;span style="color:#a6e22e">dotnet&lt;/span> &lt;span style="color:#a6e22e">pack&lt;/span> &lt;span style="color:#a6e22e">--no-restore&lt;/span> &lt;span style="color:#a6e22e">--no-build&lt;/span> &lt;span style="color:#a6e22e">&amp;#34;$PSScriptRoot&lt;/span>/Core/SharpGL.WPF/SharpGL.WPF.csproj&amp;#34; &lt;span style="color:#a6e22e">-c:Release&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The actual scripts are a little more complex. But the key thing here is that I can run &lt;em>any&lt;/em> part of the CI/CD process locally (to test, debug and so on) or on a CI/CD platform.&lt;/p>
&lt;p>You will most likely have to &lt;em>conditionally&lt;/em> reference certain components. The dependency for &lt;code>net40&lt;/code> might be different to that for &lt;code>netcoreapp3.0&lt;/code>. You'll see that in many of my project files there is now code like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;ItemGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net40&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Design&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net40&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Reference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Windows.Forms&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/ItemGroup&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;ItemGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.0&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.1&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.CSharp&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.7.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.0&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;netcoreapp3.1&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net45&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageReference&lt;/span> &lt;span style="color:#a6e22e">Include=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;System.Data.DataSetExtensions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Version=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;4.5.0&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#39;$(TargetFramework)&amp;#39; == &amp;#39;net472&amp;#39;&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/ItemGroup&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In my case quite a bit of trial and error was needed to find the appropriate references for each platform.&lt;/p>
&lt;h2 id="step-6---simplify">Step 6 - Simplify!&lt;/h2>
&lt;p>One benefit I have found during this process is that you can &lt;em>simplify&lt;/em> your projects. You no longer need any kind of &amp;lsquo;automated NuGet restore&amp;rsquo; functionality. This means you can remove code like this from your project files:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;Import&lt;/span> &lt;span style="color:#a6e22e">Project=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;$(SolutionDir)\.nuget\NuGet.targets&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Exists(&amp;#39;$(SolutionDir)\.nuget\NuGet.targets&amp;#39;)&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Target&lt;/span> &lt;span style="color:#a6e22e">Name=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;EnsureNuGetPackageBuildImports&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">BeforeTargets=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;PrepareForBuild&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PropertyGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;ErrorText&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>This project references NuGet package(s) that are missing on this computer. Use NuGet Package Restore to download them. For more information, see http://go.microsoft.com/fwlink/?LinkID=322105. The missing file is {0}.&lt;span style="color:#f92672">&amp;lt;/ErrorText&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/PropertyGroup&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Error&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;!Exists(&amp;#39;..\packages\NUnit.3.11.0\build\NUnit.props&amp;#39;)&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Text=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;$([System.String]::Format(&amp;#39;$(ErrorText)&amp;#39;, &amp;#39;..\packages\NUnit.3.11.0\build\NUnit.props&amp;#39;))&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Error&lt;/span> &lt;span style="color:#a6e22e">Condition=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;!Exists(&amp;#39;..\packages\NUnit3TestAdapter.3.10.0\build\net35\NUnit3TestAdapter.props&amp;#39;)&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">Text=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;$([System.String]::Format(&amp;#39;$(ErrorText)&amp;#39;, &amp;#39;..\packages\NUnit3TestAdapter.3.10.0\build\net35\NUnit3TestAdapter.props&amp;#39;))&amp;#34;&lt;/span> &lt;span style="color:#f92672">/&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/Target&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can also remove your &lt;code>project.json&lt;/code> as all of the data is now in the &lt;code>csproj&lt;/code> file.&lt;/p>
&lt;p>Another nice update is that you no longer need to maintain an &lt;code>AssemblyInfo.cs&lt;/code> file; you can keep all of your assembly metadata in the &lt;code>csproj&lt;/code> file.&lt;/p>
&lt;p>Finally, you can almost certainly remove any &lt;code>nuspec&lt;/code> files - all NuGet packaging data can also be embedded in the &lt;code>csproj&lt;/code> file. For example, here's what my SharpShell project metadata looks like:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-xml" data-lang="xml">&lt;span style="color:#f92672">&amp;lt;Project&lt;/span> &lt;span style="color:#a6e22e">Sdk=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Microsoft.NET.Sdk.WindowsDesktop&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PropertyGroup&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;TargetFrameworks&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>netcoreapp2.0;netcoreapp3.0;netcoreapp3.1;net40;net45;net472&lt;span style="color:#f92672">&amp;lt;/TargetFrameworks&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;OutputType&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Library&lt;span style="color:#f92672">&amp;lt;/OutputType&amp;gt;&lt;/span>
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> The following properies are used to manage how the project is packaged. &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageId&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>SharpShell&lt;span style="color:#f92672">&amp;lt;/PackageId&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Copyright&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Copyright (c) Dave Kerr 2020&lt;span style="color:#f92672">&amp;lt;/Copyright&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageProjectUrl&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>https://github.com/dwmkerr/sharpshell&lt;span style="color:#f92672">&amp;lt;/PackageProjectUrl&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;RepositoryUrl&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>https://github.com/dwmkerr/sharpshell&lt;span style="color:#f92672">&amp;lt;/RepositoryUrl&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Version&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>3.1.1.0&lt;span style="color:#f92672">&amp;lt;/Version&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Authors&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Dave Kerr&lt;span style="color:#f92672">&amp;lt;/Authors&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Company&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Dave Kerr&lt;span style="color:#f92672">&amp;lt;/Company&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;PackageTags&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>Shell;SharpShell;COM;Context Menu;Icon Handler&lt;span style="color:#f92672">&amp;lt;/PackageTags&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;Description&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>SharpShell is a framework that lets you build Windows Shell Extensions using .NET Core or the .NET Framework.&lt;span style="color:#f92672">&amp;lt;/Description&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/PropertyGroup&amp;gt;&lt;/span>
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> ...snip... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;/Project&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This helps to keep a lot of the project dependency and property data in one place and is probably more convenient for many users.&lt;/p>
&lt;p>You can see the &lt;a href="https://github.com/dwmkerr/sharpgl/pull/177">Pull Request&lt;/a> for SharpGL to see how the project files were updated in this case. You can also see the &lt;a href="https://github.com/dwmkerr/sharpshell/pull/331">SharpShell Pull Request&lt;/a>. The SharpShell version is still work in progress at the time of writing.&lt;/p>
&lt;h2 id="step-7---test-test-test">Step 7 - Test, Test, Test&lt;/h2>
&lt;p>Now for the fun part. You are going to &lt;em>really&lt;/em> have to test the new packages on each platform. Sadly, this kind of migration is not something which will have issues exposed via unit tests, you'll need to create test projects which import your packages, ideally for each platform, and make sure they work. There could be runtime errors, particularly if you have made mistakes with the references.&lt;/p>
&lt;p>Many issues will be caught at compile time - some will not.&lt;/p>
&lt;p>Here's a screenshot of me having fun trying out the .NET Framework 4 package for WinForms, and the .NET Core 3.1 package for WPF:&lt;/p>
&lt;p>&lt;img src="./images/test-packages.png" alt="Screenshot: Testing SharpGL">&lt;/p>
&lt;p>How you test your packages will be very dependent on what you are building. If it is highly platform specific then you will likely have to do lots of testing. If it is fairly self-contained code then you might be able to get away with some basic smoke testing.&lt;/p>
&lt;h2 id="step-8---document-compatibility">Step 8 - Document Compatibility&lt;/h2>
&lt;p>If you are supporting multiple platforms and frameworks, it's going to be a lot of help to consumers of your code if you can be very clear about &lt;em>what is supported&lt;/em>.&lt;/p>
&lt;p>This may be more complex than you think. Your library may run fine as part of a .NET Core Console Application on Windows - but does it work on MacOS? What about Linux?&lt;/p>
&lt;p>Here's a screenshot I would never have imagined when I started the SharpGL project - a terminal application running on MacOS which is using the &lt;code>SharpGL.Serialization&lt;/code> library to load geometry from a file:&lt;/p>
&lt;p>&lt;img src="./images/sharpgl-on-mac.png" alt="Screenshot: Loading Geometry in SharpGL on MacOS">&lt;/p>
&lt;p>Now of course for something like SharpGL to run on a Mac or Linux, a lot more work would be needed. SharpGL is at its core nothing more than a wrapper around &lt;code>opengl32.dll&lt;/code> on Windows, on other platforms there are no DLLs, but OpenGL &lt;em>is&lt;/em> still available. So support is possible, but not ready yet. So at this stage, docmenting what you know works &lt;em>as well as what doesn't&lt;/em> will be really helpful.&lt;/p>
&lt;p>You might also want to preserve your &amp;lsquo;pre-migration&amp;rsquo; code in a separate branch, in case you have users who for some reason have issues migrating and need to use an older version. For SharpGL, I updated the project page to indicate compatibility, what has been tested and so on:&lt;/p>
&lt;p>&lt;img src="./images/readme-compatability.png" alt="Screenshot: SharpGL README showing compatibility information">&lt;/p>
&lt;h1 id="the-key-learnings">The Key Learnings&lt;/h1>
&lt;p>Here are the key learnings which stood out for me as I worked on migration of these projects.&lt;/p>
&lt;p>&lt;strong>Consumer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>If you are careful, you don't have to break anything for consumers - with multi-targeting you can &lt;em>still&lt;/em> target older frameworks.&lt;/li>
&lt;li>You can potentially greatly increase the compatibility of your projects by offering support for .NET Core.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Developer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You need to upgrade to Visual Studio 2019&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;however, you can use Visual Studio for Mac or even the command-line to build across many platforms.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Maintainer Experience&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You will have a much larger set of potential consumers, but you will likely find bugs which are framework or platform specific.&lt;/li>
&lt;li>You will likely need to work on migrating your project files and use the latest &lt;code>dotnet&lt;/code> tooling.&lt;/li>
&lt;li>You should be careful to document known compatibility issues.&lt;/li>
&lt;/ul>
&lt;p>All in all, the process was less painful than I expected. Now that this work is done I can focus on more exciting things, such as potentially getting projects like SharpGL working on Linux or MacOS, which is much more exciting.&lt;/p>
&lt;p>As always, questions, comments, suggestions, rants, anything are welcome!&lt;/p>
&lt;p>The pull request which migrates the SharpGL project and SharpShell projects are below:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/dwmkerr/sharpgl/pull/177/">github.com/dwmkerr/sharpgl/pull/177/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/dwmkerr/sharpshell/pull/331">github.com/dwmkerr/sharpshell/pull/331&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>Useful References&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/">Microsoft Docs: .NET Core Documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-gb/dotnet/core/porting/">Microsoft Docs: Overview of porting from .NET Framework to .NET Core&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/dotnet/standard/frameworks#how-to-specify-target-frameworks">Microsoft Docs: Target frameworks in SDK-style projects&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>Observations, tips and tricks for the CKA certification</title><link>https://dwmkerr.com/tips-for-cka/</link><pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/tips-for-cka/</guid><description>&lt;p>In this article I'll share some observations, tips and tricks for the &lt;a href="https://www.linuxfoundation.org/">Linux Foundation's&lt;/a> &amp;ldquo;&lt;a href="https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/">Certified Kubernetes Administrator&lt;/a> certification and exam.&lt;/p>
&lt;p>I've been operating Kubernetes in multiple environments for a few years now. I thought this would be an easy certification to get, but I was surprised by how hard it was!&lt;/p>
&lt;p>I took this exam without doing any formal training, I mostly focused on the areas of the curriculum which I knew I was a little weak at. The task-based structure for the exam I thought was really excellent. It took me two attempts to pass, and I learnt a few things along the way.&lt;/p>
&lt;p>Here I'll share some thoughts on the certification which hopefully will be useful if you are considering taking it!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#tip-do-the-right-certification">Tip: Do the right Certification!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-understand-the-format">Tip: Understand the Format!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-your-vim">Tip: Know your Vim&lt;/a>&lt;/li>
&lt;li>&lt;a href="#you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That's it!&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h2 id="tip-do-the-right-certification">Tip: Do the right Certification!&lt;/h2>
&lt;p>The CKA exam tests &lt;em>administration&lt;/em> and &lt;em>operation&lt;/em> skills and techniques for Kubernetes. If you have set up and administered clusters before, this will likely not be too challenging. But if you've never set up a cluster by hand, troubleshot weird issues, fixed clusters and so on, then this is likely going to be very hard.&lt;/p>
&lt;p>There is a certification which is much more geared towards developers who use Kubernetes, but don't necessarily administer it - that's the &lt;a href="https://www.cncf.io/certification/ckad/">CKAD&lt;/a> exam and might be the one to take if you are not too familiar with system administration.&lt;/p>
&lt;h2 id="tip-understand-the-format">Tip: Understand the Format!&lt;/h2>
&lt;p>This is not a multiple choice question exam. It's a task based exam, meaning you have about 22 or so specific tasks to complete, in a web browser which has a terminal connected to a cluster.&lt;/p>
&lt;p>It is open-book - meaning that you can use the &lt;a href="https://kubernetes.io/docs/home/">Kubernetes Documentation&lt;/a> during the exam. It's not a memory test of specific flags for commands or whatever, it will really require you to work with a running cluster. This means you'll have to be pretty familiar with &lt;code>kubectl&lt;/code>, &lt;code>kubeadm&lt;/code> and also Linux in general!&lt;/p>
&lt;h2 id="tip-know-your-vim">Tip: Know your Vim&lt;/h2>
&lt;p>In the two exams I took, &lt;code>nano&lt;/code> was available. But if you are using &lt;code>nano&lt;/code> to work with files you may struggle for time.&lt;/p>
&lt;p>I spent a &lt;em>lot&lt;/em> of time in &lt;code>vim&lt;/code> in the exam. &lt;code>vim&lt;/code> is my main text editor for day to day work, so I'm fairly familiar with it. Knowing how to quickly copy a file (lets say for example a file which represents a deployment) and quickly manipulate the text in it will be crucial. Make sure you are going to be using a text editor which you can be efficient in!&lt;/p>
&lt;p>You won't be using a graphical text editor to work with files, so being competent in a terminal editor like &lt;code>vim&lt;/code> or &lt;code>emacs&lt;/code> could make a big difference. Of course you could install your favourite text editor, but you won't be able to use a graphical editor like VS Code.&lt;/p>
&lt;p>Also, as in most Linux distributions, &lt;code>screen&lt;/code> is available out of the box, and &lt;code>tmux&lt;/code> can also be installed. If you are familiar with either of these terminal mutliplexers it could save you a tonne of time, for example being able to run &lt;code>watch -n 5 -d kubectl get pods&lt;/code> in one pane while applying resources in another.&lt;/p>
&lt;h2 id="you-need-to-know-the-architecture-of-kubernetes">You need to know the architecture of Kubernetes&lt;/h2>
&lt;p>This exam will require you to deal with trivial tasks such as running a deployment or creating a volume. But the questions which focus on that tend to only count for one or two percent of the overall grade each. Questions which deal with troubleshooting actual Kubernetes issues could count for six or seven percent each.&lt;/p>
&lt;p>This means you &lt;em>need&lt;/em> to know how Kubernetes is architecture. The &lt;code>kubelet&lt;/code> which runs on nodes, the API server, the &lt;code>etcd&lt;/code> store, all of these things you &lt;em>have&lt;/em> to understand how they work and how they fit together.&lt;/p>
&lt;p>The online documentation covers the architecture in detail, here's the best place to start:&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">&lt;img src="./images/k8s-architecture.png" alt="Kubernetes Architecture">&lt;/a>&lt;/p>
&lt;p>You will need to know how the control plane works, how nodes communicate, how transport of messages works and is secured if you are going to have a chance at dealing with the harder questions.&lt;/p>
&lt;h2 id="tip-you-need-to-know-linux-sysadmin">Tip: You Need to know Linux Sysadmin&lt;/h2>
&lt;p>If you are not familiar with &lt;code>systemctl&lt;/code>, &lt;code>journalctl&lt;/code>, &lt;code>apt&lt;/code>, &lt;code>systemd&lt;/code> units and how the core Kubernetes components are configured, you'll really struggle.&lt;/p>
&lt;p>Look over the &lt;a href="https://github.com/cncf/curriculum">CNCF curriculum&lt;/a> - expect to not just have to know how to deal with &amp;lsquo;happy path&amp;rsquo; situations, but also broken clusters, incorrect configuration and so on.&lt;/p>
&lt;h2 id="tip-dry-run-is-your-friend">Tip: &amp;ldquo;Dry Run&amp;rdquo; is your friend&lt;/h2>
&lt;p>One thing which helped me a lot in my second attempt at the exam was the &lt;code>--dry-run&lt;/code> flag. Before you create resources or change anything, run the operation with the &lt;code>--dry-run&lt;/code> flag and see whether the output is what you would expect.&lt;/p>
&lt;p>This is a quick and easy way to see the changes to the cluster which you are going to apply - and troubleshoot them - before making any actual changes.&lt;/p>
&lt;h2 id="tip-know-how-to-troubleshoot-networking">Tip: Know how to troubleshoot networking&lt;/h2>
&lt;p>Networking in Kubernetes is complex. You must be able to troubleshoot networking issues in the cluster to be able to deal with the more complex tasks.&lt;/p>
&lt;p>This means that you should know how to be able to run typical networking tools like &lt;code>dig&lt;/code>, &lt;code>nslookup&lt;/code>, &lt;code>telnet&lt;/code> etc, in the cluster itself.&lt;/p>
&lt;p>If you are not familiar with these tools you might need to take an online course in Kubernetes or Linux Networking Administration before considering this certification. The &lt;a href="https://training.linuxfoundation.org/certification/linux-foundation-certified-sysadmin-lfcs/">Linux Certified Systems Administrator&lt;/a> training would be a good place to start.&lt;/p>
&lt;p>If you have taken the &lt;a href="https://success.docker.com/certification">Docker Certified Associate&lt;/a> exam then some of this should be familiar. If you are not very familiar with how Docker itself works, you'll likely struggle with Kubernetes.&lt;/p>
&lt;h2 id="tip-nail-the-easy-questions-quickly">Tip: Nail the easy questions quickly&lt;/h2>
&lt;p>There are a lot of tasks which only count for one or two percent each; these ones you should be able to complete in a few minutes. You'll need all the time in the exam to work on the really hard questions which deal with diagnosing and fixing cluster issues.&lt;/p>
&lt;p>Know your core Kubernetes concepts; if you have done the CKAD exam you should be good, if not, check the curriculum and make sure you can quickly complete all of the trivial tasks without wasting too much time.&lt;/p>
&lt;h2 id="thats-it">That's it!&lt;/h2>
&lt;p>Hopefully this was helpful! Good luck if you are taking the exam and hopefully you'll find it a challenging but rewarding experience. I've taken many exams over the years but this was one of the most challenging, but also one of the most enjoyable, I really felt like it was testing practical techniques rather than your ability to just remember random commands and flags.&lt;/p>
&lt;p>As always, if you have any comments or questions, please just add them in the section below!&lt;/p>
&lt;p>&lt;img src="./images/cka-cert.png" alt="CKA Certification">&lt;/p></description><category>CodeProject</category></item><item><title>Supercharge your Java Projects with Conventional Commits, Semantic Versioning and Semantic Releases</title><link>https://dwmkerr.com/conventional-commits-and-semantic-versioning-for-java/</link><pubDate>Sun, 17 May 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/conventional-commits-and-semantic-versioning-for-java/</guid><description>&lt;p>In this article we'll look at a few simple techniques which can really supercharge your Java project and make them much easier to work with!&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#semantic-versioning">Semantic Versioning&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#why-does-this-matter">Why Does This Matter?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-semantic-versioning-specification">The Semantic Versioning Specification&lt;/a>&lt;/li>
&lt;li>&lt;a href="#using-semantic-versions">Using Semantic Versions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-challenge-of-semantic-versions">The Challenge of Semantic Versions&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#conventional-commits">Conventional Commits&lt;/a>&lt;/li>
&lt;li>&lt;a href="#time-for-magic">Time for Magic&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#enforcing-conventional-commits-with-git-hooks">Enforcing Conventional Commits with Git Hooks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#how-the-hook-works">How the Hook Works&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#creating-the-initial-release">Creating the Initial Release&lt;/a>&lt;/li>
&lt;li>&lt;a href="#go-forth-and-devops">Go Forth And DevOps&lt;/a>&lt;/li>
&lt;li>&lt;a href="#the-gradle-version">The Gradle Version&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thats-it">That's It&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;p>&lt;strong>tl;dr&lt;/strong> If you know the concepts, then just jump straight to my fork of &lt;code>standard-version&lt;/code> at &lt;a href="https://github.com/dwmkerr/standard-version">&lt;code>github.com/dwmkerr/standard-version&lt;/code>&lt;/a>. It adds support for Java projects. I am currently trying to get it into the mainline, so if you like this, please comment on the &lt;a href="https://github.com/conventional-changelog/standard-version/pull/591">Pull Request&lt;/a> here. &lt;strong>tl;dr end!&lt;/strong>&lt;/p>
&lt;h2 id="semantic-versioning">Semantic Versioning&lt;/h2>
&lt;p>First, let's talk about the idea of a &lt;em>Semantic Version&lt;/em>. A semantic version is nothing more than a versioning scheme you will probably be familiar with, where versions look like this:&lt;/p>
&lt;pre>&lt;code>1.2.3
&lt;/code>&lt;/pre>&lt;p>The only thing special about a &lt;em>Semantic Version&lt;/em> is that we give a very specific meaning to each part of the version. In short:&lt;/p>
&lt;ul>
&lt;li>&lt;code>1&lt;/code> is the &lt;em>major&lt;/em> part of the version&lt;/li>
&lt;li>&lt;code>2&lt;/code> is the &lt;em>minor&lt;/em> part of the version&lt;/li>
&lt;li>&lt;code>3&lt;/code> is the &lt;em>patch&lt;/em> part of the version&lt;/li>
&lt;/ul>
&lt;p>Now we give &lt;em>semantics&lt;/em> (meaning and context) to these parts:&lt;/p>
&lt;p>&lt;strong>Major&lt;/strong>&lt;/p>
&lt;p>A &lt;em>major&lt;/em> version number change means something big has changed, and the API of the software is different to the earlier version. Essentially, this is a potentially &lt;em>breaking&lt;/em> change, so you should only use this new version after carefully reading about the changes.&lt;/p>
&lt;p>&lt;strong>Minor&lt;/strong>&lt;/p>
&lt;p>A &lt;em>minor&lt;/em> version number change means that something has been added or changed, which affects the functionality of the code, but in a &lt;em>non breaking&lt;/em> way. An example would be the addition of a new API. That won't affect existing users, so they can generally safely upgrade minor versions without too much risk.&lt;/p>
&lt;p>&lt;strong>Patch&lt;/strong>&lt;/p>
&lt;p>A &lt;em>patch&lt;/em> version number change means something really inconsequential to the user of the code has changed. It might be new documentation, better logging, but it is generally not a &lt;em>functional&lt;/em> change.&lt;/p>
&lt;h3 id="why-does-this-matter">Why Does This Matter?&lt;/h3>
&lt;p>If we have Semantic Versions, we can be a lot more sure about &lt;em>when it is safe to upgrade&lt;/em>. If we see a &lt;em>major&lt;/em> version change, we know we need to be careful. &lt;em>Minor&lt;/em> changes might need attention, and &lt;em>patches&lt;/em> are almost always going to be safe.&lt;/p>
&lt;p>Managing dependencies and keeping them up to date is hard in software development, and one of the reasons people are wary of updating dependencies is that &lt;em>they don't know if they upgrade will break their code&lt;/em>.&lt;/p>
&lt;p>Semantic Versioning tries to bring a little order to this chaotic world.&lt;/p>
&lt;h3 id="the-semantic-versioning-specification">The Semantic Versioning Specification&lt;/h3>
&lt;p>There is a detailed specification for semantic versioning, which also covers more sophisticated cases, you can find it here:&lt;/p>
&lt;p>&lt;a href="https://semver.org/">https://semver.org/&lt;/a>&lt;/p>
&lt;p>I'd suggest this is recommend reading for &lt;em>any&lt;/em> software engineer!&lt;/p>
&lt;h3 id="using-semantic-versions">Using Semantic Versions&lt;/h3>
&lt;p>Now the easiest way to start with semantic versioning is to simply adhere to the spec! For example, if you make a change which could break something for users, bump the &lt;em>major&lt;/em> part of the version.&lt;/p>
&lt;p>But, things aren't all that easy&amp;hellip;&lt;/p>
&lt;h3 id="the-challenge-of-semantic-versions">The Challenge of Semantic Versions&lt;/h3>
&lt;p>The challenge is this. Imagine you are cutting a new release of your code and many people have contributed. Some bug fixes, some patches, some documentation. How do you look through all of those changes and decide how to appropriately change the version number?&lt;/p>
&lt;p>To solve this problem, say hello to &lt;em>Conventional Commits&lt;/em>.&lt;/p>
&lt;h2 id="conventional-commits">Conventional Commits&lt;/h2>
&lt;p>If you have a commit history like this:&lt;/p>
&lt;pre>&lt;code>Updated the users API
Bugfix
trying the build again, got it working
Bugfix: [JIRA-21] fixed that issue
you can now get user's friends with this change
&lt;/code>&lt;/pre>&lt;p>Then it is &lt;em>very&lt;/em> hard to reason about what is going on. What about if the commit history looked like this?&lt;/p>
&lt;pre>&lt;code>feat(users): [#12] fetching users returns their avatar url
fix(users): [#45] display names with emojis return correctly
build(cicd): update the expired deploy key
fix(docs): [#22] fix broken links to the javadocs
feat(users): [#49] users api optionally returns friends, non-breaking
&lt;/code>&lt;/pre>&lt;p>It's much easier to see what each change means, at least at a high level.&lt;/p>
&lt;p>By having some kind of standard for commit messages, we can do a lot. We can:&lt;/p>
&lt;ul>
&lt;li>Classify changes by type (such as a feature or fix)&lt;/li>
&lt;li>Include a clear description of the change&lt;/li>
&lt;li>Use a convention to indicate a breaking change&lt;/li>
&lt;li>Link to a ticketing system&lt;/li>
&lt;/ul>
&lt;p>Just like semantic versioning, conventional commits have a specification too:&lt;/p>
&lt;p>&lt;a href="https://www.conventionalcommits.org/en/v1.0.0/">https://www.conventionalcommits.org/en/v1.0.0/&lt;/a>&lt;/p>
&lt;h2 id="time-for-magic">Time for Magic&lt;/h2>
&lt;p>Now if we have conventional commits, and want to use semantic versions, we can actually skip the whole process of looking over a commit history to create a new semantic version - we can automate it.&lt;/p>
&lt;p>We can even automate the process of creating a &amp;lsquo;changelog&amp;rsquo;, a list of each change which comes in each version. There's an &lt;em>excellent&lt;/em> library which does this, called &lt;code>standard-version&lt;/code>:&lt;/p>
&lt;p>&lt;a href="https://github.com/conventional-changelog/standard-version">https://github.com/conventional-changelog/standard-version&lt;/a>&lt;/p>
&lt;p>It's maintained by the same group behind conventional commits. The only problem? It only works for JavaScript projects (unless you are willing to write custom code which can be complex).&lt;/p>
&lt;p>But I've updated the library to support Maven projects and Gradle projects, so you can use it for Java now as well!&lt;/p>
&lt;p>Let's see it in action. Here's a very simple Java library built with Maven:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample">https://github.com/dwmkerr/java-maven-standard-version-sample&lt;/a>&lt;/p>
&lt;p>This library has no changelog, no tags, no version data at all except for &lt;code>0.1.0&lt;/code> in the &lt;code>pom.xml&lt;/code> file.&lt;/p>
&lt;p>Now if I was to clone the library, make a change and make a commit, which &lt;em>didn't&lt;/em> follow the conventional commit spec, we'll just see the usual success message:&lt;/p>
&lt;p>&lt;img src="./images/bad-commit-message.png" alt="Bad commit message" width="800px" />&lt;/p>
&lt;p>This is a problem; we want to &lt;em>enforce&lt;/em> conventional commits.&lt;/p>
&lt;h3 id="enforcing-conventional-commits-with-git-hooks">Enforcing Conventional Commits with Git Hooks&lt;/h3>
&lt;p>Git has a powerful &amp;lsquo;hooks&amp;rsquo; facility, which let you run logic at key points in operations. This is a &lt;em>massive&lt;/em> topic on its own, so we're not going to go into lots of details, but if you are interested you can read about them here:&lt;/p>
&lt;p>&lt;a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks">https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks&lt;/a>&lt;/p>
&lt;p>Now the issue with Git Hooks is that they are &lt;em>per user&lt;/em> - if I add a hook to my &lt;code>.git&lt;/code> folder, no one else will get it. We want the same hooks for &lt;em>all&lt;/em> users.&lt;/p>
&lt;p>There are a few ways to get around this. You can set up server side hooks (which could reject a push if it has an invalid commit message), but this isn't easy to do (and with some providers, like GitHub for public projects, not even available as an option). Also, we want fast feedback, so if I make a bad commit message, it fails straight away and I can fix it.&lt;/p>
&lt;p>The way I suggest getting around this is this:&lt;/p>
&lt;ol>
&lt;li>Create a &lt;code>.githooks&lt;/code> folder in your repo&lt;/li>
&lt;li>Instruct people to configure the git repo to look for hooks there&lt;/li>
&lt;/ol>
&lt;p>That way there are no global changes, only project specific ones. We still need to make sure the developer sets up the hooks though! You'll notice in my sample project's &lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample#developer-guide">&lt;code>README.md&lt;/code>&lt;/a> file the first thing I do is instruct people to setup the hooks:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">git config core.hooksPath .githooks
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Let's see how the same operation would look if we'd setup the hook first:&lt;/p>
&lt;p>&lt;img src="./images/git-hook-bad-message.png" alt="Bad commit message with hook" width="800px" />&lt;/p>
&lt;p>Our hook has fired off and told us we've not used a conventional commit message - it even let's us know where to go to find out more.&lt;/p>
&lt;p>Let's try a message which should work, as it meets the standard:&lt;/p>
&lt;p>&lt;img src="./images/git-hook-good-message.png" alt="Good commit message with hook" width="800px" />&lt;/p>
&lt;p>Awesome! We've been informed that our message meets the standard (useful to actually remind us that this is being checked!) and the commit has succeeded!&lt;/p>
&lt;p>Remember; we only need to setup the hooks once - it's a one time activity.&lt;/p>
&lt;h3 id="how-the-hook-works">How the Hook Works&lt;/h3>
&lt;p>Hooks are just shell scripts. You can write them in Ruby, Python, whatever. I have written this one in pure Bash because it's really just checking a regex, which Bash is more than capable of. Also, I can't be sure the developer will have Ruby or another tool on their machine.&lt;/p>
&lt;p>The hook is as simple as this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/usr/bin/env bash
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Create a regex for a conventional commit.&lt;/span>
convetional_commit_regex&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">^(build|chore|ci|docs|feat|fix|perf|refactor|revert|style|test)(\([a-z \-]+\))?!?: .+&lt;/span>$&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Get the commit message (the parameter we&amp;#39;re given is just the path to the&lt;/span>
&lt;span style="color:#75715e"># temporary file which holds the message).&lt;/span>
commit_message&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>cat &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$1&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#75715e"># Check the message, if we match, all good baby.&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span>&lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$commit_message&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">=&lt;/span>~ $convetional_commit_regex &lt;span style="color:#f92672">]&lt;/span>&lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo -e &lt;span style="color:#e6db74">&amp;#34;\e[32mCommit message meets Conventional Commit standards...\e[0m&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">0&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#75715e"># Uh-oh, this is not a conventional commit, show an example and link to the spec.&lt;/span>
echo -e &lt;span style="color:#e6db74">&amp;#34;\e[31mThe commit message does not meet the Conventional Commit standard\e[0m&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;An example of a valid message is: &amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34; feat(login): add the &amp;#39;remember me&amp;#39; button&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;More details at: https://www.conventionalcommits.org/en/v1.0.0/#summary&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The only really tricky bit is the regex, and the weird &lt;code>\e[32&lt;/code> type characters which are used to set the colours. You might find it easier to write your hooks in a proper programming language - and for anything more complex I'd suggest that makes far more sense! But if a bit of Bash will do the trick, there's nothing wrong with that.&lt;/p>
&lt;p>As a side-note, if you are into Bash and the shell, check out my online &lt;a href="https://effective-shell.com">Effective Shell&lt;/a> book.
git config core.hooksPath .githooks&lt;/p>
&lt;h2 id="creating-the-initial-release">Creating the Initial Release&lt;/h2>
&lt;p>Now the chances are, if you are interested in this technique, you've probably got an existing project you want to use it on. It probably doesn't have a changelog or conventional commits. That's OK, just start from now.&lt;/p>
&lt;p>Here's how we'd start using the &lt;code>standard-version&lt;/code> library to manage our versions. I've added a new API to the &lt;a href="https://github.com/dwmkerr/java-maven-standard-version-sample/tree/release">&lt;code>release&lt;/code>&lt;/a> branch (to keep &lt;code>master&lt;/code> clean for people reading the sample) and committed it.&lt;/p>
&lt;p>Now lets actually create our changelog:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --first-release --packageFiles pom.xml --bumpFiles pom.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="./images/first-release.png" alt="First release" width="800px" />&lt;/p>
&lt;p>Now it's a pain I know, but you need &lt;a href="https://nodejs.org/en/download/">Node.js&lt;/a> installed for this to work. The &lt;code>standard-version&lt;/code> library is built on node, that's what is used to do all of the logic around writing a changelog and working out what the version bump should be. You also have to use my fork &lt;code>@dwmkerr/standard-version&lt;/code> rather than the main version, because at the time of writing my pull request which adds support for &lt;code>pom.xml&lt;/code> files is not yet merged.&lt;/p>
&lt;p>What has happened here is that the &lt;code>standard-version&lt;/code> tool has &lt;em>not&lt;/em> changed the version number. We told it this is the &lt;code>first-release&lt;/code>, meaning we haven't published yet, so there's no need to create a new number. What is &lt;em>has&lt;/em> done is given us a changelog and told use how to push the tags and code. If we push, we can now see the changelog:&lt;/p>
&lt;p>&lt;img src="./images/changelog-v1.png" alt="Changelog v1" width="800px" />&lt;/p>
&lt;p>See how we get a changelog showing the changes, the version and the date? We even have links to the commits for each key change!&lt;/p>
&lt;p>If we'd linked the message to GitHub Issue numbers it'd automatically have links to the issues too!&lt;/p>
&lt;p>Now in this code I deliberately made a mistake - the test for the &lt;code>Goodbye&lt;/code> api is a copy and paste of the &lt;code>Hello&lt;/code> test! And the &lt;code>Goodbye&lt;/code> api has a spelling mistake. Let's fix this and cut a new release.&lt;/p>
&lt;p>I've made the change on the &lt;code>release&lt;/code> branch, now I'll run &lt;code>standard-version&lt;/code> again:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --packageFiles pom.xml --bumpFiles pom.xml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="./images/second-release.png" alt="Second release" width="800px" />&lt;/p>
&lt;p>Note that there was no need for the &lt;code>--first-release&lt;/code> flag.&lt;/p>
&lt;p>Now this time, a new version has been generated. This was a &lt;code>fix&lt;/code> commit, so it has made it a &lt;em>minor&lt;/em> version bump. If we needed to make it a breaking change, we can use a message with an exclamation after the type, such as &lt;code>fix(goodbye)!: fix the typo&lt;/code>. Check the &lt;code>standard-version&lt;/code> docs for more about this.&lt;/p>
&lt;p>Finally, let's look at our new changelog:&lt;/p>
&lt;p>&lt;img src="./images/second-changelog.png" alt="Second changelog" width="800px" />&lt;/p>
&lt;p>We have even more info now - we have a link to the tag. This is &lt;em>incredibly&lt;/em> useful for managing releases.&lt;/p>
&lt;p>The icing on the cake? Let's look at the &lt;code>pom.xml&lt;/code>:&lt;/p>
&lt;p>&lt;img src="./images/updated-pom.png" alt="Updated pom.xml" width="800px" />&lt;/p>
&lt;p>Note that &lt;em>the version has been updated&lt;/em>. &lt;code>standard-release&lt;/code> is keeping our Git Tags and our Java Library Version numbers &lt;em>automatically in sync&lt;/em>.&lt;/p>
&lt;p>Once you've started doing this and seen it in action for a while, you'll wonder how you lived without it!&lt;/p>
&lt;h2 id="go-forth-and-devops">Go Forth And DevOps&lt;/h2>
&lt;p>This is just the beginning! Think of all the cool things we can do with this in place, here's just a few:&lt;/p>
&lt;ul>
&lt;li>Update our build pipeline so that when we merge into &lt;code>master&lt;/code> we automatically run &lt;code>standard-version&lt;/code>&lt;/li>
&lt;li>Update our build pipeline so that when a new version tag is added, we automatically publish the library&lt;/li>
&lt;li>Send out a slack notification with the changelog when a new version is committed&lt;/li>
&lt;li>Share the changelog with our consumers as our libraries are updated&lt;/li>
&lt;/ul>
&lt;p>With these basic building blocks:&lt;/p>
&lt;ul>
&lt;li>Conventional Commits&lt;/li>
&lt;li>Semantic Versioning&lt;/li>
&lt;li>Enforcing of Commit Standards&lt;/li>
&lt;li>Usage of the &lt;code>standard-release&lt;/code> tool&lt;/li>
&lt;/ul>
&lt;p>We have created a very powerful way to manage what is actually a highly complex process. We've introduced almost no additional complexity, just a few guidelines for developers.&lt;/p>
&lt;h2 id="the-gradle-version">The Gradle Version&lt;/h2>
&lt;p>It's basically the same technique for Gradle, you just tell &lt;code>standard-version&lt;/code> to hit your &lt;code>build.gradle&lt;/code> file;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">npx @dwmkerr/standard-version --packageFiles build.gradle --bumpFiles build.gradle
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's an accompanying sample project at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/java-gradle-standard-version-sample">github.com/dwmkerr/java-gradle-standard-version-sample&lt;/a>&lt;/p>
&lt;p>This is the same as the Maven version in that the &lt;code>master&lt;/code> branch has no &lt;code>standard-version&lt;/code> code or changelogs, just open the &lt;a href="https://github.com/dwmkerr/java-gradle-standard-version-sample/tree/release">&lt;code>release&lt;/code>&lt;/a> branch to see what it looks like after we've applied the same techniques as we did to the Maven version.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>There's a whole world of libraries for this. &lt;a href="https://github.com/commitizen/cz-cli">&lt;code>commitizen&lt;/code>&lt;/a> which helps you write conventional commit messages for example. But I found very little for Java. If you find this useful, please do chip in on the pull request here:&lt;/p>
&lt;p>&lt;a href="https://github.com/conventional-changelog/standard-version/pull/591">https://github.com/conventional-changelog/standard-version/pull/591&lt;/a>&lt;/p>
&lt;p>As it would be great to add it to the mainline. I'm also just finishing off the update which adds support for Gradle.&lt;/p>
&lt;p>As always, questions, comments, suggestions, rants, anything are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell for Beginners</title><link>https://dwmkerr.com/effective-shell-for-beginners/</link><pubDate>Tue, 21 Jan 2020 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-for-beginners/</guid><description>&lt;p>I have rebuilt my &amp;ldquo;Effective Shell&amp;rdquo; series as an online book - it's available now on:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">https://effective-shell.com&lt;/a>&lt;/p>
&lt;p>The whole site is built from a GitHub repo at &lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>. It is open for contributions, changes, issues and suggestions. I've also added a comment section to each page to get input.&lt;/p>
&lt;p>To keep the material as accessible as possible, I have added a new section for beginners, to help anyone who has not used a shell before. It goes over who the book is useful for, what the shell is, and how to set up your computer to work through the material:&lt;/p>
&lt;p>&lt;a href="https://effective-shell.com">&lt;img src="images/effective-shell-screenshot.png" alt="Effective Shell: Screenshot" width="1024px" />&lt;/a>&lt;/p>
&lt;p>All comments and suggestions are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Migrating from Ghost to Hugo - Why Bother?</title><link>https://dwmkerr.com/migrating-from-ghost-to-hugo/</link><pubDate>Tue, 24 Dec 2019 00:00:00 +0000</pubDate><guid>https://dwmkerr.com/migrating-from-ghost-to-hugo/</guid><description>&lt;p>With a little bit of free time for a change, I decided to finally migrate my blog from &lt;a href="https://ghost.org/">Ghost&lt;/a> to a static site generator. I've been putting this off because it's one of those things that I knew would take longer than I'd expect, and to be honest, it it ain't broke, then don't fix it.&lt;/p>
&lt;!-- vim-markdown-toc GFM -->
&lt;ul>
&lt;li>&lt;a href="#so-why-bother">So, Why Bother?&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#reason-1---i-write-in-vim">Reason 1 - I write in vim&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-2---i-backup-on-github">Reason 2 - I backup on GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-3---my-workflow-sucks-for-images">Reason 3 - My workflow sucks for images&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-4---i-have-two-sources-of-truth">Reason 4 - I have two sources of truth&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-5---i-want-to-allow-people-to-contribute">Reason 5 - I want to allow people to contribute&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-6---i-dont-want-to-manage-a-server">Reason 6 - I don't want to manage a server&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-7---i-need-to-learn-how-do-this">Reason 7 - I need to learn how do this&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reason-8---static-sites-are-fast-and-simple">Reason 8 - Static Sites are Fast and Simple&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#picking-a-generator">Picking a Generator&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#jekyll">Jekyll&lt;/a>&lt;/li>
&lt;li>&lt;a href="#gatsby">Gatsby&lt;/a>&lt;/li>
&lt;li>&lt;a href="#hugo">Hugo&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#the-migration-process">The Migration Process&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#automating-build-and-deploy">Automating Build and Deploy&lt;/a>&lt;/li>
&lt;li>&lt;a href="#changing-front-matter-to-yaml">Changing Front Matter to YAML&lt;/a>&lt;/li>
&lt;li>&lt;a href="#normalising-newlines">Normalising Newlines&lt;/a>&lt;/li>
&lt;li>&lt;a href="#restructuring-the-content">Restructuring the Content&lt;/a>&lt;/li>
&lt;li>&lt;a href="#bringing-the-images-to-the-posts">Bringing the images to the posts&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#was-it-worth-it">Was It Worth It?&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- vim-markdown-toc -->
&lt;h2 id="so-why-bother">So, Why Bother?&lt;/h2>
&lt;p>My first website was built on BlogEngine.net, then WordPress, which has grown into a very powerful platform over the years, but was overly complex for my needs.&lt;/p>
&lt;p>When I first tried Ghost, I loved it. A super clean and minimal interface, with all of the content in Markdown. The editing experience was lovely:&lt;/p>
&lt;p>&lt;img src="images/ghost-ui.png" alt="Screenshot: Thee Ghost UI">&lt;/p>
&lt;p>Ghost is great, and I've been a happy user for years. I'd highly recommend it to &lt;em>anyone&lt;/em> who wants a lean and clean content management system. However, there were a few key reasons I decided to change. This article is not be advocating for my new setup, or a criticism of Ghost, but might be useful for people who are considering similar changes.&lt;/p>
&lt;h3 id="reason-1---i-write-in-vim">Reason 1 - I write in vim&lt;/h3>
&lt;p>The Ghost UI is lovely, but I do all of my writing in vim. Writing in the Ghost UI could sometimes be a little slow, and obviously doesn't work offline. I'm very comfortable writing in vim. So I would end up writing the post in vim, then copying and pasting into Ghost.&lt;/p>
&lt;p>Right now, this is what my screen looks like:&lt;/p>
&lt;p>&lt;img src="images/vim-screenshot.png" alt="Screenshot: vim editing">&lt;/p>
&lt;p>Again, I'm not advocating for vim, it's just what works for me. The screenshot is with my &amp;lsquo;focus&amp;rsquo; mode setup, which removes all unnecessary clutter (all of my configuration is available on my &lt;a href="https://github.com/dotfiles">dotfiles repo&lt;/a>.&lt;/p>
&lt;h3 id="reason-2---i-backup-on-github">Reason 2 - I backup on GitHub&lt;/h3>
&lt;p>I'm writing all of my content in vim, and storing it in a folder. Some posts take days to write. So it makes sense to keep all of these files in a git repository. This means that I essentially have a robust backup solution, I don't need to use Ghosts's backup. Ghost's backup (for self hosted) also doesn't handle images.&lt;/p>
&lt;h3 id="reason-3---my-workflow-sucks-for-images">Reason 3 - My workflow sucks for images&lt;/h3>
&lt;p>Because I am writing in vim, and creating screenshots and images, I need to link to them. This means that what I have in my local markdown file won't work for Ghost. With Ghost I need to upload the image, and it will put it in a content folder. But I want to be able to keep my images close to the text, and have consistent addresses for local writing, like so:&lt;/p>
&lt;p>&lt;img src="images/folder-structure-screenshot.png" alt="Screenshot: Folder structure for a post">&lt;/p>
&lt;h3 id="reason-4---i-have-two-sources-of-truth">Reason 4 - I have two sources of truth&lt;/h3>
&lt;p>If I need to make a change, do I update my markdown file in my GitHub repo? Or in Ghost? Or both? If I have to change a few things, then I can't just paste in the whole markdown file without breaking the image links. So I basically have two sources of truth, which can easily diverge.&lt;/p>
&lt;h3 id="reason-5---i-want-to-allow-people-to-contribute">Reason 5 - I want to allow people to contribute&lt;/h3>
&lt;p>I'm already using GitHub and Markdown. In theory this means that it should be very straightforward for people to propose edits or contributions; they can just create pull requests. I don't expect many people would do this, but it appeals to me that people could make corrections or suggest improvements, particularly for technical content.&lt;/p>
&lt;h3 id="reason-6---i-dont-want-to-manage-a-server">Reason 6 - I don't want to manage a server&lt;/h3>
&lt;p>My website is static content. It's blog posts and that's about it. There's really no need for any kind of application server or database. Disqus handles comments, Google Analytics for traffic data. So I can save myself a few dollars a month by just generating a static site and hosting it on &lt;a href="https://pages.github.com/">GitHub Pages&lt;/a> or &lt;a href="https://www.netlify.com/">Netlify&lt;/a>.&lt;/p>
&lt;p>Static sites can be cached by CDNs so can be very fast for readers. And given the vast majority of my content is already just text and images in a GitHub repo, it doesn't make sense to pay for and manage server when there are a number of static site generators.&lt;/p>
&lt;h3 id="reason-7---i-need-to-learn-how-do-this">Reason 7 - I need to learn how do this&lt;/h3>
&lt;p>I've been putting this off for a while. But it will be &lt;em>really&lt;/em> useful to know how to quickly get up and running with a static site generator. There are other projects that I'd love to run as sites, such as:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/dwmkerr/hacker-laws">hacker-laws&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/dwmkerr/learn-a-language">learn-a-language&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Being able to quickly whip up a static site from markdown in GitHub seems like it could be really useful.&lt;/p>
&lt;h3 id="reason-8---static-sites-are-fast-and-simple">Reason 8 - Static Sites are Fast and Simple&lt;/h3>
&lt;p>Without an application server doing any work, static sites are generally fast. They can be cached, pushed to CDNs and will index well with search engines. In theory, the overall browsing experience should be faster. But I will show performance benchmarks from before and after,&lt;/p>
&lt;p>So next - how do pick a static site generator?&lt;/p>
&lt;h2 id="picking-a-generator">Picking a Generator&lt;/h2>
&lt;p>I had a few requirements for the generator:&lt;/p>
&lt;ul>
&lt;li>I can easily host on GitHub pages&lt;/li>
&lt;li>I can integrate Disqus and Google Analytic&lt;/li>
&lt;li>I have as little complexity as possible, KISS&lt;/li>
&lt;li>I can maintain all of the existing URLs of my posts, so that links from external sites will not break&lt;/li>
&lt;li>I can have a theme which is roughly similar to the original Ghost theme, something minimal and text focused&lt;/li>
&lt;/ul>
&lt;p>A little bit of research suggested that there were three main contenders:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://jekyllrb.com/">Jekyll&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gatsbyjs.org">Gatsby&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gohugo.io/">Hugo&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I actually tried all three. Each engine is popular on GitHub:&lt;/p>
&lt;p>&lt;img src="images/blogging-platforms.png" alt="Comparison of Blogging Platforms">&lt;/p>
&lt;p>The number of stars a project has is of course not a genuine indicator of quality, but it is interesting to see how quickly Gatsby and Hugo have caught up to Jekyll.&lt;/p>
&lt;h3 id="jekyll">Jekyll&lt;/h3>
&lt;p>Jekyll makes a tonne of sense. It is very easy to setup for GitHub pages (in fact, GitHub pages assumes you are using Jekyll unless you explicitly tell it you are not).&lt;/p>
&lt;p>Setting up Jekyll was easy - but I couldn't properly import my blog. I used the &lt;a href="https://github.com/eloyesp/jekyll_ghost_importer">jekyll_ghost_importer&lt;/a> tool, but the generated files seemed to be missing the slug. I wasted some time trying to see if I could resolve this issue, and then decided it was worth moving to the next platform and checking back in on Jekyll another time.&lt;/p>
&lt;h3 id="gatsby">Gatsby&lt;/h3>
&lt;p>Gatsby is written in Node.js, which had some appeal, as I am far more familiar with Node than Ruby (which Jekyll uses) or Golang (which Hugo uses, and I don't get on with).&lt;/p>
&lt;p>I quickly paused on Gatsby. I had some trouble finding a tool to import data from Ghost, but during my research I realised just how powerful Gatsby is. It can be the front-end for Ghost, with Ghost working as a headless CMS, it can serve GraphQL, runs a React front end and more. These are all technologies I use regularly, but I was concerned that the tool seemed perhaps more complicated than I needed.&lt;/p>
&lt;p>So I paused on Gatsby, but will definitely look into it in the future if I am building a more complex site from scratch.&lt;/p>
&lt;h3 id="hugo">Hugo&lt;/h3>
&lt;p>Hugo I was the least excited about. A lot of the hype seemed to be around the speed of the tool, and the fact it is written in Golang. Speed is not really an issue for me in this case and would not be a big factor in my decision. And I've spent enough time coding with the Kubernetes codebase that I have developed a deep dislike of Golang.&lt;/p>
&lt;p>I was quickly sold on Hugo. Setup was very easy, importing was seamless with &lt;a href="https://github.com/jbarone/ghostToHugo/">ghostToHugo&lt;/a>, URLs were preserved as needed. I found a nice theme called &lt;a href="https://github.com/jbub/ghostwriter">ghostwriter&lt;/a> which quickly gave me a locally running site which looked not too bad.&lt;/p>
&lt;p>The generated folder structure was trivial enough for me to quickly work out how to create the few static pages I have (public speaking, about etc).&lt;/p>
&lt;p>Again; no advocating. All three engines seem to be great at what they do. Hugo was the easiest for me to get started on. Once I'd picked Hugo, it was time to get started migrating in earnest.&lt;/p>
&lt;h2 id="the-migration-process">The Migration Process&lt;/h2>
&lt;p>I've kept some notes on how I did this in case it is useful for others. The post &lt;a href="https://rmoff.net/2018/12/17/moving-from-ghost-to-hugo/">Moving from Ghost to Hugo by Robin Moffat&lt;/a> was super useful.&lt;/p>
&lt;p>First, I downloaded &lt;a href="https://github.com/jbarone/ghostToHugo/">&lt;code>ghostToHugo&lt;/code>&lt;/a>. Then I ran the import command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e"># Note: my ghost db backup is a file locally called &amp;#39;db.json&amp;#39;&lt;/span>
./ghostToHugo --dateformat &lt;span style="color:#e6db74">&amp;#34;2006-01-02T15:04:05.000Z&amp;#34;&lt;/span> -f -p dwmkerr.com db.json
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Next I needed to copy over my images. My &lt;code>~/.ssh/config&lt;/code> is setup with my ghost server, so I could just use &lt;code>scp&lt;/code> to copy the files.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">scp -r dwmkerr.com:/var/www/ghost/content/images ./dwmkerr.com/static
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The whole site I put in it's own folder, &lt;code>dwmkerr.com&lt;/code>, so that I could use other folders for backups, guides, whatever else I might want, and not pollute the generated site structure.&lt;/p>
&lt;p>Next I downloaded a couple of themes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">git submodule add git@github.com:jbub/ghostwriter.git dwmkerr.com/themes/ghostwriter
git submodule add git@github.com:spf13/herring-cove.git dwmkerr.com/themes/herring-cove
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And I created a &lt;code>makefile&lt;/code> for common commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">make setup &lt;span style="color:#75715e"># install everything I need&lt;/span>
make serve &lt;span style="color:#75715e"># serve the site locally for testing&lt;/span>
make build &lt;span style="color:#75715e"># build the site for production&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I'm a big fan of &lt;code>makefiles&lt;/code> as a way to provide an index of key operations for any project (even if all does is call another script or program).&lt;/p>
&lt;p>At this stage I had a working site running locally. However, I noticed some images weren't rendering. It seems that some of my images had paths like &lt;code>/content/images/whatever.png&lt;/code> and some were just &lt;code>/images/whatever.png&lt;/code>.&lt;/p>
&lt;p>This was quick to fix in vim. First I used &lt;code>vimgrep&lt;/code> to populate the quickfix list with any markdown file with a &lt;code>/content/images&lt;/code> in the text, then used &lt;code>cfdo&lt;/code> to just replace the string with &lt;code>/images&lt;/code> (asking for confirmation each time to check I wasn't changing something I shouldn't.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-vim" data-lang="vim">:&lt;span style="color:#a6e22e">vimgrep&lt;/span> \&lt;span style="color:#e6db74">/content\/images **/&lt;/span>*.&lt;span style="color:#a6e22e">md&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&lt;/span>:&lt;span style="color:#a6e22e">cfdo&lt;/span> %&lt;span style="color:#a6e22e">s&lt;/span>&lt;span style="color:#e6db74">/\/content\/images\//&lt;/span>\&lt;span style="color:#e6db74">/images\//&lt;/span>&lt;span style="color:#a6e22e">gc&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="automating-build-and-deploy">Automating Build and Deploy&lt;/h3>
&lt;p>At this stage I had a working site. Setting up a workflow to publish to GitHub pages with GitHub Actions was straightforward, as I've already updated some projects (such as &lt;a href="https://github.com/dwmkerr/spaceinvaders">&lt;code>spaceinvaders&lt;/code>&lt;/a>) to publish static sites. The workflow is relatively simple:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yml" data-lang="yml">name: Build &amp;amp; Deploy
on:
push:
branches:
- &lt;span style="color:#e6db74">&amp;#39;master&amp;#39;&lt;/span>
- &lt;span style="color:#e6db74">&amp;#39;build/**&amp;#39;&lt;/span>
jobs:
build-deploy:
runs-on: ubuntu&lt;span style="color:#ae81ff">-18.04&lt;/span>
steps:
- name: Checkout
uses: actions/checkout@v1
with:
submodules: &lt;span style="color:#66d9ef">true&lt;/span>
- name: Setup Hugo
uses: peaceiris/actions-hugo@v2
with:
hugo-version: &lt;span style="color:#e6db74">&amp;#39;0.61.0&amp;#39;&lt;/span>
- name: Build
working-directory: ./dwmkerr.com
run: hugo --minify
- name: Deploy
uses: JamesIves/github-pages-deploy-action@releases/v3
with:
GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
BRANCH: gh-pages
FOLDER: dwmkerr.com/public
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Any time a change is made to &lt;code>master&lt;/code> or &lt;code>feat/static-site&lt;/code> gets built and published.&lt;/p>
&lt;h3 id="changing-front-matter-to-yaml">Changing Front Matter to YAML&lt;/h3>
&lt;p>By default the front matter for the blog is written in TOML. This is not rendered well on GitHub:&lt;/p>
&lt;p>&lt;img src="images/toml-frontmatter.png" alt="Screenshot: TOML front matter">&lt;/p>
&lt;p>It also looks less than ideal in &lt;code>vim&lt;/code>. After running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">hugo convert toYAML
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Things look a lot nicer:&lt;/p>
&lt;p>&lt;img src="images/yaml-frontmatter.png" alt="Screenshot: YAML front matter">&lt;/p>
&lt;p>YAML front matter is also rendered properly in &lt;code>vim&lt;/code> for me,&lt;/p>
&lt;h3 id="normalising-newlines">Normalising Newlines&lt;/h3>
&lt;p>A lot of the content from 2013 and earlier was either written in WordPress or BlogEngine.net.&lt;/p>
&lt;p>Ghost had no problems rendering with Windows Style line endings but I wanted to clean this up a bit.&lt;/p>
&lt;p>To convert everything to Unix style file endings, I ran:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#66d9ef">for&lt;/span> $file in ./content/**/*.md; &lt;span style="color:#66d9ef">do&lt;/span>
dos2unix $file
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="restructuring-the-content">Restructuring the Content&lt;/h3>
&lt;p>After import, my site structure looked like this:&lt;/p>
&lt;p>&lt;img src="images/posts-and-images-screenshot.png" alt="Screenshot: Site structure">&lt;/p>
&lt;p>Now this is manageable, but feels awkward. I'd rather keep images next to the blog posts themselves. I want to group posts into years so that there are not too many shown in the file tree at any one time (and adding months/weeks/days makes things too fine grained). It also means that the page doesn't render images on GitHub:&lt;/p>
&lt;p>&lt;img src="images/broken-links.png" alt="Screenshot: Broken Links">&lt;/p>
&lt;p>The ideal structure would be just like this post:&lt;/p>
&lt;p>&lt;img src="images/ideal-structure.png" alt="Screenshot: Ideal Structure">&lt;/p>
&lt;p>It turns out that this is absolutely fine to do - as long as you name the post markdown &lt;code>index.md&lt;/code>. This took an hour to work out! The feature is known as &lt;a href="https://gohugo.io/content-management/page-bundles/">Page Bundles&lt;/a>. This is a delight - the content renders on GitHub just as well as it does on the site!&lt;/p>
&lt;p>Migrating everything by hand would be something of a nightmare. Writing a program to do this is probably overkill, so here's how I did it in &lt;code>bash&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e"># Go through each post.&lt;/span>
&lt;span style="color:#66d9ef">for&lt;/span> post_path in dwmkerr.com/content/post/*.md; &lt;span style="color:#66d9ef">do&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Found &lt;/span>$post_path&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
filename&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>basename -- &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$post_path&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
filename&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>filename%.*&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Grep out the date line.&lt;/span>
dateline&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>grep -E &lt;span style="color:#e6db74">&amp;#34;^date: &amp;#34;&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$post_path&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#75715e"># We know how to get the year as the date line is consistent in all posts:&lt;/span>
&lt;span style="color:#75715e"># date: &amp;#34;2012-12-09T16:11:27Z&amp;#34;&lt;/span>
year&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>dateline:7:4&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#75715e"># i.e. the four characters from index 7&lt;/span>
&lt;span style="color:#75715e"># Create the folder for the post.&lt;/span>
new_folder&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">dwmkerr.com/content/post/&lt;/span>$year&lt;span style="color:#e6db74">/&lt;/span>$filename&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
mkdir -p &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$new_folder&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Move the post.&lt;/span>
mv &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$post_path&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$new_folder&lt;span style="color:#e6db74">/index.md&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74"> -&amp;gt; &lt;/span>$new_folder&lt;span style="color:#e6db74">/index.md&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This gives a &lt;em>much&lt;/em> more manageable folder structure:&lt;/p>
&lt;p>&lt;img src="images/folder-structure-screenshot.png" alt="Screenshot: Better Folder Structure">&lt;/p>
&lt;p>However, we still have the images sitting in the &lt;code>static&lt;/code> folder.&lt;/p>
&lt;h3 id="bringing-the-images-to-the-posts">Bringing the images to the posts&lt;/h3>
&lt;p>There are two image formats to deal with - the standard markdown image format, and &lt;code>img&lt;/code> tags, which have been used to customise the size of the image:&lt;/p>
&lt;pre>&lt;code>&amp;lt;img width=&amp;quot;600px&amp;quot; alt=&amp;quot;Image: The Evolution of Windows&amp;quot; src=&amp;quot;/images/2019/05/screenshot-windows-evolution.png&amp;quot; /&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Initially I started converting these tags using a &lt;code>bash&lt;/code> script, but this rapidly became too complex. In the end I wrote a quick-and-dirty Node.js script to handle the images. You can find it at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/dwmkerr.com/blob/master/scripts/collect-images.js">https://github.com/dwmkerr/dwmkerr.com/blob/master/scripts/collect-images.js&lt;/a>&lt;/p>
&lt;p>This script downloads the images if they are online, or moves them from a given source folder, collecting them all in an &lt;code>images&lt;/code> folder for the post.&lt;/p>
&lt;h2 id="was-it-worth-it">Was It Worth It?&lt;/h2>
&lt;p>It took a &lt;em>lot&lt;/em> longer than I expected to migrate. &lt;a href="https://github.com/dwmkerr/hacker-laws#hofstadters-law">Hofstadter's Law&lt;/a> in action. Fixing Disqus pages, trying to clean up old content from 2011, all of this took time.&lt;/p>
&lt;p>The site is definitely faster. Below are the PageSpeed results from before:&lt;/p>
&lt;p>&lt;img src="images/pagespeed-insights-home-before.png" alt="Before: PageSpeed Results">&lt;/p>
&lt;p>The results now are faster:&lt;/p>
&lt;p>&lt;img src="images/pagespeed-insights-home-after.png" alt="After: PageSpeed Results">&lt;/p>
&lt;p>And finally I can simple manage my blog using GitHub, Markdown and my preferred flow for writing. Learning about Hugo was very useful, I expect to apply it to my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series soon.&lt;/p>
&lt;p>One final comment - the &lt;a href="https://github.com/mismith0227/hugo_theme_pickles">Pickle's Theme&lt;/a> by &lt;a href="https://github.com/mismith0227">&lt;code>msmith0227&lt;/code>&lt;/a> is what I am using. It was very straightforward to get working, and the code is really well documented, so I could quickly change it as needed.&lt;/p>
&lt;p>There are still some &lt;code>TODO&lt;/code>s - getting RSS working, trying to improve the PageSpeed of posts, cleaning up old content, but all in all it was a fun and worthwhile effort as an end of year programming project.&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell Part 7: The Subtleties of Shell Commands</title><link>https://dwmkerr.com/effective-shell-7-shell-commands/</link><pubDate>Tue, 25 Jun 2019 07:25:23 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-7-shell-commands/</guid><description>&lt;p>In this chapter, we'll take a look at the various different types of shell commands that exist and how this can affect your work.&lt;/p>
&lt;p>By the end of this chapter, you might even be able to make sense of the horrifying and perfectly syntactically valid code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">which &lt;span style="color:#66d9ef">$(&lt;/span>where &lt;span style="color:#66d9ef">$(&lt;/span>what &lt;span style="color:#66d9ef">$(&lt;/span>whence &lt;span style="color:#66d9ef">$(&lt;/span>whereis who&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="what-are-commands">What Are Commands?&lt;/h2>
&lt;p>This is &lt;em>really&lt;/em> important to understand! A &lt;em>command&lt;/em> in a shell is something you execute. It might take parameters. Generally it'll have a form like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">command param1 param2
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've already seen many commands during this series:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">ls &lt;span style="color:#75715e"># Show the contents of the current directory&lt;/span>
cd ~ &lt;span style="color:#75715e"># Move to the user&amp;#39;s home&lt;/span>
cat file.txt &lt;span style="color:#75715e"># Output the contents of &amp;#39;file.txt&amp;#39; to stdout&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But to be an effective shell user, you must understand that not all commands are created equal. The differences between the types of commands will affect how you use them.&lt;/p>
&lt;p>There are four types of commands in most shells:&lt;/p>
&lt;ol>
&lt;li>Executables&lt;/li>
&lt;li>&amp;ldquo;Built-Ins&amp;rdquo; (which we'll just call &lt;em>builtins&lt;/em> from now on)&lt;/li>
&lt;li>Functions&lt;/li>
&lt;li>Aliases&lt;/li>
&lt;/ol>
&lt;p>Let's quickly dig in and see a bit more.&lt;/p>
&lt;h2 id="executables---programs">Executables - Programs&lt;/h2>
&lt;p>Executables are just files with the &amp;lsquo;executable&amp;rsquo; bit set&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. If I execute the &lt;code>cat&lt;/code> command, the shell will search for an executable named &lt;code>cat&lt;/code> in my &lt;code>$PATH&lt;/code>. If it finds it, it will run the program.&lt;/p>
&lt;pre>&lt;code>$ cat file.txt
This is a simple text file
&lt;/code>&lt;/pre>&lt;p>What is &lt;code>$PATH&lt;/code>? &lt;code>$PATH&lt;/code> is the standard environment variable used to define &lt;em>where&lt;/em> the shell should search for programs. If we temporarily &lt;em>empty&lt;/em> this variable, the shell won't find the command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span> cat file.txt
bash: cat: No such file or directory
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Normally your &lt;code>$PATH&lt;/code> variable will include the standard locations for Linux programs - folders such as &lt;code>/bin&lt;/code>, &lt;code>/sbin&lt;/code>, &lt;code>/usr/bin&lt;/code> and so on&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>If you were to print the variable, you'd see a bunch of paths (they are separated by colons; I've put them on separate lines for readability):&lt;/p>
&lt;pre>&lt;code>/usr/local/bin
/usr/bin
/bin
/usr/sbin
/sbin
&lt;/code>&lt;/pre>&lt;p>The shell will start with the &lt;em>earlier&lt;/em> locations and move to the later ones. This allows &lt;em>local&lt;/em> flavours of tools to be installed for users, which will take precedence over &lt;em>general&lt;/em> versions of tools.&lt;/p>
&lt;p>There will likely be other locations too - you might see Java folders, package manager folders and so on.&lt;/p>
&lt;h2 id="executables---scripts">Executables - Scripts&lt;/h2>
&lt;p>Imagine we create a text file called &lt;code>dog&lt;/code> in the local folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>echo &lt;span style="color:#e6db74">&amp;#34;🐶 woof 🐶&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If we make the file &lt;em>executable&lt;/em>, by running &lt;code>chmod +x dog&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, then we can run this just like any other program - as long as we tell the shell to look for programs in the current directory:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ PATH&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span> dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>More common would be to run the program by giving a path:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ./dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Or just move it to a standard location that the shell already checks for programs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ mv dog /usr/local/bin
$ dog
🐶 woof 🐶
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The point is that executables don't &lt;em>have&lt;/em> to be compiled program code. If a file starts with &lt;code>#!&lt;/code> (the &amp;lsquo;shebang&amp;rsquo;), then the system will try to run the contents of the file with the program specified in the shebang.&lt;/p>
&lt;p>We will look at shebangs in greater detail in a later chapter.&lt;/p>
&lt;h2 id="builtins">Builtins&lt;/h2>
&lt;p>OK, so we've seen executables. What about a command like this?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">local V&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;hello&amp;#34;&lt;/span> echo $V
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You will not find the &lt;code>local&lt;/code> executable anywhere on your system. It is a &lt;em>builtin&lt;/em> - a special command built directly into the shell program.&lt;/p>
&lt;p>Builtins are often highly specific to your shell. They might be used for programming (&lt;code>local&lt;/code> for example is used to declare a locally scoped variable), or they might be for very shell-specific features.&lt;/p>
&lt;p>This is where we need to take note. As soon as you are running a builtin, you are potentially using a feature that is specific to &lt;em>your&lt;/em> shell, rather than a program that is shared across the system and can be run by &lt;em>any&lt;/em> shell.&lt;/p>
&lt;p>Trying to programmatically execute &lt;code>local&lt;/code> as a process will fail - there is no executable with that name; it is purely a shell construct.&lt;/p>
&lt;p>So how do we know if a command is a builtin? The preferred method is to use the &lt;code>type&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type local
local is a shell builtin
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>type&lt;/code> command (which is &lt;em>itself&lt;/em> a builtin!) can tell you the exact type of shell command.&lt;/p>
&lt;p>Interestingly, you might be using more builtins than you think. &lt;code>echo&lt;/code> is a program, but most of the time you are not executing it when you are in a shell:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a echo
echo is a shell builtin
echo is /bin/echo
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By using the &lt;code>-a&lt;/code> flag on &lt;code>type&lt;/code> to show &lt;em>all&lt;/em> commands that match the name, we see that &lt;code>echo&lt;/code> is actually both a builtin &lt;em>and&lt;/em> a program.&lt;/p>
&lt;p>Many simple programs have builtin versions. The shell can execute them much faster.&lt;/p>
&lt;p>Some commands are a builtin so that they can function in a sensible manner. The &lt;code>cd&lt;/code> command changes the current directory - if we executed it as a process, it would change only the directory for the &lt;code>cd&lt;/code> process itself, not the shell, making it much less useful.&lt;/p>
&lt;p>Builtins will vary from shell to shell, but many shells are &amp;lsquo;Bash-like&amp;rsquo; - meaning they will have a set very similar to the Bash builtins, which you can see here:&lt;/p>
&lt;p>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html">https://www.gnu.org/software/bash/manual/html_node/Bash-Builtins.html&lt;/a>&lt;/p>
&lt;p>As should be familiar from &lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>, you can get help for builtins:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ man source &lt;span style="color:#75715e"># source is a builtin&lt;/span>
BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> BSD General Commands Manual BUILTIN&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span>
NAME
builtin, !, %, &lt;span style="color:#75715e"># ...snip...&lt;/span>
SYNOPSIS
builtin &lt;span style="color:#f92672">[&lt;/span>-options&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#f92672">[&lt;/span>args ...&lt;span style="color:#f92672">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, the manual will &lt;em>not&lt;/em> show information on specific builtins, which is a pain. Your shell &lt;em>might&lt;/em> have an option to show more details - for example, in Bash you can use &lt;code>help&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ help source
source: source filename &lt;span style="color:#f92672">[&lt;/span>arguments&lt;span style="color:#f92672">]&lt;/span>
Read and execute commands from FILENAME and &lt;span style="color:#66d9ef">return&lt;/span>. The pathnames
in $PATH are used to find the directory containing FILENAME. If any
ARGUMENTS are supplied, they become the positional parameters when
FILENAME is executed.
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But remember: &lt;code>help&lt;/code> is a builtin; you might not find it in all shells (you won't find it in &lt;code>zsh&lt;/code>, for example). This highlights again the challenges of builtins.&lt;/p>
&lt;h2 id="functions">Functions&lt;/h2>
&lt;p>You can define your own shell functions. We will see a lot more of this later, but let's show a quick example for now:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span> exec -l &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$SHELL&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet creates a function that restarts the shell (quite useful if you are messing with shell configuration files or think you might have irreversibly goofed up your current session).&lt;/p>
&lt;p>We can execute this function just like any command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ restart-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And running &lt;code>type&lt;/code> will show us that this is a function:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type restart-shell
restart-shell is a &lt;span style="color:#66d9ef">function&lt;/span>
restart-shell &lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span>
&lt;span style="color:#f92672">{&lt;/span>
exec -l $SHELL
&lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Functions are one of the most powerful shell constructs we will see; they are extremely useful for building sophisticated logic. We're going to see them in a lot more detail later, but for now it is enough to know that they exist, and can run logic, and are run as commands.&lt;/p>
&lt;h2 id="aliases">Aliases&lt;/h2>
&lt;p>An alias is just a shortcut. Type in a certain set of characters, and the shell will replace them with the value defined in the alias.&lt;/p>
&lt;p>Some common commands are actually already aliases - for example, in my &lt;code>zsh&lt;/code> shell, the &lt;code>ls&lt;/code> command is an alias:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I make sure that when I use the &lt;code>ls&lt;/code> command, the shell always expands it to &lt;code>ls -G&lt;/code>, which colours the output.&lt;/p>
&lt;p>We can quickly define aliases to save on keystrokes. For example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ alias k&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;kubectl&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>From this point on, I can use the &lt;code>k&lt;/code> alias as shorthand for the &lt;code>kubectl&lt;/code> command.&lt;/p>
&lt;p>Aliases are far less sophisticated than functions. Think of them as keystroke savers and nothing more, and you won't go far wrong. Aliases are not portable across shells and have certain behaviours which can make them problematic to work with, there will be an entire chapter dedicated to alisases coming up in the series.&lt;/p>
&lt;h2 id="so-what">So What?&lt;/h2>
&lt;p>So we now hopefully have a greater understanding of the variety of shell commands. Not all commands are executables, not all of the commands we &lt;em>think&lt;/em> are executables necessarily are, and some commands might be more sophisticated.&lt;/p>
&lt;p>As a shell user, the key things to remember are:&lt;/p>
&lt;ol>
&lt;li>Executables are &amp;lsquo;safe&amp;rsquo; - they are programs your system can use; your shell just calls out to them.&lt;/li>
&lt;li>Builtins are &lt;em>very&lt;/em> shell-specific and usually control the shell itself&lt;/li>
&lt;li>Functions are powerful ways to write logic but will normally be shell-specific.&lt;/li>
&lt;li>Aliases are conveniences for human operators, but only in the context of an interactive shell.&lt;/li>
&lt;/ol>
&lt;p>To find out how a command is implemented, just use the &lt;code>type -a&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ type -a cat
cat is /bin/cat
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="more-than-you-need-to-know">More than You Need to Know&lt;/h2>
&lt;p>OK, for the masochistic few, you might be wondering about all of the other commands and utilities you may have seen that can tell you about programs and commands:&lt;/p>
&lt;ul>
&lt;li>&lt;code>what&lt;/code>&lt;/li>
&lt;li>&lt;code>whatis&lt;/code>&lt;/li>
&lt;li>&lt;code>which&lt;/code>&lt;/li>
&lt;li>&lt;code>whence&lt;/code>&lt;/li>
&lt;li>&lt;code>where&lt;/code>&lt;/li>
&lt;li>&lt;code>whereis&lt;/code>&lt;/li>
&lt;li>&lt;code>command&lt;/code>&lt;/li>
&lt;li>&lt;code>type&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>A &lt;em>lot&lt;/em> of these are legacy and should be avoided, but for completeness sake, we'll go through them.&lt;/p>
&lt;h3 id="what">&lt;code>what&lt;/code>&lt;/h3>
&lt;p>&lt;code>what&lt;/code> reads out special metadata embedded in a program, generally used to identify the version of source code it was built from:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ what /bin/ls
/bin/ls
Copyright &lt;span style="color:#f92672">(&lt;/span>c&lt;span style="color:#f92672">)&lt;/span> 1989, 1993, &lt;span style="color:#ae81ff">1994&lt;/span>
PROGRAM:ls PROJECT:file_cmds-272.220.1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There should be almost no circumstance in which you need to use it in your day-to-day work, but you might come across it if you &lt;em>meant&lt;/em> to type &lt;code>whatis&lt;/code>.&lt;/p>
&lt;h3 id="whatis">&lt;code>whatis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whatis&lt;/code> searches a local help database for text. This can be useful in tracking down manual pages:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ whatis bash
bash&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - GNU Bourne-Again SHell
bashbug&lt;span style="color:#f92672">(&lt;/span>1&lt;span style="color:#f92672">)&lt;/span> - report a bug in bash
&lt;/code>&lt;/pre>&lt;/div>&lt;p>But I can't imagine it will be a regularly used tool by most users.&lt;/p>
&lt;h3 id="which">&lt;code>which&lt;/code>&lt;/h3>
&lt;p>&lt;code>which&lt;/code> will search your &lt;code>$PATH&lt;/code> to see whether an executable can be found. With the &lt;code>-a&lt;/code> flag, it will show all results.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ which -a vi
/usr/local/bin/vi
/usr/bin/vi
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>which&lt;/code> originated in &lt;code>csh&lt;/code>. It remains on many systems for compatibility but in general should be avoided due to potentially odd behaviour&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>.&lt;/p>
&lt;h3 id="whence">&lt;code>whence&lt;/code>&lt;/h3>
&lt;p>&lt;code>whence&lt;/code> was added to the Korn shell. You are unlikely to use it unless you are on systems using &lt;code>ksh&lt;/code>. &lt;code>zsh&lt;/code> also has this command, but it should be avoided and considered non-standard.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whence brew
/usr/local/bin/brew
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="where">&lt;code>where&lt;/code>&lt;/h3>
&lt;p>This is a shell builtin that can provide information on commands, similar to &lt;code>type&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% where ls
ls: aliased to ls -G
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, &lt;code>type&lt;/code> should be preferred, as it is more standard.&lt;/p>
&lt;h3 id="whereis">&lt;code>whereis&lt;/code>&lt;/h3>
&lt;p>&lt;code>whereis&lt;/code> is available on some systems and generally operates the same as &lt;code>which&lt;/code>, searching paths for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% whereis ls
/bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, &lt;code>type&lt;/code> should be preferred for compatability.&lt;/p>
&lt;h3 id="command">&lt;code>command&lt;/code>&lt;/h3>
&lt;p>&lt;code>command&lt;/code> is defined in the POSIX standard, so should be expected to be present on most modern systems. Without arguments, it simply executes a command. With the &lt;code>-v&lt;/code> argument, you get a fairly machine-readable or processable response; with the &lt;code>-V&lt;/code> argument, you get a more human readable response:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% command -v ls
alias ls&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;ls -G&amp;#39;&lt;/span>
% command -V ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>command&lt;/code> can be useful in scripts, as we will see in later chapters.&lt;/p>
&lt;h3 id="type">&lt;code>type&lt;/code>&lt;/h3>
&lt;p>&lt;code>type&lt;/code> is part of the Unix standard and will be present in most modern systems. As we've already seen, it will identify the type of command as well as the location for an executable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -a ls
ls is an alias &lt;span style="color:#66d9ef">for&lt;/span> ls -G
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command can also be used to only search for paths:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% type -p ls
ls is /bin/ls
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>Summary&lt;/strong>&lt;/p>
&lt;p>In summary, avoid anything that starts with &amp;lsquo;&lt;code>w&lt;/code>&amp;rsquo;! These are legacy commands, generally needed only when working on older Unix machines. &lt;code>type&lt;/code> or &lt;code>command&lt;/code> should be used instead.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>We will cover permissions and modes in later chapters. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Why these names and locations? It's a long story. The best place to start if you are intersted is the &lt;a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>&lt;code>chmod&lt;/code> changes the mode of a file; &lt;code>+x&lt;/code> means &amp;lsquo;add the executable bit&amp;rsquo;. This tells the operating system the file can be executed. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>&lt;a href="https://unix.stackexchange.com/questions/85249/why-not-use-which-what-to-use-then">Stack Exchange: Why not use “which”? What to use then?&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 6: Everything You Don't Need To Know About Job Control</title><link>https://dwmkerr.com/effective-shell-6-job-control/</link><pubDate>Mon, 10 Jun 2019 08:26:33 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-6-job-control/</guid><description>&lt;p>&lt;em>Job control&lt;/em> is a feature of most shells, which is generally not particularly intuitive to work with. However, knowing the basics can help prevent you from getting yourself into a tangle, and can from time to time make certain tasks a little easier.&lt;/p>
&lt;p>In this chapter, we'll look at the main features of job control, why it can be a problematic, and some alternatives.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-job-control">What Is Job Control?&lt;/h2>
&lt;p>Let's start with an example. I am building a simple web page. It has one &lt;code>index.html&lt;/code> file, one &lt;code>styles.css&lt;/code> file, and one &lt;code>code.js&lt;/code> file. The &lt;code>index.html&lt;/code> file looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">title&lt;/span>&amp;gt;My New Project&amp;lt;/&lt;span style="color:#f92672">title&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">link&lt;/span> &lt;span style="color:#a6e22e">rel&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;stylesheet&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text/css&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;styles.css&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;code.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">head&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Snip... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;/&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Opening the file in a browser doesn't quite work, as it won't load the code or the styles. We need a web server to serve styles and code.&lt;/p>
&lt;p>A super-useful one-liner to run a web server on any machine with Python installed is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, this is so useful that I normally &lt;em>alias&lt;/em> this command, so that I can just type &lt;code>serve&lt;/code>. We'll see aliases in a later chapter.&lt;/p>
&lt;p>For now, if we run this command (you can get &lt;a href="https://github.com/dwmkerr/effective-shell/tree/master/6-job-control/sample">the three sample files here&lt;/a> if you want to try this yourself), then we can open the webpage in a browser, with the styles and code loaded:&lt;/p>
&lt;p>&lt;img src="images/website-screenshot.png" alt="Screenshot: Website" width="600" />&lt;/p>
&lt;p>We can also see that the server has served the HTML, JavaScript, and CSS files:&lt;/p>
&lt;p>&lt;img src="images/server-screenshot.png" alt="Screenshot: Server" width="600" />&lt;/p>
&lt;p>All well and good so far.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>Let's say we want to now continue using our shell, maybe to edit the website with a terminal editor like Vim or Emacs, or we want to zip up the site, or just run any shell command&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We have a problem. The &lt;code>python&lt;/code> process is still running - it's serving the website. Our shell is essentially useless, until we stop the server. See what happens when I try to edit a file:&lt;/p>
&lt;p>&lt;img src="images/blocked-shell.gif" alt="Demo: Blocked Shell" width="600" />&lt;/p>
&lt;p>In the example above, I try to run &lt;code>vi&lt;/code>, but nothing is happening. Standard input is not being read by the server and not being interpreted by the shell.&lt;/p>
&lt;p>I have to kill the server by hitting &lt;code>Ctrl+C&lt;/code> (which sends a &lt;code>SIGINT&lt;/code>&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> - we'll see more about signals later), clear my screen to get rid of all of the error messages, then start again.&lt;/p>
&lt;p>This is obviously not optimal. Let's look at some solutions.&lt;/p>
&lt;h2 id="solution-1-start-the-server-in-the-background">Solution 1: Start the Server in the Background&lt;/h2>
&lt;p>In most shells, you can run a command and instruct the shell to run it in the &lt;em>background&lt;/em>. To do this, you end the line with an ampersand. Here's how the example would look in this case:&lt;/p>
&lt;p>&lt;img src="images/start-in-background.gif" alt="Demo: Starting a Background Job" width="600" />&lt;/p>
&lt;p>By ending the command with an &lt;code>&amp;amp;&lt;/code> ampersand symbol, we instruct the shell to run the command as a &lt;em>background job&lt;/em>. This means that our shell is still functional. The shell has also notified us that this command is running as a background job with a specific &lt;em>job number&lt;/em>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span> &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#ae81ff">19372&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In slightly obtuse language, the shell has informed us that it has started a job in the background, with job number &lt;code>1&lt;/code> and that this job is currently handling the process with ID &lt;code>19372&lt;/code>.&lt;/p>
&lt;p>The ampersand solution is a fairly common pattern used in day-to-day work.&lt;/p>
&lt;h2 id="solution-2-move-the-server-to-the-background">Solution 2: Move the Server to the Background&lt;/h2>
&lt;p>Let's say you forgot to start the command in the background. Most likely in this case you'd kill the server with &lt;code>Ctrl+C&lt;/code> and then start it again with the &lt;code>&amp;amp;&lt;/code> option. However, what if this was a large file download or a task you didn't want to abort?&lt;/p>
&lt;p>In the example below, we'll move the job to the background:&lt;/p>
&lt;p>&lt;img src="images/move-to-background.gif" alt="Demo: Moving a Job to the Background" width="600" />&lt;/p>
&lt;p>The process is currently in the foreground, so my shell is inactive. Hitting &lt;code>Ctrl+Z&lt;/code> sends a &amp;lsquo;suspend&amp;rsquo; signal to the process&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, pausing it and moving it to the background.&lt;/p>
&lt;p>Let's dissect this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
Serving HTTP on 0.0.0.0 port &lt;span style="color:#ae81ff">3000&lt;/span> ...
127.0.0.1 - - &lt;span style="color:#f92672">[&lt;/span>03/Jun/2019 13:38:45&lt;span style="color:#f92672">]&lt;/span> &lt;span style="color:#e6db74">&amp;#34;GET / HTTP/1.1&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">200&lt;/span> -
^Z
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell echos as I type, so we see &lt;code>^Z&lt;/code> (i.e., the &lt;code>Ctrl+Z&lt;/code> chord I entered). The shell responds by moving the process into a background job and suspending it.&lt;/p>
&lt;p>The key here is that it is &lt;em>suspended&lt;/em>. The process is paused. So the web server is no longer serving. If you are following with the sample, reload your browser. The webpage fails to load, as the server process is not able to respond to requests.&lt;/p>
&lt;p>To &lt;em>continue&lt;/em> the job, in the background, we use the &lt;code>bg&lt;/code> (&amp;lsquo;background&amp;rsquo;) command, with a &lt;em>job identifier&lt;/em> (which always starts with a &lt;code>%&lt;/code> symbol - we'll see why soon) to tell the shell to continue the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% bg %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The shell lets us know the job is being continued, and if we load the webpage again, the content is shown as expected.&lt;/p>
&lt;p>As a final check, we run the &lt;code>jobs&lt;/code> command to see what jobs the shell is running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And there you have it - our server is running as a background job. This is exactly what we would see if we run &lt;code>jobs&lt;/code> after starting the server with an &lt;code>&amp;amp;&lt;/code> at the end. In fact, using an &lt;code>&amp;amp;&lt;/code> is perhaps an easier way to remember how to continue a suspended job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% %1 &amp;amp;
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">21268&lt;/span> continued python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the same way ending a command with &lt;code>&amp;amp;&lt;/code> runs it in the background, ending a job identifier with &lt;code>&amp;amp;&lt;/code> &lt;em>continues&lt;/em> it in the background.&lt;/p>
&lt;p>There is at least one more way to move a job to the background&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>, but I have not yet found it useful in any scenarios, and it is overly complex to explain. See the footnote for details if you are interested.&lt;/p>
&lt;h2 id="moving-background-jobs-to-the-foreground">Moving Background Jobs to the Foreground&lt;/h2>
&lt;p>If you have a job in the background, you can bring it back to the foreground with the &lt;code>fg&lt;/code> (&amp;lsquo;foreground&amp;rsquo;) command. Let's show the jobs, with the &lt;code>jobs&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + running python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here I have a background job running a server. Any one of the following commands will bring it back to the foreground:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">fg %1 &lt;span style="color:#75715e"># Explicitly bring Job 1 into the foreground&lt;/span>
%1 &lt;span style="color:#75715e"># ...or in shorthand, just enter the job id...&lt;/span>
fg &lt;span style="color:#75715e"># ...if not given an id, fg and bg assume the most recent job.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the job is in the foreground, and you can interact with the process again however you like.&lt;/p>
&lt;h2 id="cleaning-up-jobs">Cleaning Up Jobs&lt;/h2>
&lt;p>You might realise you cannot continue what you are doing because an old job is &lt;em>still running&lt;/em>. Here's an example:&lt;/p>
&lt;p>&lt;img src="images/kill-job.gif" alt="Demo: Cleaning Up Jobs" width="600" />&lt;/p>
&lt;p>I tried to run my web server, but there was still one running as a background job. The server failed to start because the port is in use.&lt;/p>
&lt;p>To clean it up, I run the &lt;code>jobs&lt;/code> command to list the jobs:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% jobs
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + suspended python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's my old web server. Note that even though it is suspended, it'll still be blocking the port it is serving on&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. The process is paused, but it is still holding onto all of the resources it is using.&lt;/p>
&lt;p>Now that I know the job identifier (&lt;code>%1&lt;/code> in this case), I can kill the job:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% kill %1
&lt;span style="color:#f92672">[&lt;/span>1&lt;span style="color:#f92672">]&lt;/span> + &lt;span style="color:#ae81ff">22843&lt;/span> terminated python -m SimpleHTTPServer &lt;span style="color:#ae81ff">3000&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>This is why job identifiers start with a percentage sign!&lt;/em> The &lt;code>kill&lt;/code> command I have used is not a special job control command (like &lt;code>bg&lt;/code> or &lt;code>fg&lt;/code>). It is the normal &lt;code>kill&lt;/code> command, which terminates a process. But shells that support job control can normally use a job identifier in place of a &lt;em>process identifier&lt;/em>. So rather than working out what the process identifier is that I need to kill, I can just use the job identifier&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="why-you-shouldnt-use-jobs">Why You Shouldn't Use Jobs&lt;/h2>
&lt;p>Avoid jobs. They are not intuitive to interface with, and they suffer from some serious problems.&lt;/p>
&lt;p>The most obvious one is that all jobs write to the same output, meaning you can quickly get garbled output like this:&lt;/p>
&lt;p>&lt;img src="images/output.png" alt="Screenshot: Garbled Output" width="600" />&lt;/p>
&lt;p>This is what happens when I run a job, which just outputs text every second. It's in the background, but it's printing all over my commands. Even running the &lt;code>jobs&lt;/code> command to try and find the job to stop it is difficult.&lt;/p>
&lt;p>Input is even more complex. If a job is &lt;em>running&lt;/em> in the background, but requires input, it will be &lt;em>silently suspended&lt;/em>. This can cause confusion.&lt;/p>
&lt;p>Jobs &lt;em>can&lt;/em> be used in scripts but must be done so with caution and could easily confuse a consumer of the script if they leave background jobs hanging around, which cannot be easily cleaned up&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Handling errors and exit codes for jobs can be problematic, causing confusion, poor error handling, or overly complex code.&lt;/p>
&lt;h2 id="how-to-escape-jobs">How to Escape Jobs&lt;/h2>
&lt;p>If there are two things to take away, it would be this:&lt;/p>
&lt;blockquote>
&lt;p>If you have started running a command in the foreground, and you don't want to stop it and would rather move it to the background, hit &lt;code>Ctrl+Z&lt;/code>. Then Google &amp;ldquo;job control&amp;rdquo;.&lt;/p>
&lt;/blockquote>
&lt;p>And:&lt;/p>
&lt;blockquote>
&lt;p>If you think there is a job running in the background, and it is messing with your screen, type &lt;code>fg&lt;/code> to bring it to the front and kill it with &lt;code>Ctrl+C&lt;/code>. Repeat as needed!&lt;/p>
&lt;/blockquote>
&lt;p>In either case, if you need to do something more subtle, you can return to this reference. But the first command should allow you to get your shell back while you work out how to continue the job, and the second should kill a background job that is messing with your screen.&lt;/p>
&lt;h2 id="alternatives-to-jobs">Alternatives to Jobs&lt;/h2>
&lt;p>If you are using any kind of modern terminal such as iTerm, Terminal or the GNOME Terminal, just open a new tab or split! Much easier.&lt;/p>
&lt;p>The benefit to this is that each tab gets its own standard input and output, so there's no risk of overwriting. And of course you can hide/reveal/rearrange the tabs however you like.&lt;/p>
&lt;p>The traditional alternative to a job for an operator who simply wants more than one thing going on at once would be a &lt;em>terminal multiplexer&lt;/em>, such as &lt;code>screen&lt;/code> or &lt;code>tmux&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/terminal-multiplexer.gif" alt="terminal-multiplexer">&lt;/p>
&lt;p>Multiplexers work in a very similar way to a modern graphical terminal - they manage many shell instances. The benefits to a modern terminal, such as iTerm, is that you have a very intuitive GUI and lots of features.&lt;/p>
&lt;p>The benefits to a multiplexer are that you can run them over SSH sessions to manage complex operations on remote machines and that they run a client-server model, meaning many people can work with many multiplexed processes (and they can persist beyond sessions).&lt;/p>
&lt;p>My personal preference is both - I use a modern terminal &lt;em>and&lt;/em> run everything inside it in &lt;code>tmux&lt;/code>. We'll look at both of these options in later chapters.&lt;/p>
&lt;h2 id="quick-reference">Quick Reference&lt;/h2>
&lt;p>You might find that jobs are useful, or you might find that they are not. Either way, here's a quick reference of some common commands:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Command&lt;/th>
&lt;th>Usage&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>command &amp;amp;&lt;/code>&lt;/td>
&lt;td>Run the command as a background job.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>&amp;lt;Ctrl+Z&amp;gt;&lt;/code>&lt;/td>
&lt;td>Move the current process into a background job, suspended.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>jobs&lt;/code>&lt;/td>
&lt;td>List all jobs.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>fg %1&lt;/code>&lt;/td>
&lt;td>Move background job number 1 into the foreground.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>bg %1&lt;/code>&lt;/td>
&lt;td>Continue background job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>kill %1&lt;/code>&lt;/td>
&lt;td>Terminate job number 1.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>wait %1&lt;/code>&lt;/td>
&lt;td>Block until job number 1 exits.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>If you want to find out more about the gory details of jobs, the best place to start is the &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">Bash Manual - Job Control Section&lt;/a>, or the &amp;lsquo;Job Control&amp;rsquo; section of your preferred shell's manual.&lt;/p>
&lt;p>I hope you found this useful, and, as always, please leave comments, questions or suggestions below!&lt;/p>
&lt;hr>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you are not a heavy shell user, this might seem unlikely. But if you do a lot of work in shells, such as sysadmin, devops, or do your coding from a terminal, this happens all the time! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Signals like &lt;code>SIGINT&lt;/code>, &lt;code>SIGKILL&lt;/code>, &lt;code>SIGTERM&lt;/code> and so on will be covered in a later chapter. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Technically, &lt;code>SIGTSTP&lt;/code> - which is &amp;lsquo;TTY stop&amp;rsquo;. If you have always wondered about the &amp;lsquo;TTY&amp;rsquo; acroynm, check the previous chatper, &lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Interlude: Understanding the Shell&lt;/a>. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>The alternative method is to use &lt;code>Ctrl+Y&lt;/code>, which will send a &lt;em>delayed interrupt&lt;/em>, which will continue to run the process until it tries to read from &lt;code>stdin&lt;/code>. At this point, the job is suspended and the control given to the shell. The operator can then use &lt;code>bg&lt;/code> or &lt;code>kill&lt;/code> or &lt;code>fg&lt;/code> to either move to the background, stop the process, or keep in the foreground as preferred. See: &lt;a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control">https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Job-Control&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Another super-useful snippet: &lt;code>lsof -i -P -n | grep 8000&lt;/code> to find any process that has a given port open. Another one for the aliases chapter! &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>There are times this is needed. If a job runs &lt;em>many processes&lt;/em> - for example, by running a pipeline - the process identifier will change as the command moves from one stage of the pipeline to the next. The job identifier will remain constant. Remember, a job is a shell &lt;em>command&lt;/em>, so could run many processes. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>To see how bad this can be, create a script that starts jobs, then run it. Then run the &lt;code>jobs&lt;/code> command to see what is running. The output might surprise you! &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Interlude: Understanding the Shell</title><link>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</link><pubDate>Tue, 21 May 2019 09:22:05 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/</guid><description>&lt;p>This is the first &amp;lsquo;interlude&amp;rsquo; in my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series. These interludes give some background, history or more flavour to some of the topics.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This one &lt;em>should&lt;/em> be high-level enough for even non-technical readers to enjoy (or at least understand!). I've tried to make sure any term that might be unfamiliar is described in a footnote&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. For the more technical reader, it provides an important grounding on some of the key concepts relating to shells and how they work.&lt;/p>
&lt;h2 id="introduction-for-the-non-technical-reader">Introduction for the Non-Technical Reader&lt;/h2>
&lt;p>It might come as a surprise that &lt;em>many&lt;/em> technical computer users (programmers, data scientists, systems administrators etc) spend a lot of time using an interface which looks like it's from the sixties:&lt;/p>
&lt;p>&lt;img src="images/screenshot-shell.png" alt="Diagram: The Shell" width="600px" />&lt;/p>
&lt;p>If you work with technologists, you might have seen them using an interface like this. This kind of simple, text-based interface is called a &lt;em>shell&lt;/em>, and it has been a common way to interface with computers ever since the first screens and keyboards were created.&lt;/p>
&lt;p>Given how much computing has advanced, why would people use such an interface? Just look at how much the Windows operating-system has changed over the last three decades:&lt;/p>
&lt;p>&lt;img src="images/screenshot-windows-evolution.png" alt="Image: The Evolution of Windows" width="600px" />&lt;/p>
&lt;p>&lt;em>(By Source (WP:NFCC#4), Fair use, &lt;a href="https://en.wikipedia.org/w/index.php?curid=58853841">https://en.wikipedia.org/w/index.php?curid=58853841&lt;/a>)&lt;/em>&lt;/p>
&lt;p>Why would people choose to use such an archaic interface as a shell?&lt;/p>
&lt;ul>
&lt;li>Typing is &lt;em>fast&lt;/em>: A skilled shell user can manipulate a system at dazzling speeds just using a keyboard. Typing commands is generally &lt;em>much&lt;/em> faster than exploring through user interfaces with a mouse&lt;/li>
&lt;li>Shells are &lt;em>programmable&lt;/em>: Users will often being programming as they work in a shell, creating scripts to automate time-consuming or repetetive processes&lt;/li>
&lt;li>Shells are &lt;em>portable&lt;/em>: A shell can be used to interface to almost any type of computer, from a mainframe to a Raspberry Pi, in a very similar way.&lt;/li>
&lt;/ul>
&lt;p>Not all technical users will use a shell regularly, but there are many who will spend the bulk of their time in such an interface. It is such a crucial skill to be able to operate one effectively that I have been writing this series primarily to show ways to be more efficient with this kind of interface.&lt;/p>
&lt;h2 id="introduction-for-the-technical-reader">Introduction for the Technical Reader&lt;/h2>
&lt;p>You may be familar with the shell, but it can be useful to understand some of the surrounding concepts in detail. How does a shell differ from a terminal? What is a &lt;em>tty&lt;/em>? How do shells really work? Hopefully as you read this article you'll discovery something that you didn't know about shells.&lt;/p>
&lt;h2 id="lets-get-started">Let's Get Started!&lt;/h2>
&lt;p>To understand what shells, terminals, command-prompts and so on are and how they relate, we need to start with the basics: how a modern computer works!&lt;/p>
&lt;h2 id="a-computer-in-a-nutshell">A Computer in a Nutshell&lt;/h2>
&lt;p>The diagram below shows a simplified view of a typical computer:&lt;/p>
&lt;p>&lt;img src="images/diagram1-operating-system.png" alt="Diagram: Operating System" width="600px" />&lt;/p>
&lt;p>Already there's a lot going on.&lt;/p>
&lt;p>Your computer is going to have a CPU&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> and memory&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, and almost certainly a network adapter&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> and display adapter&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. Most computers will have at least one hard disk. For home PCs, there'll also likely be a bunch of peripherals, such as a mouse, keyboard, printers, flash drives, webcams and so on.&lt;/p>
&lt;h3 id="the-operating-system">The Operating System&lt;/h3>
&lt;p>The operating system is the piece of software installed on a computer that can interface with the &lt;em>hardware&lt;/em>. Without hardware, such as a CPU, memory, a network adapter, a graphics card, disk drives and so on, there's not much that you can do with the computer. The operating system is the primary interface to this hardware. No normal programs will talk to hardware directly - the operating system abstracts this hardware away and provides a &lt;em>software&lt;/em> interface to it.&lt;/p>
&lt;p>The abstraction the operating system provides is essential. Developers don't need to know the specifics of how to work with individual devices from different vendors; the operating system provides a standardised interface to all of this. It also handles various tasks such as making sure the system starts up properly.&lt;/p>
&lt;p>The operating system is generally broken down into two parts - the &lt;em>kernel&lt;/em> and &lt;em>user space&lt;/em>:&lt;/p>
&lt;p>&lt;img src="images/diagram2-the-kernel-and-user-space.png" alt="Diagram: The Kernel and User Space" width="600px" />&lt;/p>
&lt;p>Let's look at these in more detail.&lt;/p>
&lt;h3 id="the-kernel">The Kernel&lt;/h3>
&lt;p>This is the part of the operating system that is responsible for the most sensitive tasks: interfacing with physical devices, managing the resources that are available for users and programs, starting up the various systems that are needed, and so on.&lt;/p>
&lt;p>Software running in the kernel has direct access to resources, so is &lt;em>extremely&lt;/em> sensitive. The kernel will balance resources between the programs in user space, which we'll look at shortly. If you've ever had to install &amp;lsquo;drivers&amp;rsquo;, these are examples of pieces of software that will run in the kernel - they'll have direct access to a physical device you've installed, and expose it to the rest of the software on the computer.&lt;/p>
&lt;p>Why &amp;lsquo;kernel&amp;rsquo;? The kernel is the soft, edible part of a nut or seed, which is surrounded by a shell. Below you can see a walnut - the kernel is the soft bit in the middle, and the shell surrounds and protects it. This is a useful metaphor that is used for parts of a computer.&lt;/p>
&lt;p>&lt;img src="images/image-walnut.jpg" alt="Image: Photo of a walnut, showing the kernel and the shell" width="200px" />&lt;/p>
&lt;p>&lt;em>(By Kkchaudhary11 - Own work, CC BY-SA 4.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=49069244">https://commons.wikimedia.org/w/index.php?curid=49069244&lt;/a>)&lt;/em>&lt;/p>
&lt;p>The operating system kernel really is the &lt;em>core&lt;/em> of the operating system. It's such a sensitive area of the operating system that we actually want to avoid running software in it if possible&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. And that is where &lt;em>user space&lt;/em> comes in.&lt;/p>
&lt;h3 id="user-space">User Space&lt;/h3>
&lt;p>The vast majority of programs run in &amp;lsquo;user space&amp;rsquo; (also commonly called &amp;lsquo;user land&amp;rsquo;).&lt;/p>
&lt;p>When a program starts, the kernel will allocate it a private segment of memory and provide &lt;em>limited&lt;/em> access to resources. The program is given access to a library of functions by the operating system, which it can use to access resources such as files, devices and so on. Programs in user space are essentially in sandboxes, where there is a limit to how much damage they can do.&lt;/p>
&lt;p>For example, a program running in user space can use the standard &lt;a href="http://man7.org/linux/man-pages/man3/fopen.3.html">&lt;code>fopen&lt;/code>&lt;/a> function, which is provided on almost every operating system as part of the &lt;a href="https://www.gnu.org/software/libc/">C Standard Library&lt;/a>. This allows a program to attempt to open a file. The operating system will make a decision on whether the program is &lt;em>allowed&lt;/em> to open the file (based on things such as permissions, where the file is and so on) and then, if it is OK with the call, will give the program access to the file. Under the hood, this &amp;lsquo;user space&amp;rsquo; call translates to a system call in the kernel.&lt;/p>
&lt;p>Now that the key components have been introduced, we can look at the &lt;em>shell&lt;/em>. The name should come as no surprise, as it is a &lt;em>wrapper&lt;/em> or outer layer to the operating system (which itself contains the sensitive nugget of the kernel).&lt;/p>
&lt;h3 id="the-shell">The Shell&lt;/h3>
&lt;p>So what is the shell? The shell is just a general name for any &lt;em>user space&lt;/em> program that allows access to resources in the system, via some kind of interface.&lt;/p>
&lt;p>Shells come in many different flavours but are generally provided to aid a human operator in accessing the system. This could be interactively, by typing at a terminal, or via scripts, which are files that contain a sequence of commands.&lt;/p>
&lt;p>For example, to see all of the files in a folder, the human operator &lt;em>could&lt;/em> write a program in a language such as C, making system calls to do what they want. But for day-to-day tasks, this would be repetitive. A shell will normally offer us a quick way to do that exact task, without having to manually write a program to do it.&lt;/p>
&lt;p>Here's an example, where a shell is being used to show the &amp;lsquo;png&amp;rsquo; images in the folder I am working in&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/screenshot1-example-shell.png" alt="Screenshot: Browsing Contents of the File System the the Bourne Again Shell" width="600px" />&lt;/p>
&lt;p>So a shell is a user-space program to interface with the computer. But there a few more moving parts than just a shell we are seeing in the image above. There are different types of shells, there are terminal programs, and there are the programs or commands that the shell calls (in the example above, &lt;code>tree&lt;/code> is a program). Let's pick these apart.&lt;/p>
&lt;p>Here's a diagram that more accurately shows what is going on:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We've introduced a few new things here. There's a &lt;em>user&lt;/em>, who is interfacing with a &lt;em>terminal&lt;/em>, which is running a &lt;em>shell&lt;/em>, which is showing a &lt;em>command prompt&lt;/em>. The user has written a command that is calling a program (in this case, the &lt;code>tree&lt;/code> program).&lt;/p>
&lt;p>Let's dissect this bit by bit.&lt;/p>
&lt;h3 id="the-terminal">The Terminal&lt;/h3>
&lt;p>We're not &lt;em>directly&lt;/em> interacting with the &amp;lsquo;shell&amp;rsquo; in this diagram. We're actually using a &lt;em>terminal&lt;/em>. When a user wants to work with a shell interactively, using a keyboard to provide input and a display to see the output on the screen, the user uses a &lt;em>terminal&lt;/em>.&lt;/p>
&lt;p>A terminal is just a program that reads input from the keyboard, passes that input to another program (normally a shell), and displays the results on the screen. A shell program on its own does not do this - it requires a terminal as an interface.&lt;/p>
&lt;p>Why the word &lt;em>terminal&lt;/em>? This makes sense when you look at how people interfaced with computers historically. Input to a computer might be through punch cards, and output would often be via a printer. The &lt;em>Teletype Termimal&lt;/em>&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup> became a common way for users to interface with computers.&lt;/p>
&lt;p>&lt;img src="images/image-asr-33.jpg" alt="Photo: ASR-33 TTY" width="600px" />&lt;/p>
&lt;p>&lt;em>(Photograph by Rama, Wikimedia Commons, Cc-by-sa-2.0-fr, CC BY-SA 2.0 fr, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=17821795">https://commons.wikimedia.org/w/index.php?curid=17821795&lt;/a>)&lt;/em>&lt;/p>
&lt;p>At this time, computers were very large, complex, and expensive machines. It was common to have &lt;em>many&lt;/em> terminals connected to a single large machine (or &amp;lsquo;mainframe&amp;rsquo;), or a few terminals that people would share. But the terminal itself was just a human interface to the operating system. A more modern terminal would be something like an IBM 3486:&lt;/p>
&lt;p>&lt;img src="images/image-ibm3486.jpg" alt="Photo: IBM 3486" width="600px" />&lt;/p>
&lt;p>&lt;em>(By ClickRick - Own work, CC BY-SA 3.0, &lt;a href="https://commons.wikimedia.org/w/index.php?curid=6693700">https://commons.wikimedia.org/w/index.php?curid=6693700&lt;/a>)&lt;/em>&lt;/p>
&lt;p>This is a very small computer in its own right but still basically just a dumb screen and keyboard connected by a cable to a larger mainframe computer in another location.&lt;/p>
&lt;p>This mechanism is still very much the case today. When I want to work with a computer in a data centre, I don't go and find the machine, plug in a keyboard and a display and directly interface to it. I run a &lt;em>terminal program&lt;/em> on my computer to provide access to the remote machine. My terminal program allows me to use my keyboard and display to work with a remote machine - all via a &lt;em>secure shell&lt;/em> - which is a secured-shell connection over a network.&lt;/p>
&lt;p>So terminals in many ways are quite simple - they are interfaces. But because they are quite simple programs, we can't do much with them. So normally, the first thing that a terminal program will do is run a &lt;em>shell&lt;/em> program - a program that we can use to operate the computer.&lt;/p>
&lt;p>There's nothing special about terminals - anyone can write a program to operate as a terminal, which is why you will see many different terminals around. Examples are the standard &amp;lsquo;terminal&amp;rsquo; app for MacOS X, the &lt;a href="https://wiki.gnome.org/Apps/Terminal/VTE">gnome-terminal&lt;/a> for Linux, and &lt;a href="https://www.iterm2.com/">iTerm2&lt;/a> and &lt;a href="https://hyper.is/">Hyper&lt;/a>. There's a bunch of screenshots of different setups at the end of the article.&lt;/p>
&lt;h2 id="back-to-the-shell">Back to the Shell&lt;/h2>
&lt;p>Now that we've described the terminal, we can go back and look at the shell in detail.&lt;/p>
&lt;p>The shell is the program that is going to take input from somewhere and run a series of commands. When the shell is running in a terminal, it is normally taking input interactively from the user. As the user types in commands, the terminal feeds the input to the shell and presents the output of the shell on the screen.&lt;/p>
&lt;p>A shell program can also take input from files; these files will then generally be &amp;lsquo;shell scripts&amp;rsquo;. This might be used to run automated operations, such as cleaning up certain folders when a computer starts.&lt;/p>
&lt;p>Shells can write output to files or other locations, and so on. You can run a shell program outside of a terminal - you just won't be able to interface with it using a keyboard or display. And in fact, lots of operations happen in this way: automated scripts, startup tasks, installers and so on.&lt;/p>
&lt;p>So what else does a shell do? Most of the features are related to helping human operators work with the system more efficiently.&lt;/p>
&lt;ul>
&lt;li>Quickly enter commands, see the history of commands and quickly restructure commands (see &lt;a href="http://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Effective Shell - Navigating the Command Line&lt;/a>)&lt;/li>
&lt;li>Navigate through the file system, moving from folder to folder (see &lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Effective Shell - Move Around!&lt;/a>), which makes it easier for an operator to navigate the file system.&lt;/li>
&lt;li>Chain the output of commands together - for example, taking the output of one basic program, such as the &lt;code>tree&lt;/code> program we saw, and writing it to a file (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Understanding Pipelines&lt;/a>)&lt;/li>
&lt;li>Offer a programming language, allowing the operator to perform more complicated tasks (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Basic Shell Scripting&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>And a lot more! In fact, that's what the whole &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series is about - how to get the most from these powerful programs, particularly for those who use them regularly.&lt;/p>
&lt;h3 id="the-command-prompt-or-command-line">The Command Prompt or Command Line&lt;/h3>
&lt;p>The last part of the diagram, which we haven't covered yet, is the &lt;em>command prompt&lt;/em>.&lt;/p>
&lt;p>&lt;img src="images/diagram4-command-prompt-1.png" alt="Diagram: Command Prompt" width="300px" />&lt;/p>
&lt;p>When a &lt;em>shell&lt;/em> is running in &lt;em>terminal&lt;/em>, it knows that a human operator will be interfacing with it. So to make sure that the operator has some kind of visual hint that &lt;em>they have to enter commands&lt;/em>, the shell will output some kind of prompt.&lt;/p>
&lt;p>I've included a set of screenshots at the end of the article, just after this section, and you can see how some different command prompts look.&lt;/p>
&lt;p>Note that shells don't have to use command prompts - if you use a shell program to execute a script, there will be no command prompt. Shells only show a prompt when they know they are being used interactively. Many programs which allow a user to operate interactively will show a command prompt.&lt;/p>
&lt;p>Shell command prompts can be customised, so they will often look different from machine to machine (for more details, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Customising the Command Line&lt;/a>). Below is an example that shows a &lt;em>lot&lt;/em> of technical information. This is from the highly popular &lt;a href="https://ohmyz.sh/">oh-my-zsh&lt;/a> framework for the &amp;lsquo;Z Shell&amp;rsquo; shell, which is very popular among developers:&lt;/p>
&lt;p>&lt;img src="images/image-ohmyzsh.jpg" alt="Image: Customised oh-my-zsh" width="600px" />&lt;/p>
&lt;p>*(Source: &lt;a href="https://ohmyz.sh/">https://ohmyz.sh/&lt;/a>)&lt;/p>
&lt;h3 id="shell-commands-and-different-shells">Shell Commands and Different Shells&lt;/h3>
&lt;p>A lot of the &amp;lsquo;commands&amp;rsquo; in a shell, such as &lt;code>cat&lt;/code> (which shows the contents of a file), are actually just simple programs, which will interface with the kernel. No matter what shell you use, these commands will behave the same way, because really all you are doing is calling another progam.&lt;/p>
&lt;p>Some commands, such as &lt;code>cd&lt;/code> (change directory), are built into the shell. Some commands are functions that have been defined, or aliases to other commands (for more details on commands, see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell - Commands&lt;/a>). Commands will often differ between shells.&lt;/p>
&lt;p>Not all shells are created equal - anyone can write a shell program, maybe creating a simple interface to the computer or a highly complex one with many features. In fact, a later article in this series will look at the geneology of the most common shells.&lt;/p>
&lt;p>On most Unix-like systems, the default shell is a program called &lt;code>bash&lt;/code>, which stands for &amp;quot; Bourne Again Shell&amp;rdquo; (the name and history around it will be discussed at length in the later article). But there are many other shells: the C Shell, the Korn Shell, Z Shell and Fish, just to name just a few.&lt;/p>
&lt;p>Users and administators can configure what shell they like to use. When a terminal opens, it will immediately start the user's preferred shell program. It is possible to change this. Different users will have different preferences, given that shells offer varying features. This can cause complexity when working with systems, as we cannot always expect every user to have the same shell, or even for the same shell to be set up consistently, as they can be extensively customised.&lt;/p>
&lt;p>Let's review the earlier diagram again:&lt;/p>
&lt;p>&lt;img src="images/diagram3-terminal-and-shell-1.png" alt="Diagram: The Terminal &amp; The Shell" width="600px" />&lt;/p>
&lt;p>We can see the real internals of what is going on in this &amp;ldquo;Terminal -&amp;gt; Shell -&amp;gt; Program&amp;rdquo; chain in the diagram above quite easily.&lt;/p>
&lt;p>Try the command &lt;code>pstree -psa $$&lt;/code> in a shell&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/image-psforest.png" alt="Image: Process Tree" width="600px" />&lt;/p>
&lt;p>The first &lt;code>systemd&lt;/code> process is the primary process for the OS - it is process number &lt;code>1&lt;/code>, which initialises everything else. The second &lt;code>systemd&lt;/code> process is the process that is running the interface for my user. We can ignore these for now; they are internals to how the operating system boots and starts processes.&lt;/p>
&lt;p>What is interesting is that we can see a &lt;em>terminal&lt;/em> (the gnome terminal), which has started my preferred &lt;em>shell&lt;/em> (which is &lt;code>zsh&lt;/code>), which is running a &lt;em>command&lt;/em> (the program &lt;code>pstree&lt;/code>). Here we can see the exact chain as shown in the diagram earlier.&lt;/p>
&lt;h3 id="thats-a-wrap">That's a Wrap!&lt;/h3>
&lt;p>These are the key technologies and concepts that surround a shell.&lt;/p>
&lt;p>If you are interested in more technical details of working with shells, then my &lt;a href="https://github.com/effective-shell">Effective Shell&lt;/a> series goes into these topics in depth. The goal of this series is to help teach techniques that making working with shells more efficient.&lt;/p>
&lt;p>To close the article, below are some examples of different terminals, shells, command prompts and so on.&lt;/p>
&lt;h4 id="example-iterm-2--tmux--zsh">Example: iTerm 2 / tmux / zsh&lt;/h4>
&lt;p>&lt;img src="images/example-iterm-zsh.png" alt="Example: iTerm 2, tmux, zsh" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A MacOS operating system&lt;/li>
&lt;li>iTerm2 as the terminal program&lt;/li>
&lt;li>&lt;code>tmux&lt;/code> running as a &amp;lsquo;terminal multiplexer&amp;rsquo; (see &lt;a href="https://github.com/dwmkerr/effective-shell#coming-soon">Effective Shell: Terminal Multiplexers&lt;/a>)&lt;/li>
&lt;li>&lt;code>zsh&lt;/code> (Z Shell) as the shell program, using &amp;lsquo;oh my zsh&amp;rsquo;, which is easily recognised by the &lt;code>%&lt;/code> sign in the command prompt.&lt;/li>
&lt;li>A customised command line, which shows the user and folder on one line, with only the &lt;code>%&lt;/code> symbol below, to leave lots of space for the input commands&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>.&lt;/li>
&lt;/ul>
&lt;h4 id="example-bash">Example: Bash&lt;/h4>
&lt;p>&lt;img src="images/example-bash.png" alt="Example: Bash" width="600px" />&lt;/p>
&lt;p>&lt;img src="images/example-bash-root.png" alt="Example: Bash Elevated" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>A Linux operating system (Ubuntu 14)&lt;/li>
&lt;li>The gnome terminal&lt;/li>
&lt;li>&lt;code>bash&lt;/code> as the shell&lt;/li>
&lt;li>In the second screenshot, the user has &amp;lsquo;root privileges&amp;rsquo;, and to indicate this, &lt;code>bash&lt;/code> helpfully changes the default command prompt from a dollar sign to a hash sign&lt;/li>
&lt;/ul>
&lt;h4 id="example-windows-explorer">Example: Windows Explorer&lt;/h4>
&lt;p>&lt;img src="images/example-explorer.png" alt="Example: Windows Explorer" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>No terminal&lt;/li>
&lt;li>The &lt;code>explorer.exe&lt;/code> program showing us a &lt;em>graphical&lt;/em> shell&lt;/li>
&lt;/ul>
&lt;p>This looks different from previous examples. The program, which shows the familiar Windows interface, &lt;code>explorer.exe&lt;/code>, is in fact a shell as well, offering interactive access to the operating system and computer resources. The bulk of the Windows APIs to interact with this interface are in the &lt;a href="https://msdn.microsoft.com/en-us/library/windows/desktop/bb773177(v=vs.85).aspx">Shell Library&lt;/a>. I also maintain a popular library for building extensions to the graphical Windows shell - &lt;a href="https://github.com/dwmkerr/sharpshell">sharpshell&lt;/a>.&lt;/p>
&lt;h4 id="example-windows-command-prompt">Example: Windows Command Prompt&lt;/h4>
&lt;p>&lt;img src="images/example-cmd.png" alt="Example: Command Prompt" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The command prompt terminal and shell&lt;/li>
&lt;/ul>
&lt;p>In Windows, the terminal and shell are combined into a single &lt;code>cmd.exe&lt;/code> program. There's an excellent article on the internals - &lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft DevBlogs: Windows Command-Line: Inside the Windows Console&lt;/a>&lt;/p>
&lt;h4 id="example-windows-powershell">Example: Windows PowerShell&lt;/h4>
&lt;p>&lt;img src="images/example-powershell.png" alt="Example: Windows Powershell" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The PowerShell terminal&lt;/li>
&lt;/ul>
&lt;p>PowerShell is an improvement on the &amp;lsquo;command prompt&amp;rsquo; program that was originally used in Windows, offering much more functionality for scripting and other modern shell features.&lt;/p>
&lt;h4 id="example-windows-subsystem-for-linux-wsl">Example: Windows Subsystem for Linux (WSL)&lt;/h4>
&lt;p>&lt;img src="images/example-wsl.png" alt="Example: WSL" width="600px" />&lt;/p>
&lt;p>In this example, we have:&lt;/p>
&lt;ul>
&lt;li>The Windows 10 operating system&lt;/li>
&lt;li>The &lt;code>Bash.exe&lt;/code> program&lt;/li>
&lt;/ul>
&lt;p>This screenshot, from &lt;a href="https://docs.microsoft.com/en-us/windows/wsl/faq">MSDN: Frequently Asked Questions about Windows Subsystem for Linux&lt;/a> shows Bash running in Windows. This is a relatively new feature at the time of writing, allowing Windows users to use a Linux interface to the PC. This is a feature that may become increasingly valuable, as in general it is challenging to write shell code that can run on Windows and Unix-like systems.&lt;/p>
&lt;h2 id="share-and-discuss">Share and Discuss&lt;/h2>
&lt;p>If you enjoyed this article, please do share it! Feel free to include suggestions, improvements or corrections in the comments below.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Useful References&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>A simple Linux kernel module, showing how basic kernel programming works in Linux: &lt;a href="https://github.com/dwmkerr/linux-kernel-module">github.com/dwmkerr/linux-kernel-module&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.amazon.com/How-Linux-Works-2nd-Superuser/dp/1593275676">How Linux Works - Brian Ward&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://unix.stackexchange.com/questions/4126/what-is-the-exact-difference-between-a-terminal-a-shell-a-tty-and-a-con/4132">StackExchange: What is the exact difference between a &amp;lsquo;terminal&amp;rsquo;, a &amp;lsquo;shell&amp;rsquo;, a &amp;lsquo;tty&amp;rsquo;, and a console?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://devblogs.microsoft.com/commandline/windows-command-line-inside-the-windows-console/">Microsoft: Inside the Windows Console&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I'd be fascinated to know if this is at all interesting to less technically inclined people, so please do go ahead and let me know in the comments! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>CPU: central processing unit. This is the chip in the computer that does most of the work (which after many layers of abstraction eventually becomes arithmetic and sending simple instructions to other places). &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Memory is the &amp;lsquo;working space&amp;rsquo; where the state of your system is stored. If you are writing a document, the text lives in memory, until you save it, when it then gets written to a hard drive. Memory is &lt;em>ephemeral&lt;/em> - everything is gone when you turn off the power to it. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>This is the part of your computer that knows how to do things like connect to a WiFi network, or has a network socket you might plug a network cable into. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>This is the part of your computer you plug the screen into. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>This is because a mistake in &lt;em>Kernel Mode&lt;/em> programs can have disasterous effects. It could access any files, no matter who they belong do, control the hardware, install more software - almost anything. Errors in this code can cause terrible issues (like the infamous Windows &amp;lsquo;blue screen of death&amp;rsquo;), and malicious code in the kernel essentially has full access to not only all your data but also your webcam, network adapter and so on. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>As an aside, if you are curious about the visual style of my setup or customisations that have been made, everything in my setup is available online on my &amp;lsquo;dotfiles&amp;rsquo; repo - &lt;a href="https://github.com/dwmkerr/dotfiles">github.com/dwmkerr/dotfiles&lt;/a>. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>And that's where the &amp;lsquo;TTY&amp;rsquo; acronym you will see sometimes comes from. Enter the &lt;code>ps&lt;/code> command, and you'll actually see the TTY interface each process is attached to. This is a topic that will come up later in the series. &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>&lt;code>$$&lt;/code> is a Bash &lt;a href="https://www.tldp.org/LDP/abs/html/internalvariables.html#PROCCID">internal variable&lt;/a>. These will also be covered in a later article in the series. &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>Feel free to see my &lt;a href="https://github.com/dwmkerr/dotfiles">dotfiles&lt;/a> to configure a similar setup for yourself. &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell 4: Move Around!</title><link>https://dwmkerr.com/effective-shell-4-moving-around/</link><pubDate>Mon, 11 Mar 2019 09:02:00 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-4-moving-around/</guid><description>&lt;p>This is the fourth part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series, a set of practical examples of ways to be more efficient with everyday tasks in the shell or at the command line.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article we'll look at the key elements of navigation in the shell.&lt;/p>
&lt;h2 id="getting-comfortable-moving-around">Getting Comfortable Moving Around&lt;/h2>
&lt;p>You might already spend a lot of time in the shell, running various command line programs or using tooling for development projects or operational tasks. But you might also still switch back to a more visual paradigm for working with files, directories and resources.&lt;/p>
&lt;p>Being able to perform everyday file and folder manipulation tasks directly from the shell can really speed up your workflow. Let's look at some common tasks and see how we can work with them in the shell. Along the way we'll also introduce some of the most frequently used tools and commands to work with the filesystem.&lt;/p>
&lt;h2 id="where-am-i">Where Am I?&lt;/h2>
&lt;p>The first command to become familiar with is &lt;code>pwd&lt;/code> (&amp;lsquo;print working directory&amp;rsquo;). This command will echo the current absolute path. You can also use the &lt;code>$PWD&lt;/code> environment variable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ echo $PWD
/Users/dave/repos/github/dwmkerr/effective-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Depending on your shell, or your command-line setup (which we will discuss in a later chapter), you might also see your working directly on the command-line.&lt;/p>
&lt;h2 id="changing-directory">Changing Directory&lt;/h2>
&lt;p>Most likely one of the most familiar commands out there, the &lt;code>cd&lt;/code> or &lt;code>chdir&lt;/code> function changes the current directory:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd
$ pwd
/users/dave
$ cd -
~/repos/github/dwmkerr/effective-shell
$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd ~
$ pwd
/users/dave
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we can see that running &lt;code>cd&lt;/code> with no parameters moves to the users &amp;lsquo;home&amp;rsquo; directory. This directory is always available in the &lt;code>$HOME&lt;/code> environment variable.&lt;/p>
&lt;p>Running &lt;code>cd -&lt;/code> will switch &lt;em>back&lt;/em> to the previous directory — this is very useful if you want to quickly jump somewhere and then back again.&lt;/p>
&lt;p>You can use &lt;code>~&lt;/code> as an alias for the home directory, allowing you to quickly move to personal folders, with commands such as &lt;code>cd ~/Downloads&lt;/code>.&lt;/p>
&lt;p>Most commonly, you will specify a path when changing directory. This can be a fully qualified path, or it can be a relative path:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ cd /dev
$ cd ~/repos
$ cd ./github
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You can use the special link &lt;code>..&lt;/code>, which is a folder that points to the &lt;em>parent&lt;/em> directory to move &amp;lsquo;upwards&amp;rsquo;:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ cd ../../
$ pwd
/Users/dave/repos/github
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="exploring-a-directory">Exploring a Directory&lt;/h2>
&lt;p>Once we are in a directory, we will often want to see the contents. The &lt;code>ls&lt;/code> (&amp;ldquo;list directory contents&amp;rdquo;) command is useful here:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
$ ls
1-navigating-the-command-line LICENSE
2-clipboard-gymnastics README.md
3-getting-help sed.1
4-moving-around
&lt;/code>&lt;/pre>&lt;/div>&lt;p>By default, the &lt;code>ls&lt;/code> command will list the files and directories. We can show more information with the &lt;code>-l&lt;/code> (&amp;ldquo;long format&amp;rdquo;) flag:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ls -l
total &lt;span style="color:#ae81ff">48&lt;/span>
drwxr-xr-x &lt;span style="color:#ae81ff">6&lt;/span> dave staff &lt;span style="color:#ae81ff">192&lt;/span> Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 1-navigating-the-command-line
drwxr-xr-x &lt;span style="color:#ae81ff">5&lt;/span> dave staff &lt;span style="color:#ae81ff">160&lt;/span> Oct &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 2-clipboard-gymnastics
drwxr-xr-x &lt;span style="color:#ae81ff">4&lt;/span> dave staff &lt;span style="color:#ae81ff">128&lt;/span> Dec &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 3-getting-help
drwxr-xr-x &lt;span style="color:#ae81ff">3&lt;/span> dave staff &lt;span style="color:#ae81ff">96&lt;/span> Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:39 4-moving-around
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">1066&lt;/span> Jun &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> LICENSE
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">561&lt;/span> Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:30 README.md
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff &lt;span style="color:#ae81ff">15707&lt;/span> Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 sed.1
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we can see the permissions, the link count (which is rarely particularly useful and varies from platform to platform), the owner, the group, the size and the modification date (as well as the name).&lt;/p>
&lt;p>We can make the sizes more human readable, and sort by size with a few more flags &lt;code>-h&lt;/code> (&amp;ldquo;human readable&amp;rdquo;) and &lt;code>-s&lt;/code> (&amp;ldquo;sort by size&amp;rdquo;):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ ls -lhS
total &lt;span style="color:#ae81ff">48&lt;/span>
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 15K Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 sed.1
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 1.0K Jun &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> LICENSE
-rw-r--r-- &lt;span style="color:#ae81ff">1&lt;/span> dave staff 561B Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:30 README.md
drwxr-xr-x &lt;span style="color:#ae81ff">6&lt;/span> dave staff 192B Mar &lt;span style="color:#ae81ff">5&lt;/span> 16:01 1-navigating-the-command-line
drwxr-xr-x &lt;span style="color:#ae81ff">5&lt;/span> dave staff 160B Oct &lt;span style="color:#ae81ff">10&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 2-clipboard-gymnastics
drwxr-xr-x &lt;span style="color:#ae81ff">4&lt;/span> dave staff 128B Dec &lt;span style="color:#ae81ff">19&lt;/span> &lt;span style="color:#ae81ff">2017&lt;/span> 3-getting-help
drwxr-xr-x &lt;span style="color:#ae81ff">3&lt;/span> dave staff 96B Mar &lt;span style="color:#ae81ff">7&lt;/span> 15:39 4-moving-around
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are &lt;em>lot&lt;/em> of options for &lt;code>ls&lt;/code>. Check the chapter &lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Getting Help&lt;/a> for some tips on how to get more information on a command!&lt;/p>
&lt;h2 id="managing-the-directory-stack">Managing the Directory Stack&lt;/h2>
&lt;p>You might find that you want to move to a number of directories, then return to where you started. This can be particularly useful when scripting. You can use the &lt;code>pushd&lt;/code> (&amp;ldquo;push onto directory stack&amp;rdquo;) and &lt;code>popd&lt;/code> (&amp;ldquo;pop from directory stack&amp;rdquo;) commands to add or remove directories from the stack:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ pwd
/Users/dave/repos/github/dwmkerr/effective-shell
&lt;span style="color:#75715e"># OK - I&amp;#39;m writing my article at the moment, but want to check my downloads, and come back shortly...&lt;/span>
&lt;span style="color:#75715e"># Move to the downloads folder...&lt;/span>
$ ls
aws-nuke-v2.8.0-darwin-amd64
&lt;span style="color:#75715e"># OK cool - the tool I was downloading has arrived, let&amp;#39;s use it...&lt;/span>
cd aws-nuke-v2.8.0-darwin-amd64
./aws-nuke
&lt;span style="color:#75715e"># Now I want to go back to my article...&lt;/span>
$ popd
~/Downloads ~/repos/github/dwmkerr/effective-shell
~/Downloads
$ popd
~/repos/github/dwmkerr/effective-shell
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this case, using &lt;code>cd -&lt;/code> would not be sufficient — that would just switch us from the &lt;code>aws-nuke&lt;/code> folder to &lt;code>Downloads&lt;/code> and back again. But by using the &lt;em>directory stack&lt;/em> we can save where we are, move, and then &amp;lsquo;pop&amp;rsquo; our way back to where we started.&lt;/p>
&lt;h2 id="auto-completion">Auto-Completion&lt;/h2>
&lt;p>Pressing &lt;code>tab&lt;/code> when using commands like &lt;code>cd&lt;/code> will generally show an auto-completion menu:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ cd ~/repos/ &lt;span style="color:#75715e"># press &amp;#39;tab&amp;#39; now...&lt;/span>
github/ gitlab/ local/ scratch/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Pressing tab again will cycle through options, and shift-tab will cycle backwards. Enter will select an option, escape (or Ctrl-C) will cancel.&lt;/p>
&lt;p>Some shells, such as &lt;code>zsh&lt;/code>, support even more advanced auto-completion. For example, we can auto-complete to fill in partially specified directory names:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">% cd ~/r/g/d/e &lt;span style="color:#75715e"># press tab now...&lt;/span>
% cd ~/repos/github/dwmkerr/effective-
effective-container-engineering/ effective-shell/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Auto-completion is generally &lt;em>very&lt;/em> shell specific. We'll look more into the different shells that are available in later chapters. But in general, if you are uncertain, pressing tab will often show a sensible set of options.&lt;/p>
&lt;h2 id="thats-it">That's It!&lt;/h2>
&lt;p>This is a small chapter, but an important one. Later on, as we start to do more file and system manipulation from the shell, moving and copying files and so on, we will build on these concepts. But it is critical to first know the basics of how to move around the filesystem with the shell.&lt;/p></description><category>CodeProject</category></item><item><title>Dynamic and Configurable Availability Zones in Terraform</title><link>https://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</link><pubDate>Tue, 11 Dec 2018 21:24:34 +0000</pubDate><guid>https://dwmkerr.com/dynamic-and-configurable-availability-zones-in-terraform/</guid><description>&lt;p>When building Terraform modules, it is a common requirement to want to allow the client to be able to choose which region resources are created in, and which availability zones are used.&lt;/p>
&lt;p>I've seen a few ways of doing this, none of which felt entirely satisfactory. After a bit of experimentation I've come up with a solution which I think really works nicely. This solution avoids having to know in advance how many availability zones we'll support.&lt;/p>
&lt;p>&lt;img src="images/screenshot-1.jpg" alt="screenshot">&lt;/p>
&lt;p>To demonstrate, I've set up a module which deploys a cluster of web servers. My goal is to be able to configure the region, VPC CIDR block, subnets and subnet CIDR blocks as below:&lt;/p>
&lt;pre>&lt;code>module &amp;quot;cluster&amp;quot; {
source = &amp;quot;github.com/dwmkerr/terraform-aws-vpc&amp;quot;
# Note how we can specify any number of availability zones here...
region = &amp;quot;ap-northeast-2&amp;quot;
vpc_cidr = &amp;quot;10.0.0.0/16&amp;quot;
subnets = {
ap-northeast-2a = &amp;quot;10.0.1.0/24&amp;quot;
ap-northeast-2b = &amp;quot;10.0.2.0/24&amp;quot;
ap-northeast-2c = &amp;quot;10.0.3.0/24&amp;quot;
}
# This just defines the number of web servers to deploy, and uses
# adds my public key so I can SSH into the servers...
web_server_count = &amp;quot;3&amp;quot;
public_key_path = &amp;quot;~/.ssh/id_rsa.pub&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>The example module is at &lt;a href="https://github.com/dwmkerr/terraform-aws-vpc">github.com/dwmkerr/terraform-aws-vpc&lt;/a>. Let's take a look at some of the key elements.&lt;/p>
&lt;h2 id="the-variables">The Variables&lt;/h2>
&lt;p>We define the required variables very explicitly, with descriptions and a variable type to avoid confusion:&lt;/p>
&lt;pre>&lt;code>variable &amp;quot;region&amp;quot; {
description = &amp;quot;The region to deploy the VPC in, e.g: us-east-1.&amp;quot;
type = &amp;quot;string&amp;quot;
}
variable &amp;quot;vpc_cidr&amp;quot; {
description = &amp;quot;The CIDR block for the VPC, e.g: 10.0.0.0/16&amp;quot;
type = &amp;quot;string&amp;quot;
}
variable &amp;quot;subnets&amp;quot; {
description = &amp;quot;A map of availability zones to CIDR blocks, which will be set up as subnets.&amp;quot;
type = &amp;quot;map&amp;quot;
}
&lt;/code>&lt;/pre>&lt;h2 id="the-vpc">The VPC&lt;/h2>
&lt;p>Now that we have defined the variables, we can set up the VPC:&lt;/p>
&lt;pre>&lt;code>// Define the VPC.
resource &amp;quot;aws_vpc&amp;quot; &amp;quot;cluster&amp;quot; {
cidr_block = &amp;quot;${var.vpc_cidr}&amp;quot;
enable_dns_hostnames = true
}
// An Internet Gateway for the VPC.
resource &amp;quot;aws_internet_gateway&amp;quot; &amp;quot;cluster_gateway&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
}
// Create one public subnet per key in the subnet map.
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
cidr_block = &amp;quot;${element(values(var.subnets), count.index)}&amp;quot;
map_public_ip_on_launch = true
depends_on = [&amp;quot;aws_internet_gateway.cluster_gateway&amp;quot;]
availability_zone = &amp;quot;${element(keys(var.subnets), count.index)}&amp;quot;
}
// Create a route table allowing all addresses access to the IGW.
resource &amp;quot;aws_route_table&amp;quot; &amp;quot;public&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.cluster.id}&amp;quot;
route {
cidr_block = &amp;quot;0.0.0.0/0&amp;quot;
gateway_id = &amp;quot;${aws_internet_gateway.cluster_gateway.id}&amp;quot;
}
}
// Now associate the route table with the public subnet - giving
// all public subnet instances access to the internet.
resource &amp;quot;aws_route_table_association&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
subnet_id = &amp;quot;${element(aws_subnet.public-subnet.*.id, count.index)}&amp;quot;
route_table_id = &amp;quot;${aws_route_table.public.id}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>There are a few things of interest here. First, we can easily build a variable number of subnets by using the &lt;code>count&lt;/code> field on the &lt;code>aws_subnet&lt;/code> resource:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-subnet&amp;quot; {
count = &amp;quot;${length(var.subnets)}&amp;quot;
availability_zone = &amp;quot;${element(keys(var.subnets), count.index)}&amp;quot;
cidr_block = &amp;quot;${element(values(var.subnets), count.index)}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>By using the &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html">Terraform Interpolation Syntax&lt;/a>, and in particular the &lt;code>count&lt;/code>, &lt;code>keys&lt;/code>, &lt;code>values&lt;/code> and &lt;code>element&lt;/code> functions, we can grab the subnet name and CIDR block from the variables.&lt;/p>
&lt;h2 id="the-web-server-cluster">The Web Server Cluster&lt;/h2>
&lt;p>A cluster of web servers behind a load balancer are created by the module, to demonstrate that it works. There is little of interest in the script except for how the subnets are referenced:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_autoscaling_group&amp;quot; &amp;quot;cluster_node&amp;quot; {
name = &amp;quot;cluster_node&amp;quot;
vpc_zone_identifier = [&amp;quot;${aws_subnet.public-subnet.*.id}&amp;quot;]
launch_configuration = &amp;quot;${aws_launch_configuration.cluster_node.name}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>Note that we can specify the entire list of subnet ids by using the &lt;code>*&lt;/code> symbol in the resource path - &lt;code>[&amp;quot;${aws_subnet.public-subnet.*.id}&amp;quot;]&lt;/code>.&lt;/p>
&lt;h2 id="thats-it">That's It!&lt;/h2>
&lt;p>That's really all there is to it. I quite like this approach. I think it makes it very clear what is going on with the infrastructure, and is fairly manageable.&lt;/p>
&lt;p>One question which may be raised is why I am not using the &lt;a href="https://www.terraform.io/docs/configuration/interpolation.html#cidrsubnet-iprange-newbits-netnum-">&lt;code>cidrsubnet&lt;/code>&lt;/a> function to automatically calculate the CIDR blocks for the subnets. The reason is purely one of preference - I prefer to explicitly specify the CIDR blocks and use various patterns to set conventions. For example, if I see an IP address such as &lt;code>10.0.3.121&lt;/code> then it is in the third AZ of my public subnet, or &lt;code>10.2.2.11&lt;/code> is in the second AZ of my locked down data zone.&lt;/p>
&lt;p>You can see a sample Terraform module which uses this pattern at: &lt;a href="https://github.com/dwmkerr/terraform-aws-vpc-example">github.com/dwmkerr/terraform-aws-vpc-example&lt;/a>. This module also has a basic build pipeline and is published on the &lt;a href="https://registry.terraform.io/modules/dwmkerr/vpc-example">Terraform Registry&lt;/a>. I'll also be updating my &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">AWS Openshift&lt;/a> module to use this pattern.&lt;/p></description><category>CodeProject</category></item><item><title>A portable and magic-free way to open Pull Requests from the Command Line</title><link>https://dwmkerr.com/a-portable-and-magic-free-way-to-open-pull-requests-from-the-command-line/</link><pubDate>Wed, 10 Oct 2018 09:17:26 +0000</pubDate><guid>https://dwmkerr.com/a-portable-and-magic-free-way-to-open-pull-requests-from-the-command-line/</guid><description>&lt;p>This little bash snippet will let you open a GitHub or GitLab pull request from the command line on most Unix-like systems (OSX, Ubuntu, etc), without using any magic libraries, ZSH tricks or other dependencies.&lt;/p>
&lt;p>&lt;img src="images/gpr.png" alt="gpr">&lt;/p>
&lt;p>Here's how it looks in action OSX:&lt;/p>
&lt;p>&lt;img src="images/gpr.gif" alt="gpr">&lt;/p>
&lt;p>And Ubuntu:&lt;/p>
&lt;p>&lt;img src="images/gpr-ubuntu.gif" alt="gpr-ubuntu">&lt;/p>
&lt;p>The script is available as the &lt;a href="https://gist.github.com/dwmkerr/bae3fdca2d7208ec5d0008911d79b47d">&lt;code>gpr.sh&lt;/code>&lt;/a> gist. You can also find it in my &lt;a href="https://github.com/dwmkerr/dotfiles">dotfiles&lt;/a>, in the &lt;a href="https://github.com/dwmkerr/dotfiles/blob/master/profile/git.sh">git.sh&lt;/a> file.&lt;/p>
&lt;h2 id="the-script">The Script&lt;/h2>
&lt;p>Here's the script in its entirety:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Colour constants for nicer output.&lt;/span>
GREEN&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0;32m&amp;#39;&lt;/span>
RESET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0m&amp;#39;&lt;/span>
&lt;span style="color:#75715e"># Push the current branch to origin, set upstream, open the PR page if possible.&lt;/span>
gpr&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Get the current branch name, or use &amp;#39;HEAD&amp;#39; if we cannot get it.&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>git symbolic-ref -q HEAD&lt;span style="color:#66d9ef">)&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch##refs/heads/&lt;span style="color:#e6db74">}&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#66d9ef">:-&lt;/span>HEAD&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#75715e"># Pushing take a little while, so let the user know we&amp;#39;re working.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening pull request for &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Push to origin, grabbing the output but then echoing it back.&lt;/span>
push_output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>git push origin -u &lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span> 2&amp;gt;&amp;amp;1&lt;span style="color:#e6db74">`&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#75715e"># If there&amp;#39;s anything which starts with http, it&amp;#39;s a good guess it&amp;#39;ll be a&lt;/span>
&lt;span style="color:#75715e"># link to GitHub/GitLab/Whatever. So open it.&lt;/span>
link&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span> | grep -o &lt;span style="color:#e6db74">&amp;#39;http.*&amp;#39;&lt;/span> | sed -e &lt;span style="color:#e6db74">&amp;#39;s/[[:space:]]*$//&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
python -mwebbrowser &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;span style="color:#f92672">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>Blow-by-blow, let's take a look.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Colour constants for nicer output.&lt;/span>
GREEN&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0;32m&amp;#39;&lt;/span>
RESET&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;\033[0m&amp;#39;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To make colouring console output easier, we create strings with the escape code required to set the &amp;lsquo;green&amp;rsquo; colour, and reset the text colour.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">gpr&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#f92672">)&lt;/span> &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Get the current branch name, or use &amp;#39;HEAD&amp;#39; if we cannot get it.&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>git symbolic-ref -q HEAD&lt;span style="color:#66d9ef">)&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch##refs/heads/&lt;span style="color:#e6db74">}&lt;/span>
branch&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#66d9ef">:-&lt;/span>HEAD&lt;span style="color:#e6db74">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we define the &lt;code>gpr&lt;/code> (Git Pull Request) function. We'll need to push the current branch, so we need to get the current branch name. There's plenty of discussion on how this works on &lt;a href="https://stackoverflow.com/questions/6245570/how-to-get-the-current-branch-name-in-git">Stack Overflow: How to get the current branch name in Git&lt;/a>. Essentially we just get the symbolic name for the head of our current branch, which will be something like this:&lt;/p>
&lt;pre>&lt;code>refs/heads/my-new-branch
&lt;/code>&lt;/pre>&lt;p>We then use &lt;a href="https://www.tldp.org/LDP/abs/html/string-manipulation.html">Bash substring removal&lt;/a> to rip out the &lt;code>ref/heads/&lt;/code> part. If we have no branch (for example, we are detached) we just use &lt;code>HEAD&lt;/code> a the branch name.&lt;/p>
&lt;p>Next we have this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash"> &lt;span style="color:#75715e"># Pushing take a little while, so let the user know we&amp;#39;re working.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening pull request for &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Push to origin, grabbing the output but then echoing it back.&lt;/span>
push_output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>git push origin -u &lt;span style="color:#e6db74">${&lt;/span>branch&lt;span style="color:#e6db74">}&lt;/span> 2&amp;gt;&amp;amp;1&lt;span style="color:#e6db74">`&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've previously defined some strings which include the escape codes to colour terminal output. Now we just show the user the branch we're going to push, push it and then store all of the output in the &lt;code>push_output&lt;/code> variable.&lt;/p>
&lt;p>The &lt;code>2&amp;gt;&amp;amp;1&lt;/code> idiom is a common one. This simply makes sure we put all &lt;code>stderr&lt;/code> output (which is always file descriptor 2) into &lt;code>stdout&lt;/code> (which is always file descriptor 1). This means whether the program writes output to &lt;code>stdout&lt;/code> or &lt;code>stderr&lt;/code>, we capture it. There's a nice write-up on this in the blog post &amp;lsquo;&lt;a href="https://www.brianstorti.com/understanding-shell-script-idiom-redirect/">Understanding Shell Script's idiom: 2&amp;gt;&amp;amp;1
&lt;/a>'.&lt;/p>
&lt;p>The output from Git push will be dependent on the Git server being used. For GitHub it'll look like this:&lt;/p>
&lt;pre>&lt;code>remote:
remote: Create a pull request for 'feat/doc-cleanup' on GitHub by visiting:
remote: https://github.com/dwmkerr/dotfiles/pull/new/feat/doc-cleanup
remote:
To github.com:dwmkerr/dotfiles
* [new branch] feat/doc-cleanup -&amp;gt; feat/doc-cleanup
Branch feat/doc-cleanup set up to track remote branch feat/doc-cleanup from origin.
&lt;/code>&lt;/pre>&lt;p>Now all we want to do is see if there is any text which starts with &lt;code>http&lt;/code> and if there is, then open it. Here's how we do that:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash"> &lt;span style="color:#75715e"># If there&amp;#39;s anything which starts with http, it&amp;#39;s a good guess it&amp;#39;ll be a&lt;/span>
&lt;span style="color:#75715e"># link to GitHub/GitLab/Whatever. So open it.&lt;/span>
link&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>echo &lt;span style="color:#e6db74">${&lt;/span>push_output&lt;span style="color:#e6db74">}&lt;/span> | grep -o &lt;span style="color:#e6db74">&amp;#39;http.*&amp;#39;&lt;/span> | sed -e &lt;span style="color:#e6db74">&amp;#39;s/[[:space:]]*$//&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Opening: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>GREEN&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>RESET&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
python -mwebbrowser &lt;span style="color:#e6db74">${&lt;/span>link&lt;span style="color:#e6db74">}&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This uses &lt;code>grep&lt;/code> to rip out everything from &lt;code>http&lt;/code> onwards, and the &lt;code>sed&lt;/code> to remove any trailing whitespace. If we have found a link, we use &lt;code>python&lt;/code> to open it (which is a fairly safe cross-platform solution).&lt;/p>
&lt;p>That's it! When you have a branch ready which you want to push and create a pull request from, just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">gpr
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And the branch will be pushed to &lt;code>origin&lt;/code>, and if there is a Pull Request webpage, it'll be opened.&lt;/p>
&lt;h2 id="prior-art">Prior Art&lt;/h2>
&lt;p>My colleague Tobias recently shared a nice trick we worked out to open a GitLab merge request - which also now works for GitHub:&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">&lt;p lang="en" dir="ltr">git push and directly open PR in Chrome - works for &lt;a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github&lt;/a> &amp;amp; &lt;a href="https://twitter.com/gitlab?ref_src=twsrc%5Etfw">@gitlab&lt;/a> 🚀&lt;br>&lt;br>Here is how to set it up 👉 &lt;a href="https://t.co/YfNTmdwTFt">https://t.co/YfNTmdwTFt&lt;/a> &lt;a href="https://twitter.com/hashtag/github?src=hash&amp;amp;ref_src=twsrc%5Etfw">#github&lt;/a> &lt;a href="https://twitter.com/hashtag/gitlab?src=hash&amp;amp;ref_src=twsrc%5Etfw">#gitlab&lt;/a> &lt;a href="https://t.co/ISE9kVZmw1">pic.twitter.com/ISE9kVZmw1&lt;/a>&lt;/p>&amp;mdash; Tobias Büschel (@TobiasBueschel) &lt;a href="https://twitter.com/TobiasBueschel/status/1042452158430502915?ref_src=twsrc%5Etfw">September 19, 2018&lt;/a>&lt;/blockquote>
&lt;script async src="https://platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I wanted to be able to use the same trick in Ubuntu and other Linux distros, but realised it relied on &lt;a href="https://github.com/robbyrussell/oh-my-zsh">oh-my-zsh&lt;/a> and assumed OSX with Chrome as the browser, so tweaked it to the above. Thanks Tobi!&lt;/p></description><category>CodeProject</category></item><item><title>Manipulating Istio and other Custom Kubernetes Resources in Golang</title><link>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</link><pubDate>Mon, 08 Oct 2018 21:34:02 +0000</pubDate><guid>https://dwmkerr.com/manipulating-istio-and-other-custom-kubernetes-resources-in-golang/</guid><description>&lt;p>In this article I'll demonstrate how to use Golang to manipulate Kubernetes Custom Resources, with Istio as an example. No knowledge of Istio is needed, I'll just use it to demonstrate the concepts!&lt;/p>
&lt;p>&lt;img src="images/code-2.jpg" alt="code">&lt;/p>
&lt;p>&lt;a href="https://istio.io">Istio&lt;/a> is a highly popular Service Mesh platform which allows engineers to quickly add telemetry, advanced traffic management and more to their service-based applications.&lt;/p>
&lt;p>One interesting element of how Istio works is that when deployed into a Kubernetes cluster, many key configuration objects are handled as &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources&lt;/a>. Custom Resources are a very powerful Kubernetes feature, which allow you to create your own &amp;lsquo;first class&amp;rsquo; resources (just like Pods, ReplicaSets, Deployments or whatever) and then interface with them using &lt;code>kubectl&lt;/code> or the Kubernetes APIs.&lt;/p>
&lt;p>In this article I'll show you how to interface with these Custom Resources using the Golang Kubernetes client.&lt;/p>
&lt;h2 id="crds-a-quick-overview">CRDs: A Quick Overview&lt;/h2>
&lt;p>When you set up Istio for your cluster, one common thing you will likely do is specify how you will route traffic. This can be quite sophisticated, as shown below:&lt;/p>
&lt;p>&lt;img src="images/TrafficManagementOverview.svg" alt="TrafficManagementOverview">&lt;/p>
&lt;p>&lt;a href="https://istio.io/docs/concepts/traffic-management/">Figure 1: Istio Traffic Management Examples, from istio.io&lt;/a>&lt;/p>
&lt;p>One way for a system like this to be configured would be to have a ConfigMap which contains the definition of how services are routed.&lt;/p>
&lt;p>However, Istio actually registers new types of resources (Custom Resource Definitions) which represent things like Gateways or Services. We can create/update/delete/manipulate them just like any other Kubernetes object.&lt;/p>
&lt;p>For example, I could create a virtual service for the example above with something like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">cat &lt;span style="color:#e6db74">&amp;lt;&amp;lt; EOF | kubectl create -f -
&lt;/span>&lt;span style="color:#e6db74">apiVersion: networking.istio.io/v1alpha3
&lt;/span>&lt;span style="color:#e6db74">kind: VirtualService
&lt;/span>&lt;span style="color:#e6db74">metadata:
&lt;/span>&lt;span style="color:#e6db74"> name: service2
&lt;/span>&lt;span style="color:#e6db74">spec:
&lt;/span>&lt;span style="color:#e6db74"> hosts:
&lt;/span>&lt;span style="color:#e6db74"> - &amp;#34;*&amp;#34;
&lt;/span>&lt;span style="color:#e6db74"> gateways:
&lt;/span>&lt;span style="color:#e6db74"> - demo1-gateway
&lt;/span>&lt;span style="color:#e6db74"> http:
&lt;/span>&lt;span style="color:#e6db74"> - route:
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v1
&lt;/span>&lt;span style="color:#e6db74"> weight: 95
&lt;/span>&lt;span style="color:#e6db74"> - destination:
&lt;/span>&lt;span style="color:#e6db74"> host: service2
&lt;/span>&lt;span style="color:#e6db74"> subset: v2
&lt;/span>&lt;span style="color:#e6db74"> weight: 5
&lt;/span>&lt;span style="color:#e6db74">EOF&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, the important thing is not the specific content of this resource, more the fact that I can treat my Istio resources just like I would any other Kubernetes object:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io
NAME AGE
service2 93s
&lt;/code>&lt;/pre>&lt;p>Or:&lt;/p>
&lt;pre>&lt;code>$ kubectl delete virtualservices.networking.istio.io/service2
&lt;/code>&lt;/pre>&lt;p>I can use &lt;code>edit&lt;/code>, &lt;code>describe&lt;/code>, register lifecycle events, watch for changes, and so on.&lt;/p>
&lt;h2 id="working-with-crds-in-golang">Working with CRDs in Golang&lt;/h2>
&lt;p>The &lt;a href="https://github.com/kubernetes/client-go">Golang Kubernetes Client&lt;/a> allows you to create strongly defined types which you can then use to interface with CRDs. An example is in the Red Hat blog post &lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Kubernetes Deep Dive: Code Generation for Custom Resources&lt;/a>.&lt;/p>
&lt;p>This is an excellent approach, but can feel pretty heavy if you want to quickly access some data, and don't want to have to generate a lot of code.&lt;/p>
&lt;p>There is an alternative, which is to use the &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">&lt;code>DynamicClient&lt;/code>&lt;/a>. The &lt;em>preferred&lt;/em> approach seems to be the first, which involves code generation, so little documentation exists for the second approach. However, it is actually very simple.&lt;/p>
&lt;p>Here's an example of how you can list all Istio &lt;code>VirtualService&lt;/code> resources, without having to generate any code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a Dynamic Client to interface with CRDs.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">dynamicClient&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamic&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// List all of the Virtual Services.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServices&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">List&lt;/span>(&lt;span style="color:#a6e22e">metav1&lt;/span>.&lt;span style="color:#a6e22e">ListOptions&lt;/span>{})
&lt;span style="color:#66d9ef">for&lt;/span> &lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#66d9ef">range&lt;/span> &lt;span style="color:#a6e22e">virtualServices&lt;/span>.&lt;span style="color:#a6e22e">Items&lt;/span> {
&lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;VirtualService: %s\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">virtualService&lt;/span>.&lt;span style="color:#a6e22e">GetName&lt;/span>())
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This snippet omits setup and error-handling for clarity, the full example is in the &lt;a href="https://gist.github.com/dwmkerr/09ac0fd98595460456e17d5ef0c77667">k8s-list-virtualservices.go&lt;/a> gist.&lt;/p>
&lt;h2 id="patching-crds-in-golang">Patching CRDs in Golang&lt;/h2>
&lt;p>You may have noticed that the &lt;code>.Resource().Namespace().List()&lt;/code> code looks very similar to the structure for making API calls when using the Kubernetes &lt;code>Clientset&lt;/code>. In fact, it is essentially the same. Looking at &lt;a href="https://github.com/kubernetes/client-go/blob/master/dynamic/interface.go">the interface&lt;/a>, you can see you have all of the operations you'd expect:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Create&lt;/code>&lt;/li>
&lt;li>&lt;code>Update&lt;/code>&lt;/li>
&lt;li>&lt;code>Delete&lt;/code>&lt;/li>
&lt;li>&lt;code>Get&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>And so on. This is nice because you can use the same trick in my article &amp;lsquo;&lt;a href="https://www.dwmkerr.com/patching-kubernetes-resources-in-golang/">Patching Kubernetes Resources in Golang&lt;/a>&amp;rsquo; to manipulate these entities, without ever having to create a structure to represent it.&lt;/p>
&lt;p>Here's another abbreviated example, this time showing how we can adjust the weight of the routing from the services to 50%/50%:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#a6e22e">metav1&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/apis/meta/v1&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/dynamic&amp;#34;&lt;/span>
)
&lt;span style="color:#75715e">// Create a GVR which represents an Istio Virtual Service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">schema&lt;/span>.&lt;span style="color:#a6e22e">GroupVersionResource&lt;/span>{
&lt;span style="color:#a6e22e">Group&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;networking.istio.io&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Version&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;v1alpha3&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Resource&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;virtualservices&amp;#34;&lt;/span>,
}
&lt;span style="color:#75715e">// Weight the two routes - 50/50.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">patchPayload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> make([]&lt;span style="color:#a6e22e">PatchUInt32Value&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/0/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Op&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Path&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;/spec/http/0/route/1/weight&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">patchPayload&lt;/span>[&lt;span style="color:#ae81ff">1&lt;/span>].&lt;span style="color:#a6e22e">Value&lt;/span> = &lt;span style="color:#ae81ff">50&lt;/span>
&lt;span style="color:#a6e22e">patchBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">patchPayload&lt;/span>)
&lt;span style="color:#75715e">// Apply the patch to the &amp;#39;service2&amp;#39; service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">dynamicClient&lt;/span>.&lt;span style="color:#a6e22e">Resource&lt;/span>(&lt;span style="color:#a6e22e">virtualServiceGVR&lt;/span>).&lt;span style="color:#a6e22e">Namespace&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;service2&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">patchBytes&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>See the full example in the gist &lt;a href="https://gist.github.com/dwmkerr/7332888e092156ce8ce4ea551b0c321f">k8s-patch-virtualservice.go&lt;/a>&lt;/p>
&lt;p>After running the sample, you can use the Kubernetes CLI to verify the changes:&lt;/p>
&lt;pre>&lt;code>$ kubectl get virtualservices.networking.istio.io/service2 -o yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
clusterName: &amp;quot;&amp;quot;
creationTimestamp: 2018-10-08T09:53:16Z
generation: 0
name: service2
namespace: default
resourceVersion: &amp;quot;487435&amp;quot;
selfLink: /apis/networking.istio.io/v1alpha3/namespaces/default/virtualservices/service2
uid: fac5930c-cadf-11e8-90a2-42010a94005b
spec:
gateways:
- demo1-gateway
hosts:
- '*'
http:
- route:
- destination:
host: service2
subset: v1
weight: 50
- destination:
host: service2
subset: v2
weight: 50
&lt;/code>&lt;/pre>&lt;h2 id="keep-it-simple">Keep It Simple!&lt;/h2>
&lt;p>That's it! This trick made something I was working on a &lt;em>lot&lt;/em> easier, but it took a little bit of experimentation to get right. I hope you find the approach useful. Please share any thoughts/questions in the comments.&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>The following articles were using in working out this approach:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://blog.openshift.com/kubernetes-deep-dive-code-generation-customresources/">Red Hat: Deep Dive: Code Generation for Custom Resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Kubernetes Docs: Custom Resources&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>Procedural Smiles - Animating SVG with pure JavaScript</title><link>https://dwmkerr.com/procedural-smiles-animating-svg-with-pure-javascript/</link><pubDate>Sun, 29 Jul 2018 23:36:46 +0000</pubDate><guid>https://dwmkerr.com/procedural-smiles-animating-svg-with-pure-javascript/</guid><description>&lt;p>I recently needed to be able to generate a simple face image, with the face being able to scale from happy to sad.&lt;/p>
&lt;p>(&lt;em>Why&lt;/em> I needed to do this is a long story!)&lt;/p>
&lt;p>This gave me the opportunity to have a play with SVG, which is something I've not done in a while and always wished I could spend more time with. You can see the result below, move the slider to see the smile animate:&lt;/p>
&lt;p data-height="265" data-theme-id="0" data-slug-hash="ejejeX" data-default-tab="result" data-user="dwmkerr" data-pen-title="SVG Smile" class="codepen">See the Pen &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX/">SVG Smile&lt;/a> by Dave Kerr (&lt;a href="https://codepen.io/dwmkerr">@dwmkerr&lt;/a>) on &lt;a href="https://codepen.io">CodePen&lt;/a>.&lt;/p>
&lt;script async src="https://static.codepen.io/assets/embed/ei.js">&lt;/script>
&lt;p>Source: &lt;a href="https://github.com/dwmkerr/svg-smile">github.com/dwmkerr/svg-smile/&lt;/a>
CodePen: &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX">codepen.io/dwmkerr/pen/ejejeX&lt;/a>&lt;/p>
&lt;h3 id="how-it-works---geometry">How it works - geometry&lt;/h3>
&lt;p>This is quite a simple effect to achieve, the trick is just to work out how the geometry of the smile will work:&lt;/p>
&lt;p>&lt;img src="images/points.jpg" alt="Smile Geometry" />&lt;/p>
&lt;p>The black points are the start and end point of the smile, the red points are the control points for the &lt;a href="%5E1">bezier curve&lt;/a>. This means that we can scale from a smile to a frown by just interpolating the position of the anchor and control points from the two extremes shown above.&lt;/p>
&lt;p>The face itself (without styling) just looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">svg&lt;/span> &lt;span style="color:#a6e22e">viewbox&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0 0 120 120&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;translate(60 60)&amp;#39;&lt;/span>&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> First the main circle for the face. &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;50&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Then the left eye... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-20&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-10&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> Then the right... &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">circle&lt;/span>
&lt;span style="color:#a6e22e">cx&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;20&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">cy&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;-10&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">r&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;5&amp;#34;&lt;/span> /&amp;gt;
&lt;span style="color:#75715e">&amp;lt;!--&lt;/span>&lt;span style="color:#75715e"> The smile bezier curve. &lt;/span>&lt;span style="color:#75715e">--&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;translate(0, 25)&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">path&lt;/span>
&lt;span style="color:#a6e22e">d&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,-10 C-20,10 20,10 20,-10&amp;#34;&lt;/span> /&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">svg&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The trick here is really just to use whatever coordinate system works for you. I start by defining a viewbox that gives me some space, translate the origin and then put the main circle of the face slap bang in the middle at &lt;code>(0, 0)&lt;/code>.&lt;/p>
&lt;p>The code to interpolate the smile control points is easier again if we shift the origin of the smile as well. This technique works well for SVGs (or any computer graphics), manipulate and transform to get the coordinate system to work for you and make it easier to reason about what is going on.&lt;/p>
&lt;h3 id="how-it-works---animation">How it works - animation&lt;/h3>
&lt;p>I've not animated SVG before. When looking into doing this, the vast majority of tips, blogs, articles and so on were suggesting to use a libary (common suggestions were &lt;a href="https://maxwellito.github.io/vivus/">vivus&lt;/a>, &lt;a href="http://snapsvg.io/">snap.svg&lt;/a> and &lt;a href="http://svgjs.com/">svg.js&lt;/a>).&lt;/p>
&lt;p>I've got no doubt that when you know what you are doing with SVG, using a library is a huge accelerator and saves on boilerplate. But if you don't know what a library is doing, what it is wrapping, or the problems it is solving for you, you are likely missing out some fundamentals.&lt;/p>
&lt;p>Using a library is great if you know &lt;em>what the problem is you are solving&lt;/em>. But if you don't, you end up never really learning. I had no idea whether this would be challenging to do with the pure SVG APIs and definitely wanted to work by hand.&lt;/p>
&lt;p>After some experimentation, I was able to write the markup which would move the smile to a frown:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">g&lt;/span> &lt;span style="color:#a6e22e">transform&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;translate(0, 25)&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">path&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;smilepath&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">d&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,-10 C-20,10 20,10 20,-10&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">animate&lt;/span>
&lt;span style="color:#a6e22e">attributeName&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;d&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">attributeType&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;XML&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">to&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;M-20,10 C-20,-10 20,-10 20,10&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">dur&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;3s&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">repeatCount&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;indefinite&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">fill&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;freeze&amp;#34;&lt;/span>
/&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">path&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">g&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The geometry we've already seen, all we've done here is swap the position of each anchor and its associated control point. The trick is just making sure that we get the attributes of the &lt;code>animate&lt;/code> element right.&lt;/p>
&lt;p>Once this is done, the final step is just to make it all programmatic. The code to generate the geometry of the path, based on a scale from 0 (sad) to 1 (happy) is online, but the interesting thing is how to run the animation:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// note that &amp;#39;scale&amp;#39; is 0-&amp;gt;1 (sad-&amp;gt;happy)
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">points&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">writeSmilePoints&lt;/span>(&lt;span style="color:#a6e22e">smilePoints&lt;/span>(&lt;span style="color:#a6e22e">scale&lt;/span>));
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">svg&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">getElementById&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;svg&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">smilePath&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">getElementById&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;smilepath&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">animate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">createElementNS&lt;/span>(&lt;span style="color:#a6e22e">svg&lt;/span>.&lt;span style="color:#a6e22e">namespaceURI&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;animate&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;attributeName&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;d&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;attributeType&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;XML&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;to&amp;#39;&lt;/span>,&lt;span style="color:#a6e22e">points&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;dur&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;0.3s&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;repeatCount&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;1&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">setAttribute&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;fill&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;freeze&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">smilePath&lt;/span>.&lt;span style="color:#a6e22e">appendChild&lt;/span>(&lt;span style="color:#a6e22e">animate&lt;/span>);
&lt;span style="color:#a6e22e">animate&lt;/span>.&lt;span style="color:#a6e22e">beginElement&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's not much to it. The bulk of the code is just setting up the attributes for the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/animate">&lt;code>animate&lt;/code>&lt;/a> tag. Then we add it to the path as a child and call &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/SVGAnimationElement">&lt;code>beginElement&lt;/code>&lt;/a> to start the animation.&lt;/p>
&lt;p>The face is coloured in a similar way. Interpolating between a happy Simpsons yellow and angry red in JavaScript, then setting an &lt;code>animate&lt;/code> element to target the &lt;code>fill&lt;/code> of the appropriate circle.&lt;/p>
&lt;h3 id="wrapping-up">Wrapping Up&lt;/h3>
&lt;p>Playing with graphics is fun! This is only the most basic scratching of the surface of what SVG can do. The JavaScript to animate is trivial (although I can appreciate that browser inconsistencies and so on mean a libary is probably useful at some point).&lt;/p>
&lt;p>The code is available on GitHub at &lt;a href="https://github.com/dwmkerr/svg-smile">github.com/dwmkerr/svg-smile&lt;/a> or on CodePen:&lt;/p>
&lt;p data-height="265" data-theme-id="0" data-slug-hash="ejejeX" data-default-tab="js,result" data-user="dwmkerr" data-pen-title="SVG Smile" class="codepen">See the Pen &lt;a href="https://codepen.io/dwmkerr/pen/ejejeX/">SVG Smile&lt;/a> by Dave Kerr (&lt;a href="https://codepen.io/dwmkerr">@dwmkerr&lt;/a>) on &lt;a href="https://codepen.io">CodePen&lt;/a>.&lt;/p>
&lt;script async src="https://static.codepen.io/assets/embed/ei.js">&lt;/script></description><category>CodeProject</category></item><item><title>Patching Kubernetes Resources in Golang</title><link>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</link><pubDate>Tue, 24 Jul 2018 06:33:17 +0000</pubDate><guid>https://dwmkerr.com/patching-kubernetes-resources-in-golang/</guid><description>&lt;p>Recently I needed to be able to quickly adjust the number of replicas in a Kubernetes Replication Controller. The original solution I'd seen pulled down the spec, modified it, then updated it. There's a better way!&lt;/p>
&lt;p>&lt;img src="images/patch-1.jpg" alt="Kuberentes Patch API">&lt;/p>
&lt;p>There's a &lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">patch API for Kubernetes resources&lt;/a>. Patching resources is faster and easier than pulling them and updating the spec wholesale. However, the documentation is a little limited.&lt;/p>
&lt;p>After some trial and error I got it working, here's the solution. I thought it might be helpful to share for others!&lt;/p>
&lt;h3 id="the-solution">The Solution&lt;/h3>
&lt;p>I'll start with the solution. If this is all you need, you are good to go. The details of how this works are presented afterwards. In this example I'll update the number of replicas in the &lt;code>my-rc&lt;/code> controller:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#f92672">package&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>
&lt;span style="color:#f92672">import&lt;/span> (
&lt;span style="color:#e6db74">&amp;#34;encoding/json&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;fmt&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">types&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/apimachinery/pkg/types&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/kubernetes&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/plugin/pkg/client/auth&amp;#34;&lt;/span>
&lt;span style="color:#e6db74">&amp;#34;k8s.io/client-go/tools/clientcmd&amp;#34;&lt;/span>
)
&lt;span style="color:#66d9ef">var&lt;/span> (
&lt;span style="color:#75715e">// Leave blank for the default context in your kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">context&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#75715e">// Name of the replication controller to scale, and the desired number of replicas.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">replicationControllerName&lt;/span> = &lt;span style="color:#e6db74">&amp;#34;my-rc&amp;#34;&lt;/span>
&lt;span style="color:#a6e22e">replicas&lt;/span> = uint32(&lt;span style="color:#ae81ff">3&lt;/span>)
)
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a string.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchStringValue&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#75715e">// patchStringValue specifies a patch operation for a uint32.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">type&lt;/span> &lt;span style="color:#a6e22e">patchUInt32Value&lt;/span> &lt;span style="color:#66d9ef">struct&lt;/span> {
&lt;span style="color:#a6e22e">Op&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;op&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Path&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;path&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
&lt;span style="color:#a6e22e">Value&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span> &lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">json:&amp;#34;value&amp;#34;&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientSet&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">Clientset&lt;/span>, &lt;span style="color:#a6e22e">replicasetName&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span>, &lt;span style="color:#a6e22e">scale&lt;/span> &lt;span style="color:#66d9ef">uint32&lt;/span>) &lt;span style="color:#66d9ef">error&lt;/span> {
&lt;span style="color:#a6e22e">payload&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> []&lt;span style="color:#a6e22e">patchUInt32Value&lt;/span>{{
&lt;span style="color:#a6e22e">Op&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Path&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">Value&lt;/span>: &lt;span style="color:#a6e22e">scale&lt;/span>,
}}
&lt;span style="color:#a6e22e">payloadBytes&lt;/span>, &lt;span style="color:#a6e22e">_&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">json&lt;/span>.&lt;span style="color:#a6e22e">Marshal&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>)
&lt;span style="color:#a6e22e">_&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientSet&lt;/span>.
&lt;span style="color:#a6e22e">CoreV1&lt;/span>().
&lt;span style="color:#a6e22e">ReplicationControllers&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;default&amp;#34;&lt;/span>).
&lt;span style="color:#a6e22e">Patch&lt;/span>(&lt;span style="color:#a6e22e">replicasetName&lt;/span>, &lt;span style="color:#a6e22e">types&lt;/span>.&lt;span style="color:#a6e22e">JSONPatchType&lt;/span>, &lt;span style="color:#a6e22e">payloadBytes&lt;/span>)
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>
}
&lt;span style="color:#66d9ef">func&lt;/span> &lt;span style="color:#a6e22e">main&lt;/span>() {
&lt;span style="color:#75715e">// Get the local kube config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to Kubernetes Context %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">context&lt;/span>)
&lt;span style="color:#a6e22e">config&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewNonInteractiveDeferredLoadingClientConfig&lt;/span>(
&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">NewDefaultClientConfigLoadingRules&lt;/span>(),
&lt;span style="color:#f92672">&amp;amp;&lt;/span>&lt;span style="color:#a6e22e">clientcmd&lt;/span>.&lt;span style="color:#a6e22e">ConfigOverrides&lt;/span>{&lt;span style="color:#a6e22e">CurrentContext&lt;/span>: &lt;span style="color:#a6e22e">context&lt;/span>}).&lt;span style="color:#a6e22e">ClientConfig&lt;/span>()
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Creates the clientset
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">:=&lt;/span> &lt;span style="color:#a6e22e">kubernetes&lt;/span>.&lt;span style="color:#a6e22e">NewForConfig&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
&lt;span style="color:#75715e">// Scale our replication controller.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">fmt&lt;/span>.&lt;span style="color:#a6e22e">Printf&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Scaling replication controller %v to %v\n&amp;#34;&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#a6e22e">err&lt;/span> = &lt;span style="color:#a6e22e">scaleReplicationController&lt;/span>(&lt;span style="color:#a6e22e">clientset&lt;/span>, &lt;span style="color:#a6e22e">replicationControllerName&lt;/span>, &lt;span style="color:#a6e22e">replicas&lt;/span>)
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span> &lt;span style="color:#f92672">!=&lt;/span> &lt;span style="color:#66d9ef">nil&lt;/span> {
panic(&lt;span style="color:#a6e22e">err&lt;/span>.&lt;span style="color:#a6e22e">Error&lt;/span>())
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code is also available in the &lt;a href="https://gist.github.com/dwmkerr/447692c8bba28929ef914239781c4e59">k8s-patch.go&lt;/a> gist.&lt;/p>
&lt;h3 id="the-mechanism">The Mechanism&lt;/h3>
&lt;p>The Kubernetes Patch API supports a few different methods for modifying resources. It is important to be aware that there is not a universally accepted &amp;lsquo;standard&amp;rsquo; approach to representing a &lt;em>change&lt;/em> to a resource in a REST API.&lt;/p>
&lt;p>There are three strategies you can use to patch:&lt;/p>
&lt;ol>
&lt;li>&lt;code>merge&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc7386">JSON Merge Patch Spec (RFC 7386)&lt;/a>&lt;/li>
&lt;li>&lt;code>stragetic&lt;/code>: A strategic merge, which addresses some limitations of the merge patch (noted in &lt;a href="%5Bdocs/devel/api-conventions.md#patch-operations%5D(https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations)">this doc&lt;/a>.&lt;/li>
&lt;li>&lt;code>json&lt;/code>: follows the &lt;a href="https://tools.ietf.org/html/rfc6902">JSON Patch Spec (RFC 6902)&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>These are documented in detail at:&lt;/p>
&lt;p>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">docs/devel/api-conventions.md#patch-operations&lt;/a>&lt;/p>
&lt;p>The mechanism I've used here is &lt;code>json&lt;/code>, which I think is the clearest to the reader. To use this strategy we need to build a payload describing what we are changing. This might look like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-json" data-lang="json">{
&lt;span style="color:#f92672">&amp;#34;op&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;replace&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;path&amp;#34;&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;/spec/replicas&amp;#34;&lt;/span>,
&lt;span style="color:#f92672">&amp;#34;value&amp;#34;&lt;/span>: &lt;span style="color:#ae81ff">4&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>op&lt;/code> field can be &lt;code>remove&lt;/code>, &lt;code>replace&lt;/code>, &lt;code>add&lt;/code> etc etc (all the details are in the &lt;a href="https://tools.ietf.org/html/rfc6902">RFC 6902)&lt;/a>, or the slightly more readable &lt;a href="jsonpatch.com">jsonpatch.com&lt;/a>). This allows the operation to be very &lt;em>explicit&lt;/em> to the reader, which is helpful. We create a struct which represents an operation on a string or integer (or whatever data type we need), serialize it and pass to the API.&lt;/p>
&lt;p>Under the hood, the Golang client will simply translate this into an HTTP call which will look like something like this:&lt;/p>
&lt;pre>&lt;code>PATCH /api/v1/namespaces/default/replicationcontrollers/app-server-blue HTTP/1.1
Host: 127.0.0.1
Content-Type: application/json-patch+json
Content-Length: 70
[{
&amp;quot;op&amp;quot;: &amp;quot;replace&amp;quot;,
&amp;quot;path&amp;quot;: &amp;quot;/spec/replicas&amp;quot;,
&amp;quot;value&amp;quot;: 4
}]
&lt;/code>&lt;/pre>&lt;p>This corresponds to the documentation on the &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Patch Operations&lt;/a>. Note that the patch operation type is specified in the &lt;code>Content-Type&lt;/code> header.&lt;/p>
&lt;p>Hopefully this'll help you if you need to patch resources, are struggling with the docs and are a Go noob like me! Any tips on how to make the code cleaner or more idomatic would be welcome.&lt;/p>
&lt;p>Thanks to the following articles and issues which helped me unpick this:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://stackoverflow.com/questions/43415728/kubernetes-go-client-patch-example">Stack Overflow: Kubernetes Go Client Patch Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/">Kubernetes Docs: Update API Objects in Place Using kubectl patch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.1/docs/devel/api-conventions.md#patch-operations">Kubernetes Docs: Patch Operations&lt;/a>&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>mongo-monitor - a simple CLI to monitor your MongoDB cluster</title><link>https://dwmkerr.com/mongo-monitor-cli/</link><pubDate>Wed, 16 May 2018 20:09:53 +0000</pubDate><guid>https://dwmkerr.com/mongo-monitor-cli/</guid><description>&lt;p>The &lt;code>mongo-monitor&lt;/code> CLI is a lean and simple tool to check the status of a MongoDB server or cluster. The code is on GitHub:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/mongo-monitor">github.com/dwmkerr/mongo-monitor&lt;/a>&lt;/p>
&lt;p>Here's how it looks in action:&lt;/p>
&lt;p>&lt;img src="images/overview.gif" alt="Screenshot: Using the mongo-monitor CLI to monitor a sharded cluster">&lt;/p>
&lt;p>In this animation I am monitoring a simple sharded cluster, and running some example maintenance operations, adding a node to a replicaset, stepping down a primary and shutting down a replicaset node.&lt;/p>
&lt;p>A simple CLI which shows the status in real-time can be very useful to keep open when performing admin, letting you see how your changes affect the cluster as you work on it.&lt;/p>
&lt;h2 id="installing-the-cli">Installing the CLI&lt;/h2>
&lt;p>The CLI is installed with &lt;code>npm&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install -g mongo-monitor
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="connecting-to-a-cluster">Connecting to a Cluster&lt;/h2>
&lt;p>Connect to a cluster by providing a connection string. The tool uses &lt;a href="https://github.com/dwmkerr/mongo-connection-string">&lt;code>mongo-connection-string&lt;/code>&lt;/a> to parse the connection string, so you can be flexible with the input:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Connect to a local instance&lt;/span>
mongo-monitor localhost:27107
&lt;span style="color:#75715e"># Connect to a remote replicaset, authenticated&lt;/span>
mongo-monitor admin:P@sswrd@mdbnode1,mdbnode2,mdbnode3?replicaSet&lt;span style="color:#f92672">=&lt;/span>rs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once a connection is established, the tool will periodically check the status of the cluster. If the cluster is sharded, it will also inspect each individual replicaset.&lt;/p>
&lt;h2 id="replicaset-status">Replicaset Status&lt;/h2>
&lt;p>Here's the kind of output you might get from a replicaset:&lt;/p>
&lt;p>&lt;img src="images/replicaset.jpg" alt="Screenshot: Replicaset Status">&lt;/p>
&lt;p>The name of the replicaset is shown, along with each member. The status of each member is also shown, updating automatically every second.&lt;/p>
&lt;p>This is convenient when administering replicasets, stepping down a master, adding or removing nodes and so on.&lt;/p>
&lt;h2 id="sharded-cluster-status">Sharded Cluster Status&lt;/h2>
&lt;p>When connecting to a sharded cluster, you will get output like this:&lt;/p>
&lt;p>&lt;img src="images/sharded-cluster.jpg" alt="Screenshot: Sharded Cluster Status">&lt;/p>
&lt;p>Each shard is shown, along with the details of the replicaset which make it up.&lt;/p>
&lt;p>Keeping a view like this open is useful when administering sharded clusters, adding or removing shards, desharding, updating the replicasets which make up shards and so on.&lt;/p>
&lt;h2 id="get-involved">Get Involved!&lt;/h2>
&lt;p>If you like the tool, check out the code and feel free to make pull requests with additions! There are a few &lt;a href="https://github.com/dwmkerr/mongo-monitor/issues">issues&lt;/a> on the project already, and there are all sorts of features I'd love to add but haven't had the time, such as:&lt;/p>
&lt;ul>
&lt;li>Being able to see the lag for replicaset members, to see if secondaries are falling behind&lt;/li>
&lt;li>Being able to perform replicaset operations directly from the tool&lt;/li>
&lt;li>Showing the priorities of nodes if they are not the default&lt;/li>
&lt;/ul>
&lt;p>All ideas are welcome, let me know in the comments or repo, and share the tool if you find it useful!&lt;/p></description><category>CodeProject</category></item><item><title>The Death of Microservice Madness in 2018</title><link>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</link><pubDate>Fri, 12 Jan 2018 10:52:25 +0000</pubDate><guid>https://dwmkerr.com/the-death-of-microservice-madness-in-2018/</guid><description>&lt;p>&lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">En Español&lt;/a> | &lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit Thread&lt;/a> | &lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News Thread&lt;/a>&lt;/p>
&lt;p>Microservices became a very popular topic over the last couple of years&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. &amp;lsquo;Microservice madness&amp;rsquo; goes something like this:&lt;/p>
&lt;blockquote>
&lt;p>Netflix are great at devops.
Netflix do microservices.
Therefore: If I do microservices, I am great at devops.&lt;/p>
&lt;/blockquote>
&lt;p>There are many cases where great efforts have been made to adopt microservice patterns without necessarily understanding how the costs and benefits will apply to the specifics of the problem at hand.&lt;/p>
&lt;p>I'm going to describe in detail what microservices are, why the pattern is so appealing, and also some of the key challenges that they present.&lt;/p>
&lt;p>I'll finish with a set of simple questions might be valuable to ask yourself when you are considering whether microservices are the right pattern &lt;em>for you&lt;/em>. The questions are at the end of the article.&lt;/p>
&lt;p>&lt;img src="images/letterbox.png" alt="Letterbox sample of diagram">&lt;/p>
&lt;h2 id="what-are-microservices-and-why-are-they-so-popular">What are microservices, and why are they so popular?&lt;/h2>
&lt;p>Let's start with the basics. Here is how a hypothetical video sharing platform might be implemented, first in the form of a monolith (single large unit) and then in the form of microservices:&lt;/p>
&lt;p>&lt;img src="images/video-platform-monolith-microservices.png" alt="Diagram: Comparison of a Video Sharing Platform, Monolith vs Microservice">&lt;/p>
&lt;p>The difference between the two systems is that the first is a single large unit; a monolith. The second is a set of small, specific services. Each service has a specific role.&lt;/p>
&lt;p>When the diagram is drawn &lt;em>at this level of detail&lt;/em>, it is easy to see the appeal. There are a whole host of potential benefits:&lt;/p>
&lt;p>&lt;strong>Independent Development&lt;/strong>: Small, independent components can be built by small, independent teams. A group can work on a change to the &amp;lsquo;Upload&amp;rsquo; service without interfering with the &amp;lsquo;Transcode&amp;rsquo; service, or even knowing about it. The amount of time to learn about a component is greatly reduced, and it is easier to develop new features.&lt;/p>
&lt;p>&lt;strong>Independent Deployment&lt;/strong>: Each individual component can be deployed independently. This allows new features to be released with greater velocity and less risk. Fixes or features for the &amp;lsquo;Streaming&amp;rsquo; component can be deployed without requiring other components to be deployed.&lt;/p>
&lt;p>&lt;strong>Independent Scalability&lt;/strong>: Each component can be scaled independently of each other. During busy periods when new shows are released, the &amp;lsquo;Download&amp;rsquo; component can be scaled up to handle the increased load, without having to scale up every component, which makes elastic scaling more feasible and reduces costs.&lt;/p>
&lt;p>&lt;strong>Reusability&lt;/strong>: Components fulfil a small, specific function. This means that they can more easily be adapted for use in other systems, services or products. The &amp;lsquo;Transcode&amp;rsquo; component could be used by other business units, or even turned into a new business, perhaps offering transcoding services for other groups.&lt;/p>
&lt;p>At this level of detail, the benefits of a microservice model over a monolithic model seem obvious. So if that's the case - why is this pattern only recently in vogue? Where has it been all my life?&lt;/p>
&lt;h2 id="if-this-is-so-great-why-hasnt-it-been-done-before">If this is so great, why hasn't it been done before?&lt;/h2>
&lt;p>There are two answers to this question. One is that &lt;em>it has&lt;/em> - to the best of our technical capabilities, and the other is that more recent technical advances have allowed us to take it to a new level.&lt;/p>
&lt;p>When I started writing the answer to this question, it turned into a &lt;em>long&lt;/em> description, so I'm actually going to separate it into another article and publish it a little later&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. At this stage, I will skip the journey from single program to many programs, ignore ESBs and Service Orientated Architecture, component design and bounded contexts, and so on.&lt;/p>
&lt;p>Those who are interested can read more about the journey separately. Instead I'll say that in many ways we've been doing this for a while, but with the recent explosion in popularity of container technology (Docker in particular) and in orchestration technology (such as Kubernetes, Mesos, Consul and so on) this pattern has become much more viable to implement from a technical standpoint.&lt;/p>
&lt;p>So if we take it as a given that we &lt;em>can&lt;/em> implement a microservice arrangement, we need to think carefully about the &lt;em>should&lt;/em>. We've seen the high-level theoretical benefits, but what about the challenges?&lt;/p>
&lt;h2 id="whats-the-problem-with-microservices">What's the problem with microservices?&lt;/h2>
&lt;p>If microservices are so great, what's the big deal? Here are some of the biggest issues I've seen.&lt;/p>
&lt;p>&lt;strong>Increased complexity for developers&lt;/strong>&lt;/p>
&lt;p>Things &lt;em>can&lt;/em> get a lot harder for developers. In the case where a developer wants to work on a &lt;em>journey&lt;/em>, or feature which might span many services, that developer has to run them all on their machine, or connect to them. This is often more complex than simply running a single program.&lt;/p>
&lt;p>This challenge can be partially mitigated with tooling&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>, but as the number of services which makes up a system increases, the more challenges developers will face when running the system as a whole.&lt;/p>
&lt;p>&lt;strong>Increased complexity for operators&lt;/strong>&lt;/p>
&lt;p>For teams who don't develop services, but maintain them, there is an explosion in potential complexity. Instead of perhaps managing a few running services, they are managing dozens, hundreds or thousands of running services. There are more services, more communication paths, and more areas of potential failure.&lt;/p>
&lt;p>&lt;strong>Increased complexity for devops&lt;/strong>&lt;/p>
&lt;p>Reading the two points above, it may grate that operations and development are treated separately, especially given the popularity of devops as a practice (which I am a big proponent of). Doesn't devops mitigate this?&lt;/p>
&lt;p>The challenge is that many organisations still run with separated development and operations teams - and a organisation that does is much more likely to struggle with adoption of microservices.&lt;/p>
&lt;p>For organisations which have adopted devops, it's still hard. Being both a developer and an operator is already tough (but critical to build good software), but having to also understand the nuances of container orchestration systems, particularly systems which are evolving at a rapid pace, is very hard. Which brings me onto the next point.&lt;/p>
&lt;p>&lt;strong>It requires serious expertise&lt;/strong>&lt;/p>
&lt;p>When done by experts, the results can be wonderful. But imagine an organisation where perhaps things are not running smoothly with a single monolithic system. What possible reason would there be that things would be any better by increasing the number of systems, which increases the operational complexity?&lt;/p>
&lt;p>Yes, with effective automation, monitoring, orchestration and so on, this is all possible. But the challenge is rarely the technology - the challenge is finding people who can use it effectively. These skillsets are currently in very high demand, and may be difficult to find.&lt;/p>
&lt;p>&lt;strong>Real world systems often have poorly defined boundaries&lt;/strong>&lt;/p>
&lt;p>In all of the examples we used to describe the benefits of microservices, we spoke about &lt;em>independent&lt;/em> components. However in many cases components are simply not independent. On paper, certain domains may look bounded, but as you get into the muddy details, you may find that they are more challenging to model than you anticipated.&lt;/p>
&lt;p>This is where things can get &lt;em>extremely&lt;/em> complex. If your boundaries are actually not well defined, then what happens is that even though &lt;em>theoretically&lt;/em> services can be deployed in isolation, you find that due to the inter-dependencies between services, you have to deploy &lt;em>sets&lt;/em> of services as a group.&lt;/p>
&lt;p>This then means that you need to manage coherent versions of services which are proven and tested when working together, you don't actually have an independently deployable system, because to deploy a new feature, you need to carefully orchestrate the simultaneous deployment of many services.&lt;/p>
&lt;p>&lt;strong>The complexities of state are often ignored&lt;/strong>&lt;/p>
&lt;p>In the previous example, I mentioned that a feature deployment may require the simultaneous rollout of many versions of many services in tandem. It is tempting to assume that sensible deployment techniques will mitigate this, for example blue/green deployments (which most service orchestration platforms handle with little effort), or multiple versions of a service being run in parallel, with consuming channels deciding which version to use.&lt;/p>
&lt;p>These techniques mitigate a large number of the challenges &lt;em>if the services are stateless&lt;/em>. But stateless services are quite frankly, easy to deal with. In fact, if you have stateless services, then I'd be inclined to consider skipping microservices altogether and consider using a serverless model.&lt;/p>
&lt;p>In reality, many services require state. An example from our video sharing platform might be the subscription service. A new version of the subscriptions service may store data in the subscriptions database in a different shape. If you are running both services in parallel, you are running the system with two schemas at once. If you do a blue green deployment, and other services depend on data in the new shape, then they must be updated &lt;em>at the same time&lt;/em>, and if the subscription service deployment fails and rolls back, they might need to roll back too, with cascading consequences.&lt;/p>
&lt;p>Again, it might be tempting to think that with NoSQL databases these issues of schema go away, but they don't. Databases which don't enforce schema do not lead to schemaless systems - they just mean that schema tends to be managed at the application level, rather than the database level. The fundamental challenge of understanding the shape of your data, and how it evolves, cannot be eliminated.&lt;/p>
&lt;p>&lt;strong>The complexitities of communication are often ignored&lt;/strong>&lt;/p>
&lt;p>As you build a large network of services which depend on each other, the liklihood is that there will be a lot of inter-service communication. This leads to a few challenges. Firstly, there are a lot more points at which things can fail. We must expect that network calls will fail, which means when one service calls another, it should expect to have to retry a number of times at the least. Now when a service has to potentially call many services, we end up in a complicated situation.&lt;/p>
&lt;p>Imagine a user uploads a video in the video sharing service. We might need to run the upload service, pass data to the transcode service, update subscriptions, update recommendations and so on. All of these calls require a degree of orchestration, if things fail we need to retry.&lt;/p>
&lt;p>This retry logic can get hard to manage. Trying to do things synchronously often ends up being untenable, there are too many points of failure. In this case, a more reliable solution is to use asynchronous patterns to handle communication. The challenge here is that asynchronous patterns inherently make a system stateful. As mentioned in the previous point, stateful systems and systems with distributed state are very hard to handle.&lt;/p>
&lt;p>When a microservice system uses message queues for intra-service communication, you essentially have a large database (the message queue or broker) glueing the services together. Again, although it might not seem like a challenge at first, schema will come back to bite you. A service at version X might write a message with a certain format, services which depend on this message will also need to be updated when the sending service changes the details of the message it sends.&lt;/p>
&lt;p>It is possible to have services which can handle messages in many different formats, but this is hard to manage. Now when deploying new versions of services, you will have times where two different versions of a service may be trying to process messages from the same queue, perhaps even messages sent by different versions of a sending service. This can lead to complicated edge cases. To avoid these edge cases, it may be easier to only allow certain versions of messages to exist, meaning that you need to deploy a set of versions of a set of services as a coherent whole, ensuring messages of older versions are drained appropriately first.&lt;/p>
&lt;p>This highlights again that the idea of independent deployments may not hold as expected when you get into the details.&lt;/p>
&lt;p>&lt;strong>Versioning can be hard&lt;/strong>&lt;/p>
&lt;p>To mitigate the challenges mentioned previously, versioning needs to be very carefully managed. Again, there can be a tendency to assume that following a standard such as semver[4] will solve the problem. It doesn't. Semver is a sensible convention to use, but you will still have to track the versions of services and APIs which can work together.&lt;/p>
&lt;p>This can get very challenging very quickly, and may get to the point where you don't know which versions of services will actually work properly together.&lt;/p>
&lt;p>Managing dependencies in software systems is notoriously hard, whether it is node modules, Java modules, C libraries or whatever. The challenges of &lt;em>conflicts between independent components&lt;/em> when consumed by a single entity are very hard to deal with.&lt;/p>
&lt;p>These challenges are hard to deal with when the dependencies are static, and can be patched, updated, edited and so on, but if the dependencies are themselves &lt;em>live services&lt;/em>, then you may not be able to just update them - you may have to run many versions (with the challenges already described) or bring down the system until it is fixed holistically.&lt;/p>
&lt;p>&lt;strong>Distributed Transactions&lt;/strong>&lt;/p>
&lt;p>In situations where you need transaction integrity across an operation, microservices can be very painful. Distributed state is hard to deal with, many small units which can fail make orchestrating transactions very hard.&lt;/p>
&lt;p>It may be tempting to attempt to avoid the problem by making operations idempotent, offering retry mechanisms and so on, and in many cases this might work. But you may have scenarios where you simply need a transaction to fail or succeed, and never be in an intermediate state. The effort involved in working around this or implementing it in a microservice model may be very high.&lt;/p>
&lt;p>&lt;strong>Microservices can be monoliths in disguise&lt;/strong>&lt;/p>
&lt;p>Yes, individual services and components &lt;em>may&lt;/em> be deployed in isolation, however in most cases you are going to have to be running some kind of orchestration platform, such as Kubernetes. If you are using a managed service, such as Google's GKE&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> or Amazon's EKS&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>, then a large amount of the complexity of managing the cluster is handled for you.&lt;/p>
&lt;p>However, if you are managing the cluster yourself, you are managing a large, complicated, mission critical system. Although the individual services may have all of the benefits described earlier, you need to very carefully manage your cluster. Deployments of this system can be hard, updates can be hard, failover can be hard and so on.&lt;/p>
&lt;p>In many cases the overall benefits are still there, but it is important not to trivialise or underestimate the additional complexity of managing another big, complex system. Managed services may help, but in many cases these services are nascent (Amazon EKS was only announced at the end of 2017 for example).&lt;/p>
&lt;p>&lt;strong>Networking Nightmares&lt;/strong>&lt;/p>
&lt;p>A more traditional model of services running on known hosts, with known addresses, has a fairly simple networking setup.&lt;/p>
&lt;p>However, when using microservices, generally there will be many services distributed across many nodes, which typically means there's going to be a &lt;em>much&lt;/em> more complicated networking arrangement. There will be load balancing between services, DNS may be more heavily used, virtual networking layers, etc etc, to attempt to &amp;lsquo;hide&amp;rsquo; the complexity of this networking.&lt;/p>
&lt;p>However, as per &lt;a href="https://github.com/dwmkerr/hacker-laws/#the-law-of-conservation-of-complexity-teslers-law">Tesler's Law&lt;/a> (or the Law of Conservation of Compexlity), this networking complexity is inherent - when you are finding real, runtime issues in larger scale clusters, it can often be at a very low networking level. These sorts of issues can be &lt;em>very&lt;/em> hard to diagnose. I have started tracking some examples at the end of the article, but I think that &lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Migration to Kuberenetes&lt;/a> shows this challenge very well.&lt;/p>
&lt;p>Overall - the transition is still likely to be for the best, but doesn't come without some serious challenges at the networking level, which will require some serious expertise to deal with!&lt;/p>
&lt;h2 id="the-death-of-microservice-madness">The Death of Microservice Madness!&lt;/h2>
&lt;p>Avoid the madness by making careful and considered decisions. To help out on this I've noted a few questions you might want to ask yourself, and what the answers might indicate:&lt;/p>
&lt;p>&lt;img src="images/questions.png" alt="Diagram: Questions to ask yourself when considering microservices">&lt;/p>
&lt;p>You can download a PDF copy here: &lt;a href="https://github.com/dwmkerr/blog/blob/master/articles/2018/microservice-madness/images/microservice-questions.pdf">microservice-questions.pdf&lt;/a>&lt;/p>
&lt;h2 id="final-thoughts-dont-confuse-microservices-with-architecture">Final Thoughts: Don't Confuse Microservices with Architecture&lt;/h2>
&lt;p>I've deliberately avoided the &amp;lsquo;a&amp;rsquo; word in this article. But my friend &lt;a href="http://twitter.com/zoltanarvai">Zoltan&lt;/a> made a very good point when proofing this article (which he has contributed to).&lt;/p>
&lt;p>There is no microservice architecture. Microservices are just another pattern or implementation of components, nothing more, nothing less. Whether they are present in a system or not does not mean that the architecture of the system is solved.&lt;/p>
&lt;p>Microservices relate in many ways more to the technical processes around packaging and operations rather than the intrinsic design of the system. Appropriate boundaries for components continues to be one of the most important challenges in engineering systems.&lt;/p>
&lt;p>Regardless of the size of your services, whether they are in Docker containers or not, you will always need to think carefully about how to put a system together. There are no right answers, and there are a &lt;em>lot&lt;/em> of options.&lt;/p>
&lt;p>I hope you found this article interesting! As always, please do comment below if you have any questions or thoughts. You can also follow some lively discussions on:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.reddit.com/r/programming/comments/7pxriw/the_death_of_microservice_madness_in_2018/">Reddit - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://news.ycombinator.com/item?id=16200007">Hacker News - The Death of Microservice Madness&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="appendix-further-reading">Appendix: Further Reading&lt;/h2>
&lt;p>The following links might be of interest:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://martinfowler.com/bliki/BoundedContext.html">Martin Fowler - Bounded Context&lt;/a> - Martin's articles are great, I'd thoroughly recommend this.&lt;/li>
&lt;li>&lt;a href="https://martinfowler.com/articles/microservices.html">Martin Fowler - Microservices&lt;/a> - An often recommended introduction to the pattern.&lt;/li>
&lt;li>&lt;a href="https://r2m.se/microservices-good-or-bad/">Microservices - Good or Bad?&lt;/a> - Björn Frantzén's thoughts on microservices, after reading this article.&lt;/li>
&lt;li>&lt;a href="http://blog.christianposta.com/microservices/when-not-to-do-microservices/">When Not To Do Microservices&lt;/a> - Excellent post on the topic from Christian Posta&lt;/li>
&lt;li>&lt;a href="http://www.iheavy.com/2017/03/13/30-questions-to-ask-a-serverless-fanboy/">Sean Hull - 30 questions to ask a serverless fanboy&lt;/a> - Interesting thoughts on the challenges of serverless, from a serverless fan!&lt;/li>
&lt;li>&lt;a href="https://youtu.be/NVb7aljfKYo?t=6657">Dave Kerr - Monoliths to Microservices - Practical tips for CI/CD and DevOps in the Microservice world&lt;/a> - A recent conference presentation I did on devops with microservices.&lt;/li>
&lt;li>&lt;a href="https://yermakov.net/microservices-without-fundamentals/">Alexander Yermakov - Microservices without fundamentals&lt;/a> - A response to this article, with Alex's thoughts and counterpoints to the points raised here (see also &lt;a href="https://yermakov.net/microservices-as-a-self-sufficient-concept/">Microservices as a self sufficient concept&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>Please do share anything else you think makes great reading or watching on the topic!&lt;/p>
&lt;hr>
&lt;h2 id="thanks">Thanks&lt;/h2>
&lt;p>Thanks José from &lt;a href="https://www.campusmvp.es">campusmvp.es&lt;/a> for having the article translated in Spanish - &lt;a href="https://www.campusmvp.es/recursos/post/la-muerte-de-la-locura-de-los-microservicios-en-2018.aspx">La muerte de la locura de los microservicios en 2018&lt;/a>!&lt;/p>
&lt;h2 id="case-studies">Case Studies&lt;/h2>
&lt;p>Some interesting examples of experiences I am collecting of larger organisations who have made large scale transitions to microservices:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/@tinder.engineering/tinders-move-to-kubernetes-cda2a6372f44">Tinder's Move to Kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="references">References&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice">https://trends.google.com/trends/explore?date=today%205-y&amp;amp;q=microservice&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If you don't want to miss the article, you can subscribe to the &lt;a href="http://www.dwmkerr.com/rss/">RSS Feed&lt;/a>, or follow me on &lt;a href="https://www.linkedin.com/in/dwmkerr/">LinkedIn&lt;/a> or &lt;a href="https://twitter.com/dwmkerr">Twitter&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Docker Compose is a good solution, &lt;a href="https://github.com/apparatus/fuge">Fuge&lt;/a> is very clever, and there is also the option of running orchestration locally as is the case with something like MiniKube. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>Google Kubernetes Engine, a managed service from Google Cloud Platform for Kubernetes: &lt;a href="https://cloud.google.com/kubernetes-engine/">https://cloud.google.com/kubernetes-engine/&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>Amazon Elastic Container Services for Kubernetes, a managed service from Amazon Web Services for Kubernetes: &lt;a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/&lt;/a> &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 3: Getting Help</title><link>https://dwmkerr.com/effective-shell-part-3-getting-hepl/</link><pubDate>Tue, 19 Dec 2017 09:05:18 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-3-getting-hepl/</guid><description>&lt;p>This is the third part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series - practical examples of ways to be more efficient with everyday tasks in a shell.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article I'll show you how to quickly get help when working with tools in the shell, without disrupting your flow!&lt;/p>
&lt;h2 id="getting-help-is-important">Getting Help is Important!&lt;/h2>
&lt;p>If you are trying to be more effective when using the shell, it is crucial to know how to quickly look things up.&lt;/p>
&lt;p>There'll be many circumstances where you'll need to open a browser to search for help, but there's also a wealth of information only a few keystrokes away. Looking up parameters, checking how to run commads, C library docs or useful information like ASCII charts are available directly in the system.&lt;/p>
&lt;p>Before we look at the standard way of accessing documentation on unix-like systems, which is the &lt;code>man&lt;/code> command, I'm going to introduce &lt;a href="https://github.com/tldr-pages/tldr">&lt;code>tldr&lt;/code>&lt;/a>.&lt;/p>
&lt;p>Nine times out of ten I get the help I need in a few seconds with &lt;code>tldr&lt;/code>, so if you take only one thing away from the article, take the first section. Then if you want to learn more about the system manuals, read on!&lt;/p>
&lt;h2 id="tldr">tl;dr&lt;/h2>
&lt;p>Let's say I need to find and replace some text in a file. I know I can do this with the &lt;code>sed&lt;/code> command, but have forgotten the syntax.&lt;/p>
&lt;p>All I need to do is run &lt;code>tldr sed&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/tldr-sed.png" alt="tldr sed screenshot">&lt;/p>
&lt;p>The first example is exactly what I'm looking for. Now for any more detail than a few basic examples, I'm going to have to go to the manual, but it's overkill for the basics. Here's what &lt;code>man sed&lt;/code> shows me:&lt;/p>
&lt;p>&lt;img src="images/man-sed.png" alt="sed manpage">&lt;/p>
&lt;p>And this is just page one of six! There's a &lt;em>lot&lt;/em> of detail, which is great sometimes, but for a quick lookup, &lt;code>tldr&lt;/code> is perfect.&lt;/p>
&lt;p>You can install the &lt;a href="https://github.com/tldr-pages/tldr">&lt;code>tldr&lt;/code>&lt;/a> tool with &lt;code>npm install -g tldr&lt;/code>. It's open source and community maintained.&lt;/p>
&lt;p>Now a lot of the time, you are still going to need more help or more detail. For the rest of the article, we'll dive a bit deeper into &lt;code>man&lt;/code>, the system manual pages.&lt;/p>
&lt;h2 id="understanding-man">Understanding &amp;lsquo;man&amp;rsquo;&lt;/h2>
&lt;p>Most tools you encounter in the shell have manual pages available. Many people will be familiar with the &lt;code>man&lt;/code> command to get help on a tool, but let's take a look in a bit more detail, there's actually a lot more available than just the documentation for common commands.&lt;/p>
&lt;h3 id="getting-help-on-a-command">Getting help on a command&lt;/h3>
&lt;p>The most basic way to get help on a command is with &lt;code>man&lt;/code>. Here's an example:&lt;/p>
&lt;pre>&lt;code>$ man cp
CP(1) BSD General Commands Manual CP(1)
NAME
cp -- copy files
SYNOPSIS
cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file target_file
cp [-R [-H | -L | -P]] [-fi | -n] [-apvX] source_file ...
target_directory
DESCRIPTION
In the first synopsis form, the cp utility copies the contents of the
source_file to the target_file. In the second synopsis form, the con-
tents of each named source_file is copied to the destination
target_directory. The names of the files themselves are not changed. If
cp detects an attempt to copy a file to itself, the copy will fail.
...
&lt;/code>&lt;/pre>&lt;p>The &lt;code>man&lt;/code> command opens the manual for the given tool. These manuals should contain all command line options and details of how to use the tool.&lt;/p>
&lt;p>You can scroll up and down through the content with the arrow keys, this is because the information is presented in the shell &lt;em>pager&lt;/em>, which is a tool for looking through content which might not easily fit on a screen.&lt;/p>
&lt;h3 id="using-the-pager">Using the pager&lt;/h3>
&lt;p>The first thing you might notice is that you can move through the manual pages with the arrow keys.&lt;/p>
&lt;p>Manpages are just text files, and &lt;code>man&lt;/code> opens them in a pager tool, which is what is providing the keyboard interface to look through the file.&lt;/p>
&lt;p>On most systems, the pager will be the &lt;code>less&lt;/code> program. There are lots of commands you can use to navigate through files with &lt;code>less&lt;/code>, but the bare essentials are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>d&lt;/code> - Scroll down half a page&lt;/li>
&lt;li>&lt;code>u&lt;/code> - Scroll up half a page&lt;/li>
&lt;li>&lt;code>j&lt;/code> / &lt;code>k&lt;/code> - Scroll down or up a line. You can also use the arrow keys for this&lt;/li>
&lt;li>&lt;code>q&lt;/code> - Quit&lt;/li>
&lt;li>&lt;code>/&amp;lt;search&amp;gt;&lt;/code> - Search for text&lt;/li>
&lt;li>&lt;code>n&lt;/code> - When searching, find the next occurrence&lt;/li>
&lt;li>&lt;code>N&lt;/code> - When searching, find the previous occurrence&lt;/li>
&lt;/ul>
&lt;p>There are &lt;em>many&lt;/em> other commands, but the set above is normally what I find myself using the most.&lt;/p>
&lt;p>If you are interested, you can actually see what your pager is with the command below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">$ echo $PAGER
less
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>$PAGER&lt;/code> environment variable is used to tell the shell what program to use for paging. More details are found with &lt;code>man man&lt;/code>.&lt;/p>
&lt;p>You can put any text content into your pager - try this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">ls -al /usr/bin | less
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This lists the contents of the &lt;code>/usr/bin&lt;/code> folder, piping the output to &lt;code>less&lt;/code> so we can easily scroll through it.&lt;/p>
&lt;p>There are alternative pagers available (on many Unix-y systems you'll have &lt;code>less&lt;/code>, &lt;code>more&lt;/code> and &lt;code>most&lt;/code>) but in general you'll normally get what you need with &lt;code>less&lt;/code>.&lt;/p>
&lt;h3 id="whats-with-the-numbers">What's with the numbers?&lt;/h3>
&lt;p>You'll often see tools referred to in manpages with numbers after them. Take a look at &lt;code>man less&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/numbers.png" alt="Screenshot of numbers">&lt;/p>
&lt;p>The number is the manual &lt;strong>Section Number&lt;/strong>. The different sections of the manual are documented be found on most unix-like systems in &lt;code>man&lt;/code>'s documentation, which you can check by running &lt;code>man man&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Here's what you'd get on Ubuntu 16:&lt;/p>
&lt;p>| 1 | Executable programs or shell commands |
| 2 | System calls (functions provided by the kernel) |
| 3 | Library calls (functions within program libraries) |
| 4 | Special files (usually found in /dev) |
| 5 | File formats and conventions eg /etc/passwd |
| 6 | Games |
| 7 | Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7) |
| 8 | System administration commands (usually only for root) |
| 9 | Kernel routines [Non standard] |&lt;/p>
&lt;p>We'll go through the setions in detail shorltly.&lt;/p>
&lt;p>You can specifically choose &lt;em>which&lt;/em> section of the manual you are looking in by using:&lt;/p>
&lt;pre>&lt;code>man &amp;lt;section&amp;gt; &amp;lt;search&amp;gt;
&lt;/code>&lt;/pre>&lt;p>You can also get more information about the sections themselves by opening up the &lt;code>intro&lt;/code> page. For example:&lt;/p>
&lt;pre>&lt;code>$ man 1 intro
INTRO(1) BSD General Commands Manual INTRO(1)
NAME
intro -- introduction to general commands (tools and utilities)
DESCRIPTION
Section one of the manual contains most of the commands which comprise...
&lt;/code>&lt;/pre>&lt;p>Why would you do this, and why would you care? A few examples from each section show how this can be quite useful to know about.&lt;/p>
&lt;h4 id="section-1-programs-and-shell-commands">Section 1: Programs and Shell Commands&lt;/h4>
&lt;p>These are programs, probably what you are going to be looking up most regularly! For example, &lt;code>man 1 time&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>TIME(1) BSD General Commands Manual TIME(1)
NAME
time -- time command execution
SYNOPSIS
time [-lp] utility
DESCRIPTION
The time utility executes and times utility. After the utility finishes, time writes the total time
elapsed, the time consumed by system overhead, and the time used to execute utility to the standard
error stream. Times are reported in seconds.
...
&lt;/code>&lt;/pre>&lt;h4 id="section-2-system-calls">Section 2: System Calls&lt;/h4>
&lt;p>You'll probably not use this section unless you are doing systems programming&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. This section contains info on the avaiable Linux Kernel system calls. For example, running &lt;code>man 2 chown&lt;/code> gives:&lt;/p>
&lt;pre>&lt;code>CHOWN(2) BSD System Calls Manual CHOWN(2)
NAME
chown, fchown, lchown, fchownat -- change owner and group of a file
SYNOPSIS
#include &amp;lt;unistd.h&amp;gt;
int
chown(const char *path, uid_t owner, gid_t group);
...
&lt;/code>&lt;/pre>&lt;h4 id="section-3-library-calls">Section 3: Library Calls&lt;/h4>
&lt;p>These are the manpages for the C standard library functions. For example, &lt;code>man 3 time&lt;/code>:&lt;/p>
&lt;pre>&lt;code>TIME(3) BSD Library Functions Manual TIME(3)
NAME
time -- get time of day
LIBRARY
Standard C Library (libc, -lc)
SYNOPSIS
#include &amp;lt;time.h&amp;gt;
time_t
time(time_t *tloc);
...
&lt;/code>&lt;/pre>&lt;p>Here we can see why the sections are important to know about.&lt;/p>
&lt;p>Running &lt;code>man time&lt;/code> would &lt;em>not&lt;/em> open the page above, because &lt;code>man&lt;/code> searches the library in ascending section order, meaning that it actually finds &lt;code>time(1)&lt;/code> and shows the pages for the &lt;code>time&lt;/code> program, not the &lt;code>time&lt;/code> C library call.&lt;/p>
&lt;p>Because of the potential ambiguity of names if no section number is included, in lots of Linux documentation you'll see the man section number written next to library calls, system calls, programs and so on (things will refer to &lt;code>sed(1)&lt;/code> or &lt;code>time(3)&lt;/code> for example.&lt;/p>
&lt;h4 id="section-4-devices">Section 4: Devices&lt;/h4>
&lt;p>This section deals with the special devices which live in the &lt;code>/dev/*&lt;/code> folder. For example, running &lt;code>man 4 random&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>RANDOM(4) BSD Kernel Interfaces Manual RANDOM(4)
NAME
random , urandom -- random data source devices.
SYNOPSIS
pseudo-device random
DESCRIPTION
The random device produces uniformly distributed random byte values of
potentially high quality.
...
&lt;/code>&lt;/pre>&lt;p>Again, we see that section numbers can be important. If you just run &lt;code>man random&lt;/code>, you'll see:&lt;/p>
&lt;pre>&lt;code>RANDOM(3) BSD Library Functions Manual RANDOM(3)
NAME
initstate, random, setstate, srandom, srandomdev -- better random num-
ber generator; routines for changing generators
LIBRARY
Standard C Library (libc, -lc)
SYNOPSIS
#include &amp;lt;stdlib.h&amp;gt;
char *
initstate(unsigned seed, char *state, size_t size);
long
random(void);
...
&lt;/code>&lt;/pre>&lt;p>Which is the manpage for &lt;code>random(3)&lt;/code>, which is C library function, not the &lt;code>/dev/random&lt;/code> file!&lt;/p>
&lt;h4 id="section-5-file-formats">Section 5: File Formats&lt;/h4>
&lt;p>This section details special files in the system. For example, &lt;code>man 5 crontab&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>CRONTAB(5) BSD File Formats Manual CRONTAB(5)
NAME
crontab -- tables for driving cron
DESCRIPTION
A crontab file contains instructions to the cron(8) daemon of the gen-
eral form: ``run this command at this time on this date''. Each user
has their own crontab, and commands in any given crontab will be exe-
cuted as the user who owns the crontab. Uucp and News will usually
have their own crontabs, eliminating the need for explicitly running
su(1) as part of a cron command.
...
&lt;/code>&lt;/pre>&lt;p>Which describes the crontab file used to define scheduled tasks. Again, this is different to &lt;code>man crontab&lt;/code> which would document &lt;code>crontab(1)&lt;/code>. Similarly, &lt;code>man 5 passwd&lt;/code> is going to show something quite different to &lt;code>man passwd&lt;/code>.&lt;/p>
&lt;h4 id="section-6-games">Section 6: Games&lt;/h4>
&lt;p>Nothing says it better than &lt;code>man 6 intro&lt;/code> itself (this'll not work on a Mac sadly, but try it on another Linux system):&lt;/p>
&lt;pre>&lt;code>...
DESCRIPTION
Section 6 of the manual describes all the games and funny little programs available on the system.
...
&lt;/code>&lt;/pre>&lt;p>There are probably a few silly programs available on your system, here you'll find their manuals. For example, &lt;code>man 6 banner&lt;/code> on a Mac shows:&lt;/p>
&lt;pre>&lt;code>BANNER(6) BSD Games Manual BANNER(6)
NAME
banner -- print large banner on printer
SYNOPSIS
banner [-d] [-t] [-w width] message ...
DESCRIPTION
Banner prints a large, high quality banner on the standard output. If
the message is omitted, it prompts for and reads one line of its stan-
dard input.
...
&lt;/code>&lt;/pre>&lt;p>This section is going to be highly dependent on your OS!&lt;/p>
&lt;h4 id="section-7-miscellaneous">Section 7: Miscellaneous&lt;/h4>
&lt;p>This is where you'll find additional assorted documentation. For example, &lt;code>man 7 ascii&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>ASCII(7) BSD Miscellaneous Information Manual ASCII(7)
NAME
ascii -- octal, hexadecimal and decimal ASCII character sets
DESCRIPTION
The octal set:
000 nul 001 soh 002 stx 003 etx 004 eot 005 enq 006 ack 007 bel
...
&lt;/code>&lt;/pre>&lt;h4 id="section-8-system-commands">Section 8: System Commands&lt;/h4>
&lt;p>We've actually already seen one of these commands mentioned, in the manpage for &lt;code>crontab(5)&lt;/code> it mentions &lt;code>cron(8)&lt;/code>. Let's see, with &lt;code>man 8 cron&lt;/code>:&lt;/p>
&lt;pre>&lt;code>CRON(8) BSD System Manager's Manual CRON(8)
NAME
cron -- daemon to execute scheduled commands (Vixie Cron)
SYNOPSIS
cron [-s] [-o] [-x debugflag[,...]]
&lt;/code>&lt;/pre>&lt;p>These are commands which sysadmins would normally run. You might open section eight unexpectedly, for example &lt;code>man chmod&lt;/code> will open &lt;code>chmod(1)&lt;/code>, but &lt;code>man chown&lt;/code> will open &lt;code>chown(8)&lt;/code>, as it is a system command.&lt;/p>
&lt;p>Some distributions might vary for Section Nine. On my Mac it contains information about the kernel interfaces, a C style guide and some more.&lt;/p>
&lt;h4 id="getting-the-index-of-manual-section">Getting the Index of Manual Section&lt;/h4>
&lt;p>Manpages are just files on the filesystem, so you can get the index of a section just by looking in the appropriate folder.&lt;/p>
&lt;p>For example, to index the available system calls, try &lt;code>ls /usr/share/man/man2&lt;/code>:&lt;/p>
&lt;pre>&lt;code>EV_SET.2
FD_CLR.2
FD_COPY.2
FD_ISSET.2
FD_SET.2
FD_ZERO.2
_exit.2
accept.2
access.2
acct.2
...
&lt;/code>&lt;/pre>&lt;p>This is quick and easy way to see what sort of entries you have on your system. If you want to work out where an entry lives, use the &lt;code>-w&lt;/code> flag:&lt;/p>
&lt;pre>&lt;code>$ man -w printf
/usr/share/man/man1/printf.1
&lt;/code>&lt;/pre>&lt;h3 id="searching-the-manual">Searching the Manual&lt;/h3>
&lt;p>You can search the manpage titles and summaries with &lt;code>man -k&lt;/code>. For example, &lt;code>man -k cpu&lt;/code> shows:&lt;/p>
&lt;pre>&lt;code>cpuwalk.d(1m) - Measure which CPUs a process runs on. Uses DTrace
dispqlen.d(1m) - dispatcher queue length by CPU. Uses DTrace
gasm(n), grammar::me::cpu::gasm(n) - ME assembler
&lt;/code>&lt;/pre>&lt;p>You can find more advanced options for searching by using your newfound &lt;code>man&lt;/code> skills on &lt;code>man&lt;/code> itself.&lt;/p>
&lt;h2 id="thats-enough">That's Enough!&lt;/h2>
&lt;p>I'd recommend &lt;code>tldr&lt;/code> as a first-call for checking to see how to use a command.&lt;/p>
&lt;p>&lt;code>man&lt;/code> is a powerful tool to dive deeper into how programs and components of the system work. Like many tools which have been around for a long time, there's a lot you can do with &lt;code>man&lt;/code>. Much of it you'll likely never need, so I've tried to keep this article to the basics.&lt;/p>
&lt;p>Understanding manpage sections is useful - you'll see them referenced again and again in documentation on the system and online.&lt;/p>
&lt;p>I hope this helps you save some time when you are working! Please let me know in the comments if you have any questions or thoughts.&lt;/p>
&lt;p>You can also check out the &lt;a href="https://github.com/dwmkerr/effective-shell">rest of the effective shell series&lt;/a>.&lt;/p>
&lt;h2 id="appendix-dash">Appendix: Dash&lt;/h2>
&lt;p>As a final note, if you find yourself using &lt;code>man&lt;/code> a lot because you work offline (I fly a lot so find it very helpful when on a plane with no WiFi), you should also look at &lt;em>Dash&lt;/em>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Dash is simply an offline documentation aggregator. It can download online manuals for many, many different programming languages, frameworks, technologies and so on. I actually have a &lt;code>vim&lt;/code> keyboard command to open the word under the cursor in dash, with the documentation automatically set based on the type of the file.&lt;/p>
&lt;p>This is super-useful if you are offline at lot and need more sophisticated offline documentation. You can find out more about it at &lt;a href="https://kapeli.com/dash">https://kapeli.com/dash&lt;/a>.&lt;/p>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Weirdly satisfying to run. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Which it is always fun to try if you get the chance, and a great way to learn more about the fundamentals of the operating system. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Dash is a paid product. Full disclosure - I don't get any money from them or anyone else to write about anything, all content is 100% based on my experiences. I don't run ads on my site either. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Integrating OpenShift and Splunk for Docker Container Logging</title><link>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</link><pubDate>Sun, 29 Oct 2017 07:15:04 +0000</pubDate><guid>https://dwmkerr.com/integrating-openshift-and-splunk-for-logging/</guid><description>&lt;p>In this article I'm going to show you how to set up OpenShift to integrate with Splunk for logging in a Docker container orchestration environment.&lt;/p>
&lt;p>These techniques could easily be adapted for a standard Kubernetes installation as well!&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>The techniques used in this article are based on the &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging">Kubernetes Logging Cluster Administration Guide&lt;/a>. I also found Jason Poon's article &lt;a href="http://jasonpoon.ca/2017/04/03/kubernetes-logging-with-splunk/">Kubernetes Logging with Splunk&lt;/a> very helpful.&lt;/p>
&lt;p>First, clone the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">Terraform AWS OpenShift&lt;/a> repo:&lt;/p>
&lt;pre>&lt;code>git clone git@github.com:dwmkerr/terraform-aws-openshift
&lt;/code>&lt;/pre>&lt;p>This repo can be used to create a vanilla OpenShift cluster. I'm adding &amp;lsquo;recipes&amp;rsquo; to the project, which will allow you to mix in more features (but still keep the main codebase clean). For now, let's merge in the &amp;lsquo;splunk&amp;rsquo; recipe:&lt;/p>
&lt;pre>&lt;code>cd terraform-aws-openshift
git pull origin recipes/splunk
&lt;/code>&lt;/pre>&lt;p>Pulling this recipe in adds the extra config and scripts required to set up Splunk&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Now we've got the code, we can get started!&lt;/p>
&lt;h2 id="create-the-infrastructure">Create the Infrastructure&lt;/h2>
&lt;p>To create the cluster, you'll need to install the &lt;a href="https://aws.amazon.com/cli/">AWS CLI&lt;/a> and log in, and install &lt;a href="https://www.terraform.io/downloads.html">Terraform&lt;/a>.&lt;/p>
&lt;p>Before you continue, &lt;font color="red">&lt;strong>be aware&lt;/strong>&lt;/font>: the machines on AWS we'll create are going to run to about $250 per month:&lt;/p>
&lt;p>&lt;img src="images/aws-cost.png" alt="AWS Cost Calculator">&lt;/p>
&lt;p>Once you are logged in with the AWS CLI just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make infrastructure
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You'll be asked to specify a region:&lt;/p>
&lt;p>&lt;img src="images/region.png" alt="Specify Region">&lt;/p>
&lt;p>Any &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">AWS region&lt;/a> will work fine, use &lt;code>us-east-1&lt;/code> if you are not sure.&lt;/p>
&lt;p>It'll take about 5 minutes for Terraform to build the required infrastructure, which looks like this:&lt;/p>
&lt;p>&lt;img src="images/splunk-architecture.png" alt="AWS Infrastructure">&lt;/p>
&lt;p>Once it's done you'll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/apply-complete.png" alt="Apply Complete">&lt;/p>
&lt;p>The infrastructure is ready! A few of the most useful parameters are shown as output variables. If you log into AWS you'll see our new instances, as well as the VPC, network settings etc etc:&lt;/p>
&lt;p>&lt;img src="images/aws.png" alt="AWS">&lt;/p>
&lt;h2 id="installing-openshift">Installing OpenShift&lt;/h2>
&lt;p>Installing OpenShift is easy:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make openshift
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will take quite some time to run (sometimes up to 30 minutes). Once it is complete you'll see a message like this:&lt;/p>
&lt;p>&lt;img src="images/openshift-complete.png" alt="OpenShift Installation Complete">&lt;/p>
&lt;p>You can now open the OpenShift console. Use the public address of the master node (which you can get with &lt;code>$(terraform output master-url)&lt;/code>), or just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make browse-openshift
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The default username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You'll see we have a clean installation and are ready to create our first project:&lt;/p>
&lt;p>&lt;img src="images/welcome-to-openshift.png" alt="Welcome to OpenShift">&lt;/p>
&lt;p>Close the console for now.&lt;/p>
&lt;h2 id="installing-splunk">Installing Splunk&lt;/h2>
&lt;p>You've probably figured out the pattern by now&amp;hellip;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make splunk
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once this command is complete, you can open the Splunk console with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make browse-splunk
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again the username and password is &lt;code>admin&lt;/code> and &lt;code>123&lt;/code>. You can change the password on login, or leave it:&lt;/p>
&lt;p>&lt;img src="images/splunk-home.png" alt="Splunk Login">&lt;/p>
&lt;p>You can close the Splunk console now, we'll come back to it shortly.&lt;/p>
&lt;h2 id="demoing-splunk-and-openshift">Demoing Splunk and OpenShift&lt;/h2>
&lt;p>To see Splunk and OpenShift in action, it helps to have some kind of processing going on in the cluster. You can create a very basic sample project which will spin up two nodes which just write a counter every second as a way to get something running:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make sample
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will create a simple &amp;lsquo;counter&amp;rsquo; service:&lt;/p>
&lt;p>&lt;img src="images/counter-service.png" alt="Screenshot: The counter service">&lt;/p>
&lt;p>We can see the logs in OpenShift:&lt;/p>
&lt;p>&lt;img src="images/counter-service-logs.png" alt="Screenshot: The counter service logs">&lt;/p>
&lt;p>Almost immediately you'll be able to see the data in Splunk:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk-data-summary.png" alt="Screenshot: The Splunk data explorer">&lt;/p>
&lt;p>And because of the way the log files are named, we can even rip out the namespace, pod, container and id:&lt;/p>
&lt;p>&lt;img src="images/counter-service-splunk.png" alt="Screenshot: Counter service splunk">&lt;/p>
&lt;p>That's it! You have OpenShift running, Splunk set up and automatically forwarding of all container logs. Enjoy!&lt;/p>
&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>I've tried to keep the setup as simple as possible. Here's how it works.&lt;/p>
&lt;h3 id="how-log-files-are-written">How Log Files Are Written&lt;/h3>
&lt;p>The Docker Engine has a &lt;a href="https://docs.docker.com/engine/admin/logging/overview/">log driver&lt;/a> which determines how container logs are handled&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>. It defaults to the &lt;code>json-file&lt;/code> driver, which means that logs are written as a json file to:&lt;/p>
&lt;pre>&lt;code>/var/lib/docker/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;p>Or visually:&lt;/p>
&lt;p>&lt;img src="images/logging-docker-1.png" alt="Diagram: How Docker writes log files">&lt;/p>
&lt;p>Normally we wouldn't touch this file, in theory it is supposed to be used internally&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> and we would use &lt;code>docker logs &amp;lt;container-id&amp;gt;&lt;/code>.&lt;/p>
&lt;p>In theory, all we need to do is use a &lt;a href="http://docs.splunk.com/Documentation/Forwarder/7.0.0/Forwarder/Abouttheuniversalforwarder">Splunk Forwarder&lt;/a> to send this file to our indexer. The only problem is that we only get the container ID from the file name, finding the right container ID for your container can be a pain. However, we are running on Kubernetes, which means the picture is a little different&amp;hellip;&lt;/p>
&lt;h3 id="how-log-files-are-written---on-kubernetes">How Log Files Are Written - on Kubernetes&lt;/h3>
&lt;p>When running on Kubernetes, things are little different. On machines with &lt;code>systemd&lt;/code>, the log driver for the docker engine is set to &lt;code>journald&lt;/code> (see &lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">Kubernetes - Logging Architecture&lt;/a>.&lt;/p>
&lt;p>It &lt;em>is&lt;/em> possible to forward &lt;code>journald&lt;/code> to Splunk, but only by streaming it to a file and then forwarding the file. Given that we need to use a file as an intermediate, it seems easier just to change the driver back to &lt;code>json-file&lt;/code> and forward that.&lt;/p>
&lt;p>So first, we configure the docker engine to use &lt;code>json-file&lt;/code> (see &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/blob/recipes/splunk/scripts/postinstall-master.sh">this file&lt;/a>):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sed -i &lt;span style="color:#e6db74">&amp;#39;/OPTIONS=.*/c\OPTIONS=&amp;#34;--selinux-enabled --insecure-registry 172.30.0.0/16 --log-driver=json-file --log-opt max-size=1M --log-opt max-file=3&amp;#34;&amp;#39;&lt;/span> /etc/sysconfig/docker
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we just change the options to default to the &lt;code>json-file&lt;/code> driver, with a max file size of 1MB (and maximum of three files, so we don't chew all the space on the host).&lt;/p>
&lt;p>Now the cool thing about Kubernetes is that it creates symlinks to the log files, which have much more descriptive names:&lt;/p>
&lt;p>&lt;img src="images/logging-k8s.png" alt="Symlink diagram">&lt;/p>
&lt;p>We still have the original container log, in the same location. But we also have a pod container log (which is a symlink to the container log) and another container log, which is a symlink to the pod container log.&lt;/p>
&lt;p>This means we can read the container log, and extract some really useful information from the file name. The container log file name has the following format:&lt;/p>
&lt;pre>&lt;code>/var/log/containers/{container-id}/{container-id}-json.log
&lt;/code>&lt;/pre>&lt;h3 id="how-log-files-are-read">How Log Files Are Read&lt;/h3>
&lt;p>Now that we are writing the log files to a well defined location, reading them is straightforward. The diagram below shows how we use a splunk-forwarder to complete the picture:&lt;/p>
&lt;p>&lt;img src="images/how-logs-are-read.png" alt="Diagram: How logs are read">&lt;/p>
&lt;p>First, we create a DaemonSet, which ensures we run a specific pod on every node.&lt;/p>
&lt;p>The DaemonSet runs with a new account which has the &amp;lsquo;any id&amp;rsquo; privilege, allowing it to run as root. We then mount the log folders into the container (which are owned by root, which is why our container needs these extra permissions to read the files).&lt;/p>
&lt;p>The pod contains a splunk-forwarder container, which is configured to monitor the &lt;code>/var/log/containers&lt;/code> folder. It also monitors the docker socket, allowing us to see docker events. The forwarder is also configured with the IP address of the Splunk Indexer.&lt;/p>
&lt;h2 id="footnotes">Footnotes&lt;/h2>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>As a reference, you can also see the recipe pull request to see what changes from a &amp;lsquo;vanilla&amp;rsquo; installation to add Splunk: &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/pull/16">Splunk Recipe Pull Request&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>It is useful to check the documentation on logging drivers for Docker. See &lt;a href="https://docs.docker.com/engine/admin/logging/overview/#supported-logging-drivers">Configure Logging Drivers&lt;/a> and &lt;a href="https://docs.docker.com/engine/extend/plugins_logging/">Docker Log Driver Plugins&lt;/a>. It is possible to create custom log drivers. However, at the time of writing only the journald and json-file log drivers will work with the integrated logging view in OpenShift. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Effective Shell Part 2: Become a Clipboard Gymnast</title><link>https://dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/</link><pubDate>Tue, 10 Oct 2017 09:57:54 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/</guid><description>&lt;p>This is the second part of my &lt;a href="https://github.com/dwmkerr/effective-shell">Effective Shell&lt;/a> series, which contains practical tips for using the shell to help with every day tasks and be more efficient:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>In this article I'll show you how you can use the shell as an efficient tool to compliment how you use the clipboard.&lt;/p>
&lt;p>&lt;em>Note for Linux Users: In this article I'll use the &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> commands to access the clipboard, which are available on a Mac only. To get access to the same commands on other platforms, check &lt;a href="#appendixclipboardaccessonlinux">Appendix: Clipboard Access on Linux&lt;/a>&lt;/em>.&lt;/p>
&lt;h2 id="use-the-shell-on-the-clipboard">Use the Shell on the Clipboard&lt;/h2>
&lt;p>You can easily use shell commands on the contents of your clipboard. Just use &lt;code>pbpaste&lt;/code> to output the clipboard, run the output through some commands, then use &lt;code>pbcopy&lt;/code> to copy the result.&lt;/p>
&lt;p>Try copying the following text:&lt;/p>
&lt;pre>&lt;code>Kirk Van Houten
Timothy Lovejoy
Artie Ziff
&lt;/code>&lt;/pre>&lt;p>Then in the shell, run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">pbpaste
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You should see the contents of the clipboard. Now we'll look at some ways that shell access to the clipboard can help with common tasks.&lt;/p>
&lt;h2 id="removing-formatting">Removing Formatting&lt;/h2>
&lt;p>Don't you hate it when you have to copy formatted text and don't have an easy way to paste it as &lt;em>unformatted&lt;/em> text? Here's an example, I want to copy this Wikipedia page on &amp;lsquo;bash&amp;rsquo;, and paste it into a Word document:&lt;/p>
&lt;p>&lt;img src="images/strip-formatting-before.png" alt="Copying and pasting with formatting">&lt;/p>
&lt;p>Many programs have a shortcut to paste the contents of the clipboard (such as &amp;lsquo;command + shift + v&amp;rsquo;) but if you are like me you might find yourself pasting &lt;em>into&lt;/em> a plain text editor just to copy &lt;em>out&lt;/em> the plain text.&lt;/p>
&lt;p>If you just run the command &lt;code>pbpaste | pbcopy&lt;/code>, you can easily strip the formatting:&lt;/p>
&lt;p>&lt;img src="images/strip-formatting-after-2.png" alt="Stripping formatting from the clipboard">&lt;/p>
&lt;p>We're just piping out the clipboard (which ends up as plain text, cause we're in a terminal!) and then piping that plain text &lt;em>back into the clipboard&lt;/em>, replacing the formatted text which was there before.&lt;/p>
&lt;p>This little trick can be very useful. But we can use the same pattern to quickly manipulate the contents of the clipboard in more sophisticated ways.&lt;/p>
&lt;h2 id="manipulating-text">Manipulating Text&lt;/h2>
&lt;p>Let's say someone has emailed me a list of people I need to invite to an event:&lt;/p>
&lt;p>&lt;img src="images/email_list_excel.png" alt="Email List">&lt;/p>
&lt;p>The problem is:&lt;/p>
&lt;ol>
&lt;li>The list is in Excel and is formatted&lt;/li>
&lt;li>The list has duplicates&lt;/li>
&lt;li>I need to turn each name into an email address like &lt;a href="mailto:'Artie_Ziff@simpsons.com">'Artie_Ziff@simpsons.com&lt;/a>&amp;rsquo;&lt;/li>
&lt;/ol>
&lt;p>And I want to email everyone quickly.&lt;/p>
&lt;p>We can quickly handle this task without leaving the shell.&lt;/p>
&lt;p>Copy the raw text below if you want to try out the same commands and follow along:&lt;/p>
&lt;pre>&lt;code>Artie Ziff
Kirk Van Houten
Timothy Lovejoy
Artie Ziff
Nick Riviera
Seymore Skinner
Hank Scorpio
Timothy Lovejoy
John Frink
Cletus Spuckler
Ruth Powers
Artie Ziff
Agnes Skinner
Helen Lovejoy
&lt;/code>&lt;/pre>&lt;p>First, we copy the text to the clipboard.&lt;/p>
&lt;p>Now we can paste and sort:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort
Agnes Skinner
Artie Ziff
Artie Ziff
Artie Ziff
Cletus Spuckler
Hank Scorpio
Helen Lovejoy
John Frink
Kirk Van Houten
Nick Riviera
Ruth Powers
Seymore Skinner
Timothy Lovejoy
Timothy Lovejoy
&lt;/code>&lt;/pre>&lt;p>Then remove the duplicates:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq
Agnes Skinner
Artie Ziff
Cletus Spuckler
Hank Scorpio
Helen Lovejoy
John Frink
Kirk Van Houten
Nick Riviera
Ruth Powers
Seymore Skinner
Timothy Lovejoy
&lt;/code>&lt;/pre>&lt;p>Replace the underscore with an ampersand:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr &amp;quot; &amp;quot; &amp;quot;_&amp;quot;
Agnes_Skinner
Artie_Ziff
Cletus_Spuckler
Hank_Scorpio
Helen_Lovejoy
John_Frink
Kirk_Van_Houten
Nick_Riviera
Ruth_Powers
Seymore_Skinner
Timothy_Lovejoy
&lt;/code>&lt;/pre>&lt;p>Then add the final part of the email address:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr &amp;quot; &amp;quot; &amp;quot;_&amp;quot; | sed 's/$/@simpsons.com/'
Agnes_Skinner@simpsons.com
Artie_Ziff@simpsons.com
Cletus_Spuckler@simpsons.com
Hank_Scorpio@simpsons.com
Helen_Lovejoy@simpsons.com
John_Frink@simpsons.com
Kirk_Van_Houten@simpsons.com
Nick_Riviera@simpsons.com
Ruth_Powers@simpsons.com
Seymore_Skinner@simpsons.com
Timothy_Lovejoy@simpsons.com
&lt;/code>&lt;/pre>&lt;p>This looks perfect! We can now put the transformed text back onto the clipboard:&lt;/p>
&lt;pre>&lt;code>$ pbpaste | sort | uniq | tr ' ' '_' | sed 's/$/@simpsons.com' | pbcopy
&lt;/code>&lt;/pre>&lt;p>All in all we have the following pipeline:&lt;/p>
&lt;ol>
&lt;li>&lt;code>pbpaste&lt;/code> - output the clipboard&lt;/li>
&lt;li>&lt;code>sort&lt;/code> - order the output&lt;/li>
&lt;li>&lt;code>uniq&lt;/code> - deduplicate the rows&lt;/li>
&lt;li>&lt;code>tr ' ' '_'&lt;/code> - replace spaces with underscores&lt;/li>
&lt;li>&lt;code>sed /$/@simpsons.com&lt;/code> - add the email domain to the end of the row&lt;/li>
&lt;/ol>
&lt;p>Building this in one go is hard, let's look at little more at the pipeline.&lt;/p>
&lt;h2 id="thinking-in-pipelines">Thinking in Pipelines&lt;/h2>
&lt;p>Some of these commands might be unfamiliar, some might not make sense, and you might be thinking &amp;lsquo;how would I remember that&amp;rsquo;. Actually, there are many ways to solve the problem above, this is the one I came up with by &lt;em>iteratively&lt;/em> changing my input text.&lt;/p>
&lt;p>Here's what I mean - you'll see that I actually build a pipeline like this step-by-step:&lt;/p>
&lt;p>&lt;img src="images/pipeline.gif" alt="Animation of the process of building a pipeline">&lt;/p>
&lt;p>You can see in the screenshots that I start simple, and step by step add the stages we need.&lt;/p>
&lt;p>(P.S - if you are wondering how I am jumping backwards and forwards a word at a time, check the last chapter &amp;lsquo;&lt;a href="www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Navigating the Command Line&lt;/a>').&lt;/p>
&lt;p>What we're doing here is only possible because these simple commands all follow &amp;lsquo;the Unix Philosophy&amp;rsquo;. They do one thing well, and each command expects it's input to become the input of &lt;em>another&lt;/em> command later on. Specifically:&lt;/p>
&lt;ol>
&lt;li>The commands are primitive and simple - &lt;code>sort&lt;/code> is sorting a list, &lt;code>uniq&lt;/code> is making elements unique.&lt;/li>
&lt;li>The commands don't produce unnecessary output - &lt;code>sort&lt;/code> doesn't add a header such as &lt;code>Sorted Items&lt;/code>, which is great because otherwise it would clutter our pipeline.&lt;/li>
&lt;li>We are chaining commands together, the output of one becomes the input of another.&lt;/li>
&lt;/ol>
&lt;p>We don't need a command such as &amp;lsquo;Take a muddy list, sort and clean it, then turn pairs of words into an email address&amp;rsquo; - with a few simple &amp;lsquo;workhorse&amp;rsquo; commands we can easily build this functionality ourselves.&lt;/p>
&lt;p>These workhorse commands will be introduced and detailed as we go through the series. We'll also spend a lot more time looking at pipelines.&lt;/p>
&lt;p>I hope this was useful! Please comment if you have any questions or tips. To see further articles as they come out, follow the repo at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>&lt;/p>
&lt;p>Or just follow &lt;a href="https://twitter.com/dwmkerr">@dwmkerr&lt;/a> on Twitter.&lt;/p>
&lt;h1 id="appendix---clipboard-access-on-linux">Appendix - Clipboard Access on Linux&lt;/h1>
&lt;p>If you are using Linux, there is no &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> commands. You can use the &lt;a href="https://linux.die.net/man/1/xclip">&lt;code>xclip&lt;/code>&lt;/a> tool to create equivalent commands.&lt;/p>
&lt;p>First, install &lt;code>xclip&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo apt-get install -y xclip
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then add the following to your &lt;code>.bashrc&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Create mac style aliases for clipboard access.&lt;/span>
alias pbcopy&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;xclip -selection c&amp;#34;&lt;/span>
alias pbpaste&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;xclip -selection c -o&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Obviously you can use any alias you like! The article assumes that &lt;code>pbcopy&lt;/code> and &lt;code>pbpaste&lt;/code> have been used.&lt;/p></description><category>CodeProject</category></item><item><title>Effective Shell Part 1: Navigating the Command Line</title><link>https://dwmkerr.com/effective-shell-part-1-navigating-the-command-line/</link><pubDate>Sun, 11 Jun 2017 23:05:40 +0000</pubDate><guid>https://dwmkerr.com/effective-shell-part-1-navigating-the-command-line/</guid><description>&lt;p>This is the &lt;a href="https://github.com/dwmkerr/effective-shell">first part of a series&lt;/a> I am writing which contains practical tips for using the shell more effectively.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a href="https://www.dwmkerr.com/effective-shell-part-1-navigating-the-command-line/">Part 1: Navigating the Command Line&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-2-become-a-clipboard-gymnast/">Part 2: Become a Clipboard Gymnast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.dwmkerr.com/effective-shell-part-3-getting-hepl/">Part 3: Getting Help&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-4-moving-around/">Part 4: Moving Around&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-part-5-understanding-the-shell/">Part 5: Interlude - Understanding the Shell&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-6-job-control/">Part 6: Everything You Don't Need to Know About Job Control&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dwmkerr.com/effective-shell-7-shell-commands/">Part 7: The Subtleties of Shell Commands&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I can't think of a better place to start than &lt;em>navigating the command line&lt;/em>. As you start to do more and more in the shell, text in the command line can quickly become hard to handle. In this article I'll show some simple tricks for working with the command line more effectively.&lt;/p>
&lt;p>Here's a quick reference diagram, the rest of the article goes into the details!&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/effective-shell">&lt;img src="images/command-line-3.png" alt="command line">&lt;/a>&lt;/p>
&lt;p>This article, examples and diagrams are available at &lt;a href="https://github.com/dwmkerr/effective-shell">github.com/dwmkerr/effective-shell&lt;/a>.&lt;/p>
&lt;!-- TOC depthFrom:2 depthTo:3 withLinks:1 updateOnSave:1 orderedList:0 -->
&lt;ul>
&lt;li>&lt;a href="#basicnavigation">Basic Navigation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#searching">Searching&lt;/a>&lt;/li>
&lt;li>&lt;a href="#editinginplace">Editing In-Place&lt;/a>&lt;/li>
&lt;li>&lt;a href="#clearthescreen">Clear the Screen&lt;/a>&lt;/li>
&lt;li>&lt;a href="#protipallthekeys">Pro Tip: All The Keys!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#protiptransposing">Pro Tip: Transposing!&lt;/a>&lt;/li>
&lt;li>&lt;a href="#closingthoughts">Closing Thoughts&lt;/a>&lt;/li>
&lt;/ul>
&lt;!-- /TOC -->
&lt;h2 id="basic-navigation">Basic Navigation&lt;/h2>
&lt;p>Let's assume we have a very simple command we are writing, which is going to write a quote to a text file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">echo &lt;span style="color:#e6db74">&amp;#34;The trouble with writing fiction is that it has to make sense,
&lt;/span>&lt;span style="color:#e6db74">whereas real life doesn&amp;#39;t. -- Iain M. Banks&amp;#34;&lt;/span> &amp;gt;&amp;gt; quote.txt
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Navigating around long lines of text is a slow process if you are only relying on the arrow keys, so take the time to learn the following shortcuts:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Action&lt;/th>
&lt;th>Shortcut&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Go to beginning / end&lt;/td>
&lt;td>&lt;p>&lt;code>Ctrl + a&lt;/code>, &lt;code>Ctrl + e&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/begin-end.gif" target="_blank">&lt;img src="images/begin-end.gif" alt="begin / end" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Go backwards / forwards one word&lt;/td>
&lt;td>&lt;code>Alt + b&lt;/code> / &lt;code>Alt + f&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/forward-backwards.gif" target="_blank">&lt;img src="images/forward-backwards.gif" alt="backward / forward" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete a word / undo&lt;/td>
&lt;td>&lt;code>Ctrl + w&lt;/code> / &lt;code>Ctrl + -&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-undo.gif" target="_blank">&lt;img src="images/delete-undo.gif" alt="delete / undo" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete next word&lt;/td>
&lt;td>&lt;code>Alt + d&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-next-word.gif" target="_blank">&lt;img src="images/delete-next-word.gif" alt="delete next word" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete all the way to the beginning[^1]&lt;/td>
&lt;td>&lt;code>Ctrl + u&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-to-beginning.gif" target="_blank">&lt;img src="images/delete-to-beginning.gif" alt="delete to beginning" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Delete all the way to the end&lt;/td>
&lt;td>&lt;code>Ctrl + k&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/delete-to-end.gif" target="_blank">&lt;img src="images/delete-to-end.gif" alt="delete to end" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>&lt;/tbody>&lt;/table>
&lt;p>Note that if you are on a Mac, you might need to tweak your console to allow the &amp;lsquo;Alt&amp;rsquo; key to work.&lt;/p>
&lt;p>For iTerm2, go to settings (Command + ,) &amp;gt; Profiles Tab &amp;gt; select the profile you are using &amp;gt; Keys tab. There, you should see Left Option key and Right Option Key with three radio buttons. Select &amp;ldquo;Esc+&amp;rdquo; for the Left Option Key.&lt;/p>
&lt;p>For Terminal, go to Profiles Tab &amp;gt; Keyboard Tab &amp;gt; check &amp;ldquo;Use Option as Meta key&amp;rdquo; at the bottom of the screen.&lt;/p>
&lt;h2 id="searching">Searching&lt;/h2>
&lt;p>Once you have the basic navigation commands down, the next essential is searching. Let's assume we've run the following three commands:&lt;/p>
&lt;pre>&lt;code>$ command1 param1 param2 param3
$ command2 param4 param5 param6
$ command3 param7 param8 param9
&lt;/code>&lt;/pre>&lt;p>You can search backwards or forwards with &lt;code>Ctrl + r&lt;/code> and &lt;code>Ctrl + s&lt;/code>. This will search in the current command and then iteratively through previous commands:&lt;/p>
&lt;p>&lt;img src="images/search-backwards-and-forwards.gif" alt="search backwards and forwards">&lt;/p>
&lt;p>This is useful for searching in the current command, but can be also used to quickly search backwards and forwards through the command history:&lt;/p>
&lt;p>&lt;img src="images/search-commands-backwards-and-forwards-1.gif" alt="search commands backwards and forwards">&lt;/p>
&lt;p>As you type, your command history is searched, the most recent commands coming first. Use the arrow keys to edit the command, press enter to execute it, or &lt;code>Ctrl + g&lt;/code> to cancel the search.&lt;/p>
&lt;p>Here are the same commands applied to the original example:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Action&lt;/th>
&lt;th>Shortcut&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Search backwards / forwards&lt;/td>
&lt;td>&lt;code>Ctrl + r&lt;/code> / Ctrl + s&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-next.gif" target="_blank">&lt;img src="images/search-history-next.gif" alt="find next occurrence" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Run the command&lt;/td>
&lt;td>&lt;code>Enter&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-execute.gif" target="_blank">&lt;img src="images/search-history-execute.gif" alt="execute" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Edit the command&lt;/td>
&lt;td>&lt;code>Right Arrow&lt;/code> / &lt;code>Right Arrow&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-edit.gif" target="_blank">&lt;img src="images/search-history-edit.gif" alt="edit command" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Stop searching&lt;/td>
&lt;td>&lt;code>Ctrl + g&lt;/code>&lt;/td>
&lt;td>&lt;a href="images/search-history-cancel.gif" target="_blank">&lt;img src="images/search-history-cancel.gif" alt="cancel search" style="max-width:100%;">&lt;/a>&lt;/td>
&lt;/tr>&lt;/tbody>&lt;/table>
&lt;h2 id="editing-in-place">Editing In-Place&lt;/h2>
&lt;p>These tips and tricks are helpful, but if you are working with a really long or complex command, you might find it useful just to jump into your favourite editor.&lt;/p>
&lt;p>Use &lt;code>Ctrl + x , Ctrl + e&lt;/code> to edit-in place:&lt;/p>
&lt;p>&lt;img src="images/edit-in-place.gif" alt="edit in place">&lt;/p>
&lt;p>In a later article I'll talk a little more about how to configure the default editor.&lt;/p>
&lt;h2 id="clear-the-screen">Clear the Screen&lt;/h2>
&lt;p>Probably the shortcut I use the most is &lt;code>Ctrl + l&lt;/code>, which clears the screen without trashing your current command. Here's how it looks:&lt;/p>
&lt;p>&lt;img src="images/clear-screen-2.gif" alt="clear screen">&lt;/p>
&lt;h2 id="pro-tip-all-the-keys">Pro Tip: All The Keys!&lt;/h2>
&lt;p>You can use the &lt;code>bindkey&lt;/code> command to see a list of all keyboard shortcuts:&lt;/p>
&lt;pre>&lt;code>$ bindkey
&amp;quot;^@&amp;quot; set-mark-command
&amp;quot;^A&amp;quot; beginning-of-line
&amp;quot;^B&amp;quot; backward-char
&amp;quot;^D&amp;quot; delete-char-or-list
&amp;quot;^E&amp;quot; end-of-line
&amp;quot;^F&amp;quot; forward-char
&amp;quot;^G&amp;quot; send-break
&amp;quot;^H&amp;quot; backward-delete-char
&amp;quot;^I&amp;quot; expand-or-complete
&amp;quot;^J&amp;quot; accept-line
&amp;quot;^K&amp;quot; kill-line
&amp;quot;^L&amp;quot; clear-screen
...
&lt;/code>&lt;/pre>&lt;p>This is an extremely useful command to use if you forget the specific keyboard shortcuts, or just want to see the shortcuts which are available.&lt;/p>
&lt;h2 id="pro-tip-transposing">Pro Tip: Transposing!&lt;/h2>
&lt;p>If you've mastered all of the commands here and feel like adding something else to your repertoire, try this:&lt;/p>
&lt;p>&lt;img src="images/transpose-word.gif" alt="transpose-word">&lt;/p>
&lt;p>The &lt;code>Alt + t&lt;/code> shortcut will transpose the last two words. Use &lt;code>Ctrl + t&lt;/code> to transpose the last two letters:&lt;/p>
&lt;p>&lt;img src="images/transpose-letters.gif" alt="transpose-letters">&lt;/p>
&lt;p>These were new to me when I was researching for this article. I can't see myself ever being able to remember the commands more quickly than just deleting the last two words or characters and re-typing them, but there you go!&lt;/p>
&lt;h2 id="closing-thoughts">Closing Thoughts&lt;/h2>
&lt;p>If you are ever looking to go deeper, then search the web for &lt;em>GNU Readline&lt;/em>, which is the library used under the hood to handle the command line in many shells. You can actually configure lower level details of how all shells which use readline work, with the &lt;a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html">&lt;code>.inputrc&lt;/code>&lt;/a> configuration file.&lt;/p>
&lt;p>The great thing about learning these shortcuts is that they will work in any prompt which uses GNU Readline. This means everything you've learnt applies to:&lt;/p>
&lt;ol>
&lt;li>Bash&lt;/li>
&lt;li>zsh&lt;/li>
&lt;li>The Python REPL&lt;/li>
&lt;li>The Node.js REPL&lt;/li>
&lt;/ol>
&lt;p>And probably a whole bunch more&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>All of these shortcuts should be familiar to Emacs users. There is in fact a &amp;lsquo;Vi Mode&amp;rsquo; option for readline, which allows you to use vi commands to work with text. You can enter this mode with &lt;code>set -o vi&lt;/code>, I'll likely come back to this in detail in a later article.&lt;/p>
&lt;p>There's a great cheat sheet on emacs readline commands at &lt;a href="http://readline.kablamo.org/emacs.html">readline.kablamo.org/emacs&lt;/a>, which is a very useful reference if you want to dig deeper. For this article I've tried to focus on what I think are the most useful commands (and transpose just so you can show off!).&lt;/p>
&lt;p>Hope that was useful! GIFs were made with &lt;a href="http://www.cockos.com/licecap/">LICEcap&lt;/a>.&lt;/p>
&lt;hr>
&lt;h4 id="footnotes">Footnotes&lt;/h4>
&lt;h4 id="references">References&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/GNU_Readline">Wikipedia: GNU Readline&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/Readline-Init-File.html">GNU Org: Readline Init File&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://readline.kablamo.org/emacs.html">Kablamo.org: Readline Cheat Sheet&lt;/a>&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you know of any more, please let me know and I'll update the article! &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>A utility to help you wait for ports to open</title><link>https://dwmkerr.com/a-utility-to-help-you-wait-for-ports-to-open/</link><pubDate>Thu, 25 May 2017 22:15:00 +0000</pubDate><guid>https://dwmkerr.com/a-utility-to-help-you-wait-for-ports-to-open/</guid><description>&lt;p>There are occasions where you might need to have scripts or commands which wait for TCP/IP ports to open before you continue.&lt;/p>
&lt;p>I've come across this need again and again when working with &lt;a href="https://dwmkerr.com/tag/microservices/">microservices&lt;/a>, to make my life easier I've created a little utility called &lt;a href="https://github.com/dwmkerr/wait-port">wait-port&lt;/a> which will wait for a port to open:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/wait-port">&lt;img src="images/wait-port.gif" alt="Wait Port Screenshot">&lt;/a>&lt;/p>
&lt;p>It's built in Node, the project is open source, open for contributions and ready to use:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/wait-port">github.com/dwmkerr/wait-port&lt;/a>&lt;/p>
&lt;p>Installation and usage is pretty straightforward:&lt;/p>
&lt;pre>&lt;code>$ npm install -g wait-port
wait-port@0.1.4
$ wait-port 8080
Waiting for localhost:8080.....
Connected!
&lt;/code>&lt;/pre>&lt;p>You can also install locally&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>This might be useful if you have a docker-compose workflow where you need to wait for a database to start up, want to run some automated tests against a server which can be slow to start, or have a complex set of interdependent services which need to start up in a specific order.&lt;/p>
&lt;p>I'd be interested to know of any cases where people find this useful, so please share in the comments and I can add a &amp;lsquo;use cases&amp;rsquo; section to the project showing others how they might be able to save some time and energy with the utility!&lt;/p>
&lt;h2 id="the-pure-shell-way">The Pure Shell Way&lt;/h2>
&lt;p>It is actually pretty easy to do this purely in bash. Here's how you can wait for a port to open in a shell script:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#66d9ef">until&lt;/span> nc -w 127.0.0.1 3000; &lt;span style="color:#66d9ef">do&lt;/span> sleep 1; &lt;span style="color:#66d9ef">done&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will be sufficient in many cases, the reason I created the utility is:&lt;/p>
&lt;ol>
&lt;li>I want something which is very readable in scripts (&lt;code>wait-port 3000&lt;/code> to me is more readable).&lt;/li>
&lt;li>I want to be able to specify an overall timeout (i.e. wait for up to 60 seconds) which requires adding more to the script.&lt;/li>
&lt;li>I need a different error code if the overall attempt to wait times out or fails for an unknown reason.&lt;/li>
&lt;li>I want to be able to optionally show some kind of progress (you can use the &lt;code>--output&lt;/code> flag to control the output from &lt;code>wait-port&lt;/code>).&lt;/li>
&lt;li>I know I need a few other features (being able to &amp;lsquo;snooze&amp;rsquo; after the port is opening, i.e. waiting for a little extra time, controllable intervals for trying the port etc, all of which can be easily added).&lt;/li>
&lt;/ol>
&lt;h2 id="testing-tip">Testing Tip!&lt;/h2>
&lt;p>One really useful tip which will be obvious to *nix pros but I wasn't aware of is that you can create a server listening on a port with &lt;code>netcat&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">nc -l &lt;span style="color:#ae81ff">8080&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is just the barest basics of what netcat can do, it's a very powerful tool. This tip makes it very easy to test the &lt;code>wait-port&lt;/code> behaviour.&lt;/p>
&lt;hr>
&lt;h3 id="footnotes">Footnotes&lt;/h3>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I hate installing things globally, if you are like me you'll prefer local usage with something like: npm install wait-port &amp;amp;&amp;amp; ./node_modules/.bin/wait-port :3000&lt;/code> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Tips and Tricks for Beautifully Simple Mobile App CI</title><link>https://dwmkerr.com/tips-and-tricks-for-beautifully-simple-mobile-app-ci/</link><pubDate>Mon, 03 Apr 2017 11:14:58 +0000</pubDate><guid>https://dwmkerr.com/tips-and-tricks-for-beautifully-simple-mobile-app-ci/</guid><description>&lt;p>In this article I'm going to demonstrate some simple tips and tricks which will help you build and maintain beautifully simple mobile build pipelines. These techniques can be applied to different mobile app technologies and integrated into almost any build system:&lt;/p>
&lt;p>&lt;img src="images/0-sample-index.png" alt="Sample App Index">&lt;/p>
&lt;p>Each tip is demonstrated in the sample apps in the &lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">dwmkerr/beautifully-simple-app-ci&lt;/a> repo.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="#TheChallengesOfMobileAppCI">The Challenges of Mobile App CI&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip1EmbraceMakefilesForConsistency">Tip 1 - Embrace Makefiles for Consistency&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip2ControlVersionNumbersWithATouchCommand">Tip 2 - Control Version Numbers with a &amp;lsquo;Touch&amp;rsquo; Command&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tip3controlappiconswithalabelcommand">Tip 3 - Control App Icons with a &amp;lsquo;Label&amp;rsquo; Command&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip4SupportConfigurableAppIds">Tip 4 - Support Configurable App Ids&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Tip5DocumentDocumentDocument">Tip 5 - Document, Document, Document&lt;/a>&lt;/li>
&lt;li>&lt;a href="#/conclusion">Conclusion&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="the-challenges-of-mobile-app-ci">The Challenges of Mobile App CI&lt;/h2>
&lt;p>Conceptually, a mobile app CI pipeline is pretty simple:&lt;/p>
&lt;p>&lt;img src="images/1-basic-ci.png" alt="Basic CI Pipeline">&lt;/p>
&lt;p>We take our code, perform some kind of validation (such as testing, linting, whatever), generate our artifacts and then deploy them to some devices.&lt;/p>
&lt;p>Often though there's a bit more to it than that:&lt;/p>
&lt;p>&lt;img src="images/2-basic-not-basic-1.png" alt="Basic CI is not Basic">&lt;/p>
&lt;p>Our source code has some metadata associated with it at the point in time you create your binaries, such as:&lt;/p>
&lt;ul>
&lt;li>The SHA, which uniquely identifies your exact location in the source history.&lt;/li>
&lt;li>The branch, which may have some &lt;em>semantic&lt;/em> meaning for your project, for example &lt;code>master&lt;/code> meaning &amp;lsquo;production&amp;rsquo; or &lt;code>alpha&lt;/code> meaning your current unstable public build.&lt;/li>
&lt;li>A tag, which may represent something like a semver, or may have more project-specific meaning.&lt;/li>
&lt;li>A version, which might be in something like a &lt;code>package.json&lt;/code> or embedded in your project files for iOS or Android.&lt;/li>
&lt;/ul>
&lt;p>When we build we have to:&lt;/p>
&lt;ul>
&lt;li>Think about how we test and validate&lt;/li>
&lt;li>Think about how we sign&lt;/li>
&lt;li>Handle package names and bundle ids, which can cause headaches if you are going to install multiple &lt;em>versions&lt;/em> of an app (e.g. dev and UAT builds)&lt;/li>
&lt;li>Consider build numbers and version number&lt;/li>
&lt;/ul>
&lt;p>So even the &amp;lsquo;basic&amp;rsquo; CI isn't all that basic. The rest of this article is a set of tips and techniques which I have found useful when developing mobile apps.&lt;/p>
&lt;h2 id="tip-1---embrace-makefiles-for-consistency">Tip 1 - Embrace Makefiles for Consistency&lt;/h2>
&lt;p>There are a raft of platform and framework specific tools and interfaces we will have to use in mobile projects. XCode, Gradle, NPM, framework specific CLIs, tools such as Fastlane, etc etc.&lt;/p>
&lt;p>If you ensure that your main &amp;lsquo;entrypoint&amp;rsquo; to key operations is a recipe in a makefile, you can provide a degree of consistency to mobile projects. For example:&lt;/p>
&lt;ul>
&lt;li>&lt;code>make build&lt;/code> - Creates an IPA and APK, saving them to the &lt;code>./artifacts&lt;/code> folder.&lt;/li>
&lt;li>&lt;code>make test&lt;/code> - Runs all test suites.&lt;/li>
&lt;li>&lt;code>make deploy&lt;/code> - Deploys the binaries.&lt;/li>
&lt;/ul>
&lt;p>A &lt;code>makefile&lt;/code> for such commands might look like this:&lt;/p>
&lt;pre>&lt;code>test:
# Run all the tests.
npm test
build:
# Create the apk, copy to artifacts.
cd android &amp;amp;&amp;amp; ./gradlew assembleRelease &amp;amp;&amp;amp; cd ..
cp -f ./android/app/build/outputs/apk/myapp.apk ./artifacts
# Create the ipa, copy to artifacts.
cd ./ios; fastlane gym --scheme &amp;quot;app&amp;quot; --codesigning_identity &amp;quot;$(CODE_SIGNING_IDENTITY)&amp;quot;; cd ../;
cp -f ./ios/myapp.ipa ./artifacts
deploy:
# Push to TestFairy.
curl https://app.testfairy.com/api/upload \
-F api_key='$(API_KEY)' \
-F &amp;quot;file=@./artifacts/myapp.apk&amp;quot;
&lt;/code>&lt;/pre>&lt;p>This is a slightly shortened snippet, you can see a variety of working examples in the git repo:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">github.com/dwmkerr/beautifully-simple-app-ci&lt;/a>&lt;/p>
&lt;p>The first sample in the above repo demonstrates using makefiles to handle key commands for a React Native app. In the example, CircleCI is used to handle automatic builds on code changes, and the apps themselves are distributed automatically to testers&amp;rsquo; devices with TestFairy.&lt;/p>
&lt;p>The nice feature is that the bulk of the logic is in the main repo source, in the &lt;code>makefile&lt;/code> - the CI tool simply orchestrates it. Developers can run &lt;em>exactly&lt;/em> the same commands on their local machine.&lt;/p>
&lt;p>The &lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci/blob/master/1_react_native_app/README.md">&lt;code>README.md&lt;/code>&lt;/a> immediately draws attention to the makefile commands:&lt;/p>
&lt;p>&lt;img src="images/3-tip1-readme.png" alt="Screenshot of the README.md file">&lt;/p>
&lt;p>The makefiles do most of the work, that makes setting up CircleCI almost trivial. Here's a snippet of its config:&lt;/p>
&lt;pre>&lt;code># Tell Circle where we keep our artifacts.
general:
artifacts:
- ./artifacts
# When we test, we build the android app and test it.
test:
override:
- make build-android
- make test
# If there are any changes to the master branch, push a new version
# of the app.
deployment:
master:
branch: [master]
commands:
- make deploy-android
&lt;/code>&lt;/pre>&lt;p>Our commands are android specific at this stage as Circle don't support iOS builds on their free plan&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. Later samples which use other build systems demonstrate Android &lt;em>and&lt;/em> iOS.&lt;/p>
&lt;p>The CI automatically tests and builds whenever we have new code commits:&lt;/p>
&lt;p>&lt;img src="images/4-tip1-circle.png" alt="Screenshot of CircleCI and the artifacts">&lt;/p>
&lt;p>Also, if a commit is made to the &lt;code>master&lt;/code> branch, our new app is automatically pushed to TestFairy, which can be configured to automatically update the test team:&lt;/p>
&lt;p>&lt;img src="images/5-tip1-testfairy.png" alt="Screenshot of TestFairy">&lt;/p>
&lt;p>Makefile syntax is close enough to shell scripting that simple operations are generally straightforward&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> to implement. The approach is also perfectly valid for server side code and almost any project.&lt;/p>
&lt;p>Teams with many projects can build consistent patterns and syntax for building. Take a look at the image below:&lt;/p>
&lt;p>&lt;img src="images/Simple-Docker-Image-CI.png" alt="Docker Workflow">&lt;/p>
&lt;p>This is from my article on &lt;a href="http://www.dwmkerr.com/simple-continuous-integration-for-docker-images/">Simple Continuous Integration for Docker Images&lt;/a> - where exactly the same principles are applied.&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Makefiles allow you to provide an entrypoint for common app CI tasks which is framework and toolkit agnostic&lt;/li>
&lt;li>Being able to run the individual &lt;em>steps&lt;/em> of a CI build on a local machine makes it easier for developers to work with the pipeline&lt;/li>
&lt;li>By having a CI platform only need to handle the orchestration of these simple steps, we are less tied to specific platforms and can reduce lock-in&lt;/li>
&lt;/ul>
&lt;p>We'll see more interesting makefile recipes as we get into the other tips.&lt;/p>
&lt;h2 id="tip-2---control-version-numbers-with-a-touch-command">Tip 2 - Control Version Numbers with a &amp;lsquo;Touch&amp;rsquo; command&lt;/h2>
&lt;p>iOS and Android apps have both a &lt;em>version number&lt;/em> and a &lt;em>build number&lt;/em>. We might have other files in our project with version numbers too (such as a &lt;code>package.json&lt;/code> file).&lt;/p>
&lt;p>It can be very useful to have a way of keeping these version numbers in sync. Again, we can use a makefile recipe:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">make touch
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will vary in implementation depending on your platform. For example, this would be all that is needed for a Cordova based project:&lt;/p>
&lt;pre>&lt;code># The version in package.json is the 'master' version.
VERSION ?= $(shell cat package.json | jq --raw-output .version)
BUILD_NUM ?= 0
touch:
$(info &amp;quot;Touching to version $(VERSION) and build number $(BUILD_NUM).&amp;quot;)
sed -i &amp;quot;&amp;quot; -e 's/android-versionCode=\&amp;quot;[0-9]*\&amp;quot;/android-versionCode=\&amp;quot;$(BUILD_NUM)\&amp;quot;/g' ./config.xml
sed -i &amp;quot;&amp;quot; -e 's/ios-CFBundleVersion=\&amp;quot;[0-9]*\&amp;quot;/ios-CFBundleVersion=\&amp;quot;$(BUILD_NUM)\&amp;quot;/g' ./config.xml
sed -i &amp;quot;&amp;quot; -e 's/version=\&amp;quot;[.0-9a-zA-Z]*\&amp;quot;/version=\&amp;quot;$(VERSION)&amp;quot;/g' ./config.xml
&lt;/code>&lt;/pre>&lt;p>Notice we don't really need complex tools for a job like this, &lt;code>sed[^3]&lt;/code> is sufficient to quickly make changes to config files.&lt;/p>
&lt;p>This works very nicely with build systems, many of which provide a build number as an environment variable. For example, we can add a build number with TravisCI like so:&lt;/p>
&lt;pre>&lt;code>env:
- BUILD_NUM=$TRAVIS_BUILD_NUMBER
script:
- make touch
- make test
- make build-android
&lt;/code>&lt;/pre>&lt;p>To go into more detail, we'll look at the second sample in the git repo, which is a Cordova App. This sample will always set the build number in both apps and the build version to whatever is present in the &lt;code>package.json&lt;/code> file. That means you can do things like this:&lt;/p>
&lt;pre>&lt;code>$ npm version minor # Bump the version
v0.1.0
$ BUILD_NUM=3 make build &amp;amp;&amp;amp; make deploy # Build and deploy the apps
...
done
&lt;/code>&lt;/pre>&lt;p>And all of the version numbers and build numbers are updated and the apps are deployed. In this example project, they're deployed to HockeyApp:&lt;/p>
&lt;p>&lt;img src="images/6-hockey-app.png" alt="Screenshot of the newly versioned apps in HockeyApp">&lt;/p>
&lt;p>This build runs on TravisCI, so only builds the Android version. You can clone the code and build the iOS version (and deploy it) using the makefile.&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>There will come a point in your project development where you'll need to handle version numbers, having a command to explicitly deal with this adds rigour to this process&lt;/li>
&lt;li>Build numbers are just as important as version numbers during development, ensuring your CI build number is baked into your artifacts is critical for troubleshooting and control&lt;/li>
&lt;/ul>
&lt;h1 id="tip-3---control-app-icons-with-a-label-command">Tip 3 - Control App Icons with a &amp;lsquo;Label&amp;rsquo; Command&lt;/h1>
&lt;p>When you are working in a larger team, it can be very useful to label your app icon so that team members know exactly what version of the app they are using. This is often the case if you are working in a team where features or bugfixes are being deployed rapidly.&lt;/p>
&lt;p>You might label your icons with build numbers, SHAs, branch names, versions, tags, or even something custom such as &amp;lsquo;QA&amp;rsquo; or &amp;lsquo;UAT&amp;rsquo; for different versions of your app. Here are a few examples:&lt;/p>
&lt;p>&lt;img src="images/8-framed-labelled-icons.png" alt="Labelled Icons Screenshot">&lt;/p>
&lt;p>I've found this to be very useful, so created a command-line tool called &amp;lsquo;&lt;a href="github.com/dwmkerr/app-icon">app-icon&lt;/a>&amp;rsquo; to help with the task:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/app-icon">github.com/dwmkerr/app-icon&lt;/a>&lt;/p>
&lt;p>This tool has a &lt;code>label&lt;/code> command to add a label, and a &lt;code>generate&lt;/code> command to generate icons of all different sizes. This means you can add recipes like this to your &lt;code>makefile&lt;/code>:&lt;/p>
&lt;pre>&lt;code>VERSION ?= $(shell cat package.json | jq --raw-output .version)
BUILD_NUM ?= 0 # This might come from Circle, Travis or Whatever...
label:
$(info Labeling icon with '$(VERSION)' and '$(BUILD_NUM)'...)
app-icon label -i base-icon.png -o icon.png --top $(VERSION) --bottom $(BUILD_NUM)
app-icon generate -i icon.png
&lt;/code>&lt;/pre>&lt;p>Each sample app labels its icon in a different way:&lt;/p>
&lt;ol>
&lt;li>The &lt;a href="./1_react_native_app/">React Native App&lt;/a> puts the short Git SHA on the bottom of the icon.&lt;/li>
&lt;li>The &lt;a href="./2_ionic_app/">Ionic App&lt;/a> puts the &lt;code>package.json&lt;/code> version at the top of the icon.&lt;/li>
&lt;li>The &lt;a href="./3_native_app">Native App&lt;/a> puts an environment label at the top of the icon, and the build number at the bottom.&lt;/li>
&lt;li>The &lt;a href="./4_xamarinapp">Xamarin App&lt;/a> includes the configurable app environment (this is detailed in the next tip) and build number&lt;/li>
&lt;/ol>
&lt;p>There are references to each sample and the associated code in the &lt;code>README.md&lt;/code> at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/beautifully-simple-app-ci">github.com/dwmkerr/beautifully-simple-app-ci&lt;/a>&lt;/p>
&lt;p>As a quick example, the Pure Native App runs this code prior to each build:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">BUILD_NUM&lt;span style="color:#f92672">=&lt;/span>BUDDYBUILD_BUILD_NUMBER make label
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This app uses BuddyBuild as a build system, meaning we can just drop this line in the &lt;a href="./buddybuild_postclone.sh">&lt;code>buddybuild_postclone.sh&lt;/code>&lt;/a> script. You can see the labeled icons directly in the BuddyBuild UI:&lt;/p>
&lt;p>&lt;img src="images/12-buddybuild-icons.png" alt="BuddyBuild Icons">&lt;/p>
&lt;p>The Android build is currently having some issues due to fonts being accessible by the labelling tool (which uses ImageMagick under the hood), with any luck this issue will be fixed soon. This seems to be an issue with the BuddyBuild ImageMagick installation rather than the labelling code itself, which is running fine on all of the other builds!&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>A little bit of time invested in managing your app icon can potentially save many hours if you are rapidly iterating on apps&lt;/li>
&lt;li>The &lt;a href="https://github.com/dwmkerr/app-icon">&lt;code>app-icon&lt;/code>&lt;/a> tool can help you quickly label and generate icons&lt;/li>
&lt;/ul>
&lt;h1 id="tip-4---support-configurable-app-ids">Tip 4 - Support Configurable App Ids&lt;/h1>
&lt;p>Another trick I've found useful is to have a command which automatically updates your iOS Bundle ID or Android Application ID. This can be handy when you have multiple versions of an app (such as a QA build, dev build, UAT build or whatever).&lt;/p>
&lt;p>If you have users who need to have different versions of your app on their phones then this is actually a necessary step (at least for iOS), as you cannot have multiple versions of an app with the same ID installed.&lt;/p>
&lt;p>Often, I will aim to have a standard &amp;lsquo;base id&amp;rsquo;, such as:&lt;/p>
&lt;pre>&lt;code>com.dwmkerr.myapp
&lt;/code>&lt;/pre>&lt;p>and then simply append whatever the &amp;lsquo;flavour&amp;rsquo; of my app is to the end of the id:&lt;/p>
&lt;pre>&lt;code>com.dwmkerr.myapp_qa # The QA build...
com.dwmkerr.myapp_uat # The UAT build...
&lt;/code>&lt;/pre>&lt;p>The base id is then reserved for the master build, which is what goes into production.&lt;/p>
&lt;p>Just like with all of the other tricks, I tend to use a recipe in the &lt;code>makefile&lt;/code> to do the heavy lifting, and then leave the build system to orchestrate the commands (we'll see more of this later). Here's how a recipe will typically look (this comes from the fourth sample, which is a Xamarin App):&lt;/p>
&lt;pre>&lt;code>ENV ?= production
# Set the app id, with the 'production' environment implying the unaltered 'base' id.
ifeq ($(ENV),production)
APP_ID=com.dwmkerr.xamarinapp
else
APP_ID=com.dwmkerr.xamarinapp_$(ENV)
endif
name:
$(info Naming app '$(APP_ID)'...)
sed -i.bak 's/com.dwmkerr.xamarinapp.*&amp;lt;/$(APP_ID)&amp;lt;/' iOS/Info.plist
sed -i.bak 's/com.dwmkerr.xamarinapp.*\&amp;quot;/$(APP_ID)\&amp;quot;/' Droid/Properties/AndroidManifest.xml
&lt;/code>&lt;/pre>&lt;p>This small recipe can be very useful in combination with other techniques. Ensuring your build respects the &lt;code>ENV&lt;/code> variable (or whatever you name your &amp;lsquo;flavour&amp;rsquo;) means that you can have different configurations for different environments, build multiple versions of the app, each with a distinct app icon, and distribute them to your team.&lt;/p>
&lt;p>In the screenshots below, you can see how the presence of the &lt;code>ENV&lt;/code> environment variable automatically updates the App ID (this is taken from the &lt;a href="./4_xamarinapp">Xamarin Sample&lt;/a>, which orchestrates builds with Bitrise&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/9-bitrise.png" alt="The ENV Environment variable in Bitrise">&lt;/p>
&lt;p>&lt;img src="images/10-bitrise-apps.png" alt="The built apps in Bitrise">&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Configurable App Ids allow you to maintain isolated builds of your app for specific environments, even on the same physical device&lt;/li>
&lt;li>This tip must be used with caution, some features (such as iOS push notifications) will not work if the bundle id is changed (it can also cause issues if your provisioning profile does not use a wildcard)&lt;/li>
&lt;/ul>
&lt;h2 id="tip-5---document-document-document">Tip 5 - Document, Document, Document&lt;/h2>
&lt;p>Even teams which are great at documenting complex application code can sometimes be a bit lax when it comes to documenting build related code.&lt;/p>
&lt;p>Unfortunately, build related code will often need &lt;em>more&lt;/em> documentation than usual. Why is this?&lt;/p>
&lt;ul>
&lt;li>It is often &lt;em>complex&lt;/em> (spend any time working with the XCode commandline or provisioning profiles and you'll likely agree)&lt;/li>
&lt;li>It is &lt;em>rarely changed&lt;/em> (often worked on heavily at the early stages of a project then not touched)&lt;/li>
&lt;li>It is &lt;em>critical&lt;/em> (when it breaks, teams are often blocked)&lt;/li>
&lt;/ul>
&lt;p>When something goes wrong with a build process, or needs to be changed, it is a real pain when only one person knows how the code works. Be rigorous with this code, make sure it is documented and reviewed, and share the knowledge around your team. I tend to like to have a table of commands as a quick index in the README.md file, and then heavily comment the code itself:&lt;/p>
&lt;p>&lt;img src="images/11-document.png" alt="TODO">&lt;/p>
&lt;p>&lt;strong>In Summary&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Be rigorous with documentation, when things go wrong with CI code then people are often blocked&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>Most of these tips are fairly explicit, there are detailed examples in the sample project. Familiarity with these patterns and techniques can be useful, but perhaps the most valuable takeaway would be to embrace the following principles:&lt;/p>
&lt;ul>
&lt;li>Developers should be able to run all of the key CI steps on their local machine, to be able to understand, adapt and improve the process&lt;/li>
&lt;li>When building more complex features, we should create small, simple units of work which can be composed into larger pipelines&lt;/li>
&lt;li>Complexity, if needed, should be in in code - not in &amp;lsquo;black box&amp;rsquo; CI tools (such as esoteric features for specific CI providers or Jenkins plugins). For example, CircleCI offers a Git Short SHA environment variable - but you can grab a short SHA with &lt;code>git log -1 --format=&amp;quot;%h&amp;quot;&lt;/code>, and the second approach works anywhere&lt;/li>
&lt;li>Use CI platforms to &lt;em>orchestrate&lt;/em> work, use makefiles and scripts to handle logic&lt;/li>
&lt;/ul>
&lt;p>I hope this article has been useful, any thoughts or comments are always welcome!&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>I have successfully used this approach to build Android &lt;em>and&lt;/em> iOS from the same OSX build agent on their paid plan on a number of projects. The most straightforward way to do this is to have a single build run on OSX and create the Android app as well as the iOS app. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Perhaps straightforward is an overstatement, but getting those who are familiar with shell scripting will have few difficulties. Those who are not will find a learning curve, but it is &lt;em>very&lt;/em> useful to at least get the basics of shell scripting learnt. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Get up and running with OpenShift on AWS</title><link>https://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</link><pubDate>Thu, 02 Feb 2017 07:47:00 +0000</pubDate><guid>https://dwmkerr.com/get-up-and-running-with-openshift-on-aws/</guid><description>&lt;p>&lt;a href="https://www.openshift.com/">OpenShift&lt;/a> is Red Hat's platform-as-a-service offering for hosting and scaling applications. It's built on top of Google's popular &lt;a href="https://kubernetes.io/">Kubernetes&lt;/a> system.&lt;/p>
&lt;p>Getting up and running with OpenShift Online is straightforward, as it is a cloud hosted solution. Setting up your own cluster is a little more complex, but in this article I'll show you how to make it fairly painless.&lt;/p>
&lt;p>&lt;img src="images/welcome.png" alt="OpenShift Login">&lt;/p>
&lt;p>The repo for this project is at: &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">github.com/dwmkerr/terraform-aws-openshift&lt;/a>.&lt;/p>
&lt;h2 id="creating-the-infrastructure">Creating the Infrastructure&lt;/h2>
&lt;p>OpenShift has some fairly specific requirements about what hardware it runs on&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. There's also DNS to set up, as well as internet access and so on.&lt;/p>
&lt;p>All in all, for a bare-bones setup, you'll need something like this:&lt;/p>
&lt;p>&lt;img src="images/network-diagram-2.png" alt="Network Diagram">&lt;/p>
&lt;p>Which is (deep breath):&lt;/p>
&lt;ol>
&lt;li>A network&lt;/li>
&lt;li>A public subnet, with internet access via a gateway&lt;/li>
&lt;li>A master host, which will run the OpenShift master&lt;/li>
&lt;li>A pair of node hosts, which will run additional OpenShift nodes&lt;/li>
&lt;li>A hosted zone, which allows us to configure DNS&lt;/li>
&lt;li>A bastion, which allows us to SSH onto hosts, without directly exposing them&lt;/li>
&lt;li>Some kind of basic log aggregation, which I'm using CloudWatch for&lt;/li>
&lt;/ol>
&lt;p>This is not a production grade setup, which requires redundant masters and so on, but it provides the basics.&lt;/p>
&lt;p>Rather than setting this infrastructure up by hand, this is all scripted with &lt;a href="https://www.terraform.io/">Terraform&lt;/a>. To set up the infrastructure, clone the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">github.com/dwmkerr/terraform-aws-openshift&lt;/a> repo:&lt;/p>
&lt;pre>&lt;code>$ git clone git@github.com:dwmkerr/terraform-aws-openshift
...
Resolving deltas: 100% (37/37), done.
&lt;/code>&lt;/pre>&lt;p>Then use the terraform CLI&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> to create the infrastructure:&lt;/p>
&lt;pre>&lt;code>$ cd terraform-aws-openshift/
$ terraform get &amp;amp;&amp;amp; terraform apply
&lt;/code>&lt;/pre>&lt;p>You'll be asked for a region, to deploy the network into, here I'm using &lt;code>us-west-1&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/Screenshot-at-Feb-02-21-16-44.png" alt="Enter Region">&lt;/p>
&lt;p>After a few minutes the infrastructure will be set up:&lt;/p>
&lt;p>&lt;img src="images/output.png" alt="Terraform complete">&lt;/p>
&lt;p>A quick glance at the AWS console shows the new hosts we've set up:&lt;/p>
&lt;p>&lt;img src="images/aws.png" alt="AWS Console">&lt;/p>
&lt;p>The next step is to install OpenShift.&lt;/p>
&lt;h2 id="installing-openshift">Installing OpenShift&lt;/h2>
&lt;p>There are a few different ways to install OpenShift, but the one we'll use is called the &amp;lsquo;advanced installation&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>'. This essentially involves:&lt;/p>
&lt;ol>
&lt;li>Creating an &amp;lsquo;inventory&amp;rsquo;, which specifies the hosts OpenShift will be installed on and the installation options&lt;/li>
&lt;li>Downloading the advanced installation code&lt;/li>
&lt;li>Running the advanced installation Ansible Playbook&lt;/li>
&lt;/ol>
&lt;p>To create the inventory, we just run:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sed &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">s/\${aws_instance.master.public_ip}/&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>terraform output master-public_ip&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">/&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> inventory.template.cfg &amp;gt; inventory.cfg
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This takes our &amp;lsquo;inventory template&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&amp;rsquo; and populates it with the public IP of our master node, which is recorded in a Terraform output variable.&lt;/p>
&lt;p>We can then copy the inventory to the bastion:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">ssh-add ~/.ssh/id_rsa
scp ./inventory.cfg ec2-user@&lt;span style="color:#66d9ef">$(&lt;/span>terraform output bastion-public_dns&lt;span style="color:#66d9ef">)&lt;/span>:~
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can again use the Terraform output variables, this time to get the bastion IP. Finally, we pipe our install script to the bastion host:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">cat install-from-bastion.sh | ssh -A ec2-user@&lt;span style="color:#66d9ef">$(&lt;/span>terraform output bastion-public_dns&lt;span style="color:#66d9ef">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's a &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/issues/1">bug&lt;/a> which means you might see &lt;code>ansible-playbook: command not found&lt;/code>, if so, just run the script again. The install script clones the installation scripts and runs them, using the inventory we've provided:&lt;/p>
&lt;p>&lt;img src="images/ansible.png" alt="Ansible Output">&lt;/p>
&lt;p>This'll probably take about 10 minutes to run. And that's it, OpenShift is installed:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">open &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">https://&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>terraform output master-public_dns&lt;span style="color:#66d9ef">)&lt;/span>&lt;span style="color:#e6db74">:8443&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Hit &amp;lsquo;advanced&amp;rsquo; and continue, as we're using a self-signed certificate most browsers will complain:&lt;/p>
&lt;p>&lt;img src="images/console1.png" alt="Invalid Certificate">&lt;/p>
&lt;p>Enter any username and password (the system is configured to allow anyone to access it by default) and you'll be presented with the OpenShift console:&lt;/p>
&lt;p>&lt;img src="images/console2.png" alt="OpenShift console">&lt;/p>
&lt;p>As the setup requires three t2.large instances, which are not available on the free plan, you might want to clean up when you are done with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">terraform destroy
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>Hopefully you've found this useful, there are more details and references on the README of the github repo:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">https://github.com/dwmkerr/terraform-aws-openshift&lt;/a>&lt;/p>
&lt;p>Comments and feedback are always welcome!&lt;/p>
&lt;hr>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>See &lt;a href="https://docs.openshift.org/latest/install_config/install/prerequisites.html#system-requirements">https://docs.openshift.org/latest/install_config/install/prerequisites.html#system-requirements&lt;/a> &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Use &amp;lsquo;brew install terraform&amp;rsquo;, full instructions in the &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift">README.md&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>See &lt;a href="https://docs.openshift.org/latest/install_config/install/advanced_install.html">https://docs.openshift.org/latest/install_config/install/advanced_install.html&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>See &lt;a href="https://github.com/dwmkerr/terraform-aws-openshift/blob/master/inventory.template.cfg">https://github.com/dwmkerr/terraform-aws-openshift/blob/master/inventory.template.cfg&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Creating a Resilient Consul Cluster for Docker Microservice Discovery with Terraform and AWS</title><link>https://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</link><pubDate>Mon, 09 Jan 2017 07:10:40 +0000</pubDate><guid>https://dwmkerr.com/creating-a-resilient-consul-cluster-for-docker-microservice-discovery-with-terraform-and-aws/</guid><description>&lt;p>In this article I'm going to show you how to create a resilient Consul cluster, using Terraform and AWS. We can use this cluster for microservice discovery and management. No prior knowledge of the technologies or patterns is required!&lt;/p>
&lt;p>The final code is at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster">github.com/dwmkerr/terraform-consul-cluster&lt;/a>. Note that it has evolved somewhat since the time of writing, see the Appendices at the end of the article for details.&lt;/p>
&lt;h2 id="consul-terraform--aws">Consul, Terraform &amp;amp; AWS&lt;/h2>
&lt;p>&lt;a href="https://www.consul.io/">Consul&lt;/a> is a technology which enables &lt;em>Service Discovery&lt;/em>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, a pattern which allows services to locate each other via a central authority.&lt;/p>
&lt;p>&lt;a href="https://www.terraform.io/">Terraform&lt;/a> is a technology which allows us to script the provisioning of infrastructure and systems. This allows us to practice the &lt;em>Infrastructure as Code&lt;/em> pattern. The rigour of code control (versioning, history, user access control, diffs, pull requests etc) can be applied to our systems.&lt;/p>
&lt;p>And why &lt;a href="https://aws.amazon.com/">AWS&lt;/a>? We need to create many servers and build a network to see this system in action. We can simulate parts of this locally with tools such as &lt;a href="https://www.vagrantup.com/">Vagrant&lt;/a>, but we can use the arguably most popular&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> IaaS platfom for this job at essentially zero cost, and learn some valuable skills which are readily applicable to other projects at the same time.&lt;/p>
&lt;p>A lot of what we will learn is not really AWS specific - and the Infrastructure as Code pattern which Terraform helps us apply allows us to apply these techniques easily with other providers.&lt;/p>
&lt;h2 id="the-goal">The Goal&lt;/h2>
&lt;p>The goal is to create a system like this:&lt;/p>
&lt;p>&lt;img src="images/img-0-goal.png" alt="Overall System Diagram">&lt;/p>
&lt;p>In a nutshell:&lt;/p>
&lt;ul>
&lt;li>We have a set of homogenous Consul nodes&lt;/li>
&lt;li>The nodes form a cluster and automatically elect a leader&lt;/li>
&lt;li>The nodes span more than one availability zone, meaning the system is redundant and can survive the failure of an entire availability zone (i.e. data centre)&lt;/li>
&lt;li>The Consul UI is available to view via a gateway&lt;/li>
&lt;li>We have two example microservices which register themselves on the cluster, so we can actually see some registered services in the console&lt;/li>
&lt;/ul>
&lt;p>As a quick caveat, in reality this setup would typically live in a private subnet, not directly accessible to the outside work except via public facing load balancers. This adds a bit more complexity to the Terraform setup but not much value to the walk-though. A network diagram of how it might look is below, I invite interested readers to try and move to this model as a great exercise to cement the concepts!&lt;/p>
&lt;h2 id="step-1---creating-our-network">Step 1 - Creating our Network&lt;/h2>
&lt;p>The first logical step is to create the network itself. This means:&lt;/p>
&lt;ul>
&lt;li>The network (in AWS terminology, this is a &lt;em>VPC&lt;/em> or &lt;em>Virtual Private Cloud&lt;/em>)&lt;/li>
&lt;li>The &amp;lsquo;public&amp;rsquo; subnet, which defines our IP ranges for hosts&lt;/li>
&lt;li>The internet gateway, which provides an entry/exit point for traffic from/to the internet&lt;/li>
&lt;li>The firewall rules, which define what traffic can come in and out of the network&lt;/li>
&lt;/ul>
&lt;p>All together, that's this:&lt;/p>
&lt;p>&lt;img src="images/img-1-network.png" alt="">&lt;/p>
&lt;p>Our solution will be made more resilient by ensuring we host our Consul nodes across multiple &lt;em>availability zones&lt;/em>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/p>
&lt;p>Creating a VPC and building a subnet is fairly trivial if you have done some network setup before or spent much time working with AWS, if not, you may be a little lost already. There's a good course on Udemy&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> which will take you through the process of setting up a VPC which I recommend if you are interested in this, as it is quite hands on. It'll also show you how to build a more &amp;lsquo;realistic&amp;rsquo; network, which also contains a private subnet and NAT, but that's beyond the scope of this write-up. Instead, I'll take you through the big parts.&lt;/p>
&lt;h3 id="the-network">The Network&lt;/h3>
&lt;p>We're using AWS, we need to create a VPC. A VPC is a Virtual Private Cloud. The key thing is that it is &lt;em>isolated&lt;/em>. Things you create in this network will be able to talk to each other if you let them, but cannot communicate with the outside world, unless you specifically create the parts needed for them to do so.&lt;/p>
&lt;p>A private network is probably something you regularly use if you work in a company&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>. Most companies have their own internal network - when you use a computer on that network it can talk to other company computers (such as the company mail server). When you are off that network, you might not be able to access your company email (unless it is publicly available, like gmail, or over a VPN [and by accessing a VPN, you are actually &lt;em>joining&lt;/em> the network again, albeit remotely]).&lt;/p>
&lt;p>Perhaps the most immediately obvious part of a VPC is that &lt;em>you control the IP addresses&lt;/em>. You specify the &lt;em>range&lt;/em> of IP addresses which are available to give to machines on the network. When a machine joins, it is given an IP in that range. I'm not going to go into too much detail here, if you are interested let me know and I'll write up an article on VPCs in detail!&lt;/p>
&lt;p>&lt;img src="images/img-3-vpc.png" alt="">&lt;/p>
&lt;p>Here's how I'd suggest scripting AWS infrastructure with Terraform if you haven't done this before.&lt;/p>
&lt;ol>
&lt;li>Use the AWS console to create what you want&lt;/li>
&lt;li>Search the Terraform documentation for the entity you want to create (e.g. &lt;a href="https://www.terraform.io/docs/providers/aws/r/vpc.html">VPC&lt;/a>), &lt;em>script&lt;/em> the component and &lt;em>apply&lt;/em> the provisioning&lt;/li>
&lt;li>Compare the hand-made VPC to the script-made VPC, if the two are the same, you are done&lt;/li>
&lt;li>If the two are different, check the documentation and try again&lt;/li>
&lt;/ol>
&lt;p>Ensure you have an AWS account, and note your Secret Key and Access Key. We'll need these to remotely control it. Here's the terraform script to create a VPC:&lt;/p>
&lt;pre>&lt;code>// Setup the core provider information.
provider &amp;quot;aws&amp;quot; {
access_key = &amp;quot;${var.access_key}&amp;quot;
secret_key = &amp;quot;${var.secret_key}&amp;quot;
region = &amp;quot;${var.region}&amp;quot;
}
// Define the VPC.
resource &amp;quot;aws_vpc&amp;quot; &amp;quot;consul-cluster&amp;quot; {
cidr_block = &amp;quot;10.0.0.0/16&amp;quot; // i.e. 10.0.0.0 to 10.0.255.255
enable_dns_hostnames = true
tags {
Name = &amp;quot;Consul Cluster VPC&amp;quot;
Project = &amp;quot;consul-cluster&amp;quot;
}
}
&lt;/code>&lt;/pre>&lt;p>This script uses &lt;a href="https://www.terraform.io/docs/configuration/variables.html">Terraform Variables&lt;/a>, such as &lt;code>var.access_key&lt;/code>, which we keep in a &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/variables.tf">variables.tf&lt;/a> file. Terraform will use the default values defined in the file if they are present, or ask the user to supply them. Let's build the network:&lt;/p>
&lt;pre>&lt;code>terraform apply
&lt;/code>&lt;/pre>&lt;p>After supplying the values for the variables, Terraform will provision the network, using the AWS SDK internally.&lt;/p>
&lt;p>&lt;img src="images/img-2-terraform-apply.png" alt="">&lt;/p>
&lt;p>You'll see lots of info about what it is creating, then a success message.&lt;/p>
&lt;h3 id="the-public-subnet">The Public Subnet&lt;/h3>
&lt;p>You don't put hosts directly into a VPC, they need to go into a structure called a &amp;lsquo;subnet&amp;rsquo;, which is a &lt;em>part&lt;/em> of a VPC. Subnets get their own subset of the VPC's available IP addresses, which you specify.&lt;/p>
&lt;p>Subnets are used to build &lt;em>zones&lt;/em> in a network. Why would you need this? Typically it is to manage security. You might have a &amp;lsquo;public zone&amp;rsquo; in which all hosts can be accessed from the internet, and a &amp;lsquo;private zone&amp;rsquo; which is inaccessible directly (and therefore a better location for hosts with sensitive data). You might have an &amp;lsquo;operator&amp;rsquo; zone, which only sysadmins can access, but they can use to get diagnostic information.&lt;/p>
&lt;p>Here's a common subnet layout for multi-tiered applications:&lt;/p>
&lt;p>&lt;img src="images/img-4-subnets.png" alt="">&lt;/p>
&lt;p>The defining characteristics of zones is that they are used to create &lt;em>boundaries&lt;/em> to isolate hosts. These boundaries are normally secured by firewalls, traversed via gateways or NATs etc. We're going to create two public subnets, one in each of the availability zones&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>:&lt;/p>
&lt;pre>&lt;code>// Create a public subnet for each AZ.
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-a&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.consul-cluster.id}&amp;quot;
cidr_block = &amp;quot;10.0.1.0/24&amp;quot; // i.e. 10.0.1.0 to 10.0.1.255
availability_zone = &amp;quot;ap-southeast-1a&amp;quot;
map_public_ip_on_launch = true
}
resource &amp;quot;aws_subnet&amp;quot; &amp;quot;public-b&amp;quot; {
vpc_id = &amp;quot;${aws_vpc.consul-cluster.id}&amp;quot;
cidr_block = &amp;quot;10.0.2.0/24&amp;quot; // i.e. 10.0.2.0 to 10.0.1.255
availability_zone = &amp;quot;ap-southeast-1b&amp;quot;
map_public_ip_on_launch = true
}
&lt;/code>&lt;/pre>&lt;p>With Terraform, resources can depend on each other. In this case, the subnets need to reference the ID of the VPC we want to place them in (so we use &lt;code>aws_vpc.consul-cluster.id&lt;/code>).&lt;/p>
&lt;h3 id="the-internet-gateway-route-tables-and-security-groups">The Internet Gateway, Route Tables and Security Groups&lt;/h3>
&lt;p>The final parts of the network you can see in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/network.tf">./infrastructure/network.tf&lt;/a> script. These are the Internet Gateway, Route Table and Security Group resources. Essentially they are for controlling access between hosts and the internet. AWS have a &lt;a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario1.html">good guide&lt;/a> if you are not familiar with these resources; they don't add much to the article so I'll leave you to explore on your own.&lt;/p>
&lt;p>That's it for the network, we now have the following structure:&lt;/p>
&lt;p>&lt;img src="images/img-1-network-1.png" alt="">&lt;/p>
&lt;p>If you want to see the code as it stands now, check the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-1">Step 1&lt;/a> branch. Now we need to look at creating the hosts to install Consul on.&lt;/p>
&lt;h2 id="step-2---creating-the-consul-hosts">Step 2 - Creating the Consul Hosts&lt;/h2>
&lt;p>The Consul documentation recommends running in a cluster or 3 or 5 nodes&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>. We want to set up a system which is self-healing - if we lose a node, we want to create a new one.&lt;/p>
&lt;p>Enter &lt;a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html">Auto-Scaling Groups&lt;/a>. Auto-scaling groups allow us to define a template for an instance, and ask AWS to make sure there are always a certain number of these instances. If we lose an instance, a new one will be created to keep the group at the correct size&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>So we now need to create:&lt;/p>
&lt;ol>
&lt;li>A &amp;lsquo;Launch Configuration&amp;rsquo; which determines what instances our Auto-scaling Group creates&lt;/li>
&lt;li>A &amp;lsquo;user data script&amp;rsquo; which runs on newly created instances, which must install and start Consul&lt;/li>
&lt;li>An Auto-scaling group, configured to run five instances across the two public subnets&lt;/li>
&lt;li>A load balancer, configured to pass incoming requests for the Consul Admin console to the nodes&lt;/li>
&lt;/ol>
&lt;p>Or visually:&lt;/p>
&lt;p>&lt;img src="images/img-5-cluster-basic-2.png" alt="Basic Cluster Diagram">&lt;/p>
&lt;p>Let's get to it.&lt;/p>
&lt;h3 id="the-launch-configuration--auto-scaling-group">The Launch Configuration &amp;amp; Auto-scaling Group&lt;/h3>
&lt;p>The Launch Configuration will define the characteristics of our instances and the auto-scaling group determines the size of our cluster:&lt;/p>
&lt;pre>&lt;code>// Launch configuration for the consul cluster auto-scaling group.
resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
name_prefix = &amp;quot;consul-node-&amp;quot;
image_id = &amp;quot;${lookup(var.ami_ecs_optimised, var.region)}&amp;quot;
instance_type = &amp;quot;t2.micro&amp;quot;
security_groups = [&amp;quot;${aws_security_group.consul-cluster-vpc.id}&amp;quot;]
lifecycle {
create_before_destroy = true
}
}
// Auto-scaling group for our cluster.
resource &amp;quot;aws_autoscaling_group&amp;quot; &amp;quot;consul-cluster-asg&amp;quot; {
name = &amp;quot;consul-asg&amp;quot;
launch_configuration = &amp;quot;${aws_launch_configuration.consul-cluster-lc.name}&amp;quot;
min_size = 5
max_size = 5
vpc_zone_identifier = [
&amp;quot;${aws_subnet.public-a.id}&amp;quot;,
&amp;quot;${aws_subnet.public-b.id}&amp;quot;
]
lifecycle {
create_before_destroy = true
}
}
&lt;/code>&lt;/pre>&lt;p>A few key things to note:&lt;/p>
&lt;ol>
&lt;li>I have omitted the &lt;code>tag&lt;/code> properties in the scripts for brevity&lt;/li>
&lt;li>The &amp;lsquo;image&amp;rsquo; for the launch configuration is looked up based on the region we've specified - we're a basic linux image&lt;sup id="fnref:8">&lt;a href="#fn:8" class="footnote-ref" role="doc-noteref">8&lt;/a>&lt;/sup>&lt;/li>
&lt;li>We are using micro instances, which are free-tier eligible&lt;/li>
&lt;li>The auto-scaling group spans both availability zones.&lt;/li>
&lt;/ol>
&lt;p>Once we run &lt;code>terraform apply&lt;/code>, we'll see our auto-scaling group, which references the new launch configuration and works over multiple availability zones:&lt;/p>
&lt;p>&lt;img src="images/img-6-lc-asg.png" alt="Auto scaling group and launch configuration">&lt;/p>
&lt;p>We can also see the new instances:&lt;/p>
&lt;p>&lt;img src="images/img-7-instances.png" alt="Instances">&lt;/p>
&lt;p>These instances don't do much yet though, we've not installed Docker or Consul.&lt;/p>
&lt;h3 id="installing-consul-and-accessing-the-admin-interface">Installing Consul and Accessing the Admin Interface&lt;/h3>
&lt;p>To set up our instances we use a &amp;lsquo;userdata&amp;rsquo; script&amp;rsquo; A userdata runs once when an instance is created. We can create a script in our repository, and reference it in our Terraform files.&lt;/p>
&lt;p>We add a new file called &lt;code>consul-node.sh&lt;/code> to a &lt;code>files&lt;/code> folder. This script installs Docker and runs Consul:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">yum install -y docker
usermod -a -G docker ec2-user
service docker start
&lt;span style="color:#75715e"># Get my IP address.&lt;/span>
IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>curl http://169.254.169.254/latest/meta-data/local-ipv4&lt;span style="color:#66d9ef">)&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Instance IP is: &lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Start the Consul server.&lt;/span>
docker run -d --net&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name&lt;span style="color:#f92672">=&lt;/span>consul &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> consul agent -server -ui &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bind&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -client&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0.0.0.0&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bootstrap-expect&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;1&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here's a breakdown of what we're doing:&lt;/p>
&lt;ol>
&lt;li>Install Docker. These scripts run as root, so we add the ec2-user to the Docker group, meaning when we log in later on via SSH, we can run Docker&lt;/li>
&lt;li>Get our IP address. AWS provide a magic address (169.254.169.254) which lets you query data about your instance, see &lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance Metadata &amp;amp; User Metadata&lt;/a>&lt;/li>
&lt;li>Run the Consul docker image in server mode, with the UI enabled, expecting only one instance&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>The actual scripts contains more!&lt;/strong> Getting userdata scripts right, testing and debugging them is tricky. See how I do it in detail in &lt;a href="#Appendix-1-Logging">Appendix 1: Logging&lt;/a>.&lt;/p>
&lt;p>Now we need to tell Terraform to include this script as part of the instance metadata. Here's how we do that:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
/// ...add the line below....
user_data = &amp;quot;${file(&amp;quot;files/consul-node.sh&amp;quot;)}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>When Consul is running with the &lt;code>-ui&lt;/code> option, it provides an admin UI. You can try it by running Consul locally with &lt;code>docker run -p8500:8500 consul&lt;/code> and navigating to http://localhost:8500/ui.&lt;/p>
&lt;p>We can install a load balancer in front of our auto-scaling group, to automatically forward incoming traffic to a host. Here's the config:&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_elb&amp;quot; &amp;quot;consul-lb&amp;quot; {
name = &amp;quot;consul-lb-a&amp;quot;
security_groups = [
&amp;quot;${aws_security_group.consul-cluster-vpc.id}&amp;quot;,
&amp;quot;${aws_security_group.web.id}&amp;quot;
]
subnets = [
&amp;quot;${aws_subnet.public-a.id}&amp;quot;,
&amp;quot;${aws_subnet.public-b.id}&amp;quot;
]
listener {
instance_port = 8500
instance_protocol = &amp;quot;http&amp;quot;
lb_port = 80
lb_protocol = &amp;quot;http&amp;quot;
}
health_check {
healthy_threshold = 2
unhealthy_threshold = 2
timeout = 3
target = &amp;quot;HTTP:8500/ui/&amp;quot;
interval = 30
}
}
&lt;/code>&lt;/pre>&lt;p>Blow-by-blow:&lt;/p>
&lt;ol>
&lt;li>Create a load balancer, with the same security groups as the rest of the VPC, but also a security group which allows web access&lt;/li>
&lt;li>Point to two subnets first subnet&lt;/li>
&lt;li>Forward HTTP 8500 traffic&lt;/li>
&lt;li>Configure a healthcheck&lt;sup id="fnref:9">&lt;a href="#fn:9" class="footnote-ref" role="doc-noteref">9&lt;/a>&lt;/sup>&lt;/li>
&lt;/ol>
&lt;p>The final change we make is to add an &lt;code>outputs.tf&lt;/code> file, which lists all of the properties Terraform knows about which we want to save. All it includes is:&lt;/p>
&lt;pre>&lt;code>output &amp;quot;consul-dns&amp;quot; {
value = &amp;quot;${aws_elb.consul-lb.dns_name}&amp;quot;
}
&lt;/code>&lt;/pre>&lt;p>When we finally run &lt;code>terraform apply&lt;/code>, we see the public DNS of our load balancer:&lt;/p>
&lt;p>&lt;img src="images/img-8-cluster-dns.png" alt="Screenshot showing &amp;lsquo;terraform apply&amp;rsquo; output, indicating our newly generated ELB's public DNS">&lt;/p>
&lt;p>And running in a browser on port 8500 we see the Consul admin interface:&lt;/p>
&lt;p>&lt;img src="images/img-9-admin-ui.png" alt="Screenshot showing the Consul admin interface">&lt;/p>
&lt;p>Every time we refresh we will likely see a different node. We've actually created five clusters each of one node - what we now need to do is connect them all together into a single cluster of five nodes.&lt;/p>
&lt;p>If you want to see the code as it stands now, check the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-2">Step 2&lt;/a> branch.&lt;/p>
&lt;h2 id="step-3---creating-the-cluster">Step 3 - Creating the Cluster&lt;/h2>
&lt;p>Creating the cluster is now not too much of a challenge. We will update the userdata script to tell the consul process we are expecting 5 nodes (via the &lt;a href="https://www.consul.io/docs/agent/options.html#_bootstrap_expect">&lt;code>bootstrap-expect&lt;/code>&lt;/a> flag.&lt;/p>
&lt;p>Here's the updated script:&lt;/p>
&lt;pre>&lt;code># Get my IP address.
IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
echo &amp;quot;Instance IP is: $IP&amp;quot;
# Start the Consul server.
docker run -d --net=host \
--name=consul \
consul agent -server -ui \
-bind=&amp;quot;$IP&amp;quot; \
-client=&amp;quot;0.0.0.0&amp;quot; \
-bootstrap-expect=&amp;quot;5&amp;quot;
&lt;/code>&lt;/pre>&lt;p>The problem is &lt;strong>this won't work&lt;/strong>&amp;hellip; We need to tell each node the address of &lt;em>another&lt;/em> server in the cluster. For example, if we start five nodes, we should tell nodes 2-5 the address of node 1, so that the nodes can discover each other.&lt;/p>
&lt;p>The challenge is how do we get the IP of node 1? The IP addresses are determined by the network, we don't preset them so cannot hard code them. Also, we can expect nodes to occasionally die and get recreated, so the IP addresses of nodes will in fact change over time.&lt;/p>
&lt;h3 id="getting-the-ip-addresses-of-nodes-in-the-cluster">Getting the IP addresses of nodes in the cluster&lt;/h3>
&lt;p>There's a nice trick we can use here. We can ask AWS to give us the IP addresses of each host in the auto-scaling group. If we tell each node the addresses of the &lt;em>other nodes&lt;/em>, then they will elect a leader themselves&lt;sup id="fnref:10">&lt;a href="#fn:10" class="footnote-ref" role="doc-noteref">10&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;img src="images/img-12-choose-leader-1.png" alt="Diagram showing how we decide on a leader IP">&lt;/p>
&lt;p>There are a couple of things we need to do to get this right. First, update the userdata script to provide the IPs of other nodes when we're starting up, then update the &lt;strong>role&lt;/strong> of our nodes so that they have permissions to use the APIs we're going to call.&lt;/p>
&lt;h3 id="getting-the-cluster-ips">Getting the Cluster IPs&lt;/h3>
&lt;p>This is actually fairly straightforward. We update our userdata script to the below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># A few variables we will refer to later...&lt;/span>
ASG_NAME&lt;span style="color:#f92672">=&lt;/span>consul-asg
REGION&lt;span style="color:#f92672">=&lt;/span>ap-southeast-1
EXPECTED_SIZE&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">5&lt;/span>
&lt;span style="color:#75715e"># Return the id of each instance in the cluster.&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span> cluster-instance-ids &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#75715e"># Grab every line which contains &amp;#39;InstanceId&amp;#39;, cut on double quotes and grab the ID:&lt;/span>
&lt;span style="color:#75715e"># &amp;#34;InstanceId&amp;#34;: &amp;#34;i-example123&amp;#34;&lt;/span>
&lt;span style="color:#75715e">#....^..........^..^.....#4.....^...&lt;/span>
aws --region&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$REGION&lt;span style="color:#e6db74">&amp;#34;&lt;/span> autoscaling describe-auto-scaling-groups &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --auto-scaling-group-name $ASG_NAME &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | grep InstanceId &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | cut -d &lt;span style="color:#e6db74">&amp;#39;&amp;#34;&amp;#39;&lt;/span> -f4
&lt;span style="color:#f92672">}&lt;/span>
&lt;span style="color:#75715e"># Return the private IP of each instance in the cluster.&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span> cluster-ips &lt;span style="color:#f92672">{&lt;/span>
&lt;span style="color:#66d9ef">for&lt;/span> id in &lt;span style="color:#66d9ef">$(&lt;/span>cluster-instance-ids&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">do&lt;/span>
aws --region&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$REGION&lt;span style="color:#e6db74">&amp;#34;&lt;/span> ec2 describe-instances &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --query&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;Reservations[].Instances[].[PrivateIpAddress]&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --output&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --instance-ids&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$id&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;span style="color:#f92672">}&lt;/span>
&lt;span style="color:#75715e"># Wait until we have as many cluster instances as we are expecting.&lt;/span>
&lt;span style="color:#66d9ef">while&lt;/span> COUNT&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>cluster-instance-ids | wc -l&lt;span style="color:#66d9ef">)&lt;/span> &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#f92672">[&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$COUNT&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -lt &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>
&lt;span style="color:#66d9ef">do&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>$COUNT&lt;span style="color:#e6db74"> instances in the cluster, waiting for &lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74"> instances to warm up...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
sleep &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">done&lt;/span>
&lt;span style="color:#75715e"># Get my IP address, all IPs in the cluster, then just the &amp;#39;other&amp;#39; IPs...&lt;/span>
IP&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>curl http://169.254.169.254/latest/meta-data/local-ipv4&lt;span style="color:#66d9ef">)&lt;/span>
mapfile -t ALL_IPS &amp;lt; &amp;lt;&lt;span style="color:#f92672">(&lt;/span>cluster-ips&lt;span style="color:#f92672">)&lt;/span>
OTHER_IPS&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#f92672">(&lt;/span> &lt;span style="color:#e6db74">${&lt;/span>ALL_IPS[@]/&lt;span style="color:#e6db74">${&lt;/span>IP&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>/&lt;span style="color:#f92672">}&lt;/span> &lt;span style="color:#f92672">)&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Instance IP is: &lt;/span>$IP&lt;span style="color:#e6db74">, Cluster IPs are: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>CLUSTER_IPS[@]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">, Other IPs are: &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[@]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;span style="color:#75715e"># Start the Consul server.&lt;/span>
docker run -d --net&lt;span style="color:#f92672">=&lt;/span>host &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --name&lt;span style="color:#f92672">=&lt;/span>consul &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> consul agent -server -ui &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bind&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$IP&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[0]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[1]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[2]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> -retry-join&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>OTHER_IPS[3]&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -bootstrap-expect&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>$EXPECTED_SIZE&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Right, here's what's going on:&lt;/p>
&lt;ol>
&lt;li>We create a few variables we'll use repeatedly&lt;/li>
&lt;li>We create a &lt;code>cluster-instance-ids&lt;/code> function which returns the ID of each instance in the auto-scaling group&lt;/li>
&lt;li>We create a &lt;code>cluster-ips&lt;/code> function which returns the private IP address of each instance in the cluster.&lt;/li>
&lt;li>We wait until the auto-scaling group has our expected number of instances (it can take a while for them all to be created)&lt;/li>
&lt;li>We get the 5 IP addresses&lt;/li>
&lt;li>We remove our IP from the array, leaving us with the IPs of the &lt;em>other&lt;/em> nodes&lt;/li>
&lt;li>We start the Consul agent in server mode, expecting 5 nodes and offering the IP of each other agent&lt;/li>
&lt;/ol>
&lt;p>The problem is, if we try to run the script we will fail, because calling the AWS APIs requires some permissions we don't have. Let's fix that.&lt;/p>
&lt;h3 id="creating-a-role-for-our-nodes">Creating a Role for our nodes&lt;/h3>
&lt;p>Our nodes now have a few special requirements. They need to be able to query the details of an auto-scaling group and get the IP of an instance&lt;sup id="fnref:11">&lt;a href="#fn:11" class="footnote-ref" role="doc-noteref">11&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>We will need to create a policy which describes the permissions we need, create a role, attach the policy to the role and then ensure our instances are assigned the correct role. This is &lt;code>consul-node-role.tf&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>// This policy allows an instance to discover a consul cluster leader.
resource &amp;quot;aws_iam_policy&amp;quot; &amp;quot;leader-discovery&amp;quot; {
name = &amp;quot;consul-node-leader-discovery&amp;quot;
path = &amp;quot;/&amp;quot;
policy = &amp;lt;&amp;lt;EOF
{
&amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
&amp;quot;Statement&amp;quot;: [
{
&amp;quot;Sid&amp;quot;: &amp;quot;Stmt1468377974000&amp;quot;,
&amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
&amp;quot;Action&amp;quot;: [
&amp;quot;autoscaling:DescribeAutoScalingInstances&amp;quot;,
&amp;quot;autoscaling:DescribeAutoScalingGroups&amp;quot;,
&amp;quot;ec2:DescribeInstances&amp;quot;
],
&amp;quot;Resource&amp;quot;: [
&amp;quot;*&amp;quot;
]
}
]
}
EOF
}
// Create a role which consul instances will assume.
// This role has a policy saying it can be assumed by ec2
// instances.
resource &amp;quot;aws_iam_role&amp;quot; &amp;quot;consul-instance-role&amp;quot; {
name = &amp;quot;consul-instance-role&amp;quot;
assume_role_policy = &amp;lt;&amp;lt;EOF
{
&amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;,
&amp;quot;Statement&amp;quot;: [
{
&amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot;,
&amp;quot;Principal&amp;quot;: {
&amp;quot;Service&amp;quot;: &amp;quot;ec2.amazonaws.com&amp;quot;
},
&amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
&amp;quot;Sid&amp;quot;: &amp;quot;&amp;quot;
}
]
}
EOF
}
// Attach the policy to the role.
resource &amp;quot;aws_iam_policy_attachment&amp;quot; &amp;quot;consul-instance-leader-discovery&amp;quot; {
name = &amp;quot;consul-instance-leader-discovery&amp;quot;
roles = [&amp;quot;${aws_iam_role.consul-instance-role.name}&amp;quot;]
policy_arn = &amp;quot;${aws_iam_policy.leader-discovery.arn}&amp;quot;
}
// Create a instance profile for the role.
resource &amp;quot;aws_iam_instance_profile&amp;quot; &amp;quot;consul-instance-profile&amp;quot; {
name = &amp;quot;consul-instance-profile&amp;quot;
roles = [&amp;quot;${aws_iam_role.consul-instance-role.name}&amp;quot;]
}
&lt;/code>&lt;/pre>&lt;p>Terraform is a little verbose here! Finally, we update our launch configuration to ensure that the instances assume this role.&lt;/p>
&lt;pre>&lt;code>resource &amp;quot;aws_launch_configuration&amp;quot; &amp;quot;consul-cluster-lc&amp;quot; {
// Add this line!!
iam_instance_profile = &amp;quot;${aws_iam_instance_profile.consul-instance-profile.id}&amp;quot;
}
}
&lt;/code>&lt;/pre>&lt;p>Let's create the cluster again, with &lt;code>terraform apply&lt;/code>. When we log into the UI we should now see a cluster containing all five nodes:&lt;/p>
&lt;p>&lt;img src="images/img-13-cluster.png" alt="Screenshot of the Consul UI, showing that the Consul server is running on five nodes in the Datacenter">&lt;/p>
&lt;p>This code is all in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/tree/step-3">Step 3&lt;/a> branch.&lt;/p>
&lt;p>If you are familiar with Consul, this may be all you need. If not, you might be interested in seeing how we actually create a new instance to host a service, register it with Consul and query its address.&lt;/p>
&lt;h2 id="step-4---adding-a-microservice">Step 4 - Adding a Microservice&lt;/h2>
&lt;p>I've created a docker image for as simple a microservice as you can get. It returns a quote from Futurama's Zapp Brannigan. The image is tagged as &lt;code>dwmkerr/zapp-service&lt;/code>.&lt;/p>
&lt;p>On a new EC2 instance, running in either subnet, with the same roles as the Consul nodes, we run the following commands:&lt;/p>
&lt;pre>&lt;code># Install Docker
sudo su
yum update -y
yum install -y docker
service docker start
# Get my IP and the IP of any node in the server cluster.
IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
NODE_ID=$(aws --region=&amp;quot;ap-southeast-1&amp;quot; autoscaling describe-auto-scaling-groups --auto-scaling-group-name &amp;quot;consul-asg&amp;quot; \
| grep InstanceId \
| cut -d '&amp;quot;' -f4 \
| head -1)
NODE_IP=$(aws --region=&amp;quot;ap-southeast-1&amp;quot; ec2 describe-instances \
--query=&amp;quot;Reservations[].Instances[].[PrivateIpAddress]&amp;quot; \
--output=&amp;quot;text&amp;quot; \
--instance-ids=&amp;quot;$NODE_ID&amp;quot;)
# Run the consul agent.
docker run -d --net=host \
consul agent \
-bind=&amp;quot;$IP&amp;quot; \
-join=$NODE_IP
# Run registrator - any Docker images will then be auto registered.
docker run -d \
--name=registrator \
--net=host \
--volume=/var/run/docker.sock:/tmp/docker.sock \
gliderlabs/registrator:latest \
consul://localhost:8500
# Run the example microservice - registrator will take care of letting consul know.
docker run -d -p 5000:5000 dwmkerr/zapp-service
&lt;/code>&lt;/pre>&lt;p>What's going on here?&lt;/p>
&lt;ol>
&lt;li>We grab our own IP address and the IP address of the first instance we find in the server cluster, using the same tricks as before&lt;/li>
&lt;li>We run the Consul agent - telling it the IP to use to join the cluster&lt;/li>
&lt;li>We run &lt;a href="https://github.com/gliderlabs/registrator">Registrator&lt;/a>, a handy utility which will automatically register any new services we run to Consul&lt;/li>
&lt;li>We run a goofy sample microservice (which registrator will register for us)&lt;/li>
&lt;/ol>
&lt;p>Now we can check the Consul UI:&lt;/p>
&lt;p>&lt;img src="images/img-15-sample-service.png" alt="The Consul UI showing a new service">&lt;/p>
&lt;p>And there we have it. Our new node joins the cluster (as a client), we can register a new service with Consul.&lt;/p>
&lt;p>We can call this service from any node in the subnet, seeing output like the below:&lt;/p>
&lt;p>&lt;img src="images/img-x-zapp.png" alt="Screenshot of the Zapp service">&lt;/p>
&lt;p>In this example, I used a DNS SRV query to ask where the &lt;code>zapp-service&lt;/code> is, was told it was at &lt;code>10.0.2.158&lt;/code> on port &lt;code>5000&lt;/code>, then called the service, receiving a response. I can discover any service using this method, from any node. As services are added, removed, moved etc, I can ask Consul for accurate information on where to find them.&lt;/p>
&lt;p>Check the &lt;a href="">Step 4&lt;/a> branch to see the code in its current state.&lt;/p>
&lt;h2 id="step-5---spanner-throwing">Step 5 - Spanner Throwing&lt;/h2>
&lt;p>We can now try to throw some spanners in the works, to see how resilient the system is.&lt;/p>
&lt;p>According to the &lt;a href="https://www.consul.io/docs/internals/consensus.html#deployment-table">Deployment Table&lt;/a> from the Consul documentation, a cluster of five nodes means we have a quorum of three nodes (i.e. a minimum of three nodes are needed for a working system). This means we can tolerate the failure of two nodes.&lt;/p>
&lt;p>The easiest way to test this is to simply manually kill two nodes:&lt;/p>
&lt;p>&lt;img src="images/img-16-terminate.png" alt="Screenshot showing two AWS instances being terminated">&lt;/p>
&lt;p>If we pick two random nodes, as above, and terminate them, we see the cluster determines that we have two failed nodes but will still function (if one was the leader, a new leader will be automatically elected):&lt;/p>
&lt;p>&lt;img src="images/img-17-node-failure.png" alt="Screenshot showing the cluster highlighting two failed nodes">&lt;/p>
&lt;p>What's nice about this setup is that no manual action is needed to recover. Our load balancer will notice the nodes are unhealthy and stop forwarding traffic. Our auto-scaling group will see the nodes have terminated and create two new ones, which will join the cluster in the same way as the original nodes. Once they join, the load balancer will find them healthy and bring them back into rotation.&lt;/p>
&lt;p>We can see from the load balancer monitoring that it notices we have unhealthy nodes and also notices when new ones come into service:&lt;/p>
&lt;p>&lt;img src="images/img-18-recovery-1.png" alt="Screenshot showing the load balancer monitoring">&lt;/p>
&lt;p>A quick check of the admin dashboard shows we now have a recovered system, with five healthy nodes:&lt;/p>
&lt;p>&lt;img src="images/img-18b-recovered.png" alt="Screenshot showing recovered system">&lt;/p>
&lt;p>The nodes which were terminated are still listed as failing. After 72 hours Consul will stop trying to periodically reconnect to these nodes and completely remove them&lt;sup id="fnref:12">&lt;a href="#fn:12" class="footnote-ref" role="doc-noteref">12&lt;/a>&lt;/sup>.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>Hopefully this should provide a good starting point to think about building your own resilient and robust systems for services like Consul.&lt;/p>
&lt;p>Interesting areas to look into to extend the project would be:&lt;/p>
&lt;ol>
&lt;li>Setting up alerts so that if we lose more than one node, we are informed&lt;/li>
&lt;li>Automating resilience tests by programatically bringing down servers and monitoring how long it takes the system to return to five nodes&lt;/li>
&lt;li>Instead of using a userdata script to set up a node, bake it into a new custom AMI with &lt;a href="https://www.packer.io/">Packer&lt;/a>&lt;/li>
&lt;li>Adding alerts for if we lose three of more nodes, which always requires manual intervention (see &lt;a href="https://www.consul.io/docs/guides/outage.html">Outage Recovery&lt;/a>)&lt;/li>
&lt;/ol>
&lt;p>As always, any questions or comments are welcome! All code is available at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster">github.com/dwmkerr/terraform-consul-cluster&lt;/a>.&lt;/p>
&lt;hr>
&lt;h2 id="appendix-1-logging">Appendix 1: Logging&lt;/h2>
&lt;p>Small typos or mistakes in the userdata script are almost impossible to effectively diagnose. The scripts were actually built in the following way:&lt;/p>
&lt;ol>
&lt;li>Draft a script on my local machine which configures script logging and CloudWatch&lt;sup id="fnref:13">&lt;a href="#fn:13" class="footnote-ref" role="doc-noteref">13&lt;/a>&lt;/sup>&lt;/li>
&lt;li>Spin up a new EC2 instance manually&lt;/li>
&lt;li>SSH onto the instance, and run the script line by line until I'm sure it's right&lt;/li>
&lt;li>Ensure the logs are forwarded to CloudWatch, then add the more complex features and repeatedly test&lt;/li>
&lt;/ol>
&lt;p>I've included CloudWatch logging in the code. In this write-up I've omitted this code as it is purely for diagnostics and doesn't contribute to the main topic. The setup is in the &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/blob/master/files/consul-node.sh">&lt;code>consul-node.sh&lt;/code>&lt;/a> and &lt;a href="%60https://github.com/dwmkerr/terraform-consul-cluster/blob/master/consul-node-role.tf">&lt;code>consul-node-role.tf&lt;/code>&lt;/a> files.&lt;/p>
&lt;p>If you want more details, let me know, or just check the code. I would heartily recommend setting up logging like this for all but the most straightforward projects:&lt;/p>
&lt;p>&lt;img src="images/img-19-cloudwatch-1.png" alt="Screenshot showing logs">&lt;/p>
&lt;p>Being able to diagnose issues like this is vital when working with distributed systems which may be generating many log files.&lt;/p>
&lt;h2 id="appendix-2-modularisaton">Appendix 2: Modularisaton&lt;/h2>
&lt;p>I got some a great PR from &lt;a href="https://github.com/arehmandev">arehmandev&lt;/a> which modularises the code. This makes it more reusable and cleans up the structure significantly. If you want to see the before/after, check the original PR at &lt;a href="https://github.com/dwmkerr/terraform-consul-cluster/pull/4">https://github.com/dwmkerr/terraform-consul-cluster/pull/4&lt;/a>.&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Further Reading&lt;/strong>&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://www.consul.io/docs/internals/consensus.html">Consul - Consensus Protocol&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://sitano.github.io/2015/10/06/abt-consul-outage/">What you have to know about Consul and how to beat the outage problem&lt;/a>, John Koepi&lt;/li>
&lt;/ol>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>This kind of pattern is critical in the world of microservices, where many small services will be running on a cluster. Services may die, due to errors or failing hosts, and be recreated on new hosts. Their IPs and ports may be ephemeral.It is essential that the system as a whole has a registry of where each service lives and how to access it. Such a registry must be &lt;em>resilient&lt;/em>, as it is an essential part of the system. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Most popular is a fairly loose term. Well ranked by Gartner and anecdotally with the largest infrastructure footprint. &lt;a href="https://www.gartner.com/doc/reprints?id=1-2G2O5FC&amp;amp;ct=150519&amp;amp;st=sb">https://www.gartner.com/doc/reprints?id=1-2G2O5FC&amp;amp;ct=150519&amp;amp;st=sb&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>This is AWS parlance again. An availabilty zone is an isolated datacenter. Theoretically, spreading nodes across AZs will increase resilience as it is less likely to have catastrophic failures or outages across multiple zones. &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>I don't get money from Udemy or anyone else for writing anything on this blog. All opinions are purely my own and influenced by my own experience, not sponsorship. Your milage may vary (yada yada) but I found the course quite good: &lt;a href="https://www.udemy.com/aws-certified-solutions-architect-associate/">https://www.udemy.com/aws-certified-solutions-architect-associate/&lt;/a>. &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>For more expert readers that may sound horribly patronising, I don't mean it to be. For many less experienced technologists the basics of networking might be more unfamiliar! &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>See &lt;a href="https://www.consul.io/docs/internals/consensus.html">https://www.consul.io/docs/internals/consensus.html&lt;/a>. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>A common pattern is to actually make the group size dynamic, responding to events. For example, we could have a group of servers which increases in size if the average CPU load of the hosts stays above 80% for five minutes, and scales down if it goes below 10% for ten minutes. This is more common for app and web servers and not needed for our system. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:8" role="doc-endnote">
&lt;p>Specifically, the current latest &lt;a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux AMI&lt;/a>. &lt;a href="#fnref:8" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:9" role="doc-endnote">
&lt;p>Check the admin UI every 30 seconds, more than 3 seconds indicates a timeout and failure. Two failures in a row means an unhealthy host, which will be destroyed, two successes in a row for a new host means healthy, which means it will receive traffic. &lt;a href="#fnref:9" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:10" role="doc-endnote">
&lt;p>This is a fairly sophisticated topic in itself, see &lt;a href="https://www.consul.io/docs/internals/consensus.html">Consul - Consensus Protocol&lt;/a> for details. &lt;a href="#fnref:10" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:11" role="doc-endnote">
&lt;p>In fact, we actually have more permissions required, because in the &amp;lsquo;real&amp;rsquo; code we also have logs forwarded to CloudWatch. &lt;a href="#fnref:11" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:12" role="doc-endnote">
&lt;p>These nodes can be removed manually, see &lt;a href="https://www.consul.io/docs/commands/force-leave.html">Consul Force Leave&lt;/a>. &lt;a href="#fnref:12" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:13" role="doc-endnote">
&lt;p>Amazon's service for managing and aggregating logs &lt;a href="#fnref:13" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Using Slack for Server Development</title><link>https://dwmkerr.com/using-slack-for-server-development/</link><pubDate>Fri, 18 Nov 2016 01:25:00 +0000</pubDate><guid>https://dwmkerr.com/using-slack-for-server-development/</guid><description>&lt;p>I recently found a surprisingly helpful approach for server-side development which uses Slack in a creative way.&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>The scenario can be roughly simplified to this:&lt;/p>
&lt;p>&lt;img src="images/0-problem.png" alt="Planned Architecture">&lt;/p>
&lt;p>We are building a mobile app and application server. This will take data from a user, transform it and then pass it to the enterprise system processing.&lt;/p>
&lt;p>The problem is that the enterprise system doesn't exist yet!&lt;/p>
&lt;p>Now this is not too much of a challenge, the first thing we did was build a simple mock of the enterprise system in Node.js, so that we can at least talk to &lt;em>something&lt;/em>:&lt;/p>
&lt;p>&lt;img src="images/0-problem-2.png" alt="The Mock System">&lt;/p>
&lt;p>So now we have the question - is our application server transforming the data correctly?&lt;/p>
&lt;p>Let's say that in our example we bring in three pieces of data from the UI - a first name, middle name and last name.&lt;/p>
&lt;p>Our enterprise system, in this case we'll say it is a CRM system, only accepts a first name and last name. So in our app server, we are going to concatenate the middle name and last name.&lt;/p>
&lt;p>Our testers want to make sure that the enterprise system will receive the right data - but at the moment it is only a mock, we cannot log in a check the middle and last names have been combined properly. What to do?&lt;/p>
&lt;h2 id="slack-to-the-rescue">Slack to the Rescue!&lt;/h2>
&lt;p>It's a trivial change to our mock server to send the received messages to Slack:&lt;/p>
&lt;p>&lt;img src="images/1-slack.png" alt="Slack Diagram">&lt;/p>
&lt;p>Now our testers can input data in the mobile app and then watch a slack channel to see the data our application server will actually send to the enterprise system. They can verify the logic has been implemented correctly.&lt;/p>
&lt;p>Here's how it might look - in the image below I am running my mock enterprise server, which has Swagger UI to show the mocked APIs and allow me to call them:&lt;/p>
&lt;p>&lt;img src="images/4-swagger.png" alt="Swagger UI">&lt;/p>
&lt;p>The message is received on the server, sent to slack and we can check the result:&lt;/p>
&lt;p>&lt;img src="images/5-slack.png" alt="Slack">&lt;/p>
&lt;p>Now this is obviously a trivial and contrived example, but Slack offers a lot of capabilities. Imagine you have a server which watermarks images, you could send an image file to render to the screen. There are a whole bunch of ways you can extend this use case.&lt;/p>
&lt;p>In the early stages of a project, where they may be many mocked systems, being able to see what they are doing can be really useful.&lt;/p>
&lt;h2 id="setting-it-up">Setting it up&lt;/h2>
&lt;p>I've created a super-simple demo setup here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/slack-backend">github.com/dwmkerr/slack-backend&lt;/a>&lt;/p>
&lt;p>Here's how you go about it.&lt;/p>
&lt;p>Step 1: Set up a webhook on slack&lt;/p>
&lt;p>&lt;img src="images/1-menu.png" alt="Menu">&lt;/p>
&lt;p>&lt;img src="images/1-incoming-webhook.png" alt="Webhook">&lt;/p>
&lt;p>&lt;img src="images/3-hook.png" alt="">&lt;/p>
&lt;p>Step 2: Use the HTTP APIs from Slack, or a client from your platform of choice to send the message:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">
&lt;span style="color:#75715e">// Create the Slack webhook based on our config.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">slack&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Slack&lt;/span>();
&lt;span style="color:#a6e22e">slack&lt;/span>.&lt;span style="color:#a6e22e">setWebhook&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;https://hooks.slack.com/services/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&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Every time we&amp;#39;re about to handle a request, tell our friend Slack.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">ext&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;onPreHandler&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">request&lt;/span>, &lt;span style="color:#a6e22e">reply&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Never bother logging any requests to swagger UI.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/swaggerui\//&lt;/span>) &lt;span style="color:#f92672">||&lt;/span>
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/swagger.json/&lt;/span>) &lt;span style="color:#f92672">||&lt;/span>
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">match&lt;/span>(&lt;span style="color:#e6db74">/\/$/&lt;/span>)) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reply&lt;/span>.&lt;span style="color:#66d9ef">continue&lt;/span>();
}
&lt;span style="color:#75715e">// Send the Slack message.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">slack&lt;/span>.&lt;span style="color:#a6e22e">webhook&lt;/span>({
&lt;span style="color:#a6e22e">text&lt;/span>&lt;span style="color:#f92672">:&lt;/span>
&lt;span style="color:#e6db74">`&lt;/span>&lt;span style="color:#e6db74">Request *&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">*
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">method&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74"> &lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">path&lt;/span>&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">${&lt;/span>&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">payload&lt;/span>, &lt;span style="color:#66d9ef">null&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#e6db74">}&lt;/span>&lt;span style="color:#e6db74">
&lt;/span>&lt;span style="color:#e6db74">&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">\`&lt;/span>&lt;span style="color:#e6db74">`&lt;/span>
});
&lt;span style="color:#a6e22e">reply&lt;/span>.&lt;span style="color:#66d9ef">continue&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This approach was quick and easy to implement, hopefully others will find it useful!&lt;/p></description><category>CodeProject</category></item><item><title>Simple Continuous Integration for Docker Images</title><link>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</link><pubDate>Thu, 03 Nov 2016 05:14:35 +0000</pubDate><guid>https://dwmkerr.com/simple-continuous-integration-for-docker-images/</guid><description>&lt;p>In this article I'm going to demonstrate a few tips and tricks which can make your life easier when you are building or maintaining Dockerfiles.&lt;/p>
&lt;h2 id="the-need-for-a-build-pipeline">The need for a Build Pipeline&lt;/h2>
&lt;p>Do we really need any kind of continuous integration or build pipeline for Dockerfiles?&lt;/p>
&lt;p>There will be cases when the answer is no. However, if the answer to any of the following questions is &amp;lsquo;yes&amp;rsquo;, it might be worth considering:&lt;/p>
&lt;ol>
&lt;li>Do you want others to be able to contribute to the Dockerfile, perhaps changing the image over time?&lt;/li>
&lt;li>Are there specific functionalities in your Dockerfiles which could break if altered?&lt;/li>
&lt;li>Do you expect to need to release updates to your Dockerfile?&lt;/li>
&lt;/ol>
&lt;p>Essentially, if we are looking at providing some kind of automated quality assurance and automation around building and releasing, then a build pipeline is not a bad idea.&lt;/p>
&lt;h2 id="a-simple-build-pipeline">A simple Build Pipeline&lt;/h2>
&lt;p>Here's what a simple build pipeline could look like. This example is for a Docker Image I just created for local DynamoDB development - &lt;a href="https://github.com/dwmkerr/docker-dynamodb">dwmkerr/docker-dynamodb&lt;/a>:&lt;/p>
&lt;p>&lt;img src="images/Simple-Docker-Image-CI.png" alt="Simple Continous Intergration Pipeline">&lt;/p>
&lt;p>Let's dissect what we've got here.&lt;/p>
&lt;h3 id="the-dockerfile">The Dockerfile&lt;/h3>
&lt;p>This is the main &amp;lsquo;code&amp;rsquo; of the project if you like. The &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/Dockerfile">Dockerfile&lt;/a> is the recipe for the image we create.&lt;/p>
&lt;h3 id="the-continuous-integration-service">The Continuous Integration Service&lt;/h3>
&lt;p>In this case, I am using &lt;a href="https://circleci.com/">CircleCI&lt;/a>, however the approach described would work fine with most CI systems (such as Jenkins, TravisCI and TeamCity). There &lt;em>is&lt;/em> an option to use the &lt;a href="https://docs.docker.com/docker-hub/builds/">Docker Hub Automated Builds&lt;/a>, but I've found this doesn't give the flexibility I need (see &lt;a href="#appendix1whynotdockerhubautomatedbuilds">Why not Docker Hub Automated Builds&lt;/a>).&lt;/p>
&lt;p>Essentially the CI service needs to offer the option to have three distinct steps in the pipeline, each of which must pass for process to proceed:&lt;/p>
&lt;ol>
&lt;li>Build&lt;/li>
&lt;li>Test&lt;/li>
&lt;li>Deploy&lt;/li>
&lt;/ol>
&lt;h3 id="the-build">The Build&lt;/h3>
&lt;p>We can build with tools, script files, whatever. At the moment, I am leaning towards &lt;a href="https://www.gnu.org/software/make/">makefiles&lt;/a>. Normally I only need a few lines of shell script to do a build - anything more complex and the makefile can call a shell script. See also &lt;a href="#appendix2whymakefiles">Why Makefiles?&lt;/a>&lt;/p>
&lt;p>Here's what it might look like:&lt;/p>
&lt;pre>&lt;code>build:
docker build -t dwmkerr/dynamodb:latest .
ifndef BUILD_NUM
$(warning No build number is defined, skipping build number tag.)
else
docker build -t dwmkerr/dynamodb:$(BUILD_NUM) .
endif
&lt;/code>&lt;/pre>&lt;p>This command just builds the &lt;code>Dockerfile&lt;/code> and tags it as &lt;code>dwmkerr/dynamodb:lastest&lt;/code>. If a &lt;code>BUILD_NUM&lt;/code> variable is present, we also create the tag &lt;code>dwmkerr/dynamodb:BUILD_NUM&lt;/code>. This means if we want to deploy to a service such as &lt;a href="https://aws.amazon.com/ecs/">Amazon ECS&lt;/a> we can push a specific build by referring to the image with that tag.&lt;/p>
&lt;h3 id="the-tests">The Tests&lt;/h3>
&lt;p>Again I'm relying on &lt;code>make&lt;/code>. I just want to be able to run &lt;code>make test&lt;/code> - if zero is returned I'm happy. If not, the pipeline should stop and I'll check the output. Here's my test command:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>Not a thing of beauty, but it works. These scripts I'll discuss a little bit later on, in the delightly titled &lt;a href="#appendix3whatarethesetestscripts">What are these test scripts&lt;/a> section.&lt;/p>
&lt;p>For CircleCI, this is enough to have the main part of our pipeline. Here's how the &lt;code>circle.yml&lt;/code> file looks at this stage:&lt;/p>
&lt;pre>&lt;code>machine:
services:
- docker
environment:
# Set the build number, used in makefiles.
BUILD_NUM: $CIRCLE_BUILD_NUM
test:
override:
- make test
&lt;/code>&lt;/pre>&lt;p>(Actually there's a couple of other bits but they're just to make sure circle uses the right version of Docker, &lt;a href="https://github.com/dwmkerr/docker-dynamodb/blob/master/circle.yml">see the full circle.yml file here&lt;/a>).&lt;/p>
&lt;h3 id="the-deployments">The Deployments&lt;/h3>
&lt;p>Deployments are trivial as all we need to do is push to the Docker Hub. The &lt;code>make deploy&lt;/code> command looks-a like this:&lt;/p>
&lt;pre>&lt;code>deploy:
docker push dwmkerr/dynamodb:latest
ifndef BUILD_NUM
$(warning No build number is defined, skipping push of build number tag.)
else
docker push dwmkerr/dynamodb:$(BUILD_NUM)
endif
&lt;/code>&lt;/pre>&lt;p>We're pushing the &lt;code>latest&lt;/code> tag and &lt;code>BUILD_NUM&lt;/code> tag if present. To add this to the CircleCI pipeline, we just add the following to &lt;code>circle.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>deployment:
master:
branch: master
commands:
- docker login -e $DOCKER_EMAIL -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
- make deploy
&lt;/code>&lt;/pre>&lt;p>If we have a push to &lt;code>master&lt;/code>, we log in to Docker (using environment variables I configure in the CircleCI UI) and then run &lt;code>make deploy&lt;/code> to push our images.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>That's about it. This is a pretty simple approach, you can see it in action at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/docker-dynamodb">github.com/dwmkerr/docker-dynamodb&lt;/a>&lt;/p>
&lt;p>The rest of this post is a bit of a deep dive into some specific areas I found interesting.&lt;/p>
&lt;h2 id="appendix-1-why-not-docker-hub-automated-builds">Appendix 1: Why not Docker Hub Automated Builds?&lt;/h2>
&lt;p>There are automated builds available in the Docker Hub:&lt;/p>
&lt;p>&lt;img src="images/dockerhubbuilds.png" alt="Docker Hub Automated Builds">&lt;/p>
&lt;p>I'm not using this feauture at the moment, here's a brief roundup of what I think are the current pros and cons:&lt;/p>
&lt;p>Pros&lt;/p>
&lt;ul>
&lt;li>You don't have to goof around installing Docker on a CI platform.&lt;/li>
&lt;li>It allows you to update the description of your Docker image automatically, from the GitHub &lt;code>README.md&lt;/code>.&lt;/li>
&lt;li>It allows you to associate the image with a specific GitHub repo (rather than just linking from the image description).&lt;/li>
&lt;li>Branch management - allowing tags to be built for specific branches.&lt;/li>
&lt;/ul>
&lt;p>Cons&lt;/p>
&lt;ul>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of configurable gating, such as a running a test command prior to deploying.&lt;/li>
&lt;li>It doesn't &lt;em>seem&lt;/em> to support any kind of triggering of downstream processes, such as updating environments, sending notifications or whatever.&lt;/li>
&lt;/ul>
&lt;p>The lack of ability to perform tests on the image before deploying it why I'm currently not using the service.&lt;/p>
&lt;p>By doing the testing in a CI system for every pull request and only merging PRs where the tests pass we could mitigate the risk here. This service is worth watching as I'm sure it will evolve quickly.&lt;/p>
&lt;h2 id="appendix-2-why-makefiles">Appendix 2: Why Makefiles?&lt;/h2>
&lt;p>I started coding with a commandline compiler in DOS. When I used my first GUI (Borland Turbo C++) it felt like a huge leap:&lt;/p>
&lt;p>&lt;img src="images/turbocpp.png" alt="Borland Turbo C++">&lt;/p>
&lt;p>Later on I moved onto Microsoft Visual C++ 4.2:&lt;/p>
&lt;p>&lt;img src="images/visualcpp.png" alt="Visual C++ 4.2">&lt;/p>
&lt;p>And you cannot imagine the excitement when I got my boxed edition of Visual Studio .NET:&lt;/p>
&lt;p>&lt;img src="images/visualstudiodotnet.jpg" alt="Visual Studio .NET">&lt;/p>
&lt;p>Wow!&lt;/p>
&lt;p>Anyway, I digress. GNU &lt;code>make&lt;/code> was invented by Leonardo Da Vinci in 1473 to allow you to build something from the commandline, using a fairly consistent syntax.&lt;/p>
&lt;p>It is near ubiquitous on *nix systems. I am increasingly using it as an &amp;lsquo;entry point&amp;rsquo; to builds, as I use variety of languages and platforms. Being able to know that most of the time:&lt;/p>
&lt;pre>&lt;code>make build
make test
&lt;/code>&lt;/pre>&lt;p>Will build and test something is convenient. Makefiles actually are not that great to work with (see &lt;a href="http://stackoverflow.com/questions/448910/makefile-variable-assignment">this&lt;/a>, &lt;a href="http://stackoverflow.com/questions/10121182/multiline-bash-commands-in-makefile">this&lt;/a> and &lt;a href="http://www.conifersystems.com/whitepapers/gnu-make/">this&lt;/a>). I've found as long as you keep the commands simple, they're OK. For anything really complex, I normally have a &lt;code>scripts/&lt;/code> folder, but call the scripts &lt;em>from&lt;/em> the makefile, so that there's still a simple entrypoint.&lt;/p>
&lt;p>I'm not entirely sold on makefiles, but they tend to be my default at the moment if I know I'm going to use the commandline for builds (for example, in Java projects I'll often write a makefile to call Maven or Gradle).&lt;/p>
&lt;p>For things like Node.js, where you have commands like &lt;code>npm test&lt;/code> or &lt;code>npm run xyz&lt;/code> I &lt;em>still&lt;/em> sometimes use makefiles, using &lt;code>npm&lt;/code> for day-to-day dev tests (&lt;code>npm start&lt;/code>) and &lt;code>make&lt;/code> if it's something more complex (e.g. &lt;code>make deploy-sit&lt;/code> to deploy to an SIT environment).&lt;/p>
&lt;h2 id="appendix-3-what-are-these-test-scripts">Appendix 3: What are these test scripts?&lt;/h2>
&lt;p>You may have noticed:&lt;/p>
&lt;pre>&lt;code>test: build
./test/basics.test.sh
./test/ephemeral.test.sh
./test/persistent.test.sh
&lt;/code>&lt;/pre>&lt;p>What's going on here?&lt;/p>
&lt;p>My Docker image is just a wrapper around &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">Amazon's Local DynamoDB tool&lt;/a>. I don't really need to test that tool. But what I wanted to test was the capabilities which lie at the &lt;em>intersection&lt;/em> between &amp;lsquo;native&amp;rsquo; Docker and &amp;lsquo;native&amp;rsquo; DynamoDB.&lt;/p>
&lt;p>For example, I know Docker supports volume mapping. I know DynamoDB supports using a data directory, to allow persistent between runs. I want to test I can combine Docker volume mapping and the DynamoDB data directory features. I know Docker images should default to being ephemeral, I want to test this holds true by default for my image.&lt;/p>
&lt;p>Testing Docker is a little hard - I want to test that I can run containers, start, stop, check state before and after and so on. This is essentially an integration test, it can be tricky to make it truly isolated and deterministic.&lt;/p>
&lt;p>I've given it my best go with these scripts. Here's an example for the &amp;lsquo;ephemeral&amp;rsquo; test, where I'm trying to assert that if I run a container, create a table, stop the container and run a new one, I no longer have the table. Here's the test:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">&lt;span style="color:#75715e"># Bomb if anything fails.&lt;/span>
set -e
&lt;span style="color:#75715e"># Kill any running dynamodb containers.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Cleaning up old containers...&amp;#34;&lt;/span>
docker ps -a | grep dwmkerr/dynamodb | awk &lt;span style="color:#e6db74">&amp;#39;{print $1}&amp;#39;&lt;/span> | xargs docker rm -f &lt;span style="color:#f92672">||&lt;/span> true
&lt;span style="color:#75715e"># Run the container.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Checking we can run the container...&amp;#34;&lt;/span>
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># Create a table.&lt;/span>
aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> create-table &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --table-name Supervillains &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --attribute-definitions AttributeName&lt;span style="color:#f92672">=&lt;/span>name,AttributeType&lt;span style="color:#f92672">=&lt;/span>S &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --key-schema AttributeName&lt;span style="color:#f92672">=&lt;/span>name,KeyType&lt;span style="color:#f92672">=&lt;/span>HASH &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> --provisioned-throughput ReadCapacityUnits&lt;span style="color:#f92672">=&lt;/span>1,WriteCapacityUnits&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Clean up the container. On CircleCI the FS is BTRFS, so this might fail...&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Stopping and restarting...&amp;#34;&lt;/span>
docker stop $ID &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm $ID &lt;span style="color:#f92672">||&lt;/span> true
ID&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>docker run -d -p 8000:8000 dwmkerr/dynamodb&lt;span style="color:#66d9ef">)&lt;/span>
sleep &lt;span style="color:#ae81ff">2&lt;/span>
&lt;span style="color:#75715e"># List the tables - there shouldn&amp;#39;t be any!&lt;/span>
COUNT&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">$(&lt;/span>aws dynamodb --endpoint-url http://localhost:8000 --region us-east-1 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> list-tables &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> | jq &lt;span style="color:#e6db74">&amp;#39;.TableNames | length&amp;#39;&lt;/span>&lt;span style="color:#66d9ef">)&lt;/span>
&lt;span style="color:#66d9ef">if&lt;/span> &lt;span style="color:#f92672">[&lt;/span> $COUNT -ne &lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span> &lt;span style="color:#f92672">]&lt;/span>; &lt;span style="color:#66d9ef">then&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;&lt;/span>&lt;span style="color:#e6db74">Expected to find no tables, found &lt;/span>$COUNT&lt;span style="color:#e6db74">...&lt;/span>&lt;span style="color:#e6db74">&amp;#34;&lt;/span>
exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#66d9ef">fi&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>It's a bit dirty - it removes containers from the host, changes things and so on. But it works.&lt;/p>
&lt;p>I did experiment with running these tests &lt;em>in a container&lt;/em>, which has the benefit of giving you a clean host to start with, which you can throw away after each test.&lt;/p>
&lt;p>I had to give up after a little while due to time constraints, but will probably revisit this process. The benefits of running these integration tests in a container is that we get a degree of isolation from the host.&lt;/p>
&lt;p>If anyone is interested, my attempts so far are on this &lt;a href="https://github.com/dwmkerr/docker-dynamodb/pull/2">RFC Pull Request&lt;/a>. Feel free to jump in!&lt;/p></description><category>CodeProject</category></item><item><title>Run Amazon DynamoDB locally with Docker</title><link>https://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</link><pubDate>Thu, 27 Oct 2016 08:06:00 +0000</pubDate><guid>https://dwmkerr.com/run-amazon-dynamodb-locally-with-docker/</guid><description>&lt;p>&lt;strong>tl;dr:&lt;/strong> Run DynamoDB locally using Docker:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8000:8000 dwmkerr/dynamodb
&lt;/code>&lt;/pre>&lt;p>Try it out by opening the shell, &lt;a href="http://localhost:8000/shell">localhost:8000/shell&lt;/a>:&lt;/p>
&lt;p>&lt;img src="images/banner.jpg" alt="DynamoDB Shell">&lt;/p>
&lt;p>That's all there is to it!&lt;/p>
&lt;h2 id="dynamodb">DynamoDB&lt;/h2>
&lt;p>&lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html">Amazon DynamoDB&lt;/a> is a NoSQL database-as-a-service, which provides a flexible and convenient repository for your services.&lt;/p>
&lt;p>Building applications which use DynamoDB is straightforward, there are APIs and clients for many languages and platforms.&lt;/p>
&lt;p>One common requirement is to be able to run a local version of DynamoDB, for testing and development purposes. To do this, you need to:&lt;/p>
&lt;ol>
&lt;li>Hit the &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">DynamoDB Local&lt;/a> documentation page&lt;/li>
&lt;li>Download an archive&lt;/li>
&lt;li>Extract it to a sensible location&lt;/li>
&lt;li>Run the extracted JAR, perhaps passing in some options&lt;/li>
&lt;/ol>
&lt;p>This can be a little cumbersome if you regularly use DynamoDB, so here's a easier way:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker run -p 8000:8000 dwmkerr/dynamodb
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>dwmkerr/dynamodb&lt;/code> image runs the JAR in a container, exposing the database on port 8000 by default.&lt;/p>
&lt;p>You can see the &lt;a href="dockeri.co/image/dwmkerr/dynamodb">image on the Docker Hub&lt;/a> and the source code at &lt;a href="https://github.com/dwmkerr/docker-dynamodb">github.com/dwmkerr/docker-dynamodb&lt;/a>.&lt;/p>
&lt;h2 id="customising-dynamodb">Customising DynamoDB&lt;/h2>
&lt;p>You can pass any of &lt;a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.html">the documented commandline flags to DynamoDB&lt;/a>. There are instructions on the GitHub page. Here's an example of how you can pass in a data directory, which allows DynamoDB data to be persisted after restarting a container (the image is ephemeral by default, as per &lt;a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">Dockerfile best practices&lt;/a>).&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker run -d -p 8000:8000 -v /tmp/data:/data/ dwmkerr/dynamodb -dbPath /data/
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Running DynamoDB in a container gives an extra degree of flexibility and can speed up your workflow too!&lt;/p></description><category>CodeProject</category></item><item><title>Effective Node.js Debugging</title><link>https://dwmkerr.com/effective-node-js-debugging/</link><pubDate>Sat, 03 Sep 2016 01:36:09 +0000</pubDate><guid>https://dwmkerr.com/effective-node-js-debugging/</guid><description>&lt;p>If you are interested in improving your Node.js debugging skills, then check out my talk at the recent &lt;a href="">JSChannel 2016&lt;/a> conference in Bangalore:&lt;/p>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/-iCygy2wGpM" frameborder="0" allowfullscreen>&lt;/iframe>
&lt;p>Comments and observations are always welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Testing the Docker for Mac Beta</title><link>https://dwmkerr.com/testing-the-docker-for-mac-beta/</link><pubDate>Fri, 03 Jun 2016 10:45:24 +0000</pubDate><guid>https://dwmkerr.com/testing-the-docker-for-mac-beta/</guid><description>&lt;p>I've finally had a chance to install the new Docker for Mac Beta and give it a whirl. In this article I'm going to talk a bit about how Docker works, the challenges of running Docker on a Mac or Windows and how the new Beta helps.&lt;/p>
&lt;p>&lt;em>Below: The welcome message for the new Docker for Mac app&lt;/em>&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-20-33-20.png" alt="Docker for Mac Icon">&lt;/p>
&lt;h1 id="so-what-is-docker-for-mac">So What is Docker for Mac?&lt;/h1>
&lt;p>If you don't know what Docker is, check out my article &lt;a href="http://www.dwmkerr.com/learn-docker-by-building-a-microservice/">Learn Docker by Building a Microservice&lt;/a> or the lovely &lt;a href="https://www.docker.com/what-docker">What is Docker&lt;/a> page from the docs.&lt;/p>
&lt;p>You may be aware that Docker creates processes in isolated containers using some key Linux technologies which allow for low-level isolation (such as &lt;strong>namespaces&lt;/strong> and &lt;strong>cgroups&lt;/strong>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>).&lt;/p>
&lt;p>This is described in detail on the &lt;a href="https://docs.docker.com/engine/understanding-docker/">Understand the Docker Architecture&lt;/a> page, but essentially means we can do this:&lt;/p>
&lt;p>&lt;img src="images/Docker-on-Ubuntu.png" alt="Docker Running on Ubuntu">&lt;/p>
&lt;p>Here I have:&lt;/p>
&lt;ol>
&lt;li>My machine, called &lt;code>Dave-Ubuntu&lt;/code>, which is running Ubuntu&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, with a local IP 192.168.0.1.&lt;/li>
&lt;li>The &lt;code>docker&lt;/code> executable, which I use to issue commands to&amp;hellip;&lt;/li>
&lt;li>&amp;hellip;the Docker Host, which runs the docker daemon, which actually does the work of starting/stopping/building containers and so on.&lt;/li>
&lt;li>Some containers in the Docker Host - one is based on a MySQL image and has a DB, one is based on a Node.js image and is running an app.&lt;/li>
&lt;/ol>
&lt;p>The Docker host is actually my machine - I can connect using the loopback IP 127.0.0.1 (i.e. localhost). The containers also have the IP of the host. If I want to create and connect to a MySQL DB from my machine, I just type:&lt;/p>
&lt;pre>&lt;code>docker run -d -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 mysql
mysql -uroot -p123 -h127.0.0.1
&amp;gt; show databases;
&amp;gt; ...etc...
&amp;gt; exit;
&lt;/code>&lt;/pre>&lt;p>The container was created on my machine (in the host) and addressable using my loopback IP.&lt;/p>
&lt;h2 id="so-what">So What?&lt;/h2>
&lt;p>This is all great, but things get a little harder on a Mac or Windows. MacOS and the Windows OS don't have the same kernel level support for process isolation, control groups and so on, so the Docker Host cannot run on these operating systems. Instead, an extra layer and component is introduced:&lt;/p>
&lt;p>&lt;img src="images/Docker-on-MacOS.png" alt="Docker on OSX">&lt;/p>
&lt;p>What's new?&lt;/p>
&lt;ol>
&lt;li>Oracle VirtualBox has been installed to create and manage virtual machines.&lt;/li>
&lt;li>A virtual machine running Linux (called in this case a &amp;lsquo;docker machine&amp;rsquo;) called &amp;lsquo;default&amp;rsquo; has been created (by convention with the IP 192.168.99.100).&lt;/li>
&lt;li>This virtual machine runs Linux, so can perfectly happily act as the docker host.&lt;/li>
&lt;li>The docker host is still addressable as 127.0.0.1 - &lt;em>from the virtual machine&lt;/em> - from the outside world (i.e. my Mac) I have to use the virtual machine IP.&lt;/li>
&lt;/ol>
&lt;p>So this is how Docker works on a Mac or on Windows. Things are made seemless where possible, for example, all of the required components are installed when you install the &lt;a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox&lt;/a>.&lt;/p>
&lt;h2 id="so-what-1">So What?&lt;/h2>
&lt;p>Well the problem here is that one of the big benefits of using docker is that it allows us to create development environments which are much closer to production environments (at least from a software point of view).&lt;/p>
&lt;p>This kind of breaks down if we are doing development on a Mac or on Windows - because we have introduced an additional component which is simply not going to be present in our production environment. What are the problems?&lt;/p>
&lt;h3 id="1-localhost-vs-docker-machine-ip">1. Localhost vs docker-machine IP&lt;/h3>
&lt;p>Docker helps us be a lot more agnostic to our development box, but if I'm writing about how to interact with docker containers there's a problem:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8080:8080 my-app-server
curl http://localhost:8080/some-api-call
&lt;/code>&lt;/pre>&lt;p>This works on a Linux machine - it does not work on a Mac or Windows. On a Mac I need to run something like:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 8080:8080 my-app-server
curl http://$(docker-machine ip default)/some-api-call
&lt;/code>&lt;/pre>&lt;p>This will &lt;em>not&lt;/em> work on Linux or Windows.&lt;/p>
&lt;p>Is this a big deal? Actually, kind of. What if I have an integration test which spins up some containers and runs calls against them - the test has to know about the execution environment. That's a pain. An alternative is to run tests in a container and link them with something like docker-compose, but this is not ideal.&lt;/p>
&lt;h3 id="2-terminal-hassle">2. Terminal Hassle&lt;/h3>
&lt;p>If I open a terminal and check to see what containers are running:&lt;/p>
&lt;pre>&lt;code>docker ps
&lt;/code>&lt;/pre>&lt;p>I'll see nothing. If I try to run a container:&lt;/p>
&lt;pre>&lt;code>docker run -it mongo
&lt;/code>&lt;/pre>&lt;p>I'll get an error - because my docker instance cannot communicate with the host. I need to use a specially set up terminal to tell it to connect to the VM.&lt;/p>
&lt;p>Again, the Docker Toolkit is set up to try and make things easy. If I install the toolkit I can run an app called Docker Quickstart Terminal:&lt;/p>
&lt;p>&lt;img src="images/Quickstart.jpg" alt="Docker Quickstart Terminal">&lt;/p>
&lt;p>And this will open a terminal where I &lt;em>can&lt;/em> use these commands. It will also start the docker machine VM if it has to. It's even smart enough to recognise if I have multiple terminal apps, such as iTerm, and ask which one I want to use.&lt;/p>
&lt;p>This problem is - this doesn't always work smoothly. Sometimes it will seem that the machine has started but will still not accept commands. Typically a restart is needed in this scenario.&lt;/p>
&lt;p>Also, it's an interruption. If you are running a terminal already and want to issue a quick command, it will fail, unless it was a terminal started with the Docker Quickstart app.&lt;/p>
&lt;h3 id="3-inotify---in-container-development">3. inotify - In Container Development&lt;/h3>
&lt;p>If you recognise the term, you probably know the issue. If not, a little explanation is necessary.&lt;/p>
&lt;p>As you get more and more familiar with Docker, you will probably find that you are spending more and more time testing, building then running your image in a container. In fact, you might be changing a single code file and using the container as the dev test server on your machine.&lt;/p>
&lt;p>This fast gets painful - the container image takes time to build and slows down the development cycle. There's a great technique in this scenario: &lt;strong>In Container Development&lt;/strong>.&lt;/p>
&lt;p>In container development is pretty much what it sounds like. Instead of editing your code on your machine, building an image and creating a container to debug, you simply create the container with what you need, &lt;strong>mount your code&lt;/strong> in to the container and run all of your development tooling from inside the container:&lt;/p>
&lt;p>&lt;img src="images/In-Container-Development.png" alt="Docker In Container Development">&lt;/p>
&lt;p>In this diagram, I have my code locally on my machine. I have built a container which runs &lt;code>nodemon&lt;/code>, watching a directory on the container. That directory is actually just a volume containing my code which I have mounted into my container.&lt;/p>
&lt;p>This is a really nice technique - I can still code locally, but as I make changes, &lt;code>nodemon&lt;/code> serves up my new content.&lt;/p>
&lt;p>This specific example applies to Node.js, but can be applied to many scenarios.&lt;/p>
&lt;p>The problem is that many watcher tools like &lt;code>nodemon&lt;/code> use a kernel subsystem called &lt;code>inotify&lt;/code>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup> to get notifications when files change. But &lt;code>inotify&lt;/code> doesn't work on virtualbox&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>. This means that this technique isn't supported for Mac or Windows. There are however some tools which try and work around this with polling.&lt;/p>
&lt;p>So now we have another issue. The develop/test process might be nice on Linux, but for devs on other platforms the process is more clunky.&lt;/p>
&lt;h1 id="docker-for-mac-and-windows-to-the-rescue">Docker for Mac and Windows to the rescue&lt;/h1>
&lt;p>The issues I've mentioned so far are the big ones which cause me problems personally, I'm sure there are others (please comment and let me know!).&lt;/p>
&lt;p>This is why there was rather a lot of interest in the new Docker Beta - one of the big features is that the Docker Machine is going away. In theory, we can use Docker on a Mac or Windows and have the same experience as on Linux.&lt;/p>
&lt;h2 id="so-how">So how?&lt;/h2>
&lt;p>Virtualbox is gone. We still need a VM, but this VM is now a very lightweight Alpine Linux based image which runs on xhyve for MacOS and Hyper-V for Windows. All management of this VM is handled &lt;em>by the docker executable&lt;/em>.&lt;/p>
&lt;p>If these are not familiar terms, &lt;a href="https://en.wikipedia.org/wiki/Alpine_Linux">Alpine Linux&lt;/a> is an &lt;em>extreeeemely&lt;/em> lightweight Linux distro originally design to fit on a floppy disk (I think it clocks at around 5 MB now). &lt;a href="https://github.com/mist64/xhyve">xhyve&lt;/a> is an &lt;em>extremely&lt;/em> lightweight hypervisor which allows FreeBSD and some other distros on OSX. &lt;a href="https://en.wikipedia.org/wiki/Hyper-V">Hyper-V&lt;/a> is a native hypervisor for Windows Server which can run on Windows 8 onwards&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Using tools specifically designed for each platform (and with the help of both Apple and Microsoft), Docker have been able to make the experience much more seamless and smooth.&lt;/p>
&lt;h1 id="trying-it-out">Trying It Out&lt;/h1>
&lt;p>Removing the three pain points discussed and a clean and simple setup process is what I'm looking at today, and here's the results.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Piece of cake. Download the beta, install, run, enter the beta key and pop, there's the new docker:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-20-33-20-1.png" alt="Docker Welcome Message">&lt;/p>
&lt;p>The new status bar icon gives me a way to quickly see the status of the machine. Some of the commands hint at features to come, others offer the instructions needed. Settings are fairly basic, but I'm not sure what else you'd need:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-09-56.png" alt="Status Bar Screenshot 1">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-10-07.png" alt="Status Bar Screenshot 2">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-10-23.png" alt="Status Bar Screenshot 3">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-44-04.png" alt="Status Bar Screenshot 4">&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-44-12.png" alt="Status Bar Screenshot 5">&lt;/p>
&lt;h3 id="1-localhost-vs-docker-machine-ip-1">1. Localhost vs docker-machine IP&lt;/h3>
&lt;p>Quickly bashing out the commands below shows that the virtual machine IP address issue is gone:&lt;/p>
&lt;pre>&lt;code>docker run -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123 mysql
mysql -uroot -p123 -h127.0.0.1
&amp;gt; show databases;
&lt;/code>&lt;/pre>&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-23-37-39.png" alt="Localhost Screenshot">&lt;/p>
&lt;p>Great news!&lt;/p>
&lt;p>How this works under the hood is a mystery to me. If anyone knows, I'd be interested and would like to update this writeup!&lt;/p>
&lt;h3 id="2-terminal-hassle-1">2. Terminal Hassle&lt;/h3>
&lt;p>Quick and easy to test - running any terminal any way I like lets me access containers using the &lt;code>docker&lt;/code> executable - no magic needed:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-03-at-23-46-57.png" alt="Shells">&lt;/p>
&lt;p>Here's a screenshot of iTerm3, the Terminal App and the Terminal App running &lt;code>zsh&lt;/code>, all of which are happily communicating with the docker deamon through the &lt;code>docker&lt;/code> app.&lt;/p>
&lt;h3 id="3-in-container-development">3. In Container Development&lt;/h3>
&lt;p>I've not thrashed this one too hard, but gone for a quick sanity check. Throwing together probably my best ever node.js app&lt;sup id="fnref:6">&lt;a href="#fn:6" class="footnote-ref" role="doc-noteref">6&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;strong>main.js&lt;/strong>&lt;/p>
&lt;pre>&lt;code>setInterval(function() {
console.log(&amp;quot;Goodbye, cruel world!&amp;quot;);
}, 1000);
&lt;/code>&lt;/pre>&lt;p>and a simple dockerfile:&lt;/p>
&lt;p>&lt;strong>Dockerfile&lt;/strong>&lt;/p>
&lt;pre>&lt;code>FROM node:6
WORKDIR src/
ADD package.json .
RUN npm install
CMD npm start
&lt;/code>&lt;/pre>&lt;p>is enough to test this. I can build then run the container, mounting the working directory into the &lt;code>src&lt;/code> volume on the container:&lt;/p>
&lt;pre>&lt;code>docker build -t incontainerdev .
docker run -it -v `pwd`:/src incontainerdev]
&lt;/code>&lt;/pre>&lt;p>Immediately, I open a new window and change the source code and save (on my local Mac, not in the container). Voila:&lt;/p>
&lt;p>&lt;img src="images/Screen-Shot-2016-06-04-at-00-03-23.png" alt="Live Reloading">&lt;/p>
&lt;p>Live reloading works without a hitch! &lt;code>nodemon&lt;/code> picks up my changes, using &lt;code>inotify&lt;/code> from the VM (all through a lightweight userspace hypervisor).&lt;/p>
&lt;p>You know what is cool&lt;sup id="fnref:7">&lt;a href="#fn:7" class="footnote-ref" role="doc-noteref">7&lt;/a>&lt;/sup>? &lt;strong>I don't even need Node.js installed to build this Node app!&lt;/strong> The runtime is in the container, all of the execution happens in the container.&lt;/p>
&lt;h1 id="thats-a-wrap">That's a Wrap&lt;/h1>
&lt;p>That's it for my initial impressions. From this point onwards I'm going to be using Docker for Mac heavily as I'll do all of my work with it installed, so from time to time I may update this article with other observations.&lt;/p>
&lt;p>The key takeaway is: at the moment, Docker for Mac just &lt;em>works&lt;/em>. I'm using it in the same way I would on Ubuntu with no messing around. This is great, it seems like a simple thing but I'm guessing it was a lot of effort from the guys and girls at Docker, Microsoft and Apple.&lt;/p>
&lt;p>This is still a Beta, there'll be bugs and they'll be fixed. I can't wait for the Beta to go fully into the wild, and see what exciting things people can do with it.&lt;/p>
&lt;p>As usual, any comments or observations are welcome!&lt;/p>
&lt;p>&lt;strong>References&lt;/strong>&lt;/p>
&lt;p>&lt;strong>Further Reading&lt;/strong>&lt;/p>
&lt;p>Namespaces: &lt;a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">http://man7.org/linux/man-pages/man7/namespaces.7.html&lt;/a>
cgroups: &lt;a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">http://man7.org/linux/man-pages/man7/cgroups.7.html&lt;/a>
Docker Execution Drivers: &lt;a href="https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/">https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/&lt;/a>
inotify: &lt;a href="http://man7.org/linux/man-pages/man7/inotify.7.html">http://man7.org/linux/man-pages/man7/inotify.7.html&lt;/a>
The challenges of in-container development on OSX: &lt;a href="http://hharnisc.github.io/2015/09/16/developing-inside-docker-containers-with-osx.html">http://hharnisc.github.io/2015/09/16/developing-inside-docker-containers-with-osx.html&lt;/a>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Read up on namespaces &lt;a href="http://man7.org/linux/man-pages/man7/namespaces.7.html">here&lt;/a> and cgroups &lt;a href="http://man7.org/linux/man-pages/man7/cgroups.7.html">here&lt;/a>. Docker can also use &lt;a href="https://en.wikipedia.org/wiki/LXC">LXC&lt;/a> but no longer &lt;em>has&lt;/em> to, there's a great write-up &lt;a href="https://blog.docker.com/2014/03/docker-0-9-introducing-execution-drivers-and-libcontainer/">here&lt;/a>. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Surprise! &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Read up on inotify &lt;a href="http://man7.org/linux/man-pages/man7/inotify.7.html">here&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>The issue will not be resolved: &lt;a href="https://www.virtualbox.org/ticket/10660">https://www.virtualbox.org/ticket/10660&lt;/a> &lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>I've not used the Docker for Windows Beta yet so have not got first hand experience of it. I've also not looked into compatibility, from memory Hyper-V isn't available on Home versions of Windows, but I might be wrong. &lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:6" role="doc-endnote">
&lt;p>Inspired by my first programming book, the excellent &lt;a href="http://www.amazon.com/C-Dummies-Dan-Gookin/dp/0764570684">C for Dummies&lt;/a> by Dan Gookin. &lt;a href="#fnref:6" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:7" role="doc-endnote">
&lt;p>For a given definition of cool. &lt;a href="#fnref:7" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Is it worth persevering with Golang?</title><link>https://dwmkerr.com/is-it-worth-persevering-with-golang/</link><pubDate>Wed, 01 Jun 2016 22:10:40 +0000</pubDate><guid>https://dwmkerr.com/is-it-worth-persevering-with-golang/</guid><description>&lt;p>I recently decided to try out &lt;a href="https://golang.org/">the Go Programming Language&lt;/a>, by building a little project called &lt;a href="http://www.github.com/dwmkerr/google-it">google-it&lt;/a> which let's me run a google search from a terminal:&lt;/p>
&lt;p>&lt;img src="images/google-it.gif" alt="google-it screenshot">&lt;/p>
&lt;p>The idea behind the project is simple - avoid jumping into a browser if you need to quickly look up something which you can find in the first line of a Google search result. The idea is to try and stay in the zone. For example, forgotten how to split panes in tmux?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">google-it &lt;span style="color:#e6db74">&amp;#34;split pane tmux&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Would probably show enough information to get going without leaving the terminal.&lt;/p>
&lt;p>Anyway, the project itself is not that useful&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> but it seemed like an ideal project to use as a learning exercise for a new language. After perhaps 10-20 hours of learning, coding and messing around, I'm wondering - is it worth persevering with Golang?&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> If you are learning too, check the &lt;a href="#tipsfornoobs">Tips for Noobs&lt;/a> section at the end of the article, great tips from members of the community!&lt;/p>
&lt;h2 id="why-go2">Why Go&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>?&lt;/h2>
&lt;p>The decision to choose Go for this learning exercise was fairly arbitrary. For the last few years I've been using mainly interpretted languages or languages which use a platform (.NET, Node.js, Java etc) and the idea of going back to something which compiles into in good ol&amp;rsquo; binaries seemed appealing. I'd also heard a lot of good things about Go in general, mostly relating to simplicity, ease of use and concurrency.&lt;/p>
&lt;h2 id="why-persevere">Why Persevere?&lt;/h2>
&lt;p>That's where I'm looking for guidance. I've collected some of my observations so far, and my overall experience with the language is uninspiring. Anyone who can comment on what makes Go great, or whether my ambivalence is justified will help me decide whether to build my next mess-around project in Go or move on to something else.&lt;/p>
&lt;h2 id="frustrations-so-far">Frustrations So Far&lt;/h2>
&lt;p>Before I upset anyone, this is all just the opinion of a total Go noob with maybe 15 hours of coding time in Go. But I've been developing using a few different languages and platforms for while.&lt;/p>
&lt;h3 id="folder-structure-is-way-too-opinionated">Folder structure is way too opinionated&lt;/h3>
&lt;p>Setup itself is easy, at least on unix or a Mac. But like many coders, I'm anal-retentive about how I like to organise things:&lt;/p>
&lt;pre>&lt;code>~
└───repositories
├───github.com
├───dwmkerr
├───project1
├───etc
├───organisation1
├───etc
├───bitbucket.com
├───etc
&lt;/code>&lt;/pre>&lt;p>This is how I structure my projects on all my machines, and it works for me.&lt;/p>
&lt;p>Go forces me to put all of my Go projects in the &lt;code>$GOPATH&lt;/code>, so now I have:&lt;/p>
&lt;pre>&lt;code>└───repositories
├───github.com
├───etc
├───go
├───src
├───github.com
├───dwmkerr
├───goproject1
&lt;/code>&lt;/pre>&lt;p>Which unnecessarily spreads out my projects. Other thoughts:&lt;/p>
&lt;ol>
&lt;li>My &lt;code>src&lt;/code> folder is increasingly cluttered with dependent modules, making it harder to find my own work.&lt;/li>
&lt;li>Even within the project folder, I have little flexibility. I'd like to have a &lt;code>src&lt;/code> folder to keep my code in, with just the &lt;code>README.md&lt;/code> at the root (leaving space for a &lt;code>docs&lt;/code> folder and others if necessary) - this cannot be done, so &lt;a href="https://github.com/dwmkerr/google-it">my root folder is cluttered&lt;/a>.&lt;/li>
&lt;li>Again, in the project folder itself, &lt;a href="https://www.reddit.com/r/golang/comments/2lq3it/is_there_a_way_to_arrange_go_code_into_multiple/">I cannot use sub-folders for code&lt;/a>. Some might argue if you need subfolders you have too much code in one project.&lt;/li>
&lt;/ol>
&lt;p>All in all it feels like there are a lot of constraints for structure and organisation, with little benefit.&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> Steve Francia has rightly pointed out that points 2 and 3 are actually wrong, a project can be simply a &lt;code>main.go&lt;/code> file in the root and a set of submodules, see &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2708416211">this comment&lt;/a> for details.&lt;/p>
&lt;p>&lt;strong>Update 3/6/2016&lt;/strong> A very nice way to separate internal and external go modules is described in &lt;a href="https://www.reddit.com/r/golang/comments/4m5it3/is_it_worth_persevering_with_golang/d3ssyts">this reddit thread&lt;/a>.&lt;/p>
&lt;h3 id="the-idiomatic-approach-to-error-handling-is-flawed">The idiomatic approach to error handling is flawed&lt;/h3>
&lt;p>This is likely to prove contentious.&lt;/p>
&lt;p>My code contains sections like this:&lt;/p>
&lt;pre>&lt;code>func LoadSettings() (Settings, error) {
var s Settings
exists, err := exists(GetSettingsPath())
if err != nil {
return s, err
}
if !exists {
return CreateDefaultSettings(), nil
}
raw, err := ioutil.ReadFile(GetSettingsPath())
if err != nil {
return s, err
}
json.Unmarshal(raw, &amp;amp;s)
return s, err
}
&lt;/code>&lt;/pre>&lt;p>I see smells:&lt;/p>
&lt;ol>
&lt;li>The &lt;code>s&lt;/code> structure is created even though I may not need it.&lt;/li>
&lt;li>Even worse, it is &lt;strong>returned uninitialised&lt;/strong> in error conditions.&lt;/li>
&lt;li>Repetitive code for dealing with error conditions for calls.&lt;/li>
&lt;/ol>
&lt;p>Now I could avoid the first smell by returning a pointer to the structure, but that incures unnecessary complexity and heap allocations. Here I feel the language is forcing me to do something awful (return a structure I know is invalid) and expect the caller to deal with it.&lt;/p>
&lt;p>Even worse - the calling code now does this:&lt;/p>
&lt;pre>&lt;code>settings, err := LoadSettings()
if err != nil {
color.Red(&amp;quot;Error loading settings: &amp;quot;, err)
os.Exit(1)
}
&lt;/code>&lt;/pre>&lt;p>I've seen this in many places - nested calls passing the same error around, with little extra context, and eventually terminating.&lt;/p>
&lt;p>&lt;strong>This is what exceptions are for.&lt;/strong>&lt;/p>
&lt;p>Native exceptions in languages handle this for you, giving stack information and killing the process by default.&lt;/p>
&lt;p>The &amp;lsquo;pass the error on to the caller approach&amp;rsquo; may not be the right way to go, but the Go blog suggests exactly this:&lt;/p>
&lt;p>&lt;a href="https://blog.golang.org/error-handling-and-go">https://blog.golang.org/error-handling-and-go&lt;/a>&lt;/p>
&lt;p>And to me it stinks a bit. If this is the truly desired idomatic approach, then why not supported it natively by the language? Here's the same pseudo-code in F#:&lt;/p>
&lt;pre>&lt;code>let loadSettings =
let path = getSettingsPath()
match exists path with
| true -&amp;gt; path |&amp;gt; readFile |&amp;gt; readSettings
| _ -&amp;gt; createDefaultSettings
match loadSettings with
| Some settings -&amp;gt; // ..whatever
| None -&amp;gt; // ..deal with errors
&lt;/code>&lt;/pre>&lt;p>If &lt;code>loadSettings&lt;/code> can't return settings, it doesn't return settings. If the caller doesn't handle the &amp;lsquo;no settings&amp;rsquo; scenario explicitly, the compiler will complain that there's a case missing. In this case we have an approach which will warn the coder if they miss something.&lt;/p>
&lt;h3 id="inconsistent-syntax">Inconsistent Syntax&lt;/h3>
&lt;p>A small one, but when I'm defining a structure I can do this:&lt;/p>
&lt;pre>&lt;code>type Link struct {
Id string
Uri string
}
&lt;/code>&lt;/pre>&lt;p>but when I'm returning a structure, I need commas:&lt;/p>
&lt;pre>&lt;code>return Link{
Id: strconv.Itoa(linkNumber),
Uri: item.Link,
}
&lt;/code>&lt;/pre>&lt;p>I can see the benefit of &lt;strong>allowing&lt;/strong> a comma on the last line, to support quick refactoring, but &lt;strong>forcing&lt;/strong> it seems odd. Why commas for some constructs and not others&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>?&lt;/p>
&lt;p>Also, some more &amp;lsquo;unusual&amp;rsquo; syntax (depending on your background) is present, I assume to save space:&lt;/p>
&lt;pre>&lt;code>something := createAndAssign()
// rather than
var something SomeType
something = assign()
&lt;/code>&lt;/pre>&lt;p>But some space saving constructs such as ternary operators are missing:&lt;/p>
&lt;pre>&lt;code>// easy- c++, c#, java style
something := condition ? case1() : case2()
// easy- python style
something := case1() if condition else case2() // python
// hard - go style
var something SomeType
if condition {
something = case1()
} else {
something = case2()
}
&lt;/code>&lt;/pre>&lt;h3 id="difficult-debugging">Difficult Debugging&lt;/h3>
&lt;p>For C, C++, .NET, Java and many other languages, debugging is pretty straightforward. For Node.js, you can just use the excellent Chrome debugging tools. For Go, it seems like it's &lt;strong>much&lt;/strong> harder.&lt;/p>
&lt;p>In my limited time using the language, I avoided &lt;code>gdb&lt;/code> because it looked like a lot of work:&lt;/p>
&lt;p>&lt;a href="https://golang.org/doc/gdb">https://golang.org/doc/gdb&lt;/a>&lt;/p>
&lt;p>I did see some projects like &lt;a href="https://github.com/mailgun/godebug">godebug&lt;/a> which may ease the process but I was initially surprised by the effort needed to get into debugging.&lt;/p>
&lt;p>Commenter Sotirios Mantziaris &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2707804888">mentioned that delve provides a nice experience as a debugger&lt;/a>, so this would be worth exploring.&lt;/p>
&lt;h2 id="delights-so-far">Delights So Far&lt;/h2>
&lt;p>It's also worth talking about what I've liked or loved about Go so far.&lt;/p>
&lt;h3 id="simple-tooling">Simple Tooling&lt;/h3>
&lt;p>A project can be nothing more than a single file, go knows how to build and install it. Compare that to Java, where you have a lot of &amp;lsquo;project&amp;rsquo; related stuff - Gradle stuff, Ant stuff, Maven stuff, xml project files stuff and it feels much cleaner.&lt;/p>
&lt;p>The tooling is intuitive, fast and works well if you are happy living in a terminal.&lt;/p>
&lt;h3 id="fantastic-community">Fantastic Community&lt;/h3>
&lt;p>I've added this observation just recently, since writing the article I've had a &lt;strong>huge&lt;/strong> amount of positive input, describing how to improve my code, better understand Go idioms and where its sweet spots like.&lt;/p>
&lt;p>For someone new to a language, the community support is great and will really help people just getting into Go get advice and guidance.&lt;/p>
&lt;h3 id="testing-as-a-first-class-citizen">Testing as a First Class Citizen&lt;/h3>
&lt;p>Testing is built in, which is great. Knowing that you can run &lt;code>go test&lt;/code> on a project and have a standard way of executing tests is really quite nice. I love &lt;code>npm test&lt;/code> for Node.js projects as it has helped standardise testing as a practice (checkout &lt;code>npm install&lt;/code> then &lt;code>npm test&lt;/code>).&lt;/p>
&lt;p>However, I did have to rely on a library, &lt;a href="https://github.com/smartystreets/goconvey">goconvey&lt;/a>, to allow me to write tests in the more BBD structured style which I prefer:&lt;/p>
&lt;pre>&lt;code>func TestSpec(t *testing.T) {
Convey(&amp;quot;The param loader&amp;quot;, t, func() {
Convey(&amp;quot;Should handle no params&amp;quot;, func() {
params, err := ParseParams([]string{})
So(params.ShowHelp.Present, ShouldEqual, false)
So(params.Results.Present, ShouldEqual, false)
So(params.Open.Present, ShouldEqual, false)
So(err, ShouldEqual, nil)
})
&lt;/code>&lt;/pre>&lt;p>But that's a totally personal thing and I'm sure many others will prefer more &amp;lsquo;vanilla&amp;rsquo; tests.&lt;/p>
&lt;h3 id="great-documentation">Great Documentation&lt;/h3>
&lt;p>I've found everything I've needed so far on &lt;a href="https://golang.org/doc/">Go's own documentation&lt;/a>. The documentation is clean, accessible and seems fairly complete from my limited interactions with it.&lt;/p>
&lt;h3 id="delightful-vim-development-experience">Delightful Vim Development Experience&lt;/h3>
&lt;p>OK - this is not a language feature. But if you are a noob like me moving from this:&lt;/p>
&lt;p>&lt;img src="images/VimGoVanilla-1.jpg" alt="Vim vanilla">&lt;/p>
&lt;p>to this:&lt;/p>
&lt;p>&lt;img src="images/VimWithVimGo.jpg" alt="Vim with vim-go plugin screenshot">&lt;/p>
&lt;p>made a big difference. The excellent &lt;a href="https://github.com/fatih/vim-go">vim-go&lt;/a> plugin gives syntax highlighting and supports some really useful commands. As a learner, regularly running &lt;code>:GoLint&lt;/code> is really helping me write more &amp;lsquo;conventional&amp;rsquo; Go.&lt;/p>
&lt;h2 id="what-am-i-missing">What am I missing?&lt;/h2>
&lt;p>There are some things I know I haven't had a chance to look at which may really be demonstrating the best parts of Go:&lt;/p>
&lt;ol>
&lt;li>Concurrency patterns&lt;/li>
&lt;li>Performance&lt;/li>
&lt;li>Writing web servers&lt;/li>
&lt;li>Godoc&lt;/li>
&lt;li>Debugging with Delve&lt;/li>
&lt;/ol>
&lt;h2 id="should-i-continue">Should I continue?&lt;/h2>
&lt;p>At this stage I'm leaning towards moving on and trying something different, hoping that I'll come back to Go later. Should I persevere with Go for my next project, would Go enthusiasts suggest so and what sort of project hits the &amp;lsquo;sweet spot&amp;rsquo; where Go is a really effective choice?&lt;/p>
&lt;p>An interesting comment by a colleague was: &amp;ldquo;I would say the usual &amp;lsquo;does it change the way you think about programming?', if yes then persevere, if no then are you going to really leverage Go’s strengths (and find out weaknesses) in your project? If no then either change language or project.&amp;rdquo; was rather insightful.&lt;/p>
&lt;p>Any comments are welcome!&lt;/p>
&lt;h2 id="can-you-help-me-get-better">Can you help me get better?&lt;/h2>
&lt;p>Any pull requests to my project or comments which show where I've gone wrong and what I could do to improve my experience and code would be welcome at:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/google-it">https://github.com/dwmkerr/google-it&lt;/a>&lt;/p>
&lt;p>Thanks!&lt;/p>
&lt;h2 id="tips-for-noobs">Tips for Noobs!&lt;/h2>
&lt;p>Since publishing this article I've collected some useful tips from people who've commented or got in touch.&lt;/p>
&lt;h4 id="use-gofmt-and-lint">Use gofmt and lint&lt;/h4>
&lt;p>The tool &lt;code>gofmt&lt;/code> will update your code to format it in a conventional go style. This'll help you keep your code consistent with others&amp;rsquo;. Using a linter will also help you stay conventional - if you are using &lt;a href="https://github.com/fatih/vim-go">vim-go&lt;/a> you can run it from vim with &lt;code>:GoLint&lt;/code>. Thanks @snoproblem!&lt;/p>
&lt;h4 id="understand-where-go-is-a-ferrari">Understand where Go is a Ferrari&lt;/h4>
&lt;p>This I am still working on, and it's certainly tricky for a noob. But commenter devdungeon pointed out that a project like mine is not a great use case for Go - Go excels at speed and concurrency. Projects where that is key are going to be more inspiring. See &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2708265044">this comment&lt;/a> for more.&lt;/p>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Mainly because you have to sign up for the Google Cloud Platform to get an API key so you can perform searches, as Google have deprecated the free and easy search API. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>&lt;a href="https://www.youtube.com/watch?v=DvijZuvEiQo">https://www.youtube.com/watch?v=DvijZuvEiQo&lt;/a> &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>SnoProblem describes why in &lt;a href="http://www.dwmkerr.com/is-it-worth-persevering-with-golang/#comment-2707767852">this comment&lt;/a> &lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>What's your Vim Name?</title><link>https://dwmkerr.com/whats-your-vim-name/</link><pubDate>Wed, 01 Jun 2016 08:58:16 +0000</pubDate><guid>https://dwmkerr.com/whats-your-vim-name/</guid><description>&lt;p>I'm a few weeks into moving to Vim as my main editor, I've stopped crying and shaking mostly (at least about my editing ability).&lt;/p>
&lt;p>Now I'm wondering: what's your Vim name? And who's got the best one?&lt;/p>
&lt;p>As far as I can work out, my Vim name is:&lt;/p>
&lt;pre>&lt;code>Replace everything from the cursor to the end of the line with 've'.
&lt;/code>&lt;/pre>&lt;p>Which is what happens if I get bored and type my name (Dave) into Vim.&lt;/p>
&lt;p>Has anyone out there got a name which does something cool in Vim?&lt;/p>
&lt;h3 id="federico---keep-it-casual">federico - Keep it Casual&lt;/h3>
&lt;p>Given a file like:&lt;/p>
&lt;pre>&lt;code>Hello, world!
&lt;/code>&lt;/pre>&lt;p>&lt;code>federico&lt;/code> transforms this into:&lt;/p>
&lt;pre>&lt;code>Hi, world!
&lt;/code>&lt;/pre>&lt;p>Which is pretty cool :)&lt;/p></description><category>CodeProject</category></item><item><title>Quick Tip: Sending Newlines with cURL</title><link>https://dwmkerr.com/quick-tip-sending-newlines-with-curl/</link><pubDate>Tue, 03 May 2016 22:12:28 +0000</pubDate><guid>https://dwmkerr.com/quick-tip-sending-newlines-with-curl/</guid><description>&lt;p>Yikes, this took far too long to figure out!&lt;/p>
&lt;p>I have a service which takes plain text multi-line input and outputs an object for each line, something like this:&lt;/p>
&lt;p>&lt;strong>Input&lt;/strong>&lt;/p>
&lt;pre>&lt;code>Line 1
Line 2
Line 3
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Output&lt;/strong>&lt;/p>
&lt;pre>&lt;code>[
{line: &amp;quot;Line 1&amp;quot;},
{line: &amp;quot;Line 2&amp;quot;},
{line: &amp;quot;Line 3&amp;quot;}
]
&lt;/code>&lt;/pre>&lt;p>There's a bit more to it than that, but that's the gist.&lt;/p>
&lt;p>I want to test my service with cURL, trying:&lt;/p>
&lt;pre>&lt;code>curl --data &amp;quot;Line 1\nLine 2\nLine 3&amp;quot; \
-H &amp;quot;Content-Type: text/plain&amp;quot; localhost:3000/parse
&lt;/code>&lt;/pre>&lt;p>This did not work. Nor did some alternatives. And I really didn't want to have to write the text to a file and load it in.&lt;/p>
&lt;p>Turns out there's a nice little shell trick to let you use escape characters C style, use &lt;code>$'some\ncontent'&lt;/code> to use ANSI C escaping. Now you can cURL with newlines!&lt;/p>
&lt;pre>&lt;code>curl --data $'Line 1\nLine 2\nLine 3' \
-H &amp;quot;Content-Type: text/plain&amp;quot; localhost:3000/parse
&lt;/code>&lt;/pre>&lt;p>Enjoy!&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.gnu.org/software/bash/manual/html_node/ANSI_002dC-Quoting.html">GNU Bash ANSI C Quoting&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://stackoverflow.com/questions/8467424/echo-newline-in-bash-prints-literal-n">Stack Overflow - Echo Newline Bash Prints \n&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://stackoverflow.com/questions/3872427/how-to-send-line-break-with-curl">Stack Overflow - How to send line break with cURL&lt;/a>&lt;/li>
&lt;/ol></description><category>CodeProject</category></item><item><title>Moving from React + Redux to Angular 2</title><link>https://dwmkerr.com/moving-from-react-redux-to-angular-2/</link><pubDate>Mon, 25 Apr 2016 09:45:00 +0000</pubDate><guid>https://dwmkerr.com/moving-from-react-redux-to-angular-2/</guid><description>&lt;p>I've just finished working on a very large project written in React and Redux. The whole team were new to both and we loved them.&lt;/p>
&lt;p>I'm going to share my experiences of experimenting in Angular 2 with you, from the point of view of someone who needs a pretty compelling reason to move away from my JSX and reducers.&lt;/p>
&lt;h1 id="the-journey-so-far">The Journey So Far&lt;/h1>
&lt;p>Let me highlight a few key moments in my UI development experiences, to give a bit of context to my ramblings.&lt;/p>
&lt;p>&lt;img src="images/Journey.jpg" alt="The Journey So Far">&lt;/p>
&lt;p>Reading about redux was a lightbulb moment for me - rather than a complex framework it's a simply library to help apply a few common sense functional programming principles - state is immutable, functions apply predictable transformations to data to produce new data.&lt;/p>
&lt;p>Learning React took a little bit of getting used to, but not too much, it was quite a bit more simple than Angular anyway.&lt;/p>
&lt;p>Long story short, simple React components and rigorous state management has so far resulted in the most manageable and well written very large scale UIs I've worked on so far - can Angular 2 compete with this?&lt;/p>
&lt;h1 id="first-step-with-angular-2---folder-structure-typescript-sublime-text">First Step with Angular 2 - Folder Structure, Typescript, Sublime Text&lt;/h1>
&lt;p>I checked out &lt;a href="https://angular.io/docs/ts/latest/quickstart.html">the pretty neat &amp;lsquo;Getting Started&amp;rsquo; guide from Angular&lt;/a> which promised to get me started in five minutes.&lt;/p>
&lt;p>It didn't take five minutes, there's a few gotchas, so I'm going to give a condensed guide here.&lt;/p>
&lt;h2 id="step-1-the-folder-structure">Step 1: The Folder Structure&lt;/h2>
&lt;p>The first few steps of the angular guide creates the following folder structure:&lt;/p>
&lt;pre>&lt;code>|-- angular2-starter
|-- tsconfig.json
|-- typings.json
|-- package.json
&lt;/code>&lt;/pre>&lt;p>This is the standard &lt;code>package.json&lt;/code> with some scripts ready to go. We also have &lt;code>tsconfig.json&lt;/code> to configure the typescript compiler and &lt;code>typings.json&lt;/code> to provide info to the compiler on where to get type information.&lt;/p>
&lt;p>You can check the code at this stage here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step1">https://github.com/dwmkerr/angular2-starter/tree/step1&lt;/a>&lt;/p>
&lt;p>&lt;img src="images/Step1.png" alt="Step 1 GitHub Screenshot">&lt;/p>
&lt;h2 id="node--npm-issues">Node &amp;amp; NPM Issues&lt;/h2>
&lt;p>At this stage the quickstart says you can run &lt;code>npm install&lt;/code> and all will be well:&lt;/p>
&lt;p>&lt;img src="images/npm-install.png" alt="npm install screenshot">&lt;/p>
&lt;pre>&lt;code>npm ERR! cb() never called!
&lt;/code>&lt;/pre>&lt;p>Not so good! For the record I'm using NPM 3.7.3 installed via homebrew. This looks like a bug in Beta 15 (see &lt;a href="https://github.com/angular/angular/issues/8053">Issue #8053&lt;/a>).&lt;/p>
&lt;p>I fixed this by using &lt;em>n&lt;/em> to upgrade my node version:&lt;/p>
&lt;pre>&lt;code>$ node -v
v5.9.0
$ npm install -g n # install 'n' node version manager
$ sudo n latest
installed : v5.11.0
$ node -v
v5.11.0
&lt;/code>&lt;/pre>&lt;p>Now it &lt;code>npm install&lt;/code> runs OK.&lt;/p>
&lt;h2 id="step-2-adding-components-and-configuring-sublime">Step 2: Adding Components and Configuring Sublime&lt;/h2>
&lt;p>The next steps of the walkthrough take us through adding an app component, a &lt;code>main.ts&lt;/code> file to bootstrap the application and an index file. You can check the updates here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step2">https://github.com/dwmkerr/angular2-starter/tree/step2&lt;/a>&lt;/p>
&lt;p>Essentially we now have:&lt;/p>
&lt;pre>&lt;code>|-- angular2-starter
|-- tsconfig.json
|-- typings.json
|-- package.json
|-- index.html
|-- styles.css
|-- app
|-- main.ts
|-- app.component.ts
&lt;/code>&lt;/pre>&lt;p>At this stage, running &lt;code>npm start&lt;/code> gives us a browerserified app to play with:&lt;/p>
&lt;p>&lt;img src="images/Step2.png" alt="Step 2 Screenshot">&lt;/p>
&lt;p>Clear enough so far, although the code in Sublime is not looking so pretty:&lt;/p>
&lt;p>&lt;img src="images/Step2Sublime.png" alt="Step 2 Sublime Text Screenshot">&lt;/p>
&lt;p>Quickly installing the &lt;a href="https://github.com/Microsoft/TypeScript-Sublime-Plugin">TypeScript plugin&lt;/a> from Microsoft[^n] seems to do the trick:&lt;/p>
&lt;p>&lt;img src="images/Step2SublimeFormatted.png" alt="Step 2 Sublime Text with TypeScript plugin">&lt;/p>
&lt;p>If you need more details, here's a gist with the full setup for Sublime 3, assuming you've got nothing installed.&lt;/p>
&lt;p>&lt;a href="https://gist.github.com/dwmkerr/04fa8b8c15d049d0381e7798a79bcc45">https://gist.github.com/dwmkerr/04fa8b8c15d049d0381e7798a79bcc45&lt;/a>&lt;/p>
&lt;p>At this stage the app will run, we can see the basics of the Angular 2 syntax and start experimenting.&lt;/p>
&lt;h2 id="step-3-adding-some-components">Step 3: Adding some components&lt;/h2>
&lt;p>At this stage the quick started guide starts going into more detail, guiding you through the process of creating multiple components. I decided to go off on my own here, with the rough plan of being able to write a set of goals for the day and turn it into a check-list[^n].&lt;/p>
&lt;p>Within not much time I had the some basic components, input and output, bindings and so on. Some screenshots:&lt;/p>
&lt;p>&lt;img src="images/Goals-Screenshot-1.png" alt="Goals Screenshot 1">&lt;/p>
&lt;p>&lt;img src="images/Goals-Screenshot-2-1.png" alt="Goals Screenshot 2">&lt;/p>
&lt;p>You can take a look at the code at this stage by checking out the &amp;lsquo;step3&amp;rsquo; branch:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/angular2-starter/tree/step3">github.com/dwmkerr/angular2-starter/tree/step3&lt;/a>&lt;/p>
&lt;h1 id="thoughts-so-far">Thoughts so far&lt;/h1>
&lt;p>For now, that's all I've got time for. I've had a chance to get a feel for Angular 2, I'm going to come back to this in a few weeks and integrate Redux, maybe swap out System.JS for Webpack and do some experimenting.&lt;/p>
&lt;p>Opinions[^n] so far?&lt;/p>
&lt;h3 id="not-sold-on-typescript">Not Sold on TypeScript&lt;/h3>
&lt;p>I've used TypeScript in my mess around, rather than plain &amp;lsquo;ol JavaScript, to keep the experience authentic to the angular team's goals of using TypeScript to help.&lt;/p>
&lt;p>So far, I'm not seeing an enormous benefit. Some of the extra information available to auto-completion in nice, but this is a tooling thing.&lt;/p>
&lt;p>JavaScript is not a static language, the TypeScript annotations I find slowing me down a little.&lt;/p>
&lt;blockquote>
&lt;p>There's so much extra domain specific &lt;em>stuff&lt;/em> in Angular 2 that people might be lost without it. But if your stuff is so complex you need to adapt the base language, is it &lt;strong>too&lt;/strong> complex?&lt;/p>
&lt;/blockquote>
&lt;h3 id="explicit-component-surface-areas-are-a-nice-idea">Explicit Component Surface Areas are a Nice Idea&lt;/h3>
&lt;p>When defining a component, you specify explicitly what comes &lt;em>in&lt;/em> (data) and what goes &lt;em>out&lt;/em> (events).&lt;/p>
&lt;p>This means that the surface area of a component (i.e. the part you touch if you interact with it programmatically) is well defined. This is a good thing.&lt;/p>
&lt;p>However, this is all handled with some pretty framework-specific stuff[^n]:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// e.g.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">GoalsBoxComponent&lt;/span> {
&lt;span style="color:#75715e">// Event we fire when the goals change.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">@&lt;/span>&lt;span style="color:#a6e22e">Output&lt;/span>() &lt;span style="color:#a6e22e">goalsChanged&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">EventEmitter&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Goal&lt;/span>[]&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">EventEmitter&lt;/span>();
}
&lt;span style="color:#75715e">// e.g.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">GoalListComponent&lt;/span> {
&lt;span style="color:#75715e">// Input is a set of goals to render.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">@&lt;/span>&lt;span style="color:#a6e22e">Input&lt;/span>() &lt;span style="color:#a6e22e">goals&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">Goal&lt;/span>[] &lt;span style="color:#f92672">=&lt;/span> [];
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In a nutshell&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Explicit component surface area is a cool idea.&lt;/p>
&lt;/blockquote>
&lt;p>React does this too with the optional &lt;code>propTypes&lt;/code>, but it is not enforced. &lt;em>However&lt;/em>, how this is done in Angular has already gone through a few radical changes with some &lt;a href="https://github.com/angular/angular/pull/4435#issuecomment-144789359">lively debate&lt;/a>.&lt;/p>
&lt;h3 id="not-ready-for-production-yet">Not ready for production&amp;hellip; yet&lt;/h3>
&lt;p>There's no standardised, documented way to test a component - nuff said. But things are evolving quickly.&lt;/p>
&lt;h3 id="framework-fatigue">Framework Fatigue&lt;/h3>
&lt;p>Comparing React to Angular is unfair, one is a view library, one is a framework. But it's worth pointing out this is a pretty complex framework. There's a &lt;strong>lot&lt;/strong> of very domain specific stuff. See this documentation for an example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">li&lt;/span> &lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#a6e22e">ngFor&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;#hero of heroes&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>From &lt;a href="https://angular.io/docs/ts/latest/tutorial/toh-pt2.html">the documentation&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>The (*) prefix to ngFor indicates that the &lt;code>&amp;lt;li&amp;gt;&lt;/code> element and its children constitute a master template.&lt;/p>
&lt;p>&amp;hellip;&lt;/p>
&lt;p>The # prefix before &amp;ldquo;hero&amp;rdquo; identifies the hero as a local template variable. We can reference this variable within the template to access a hero’s properties.&lt;/p>
&lt;/blockquote>
&lt;p>You'll get used to it (if you have to), but I think it's harder to &lt;em>reason&lt;/em> about than:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">render&lt;/span> () {
&lt;span style="color:#66d9ef">return&lt;/span> (
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">div&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
{&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">props&lt;/span>.&lt;span style="color:#a6e22e">goals&lt;/span>.&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">goal&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">li&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>{&lt;span style="color:#a6e22e">goal&lt;/span>.&lt;span style="color:#a6e22e">title&lt;/span>}&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">l&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">d&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">v&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">)&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>OK fair enough, JSX is very specific, but the &lt;strong>logic&lt;/strong> (mapping an iterable) is JavaScript.&lt;/p>
&lt;h1 id="wrapping-up">Wrapping Up&lt;/h1>
&lt;p>That's it, for now. Next steps are to experiment more, see if it will play nice with Redux and share the next set of opinions.&lt;/p>
&lt;p>I'd love to hear what you think, so drop your comments below!&lt;/p>
&lt;p>&lt;strong>Footnotes&lt;/strong>&lt;/p></description><category>CodeProject</category></item><item><title>Learn Docker by building a Microservice</title><link>https://dwmkerr.com/learn-docker-by-building-a-microservice/</link><pubDate>Tue, 19 Apr 2016 08:54:39 +0000</pubDate><guid>https://dwmkerr.com/learn-docker-by-building-a-microservice/</guid><description>&lt;p>If you are looking to get your hands dirty and learn all about &lt;a href="https://docker.com">Docker&lt;/a>, then look no further!&lt;/p>
&lt;p>In this article I'm going to show you how Docker works, what all the fuss is about, and how Docker can help with a basic development task - building a microservice.&lt;/p>
&lt;p>We'll use a simple Node.js service with a MySQL backend as an example, going from code running locally to containers running a microservice and database.&lt;/p>
&lt;p align="center">
&lt;img src="images/Article.png" />
&lt;/p>
&lt;p>Once you've read the article, you can find the source code here:&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h2 id="what-is-docker">What is Docker?&lt;/h2>
&lt;p>At its heart, Docker is software which lets you create an &lt;em>image&lt;/em> (which is a lot like a template for a virtual machine) and then run instances of that image in a &lt;em>container&lt;/em>.&lt;/p>
&lt;p>Docker maintains a vast repository of images, called the &lt;a href="https://hub.docker.com">Docker Hub&lt;/a> which you can use as starting points or as free storage for your own images. You can install Docker, choose an image you'd like to use, then run an instance of it in a container.&lt;/p>
&lt;p>We're going to build images, create containers from images and more in this article.&lt;/p>
&lt;h3 id="install-docker">Install Docker&lt;/h3>
&lt;p>To follow along and use this article, you'll need Docker.&lt;/p>
&lt;p>Check the installation guide for your platform, &lt;a href="https://docs.docker.com/engine/installation/">docs.docker.com/engine/installation&lt;/a>.&lt;/p>
&lt;p>If you are on Mac or Windows, consider using a Virtual Machine. I use Parallels on Mac OS X to run an Ubuntu machine for most development activities. Being able to take snapshots, break things and then revert back is very handy when experimenting.&lt;/p>
&lt;h3 id="try-it-out">Try It Out&lt;/h3>
&lt;p>Enter this command:&lt;/p>
&lt;pre>&lt;code>docker run -it ubuntu
&lt;/code>&lt;/pre>&lt;p>After a bit of spinning, you'll see a prompt like this:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/#
&lt;/code>&lt;/pre>&lt;p>Try out a few commands and then exit the container:&lt;/p>
&lt;pre>&lt;code>root@719059da250d:/# lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 14.04.4 LTS
Release: 14.04
Codename: trusty
root@719059da250d:/# exit
&lt;/code>&lt;/pre>&lt;p>This doesn't look like much, but a lot has happened!&lt;/p>
&lt;p>What you are seeing is the bash shell of an &lt;em>isolated&lt;/em> container running Ubuntu, on your machine. It's yours to place with - you can install things on it, run software, whatever you want.&lt;/p>
&lt;p>Here's a diagram and breakdown of what just happened (the digram is from the &lt;a href="https://docs.docker.com/v1.8/introduction/understanding-docker/">&amp;lsquo;Understanding the Architecture&amp;rsquo; Docker Documentation&lt;/a>, which is great):&lt;/p>
&lt;p>&lt;img src="images/Flow.png" alt="Docker Run Flow">&lt;/p>
&lt;ol>
&lt;li>We issue a docker command:&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>&lt;code>docker&lt;/code>: run the docker client&lt;/li>
&lt;li>&lt;code>run&lt;/code>: the command to run a new container&lt;/li>
&lt;li>&lt;code>-it&lt;/code>: option to give the container an interactive terminal&lt;/li>
&lt;li>&lt;code>ubuntu&lt;/code>: the image to base the container on&lt;/li>
&lt;/ul>
&lt;ol start="2">
&lt;li>The docker service running on the host (our machine) checks to see if we have a copy of the requested image locally- which there isn't.&lt;/li>
&lt;li>The docker service checks the public registry (the docker hub) to see if there's an image named &lt;code>ubuntu&lt;/code> available- which there is.&lt;/li>
&lt;li>The docker service downloads the image and stores it in its local cache of images (ready for next time).&lt;/li>
&lt;li>The docker service creates a new container, based on the &lt;code>ubuntu&lt;/code> image.&lt;/li>
&lt;/ol>
&lt;p>Try any of these:&lt;/p>
&lt;pre>&lt;code>docker run -it haskell
docker run -it java
docker run -it python
&lt;/code>&lt;/pre>&lt;p>We're not going to use &lt;a href="https://xkcd.com/1312/">Haskell&lt;/a> today, but you can see, running an environment is very easy.&lt;/p>
&lt;p>It's a snap to build images of our own, with our apps or services on them, databases, whatever we need. We can then run them on any machine with Docker installed - and the image will run in the same, predictable way. We can build our software &lt;em>and the environment it runs on&lt;/em> as code and deploy easily.&lt;/p>
&lt;p>Let's look into a simple microservice as an example.&lt;/p>
&lt;h2 id="the-brief">The Brief&lt;/h2>
&lt;p>We're going to build a microservice which lets us manage a directory of email addresses to phone numbers, using Node.js and MySQL.&lt;/p>
&lt;h2 id="getting-started">Getting Started&lt;/h2>
&lt;p>For doing local development we'll need to install MySQL and create a test database for us to&amp;hellip;&lt;/p>
&lt;p>&amp;hellip;nope.&lt;/p>
&lt;p>Creating a local database and running scripts on it is an easy start, but can get messy. Lots of uncontrolled stuff going on. It might work, we could even control it with some shell scripts checked in to our repo, but what if other developers already have MySQL installed? What if they have a database already with the creative name &amp;lsquo;users&amp;rsquo; which we want to create?&lt;/p>
&lt;h3 id="step-1-creating-a-test-database-server---in-docker">Step 1: Creating a Test Database Server - in Docker&lt;/h3>
&lt;p>This is a great Docker use case. We might not want to run our production database in Docker (perhaps we'll just use Amazon RDS for example), but we can spin up a clean MySQL database in no time as a Docker container for development - leaving our development machine clean and keeping everything we do controlled and repeatable.&lt;/p>
&lt;p>Run the following command:&lt;/p>
&lt;pre>&lt;code>docker run --name db -d -e MYSQL_ROOT_PASSWORD=123 -p 3306:3306 mysql:latest
&lt;/code>&lt;/pre>&lt;p>This starts a MySQL instance running, allowing access through port 3306 using the root password 123.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> tells the engine we want to run an image (the image comes at the end, &lt;a href="https://hub.docker.com/_/mysql/">mysql:vlatest&lt;/a>&lt;/li>
&lt;li>&lt;code>--name db&lt;/code> names this container &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-d&lt;/code> (or &lt;code>--detach&lt;/code>) detach - i.e. run the container in the background.&lt;/li>
&lt;li>&lt;code>-e MYSQL_ROOT_PASSWORD=123&lt;/code> (or &lt;code>--env&lt;/code>) environment variables - tells docker we want to provide an environment variable. The variable following it is what the MySQL image checks for setting the default root password.&lt;/li>
&lt;li>&lt;code>-p 3306:3306&lt;/code> (or &lt;code>--publish&lt;/code> tells the engine that we want to map the port 3306 from inside the container to out port 3306.&lt;/li>
&lt;/ol>
&lt;p>The last part is really important - even though that's the MySQL default port, if we don't tell docker explicitly we want to map it, it will block access through that port (because containers are isolated until you tell them you want access).&lt;/p>
&lt;p>The return value of this function is the &lt;em>container id&lt;/em>, a reference to the container which you can use to stop it, restart it, issue commands on it and so on. Let's see which containers are running:&lt;/p>
&lt;pre>&lt;code>$ docker ps
CONTAINER ID IMAGE ... NAMES
36e68b966fd0 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>The key information is the container ID, image and name. Let's connect to this image and see what's there:&lt;/p>
&lt;pre>&lt;code>$ docker exec -it db /bin/bash
root@36e68b966fd0:/# mysql -uroot -p123
mysql&amp;gt; show databases;
+--------------------+
| Database |
+--------------------+
| information_schema |
+--------------------+
1 rows in set (0.01 sec)
mysql&amp;gt; exit
Bye
root@36e68b966fd0:/# exit
&lt;/code>&lt;/pre>&lt;p>This is pretty clever too:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker exec -it db&lt;/code> tells docker we want to execute a command on the container named &lt;code>db&lt;/code> (we could also use the id, or just the first few letters of the id). &lt;code>-it&lt;/code> ensures we have an interactive terminal.&lt;/li>
&lt;li>&lt;code>mysql -uroot -p123&lt;/code> the command we actually run as a process in the container, which in this case is just the mysql client.&lt;/li>
&lt;/ol>
&lt;p>We can create databases, tables, users, whatever we need.&lt;/p>
&lt;h3 id="wrapping-up-the-test-database">Wrapping up the Test Database&lt;/h3>
&lt;p>Running MySQL inside a container has already introduced a few Docker tricks, but let's pause here and move onto the service. For now, we'll have create a &lt;code>test-database&lt;/code> folder with a script to start the database, stop the database and setup test data:&lt;/p>
&lt;pre>&lt;code>test-database\setup.sql
test-database\start.sh
test-database\stop.sh
&lt;/code>&lt;/pre>&lt;p>Start is simple:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Run the MySQL container, with a database named &amp;#39;users&amp;#39; and credentials&lt;/span>
&lt;span style="color:#75715e"># for a users-service user which can access it.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Starting DB...&amp;#34;&lt;/span>
docker run --name db -d &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_ROOT_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -e MYSQL_DATABASE&lt;span style="color:#f92672">=&lt;/span>users -e MYSQL_USER&lt;span style="color:#f92672">=&lt;/span>users_service -e MYSQL_PASSWORD&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">123&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> -p 3306:3306 &lt;span style="color:#ae81ff">\
&lt;/span>&lt;span style="color:#ae81ff">&lt;/span> mysql:latest
&lt;span style="color:#75715e"># Wait for the database service to start up.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Waiting for DB to start up...&amp;#34;&lt;/span>
docker exec db mysqladmin --silent --wait&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">30&lt;/span> -uusers_service -p123 ping &lt;span style="color:#f92672">||&lt;/span> exit &lt;span style="color:#ae81ff">1&lt;/span>
&lt;span style="color:#75715e"># Run the setup script.&lt;/span>
echo &lt;span style="color:#e6db74">&amp;#34;Setting up initial data...&amp;#34;&lt;/span>
docker exec -i db mysql -uusers_service -p123 users &amp;lt; setup.sql
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This script runs the database image in a detached container (i.e. in the background), with a user set up to access a &lt;code>users&lt;/code> database, then waits for the database server to start up, then runs a &lt;code>setup.sql&lt;/code> script to set initial data.&lt;/p>
&lt;p>&lt;code>setup.sql&lt;/code> is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">
&lt;span style="color:#66d9ef">create&lt;/span> &lt;span style="color:#66d9ef">table&lt;/span> directory (user_id INT &lt;span style="color:#66d9ef">NOT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span> AUTO_INCREMENT &lt;span style="color:#66d9ef">PRIMARY&lt;/span> &lt;span style="color:#66d9ef">KEY&lt;/span>, email TEXT, phone_number TEXT);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">homer@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1111&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">marge@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1112&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">maggie@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1113&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">lisa@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1114&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">insert&lt;/span> &lt;span style="color:#66d9ef">into&lt;/span> directory (email, phone_number) &lt;span style="color:#66d9ef">values&lt;/span> (&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">bart@thesimpsons.com&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#e6db74">+1 888 123 1115&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>stop.sh&lt;/code> script will stop the container and remove it (containers are left around by docker by default so that they can be restared quickly, we don't really need that feature for this example):&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sh" data-lang="sh">&lt;span style="color:#75715e">#!/bin/sh
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e"># Stop the db and remove the container.&lt;/span>
docker stop db &lt;span style="color:#f92672">&amp;amp;&amp;amp;&lt;/span> docker rm db
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We're going to make this even more slick later on, simplifying this further. Check the code at this stage by looking at the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step1">step1&lt;/a> branch of the repo.&lt;/p>
&lt;h3 id="step-2-creating-a-microservice-in-nodejs">Step 2: Creating a Microservice in Node.js&lt;/h3>
&lt;p>This article is really focused on learning Docker, so I'm not going to spend ages on the Node.js microservice. Instead, I'll highlight the areas and takeaways.&lt;/p>
&lt;pre>&lt;code>test-database/ # contains the code seen in Step 1
users-service/ # root of our node.js microservice
- package.json # dependencies, metadata
- index.js # main entrypoint of the app
- api/ # our apis and api tests
- config/ # config for the app
- repository/ # abstraction over our db
- server/ # server setup code
&lt;/code>&lt;/pre>&lt;p>Let's take this apart bit by bit. The first section to look at is &lt;code>repository&lt;/code>. It can be useful to wrap your database access in some kind of class or abstraction, to allow to mock it for testing purposes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// repository.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Exposes a single function - &amp;#39;connect&amp;#39;, which returns
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// a connected repository. Call &amp;#39;disconnect&amp;#39; on this object when you&amp;#39;re done.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">mysql&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;mysql&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Class which holds an open connection to a repository
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// and exposes some simple functions for accessing data.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span> {
&lt;span style="color:#a6e22e">constructor&lt;/span>(&lt;span style="color:#a6e22e">connection&lt;/span>) {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">connection&lt;/span>;
}
&lt;span style="color:#a6e22e">getUsers&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the users: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#a6e22e">resolve&lt;/span>((&lt;span style="color:#a6e22e">results&lt;/span> &lt;span style="color:#f92672">||&lt;/span> []).&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
});
});
}
&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Fetch the customer.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SELECT email, phone_number FROM directory WHERE email = ?&amp;#39;&lt;/span>, [&lt;span style="color:#a6e22e">email&lt;/span>], (&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">results&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;An error occured getting the user: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">err&lt;/span>));
}
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">results&lt;/span>.&lt;span style="color:#a6e22e">length&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>) {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">undefined&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">resolve&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phone_number&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">results&lt;/span>[&lt;span style="color:#ae81ff">0&lt;/span>].&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
});
});
}
&lt;span style="color:#a6e22e">disconnect&lt;/span>() {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">connection&lt;/span>.&lt;span style="color:#a6e22e">end&lt;/span>();
}
}
&lt;span style="color:#75715e">// One and only exported function, returns a connected repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">connectionSettings&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A host must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A user must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A password must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">connectionSettings&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A port must be specified.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Repository&lt;/span>(&lt;span style="color:#a6e22e">mysql&lt;/span>.&lt;span style="color:#a6e22e">createConnection&lt;/span>(&lt;span style="color:#a6e22e">connectionSettings&lt;/span>)));
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's probably a lot of better ways to do this! But basically we can create a &lt;code>Repository&lt;/code> object like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;127.0.0.1&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;users_service&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;123&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>);
});
&lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;homer@thesimpsons.com&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#a6e22e">user&lt;/span>);
})
&lt;span style="color:#75715e">// ...when you are done...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>There's also a set of unit tests in the &lt;code>repository/repository.spec.js&lt;/code> file. Now that we've got a repo, we can create a server. This is &lt;code>server/server.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// server.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;express&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">morgan&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;morgan&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Promise((&lt;span style="color:#a6e22e">resolve&lt;/span>, &lt;span style="color:#a6e22e">reject&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Make sure we have a repository and port provided.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a connected repository.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>) &lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;A server must be started with a port.&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Create the app, add some logging.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">express&lt;/span>();
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">use&lt;/span>(&lt;span style="color:#a6e22e">morgan&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;dev&amp;#39;&lt;/span>));
&lt;span style="color:#75715e">// Add the APIs to the app.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;../api/users&amp;#39;&lt;/span>)(&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>);
&lt;span style="color:#75715e">// Start the app, creating a running server which we return.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">listen&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">server&lt;/span>);
});
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This module exposes a &lt;code>start&lt;/code> function, which we can use like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server);
&lt;/span>&lt;span style="color:#e6db74">server.start({port: 8080, repo: repository}).then((svr) =&amp;gt; {
&lt;/span>&lt;span style="color:#e6db74"> // we&amp;#39;&lt;/span>&lt;span style="color:#a6e22e">ve&lt;/span> &lt;span style="color:#a6e22e">got&lt;/span> &lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#a6e22e">running&lt;/span> &lt;span style="color:#a6e22e">http&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">:&lt;/span>)
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice that &lt;code>server.js&lt;/code> uses &lt;code>api/users/js&lt;/code>? Here it is:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// users.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Defines the users api. Add to a server by calling:
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// require(&amp;#39;./users&amp;#39;)
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#e6db74">&amp;#39;use strict&amp;#39;&lt;/span>;
&lt;span style="color:#75715e">// Only export - adds the API to the app with the given options.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#a6e22e">app&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/users&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>, &lt;span style="color:#a6e22e">next&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUsers&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">users&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#a6e22e">users&lt;/span>.&lt;span style="color:#a6e22e">map&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; { &lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
};
}));
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>) =&amp;gt; {
&lt;span style="color:#75715e">// Get the email.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">email&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">query&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">email&lt;/span>) {
&lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> Error(&lt;span style="color:#e6db74">&amp;#34;When searching for a user, the email must be specified, e.g: &amp;#39;/search?email=homer@thesimpsons.com&amp;#39;.&amp;#34;&lt;/span>);
}
&lt;span style="color:#75715e">// Get the user from the repo.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">getUserByEmail&lt;/span>(&lt;span style="color:#a6e22e">email&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">user&lt;/span>) =&amp;gt; {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">user&lt;/span>) {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">404&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;User not found.&amp;#39;&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>({
&lt;span style="color:#a6e22e">email&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">email&lt;/span>,
&lt;span style="color:#a6e22e">phoneNumber&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">phone_number&lt;/span>
});
}
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#a6e22e">next&lt;/span>);
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Both of these files have unit tests adjacent to the source.&lt;/p>
&lt;p>We'll need config. Rather than using a specialised library, a simple file will do the trick - &lt;code>config/config.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can &lt;code>require&lt;/code> config as needed. Currently, most config is hard coded, but as you can see from &lt;code>port&lt;/code> it's easy to add environment variables as an option.&lt;/p>
&lt;p>Final step - stringing it together with an &lt;code>index.js&lt;/code> file which composes everything:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// index.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Entrypoint to the application. Opens a repository to the MySQL
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// server and starts the server.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./server/server&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">repository&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./repository/repository&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./config/config&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Lots of verbose logging when we&amp;#39;re starting up...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;--- Customer Service---&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connecting to customer repository...&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Log unhandled exceptions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;uncaughtException&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Exception&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;unhandledRejection&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">promise&lt;/span>){
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Unhandled Rejection&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">err&lt;/span>);
});
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">connect&lt;/span>({
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">host&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">database&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">password&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">db&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">repo&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Connected. Starting server...&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">server&lt;/span>.&lt;span style="color:#a6e22e">start&lt;/span>({
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span>,
&lt;span style="color:#a6e22e">repository&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">repo&lt;/span>
});
}).&lt;span style="color:#a6e22e">then&lt;/span>((&lt;span style="color:#a6e22e">app&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Server started successfully, running on port &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">port&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;.&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;close&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">repository&lt;/span>.&lt;span style="color:#a6e22e">disconnect&lt;/span>();
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a little error handling and beyond that we're just loading config, creating a repo and starting our server.&lt;/p>
&lt;p>That's the microservice. It allows us to get all users, or search a user:&lt;/p>
&lt;pre>&lt;code>HTTP GET /users # gets all users
HTTP GET /search?email=homer@thesimpons.com # searches by email
&lt;/code>&lt;/pre>&lt;p>If you checkout the code, you'll see that there's a few commands available for you:&lt;/p>
&lt;pre>&lt;code>cd ./users-service
npm install # setup everything
npm test # unit test - no need for a test database running
npm start # run the server - you must have a test database running
npm run debug # run the server in debug mode, opens a browser with the inspector
npm run lint # check to see if the code is beautiful
&lt;/code>&lt;/pre>&lt;p>Asides from the code you've seen we have:&lt;/p>
&lt;ol>
&lt;li>Node Inspector for debugging&lt;/li>
&lt;li>Mocha/shoud/supertest for unit tests&lt;/li>
&lt;li>ESLint for linting&lt;/li>
&lt;/ol>
&lt;p>That's it!&lt;/p>
&lt;p>Run the test database with:&lt;/p>
&lt;pre>&lt;code>cd test-database/
./start.sh
&lt;/code>&lt;/pre>&lt;p>Then the service with:&lt;/p>
&lt;pre>&lt;code>cd ../users-service/
npm start
&lt;/code>&lt;/pre>&lt;p>You can point your browser to &lt;a href="http://localhost:8123/users">localhost:8123/users&lt;/a> and see it in action. If you are using Docker Machine (i.e. you're on Mac or Windows) then &lt;code>localhost&lt;/code> won't work, you need the IP of the docker machine instead. You can use &lt;code>docker-machine ip&lt;/code> to get it.&lt;/p>
&lt;p>We've whipped through building the service quickly. If you'd like to see this code before we continue, check the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step2">step2&lt;/a> branch.&lt;/p>
&lt;h1 id="step-3-dockerising-our-microservice">Step 3: Dockerising our Microservice&lt;/h1>
&lt;p>OK now it gets fun!&lt;/p>
&lt;p>So we have a microservice which we can run on a dev box, as long as it has a compatible version of Node.js installed. What we'd like to do is set up our service so that we can create a &lt;em>Docker Image&lt;/em> from it, allowing us to deploy our service anywhere which supports docker.&lt;/p>
&lt;p>The way we do this is create a &lt;em>Dockerfile&lt;/em>. A Dockerfile is a recipe that tells the Docker engine how to build your image. We'll create a simple Dockerfile in our &lt;code>users-service&lt;/code> directory and start to explore how we can adapt it to our needs.&lt;/p>
&lt;h2 id="creating-the-dockerfile">Creating the Dockerfile&lt;/h2>
&lt;p>Create a new text file called &lt;code>Dockerfile&lt;/code> at &lt;code>users-service/&lt;/code> with the content below:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Run node
CMD [&amp;quot;node&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>Now run the commands below to build the image and run the a container from it:&lt;/p>
&lt;pre>&lt;code>docker build -t node4 . # Builds a new image
docker run -it node4 # Run a container with this image, interactive
&lt;/code>&lt;/pre>&lt;p>Let's look at the build command first.&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker build&lt;/code> tell the engine we want to create a new image.&lt;/li>
&lt;li>&lt;code>-t node4&lt;/code> tag this image with the tag &lt;code>node4&lt;/code>. We can refer to this image by tag from now on.&lt;/li>
&lt;li>&lt;code>.&lt;/code> use the current directory to find the &lt;code>Dockerfile&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>After some console output you'll see we have a new image created. You can see all images on your system with &lt;code>docker images&lt;/code>. The next command should be fairly familiar from what we've done so far:&lt;/p>
&lt;ol>
&lt;li>&lt;code>docker run&lt;/code> run a new container from an image.&lt;/li>
&lt;li>&lt;code>-it&lt;/code> use an interactive terminal.&lt;/li>
&lt;li>&lt;code>node4&lt;/code> the tag of the image we want to use in the container.&lt;/li>
&lt;/ol>
&lt;p>When we run this image, we get a node repl, check the current version like so:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">version&lt;/span>
&lt;span style="color:#e6db74">&amp;#39;v4.4.0&amp;#39;&lt;/span>
&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">exit&lt;/span>(&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is potentially different to the node version on your current machine.&lt;/p>
&lt;h2 id="examining-the-dockerfile">Examining the Dockerfile&lt;/h2>
&lt;p>Looking at the dockerfile we can see quite easily what is going on:&lt;/p>
&lt;ol>
&lt;li>&lt;code>FROM node:4&lt;/code> the first thing we specify in a Dockerfile is the base image. A quick google finds the &lt;a href="https://hub.docker.com/_/node/">node organisation page on the docker hub&lt;/a> showing all of the available images. This is essentially bare bones ubuntu with node installed.&lt;/li>
&lt;li>&lt;code>CMD [&amp;quot;node&amp;quot;]&lt;/code> the &lt;code>CMD&lt;/code> command tells docker that this image should run the node executable. When the executable terminates, the container shuts down.&lt;/li>
&lt;/ol>
&lt;p>With the addition of a few more commands, we can update our Dockerfile so that it runs our service:&lt;/p>
&lt;pre>&lt;code># Use Node v4 as the base image.
FROM node:4
# Add everything in the current directory to our image, in the 'app' folder.
ADD . /app
# Install dependencies
RUN cd /app; \
npm install --production
# Expose our server port.
EXPOSE 8123
# Run our app.
CMD [&amp;quot;node&amp;quot;, &amp;quot;/app/index.js&amp;quot;]
&lt;/code>&lt;/pre>&lt;p>The only addition here is that we use the &lt;code>ADD&lt;/code> command to copy everything&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> in the current directory to a folder in the container called &lt;code>app/&lt;/code> . We then use &lt;code>RUN&lt;/code> to run a command in the image, which installs our modules. Finally, we &lt;code>EXPOSE&lt;/code> the server port, telling docker we intend to support inbound connections on &lt;code>8123&lt;/code>, then run our server code.&lt;/p>
&lt;p>Ensure the test-database service is running, then build and run the image again:&lt;/p>
&lt;pre>&lt;code>docker build -t users-service .
docker run -it -p 8123:8123 users-service
&lt;/code>&lt;/pre>&lt;p>If you navigate to &lt;code>localhost:8123/users&lt;/code> in a browser you should see an error, checking the console shows our container is reporting some issues:&lt;/p>
&lt;pre>&lt;code>--- Customer Service---
Connecting to customer repository...
Connected. Starting server...
Server started successfully, running on port 8123.
GET /users 500 23.958 ms - 582
Error: An error occured getting the users: Error: connect ECONNREFUSED 127.0.0.1:3306
at Query._callback (/app/repository/repository.js:21:25)
at Query.Sequence.end (/app/node_modules/mysql/lib/protocol/sequences/Sequence.js:96:24)
at /app/node_modules/mysql/lib/protocol/Protocol.js:399:18
at Array.forEach (native)
at /app/node_modules/mysql/lib/protocol/Protocol.js:398:13
at nextTickCallbackWith0Args (node.js:420:9)
at process._tickCallback (node.js:349:13)
&lt;/code>&lt;/pre>&lt;p>Yikes! So the connection from our &lt;code>users-service&lt;/code> container to the &lt;code>test-database&lt;/code> container is being refused. We might try running &lt;code>docker ps&lt;/code> to see all containers running:&lt;/p>
&lt;pre>&lt;code>CONTAINER ID IMAGE PORTS NAMES
a97958850c66 users-service 0.0.0.0:8123-&amp;gt;8123/tcp kickass_perlman
47f91343db01 mysql:latest 0.0.0.0:3306-&amp;gt;3306/tcp db
&lt;/code>&lt;/pre>&lt;p>They're both there, so what is going on?&lt;/p>
&lt;h2 id="linking-containers">Linking Containers&lt;/h2>
&lt;p>The issue we've seen is actually to be expected. Docker containers are supposed to be isolated, so it wouldn't make much sense if we could create connections between containers without us explicitly allowing it.&lt;/p>
&lt;p>Yes, we can connect from our machine (the host) to a container, because we've opened ports for that (using the &lt;code>-p 8123:8123&lt;/code> argument for example). If we allowed containers to talk to each other in the same way, then two containers running on the same machine would be able to communicate, even if the developers didn't intend it, and that's a recipe for disaster, especially when we might have a cluster of machines whos job it is to run containers from different applications.&lt;/p>
&lt;p>If we're going to connect from one container to another, we need to &lt;em>link&lt;/em> them, which tells docker that we explicitly want to allow communication between the two. There are two ways of doing this, the first is the &amp;lsquo;old fasioned&amp;rsquo; but quite simple way, the second we'll see a little later.&lt;/p>
&lt;h3 id="linking-containers-with-the-link-parameter">Linking Containers with the &amp;lsquo;link&amp;rsquo; parameter&lt;/h3>
&lt;p>When we run a container, we can tell docker that we intend to connect to another container using the &lt;code>link&lt;/code> parameter. In our case, we can run our service correctly like this:&lt;/p>
&lt;pre>&lt;code>docker run -it -p 8123:8123 --link db:db -e DATABASE_HOST=DB users-service
&lt;/code>&lt;/pre>&lt;ol>
&lt;li>&lt;code>docker run -it&lt;/code> run a docker image in a container, with an interactive terminal.&lt;/li>
&lt;li>&lt;code>-p 8123:8123&lt;/code> map the host port 8123 to the container port 8123.&lt;/li>
&lt;li>&lt;code>link db:db&lt;/code> link to the container named &lt;code>db&lt;/code> and refer to it as &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>-e DATABASE_HOST=db&lt;/code> set the &lt;code>DATABASE_HOST&lt;/code> environment variable to &lt;code>db&lt;/code>.&lt;/li>
&lt;li>&lt;code>users-service&lt;/code> the name of the image to run in our container.&lt;/li>
&lt;/ol>
&lt;p>Now when we go to &lt;code>localhost:8123/users&lt;/code> everything works.&lt;/p>
&lt;h4 id="how-it-works">How it works&lt;/h4>
&lt;p>Remember our config file for the service? It allowed us to specify a database host with an environment variable:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// config.js
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// Simple application configuration. Extend as needed.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">PORT&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#ae81ff">8123&lt;/span>,
&lt;span style="color:#a6e22e">db&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">host&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>.&lt;span style="color:#a6e22e">DATABASE_HOST&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#e6db74">&amp;#39;127.0.0.1&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">database&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">user&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;users_service&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">password&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;123&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">port&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#ae81ff">3306&lt;/span>
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>When we run the container, we set this environment variable to &lt;code>DB&lt;/code>, which means we're connecting to a host called &lt;code>DB&lt;/code>. This is &lt;em>automatically&lt;/em> set up for us by the docker engine when we link to a container.&lt;/p>
&lt;p>To see this in action, try running &lt;code>docker ps&lt;/code> to list all running containers. Look up the name of the container running the &lt;code>users-service&lt;/code>, which will be a random name such as &lt;code>trusting_jang&lt;/code>:&lt;/p>
&lt;pre>&lt;code>docker ps
CONTAINER ID IMAGE ... NAMES
ac9449d3d552 users-service ... trusting_jang
47f91343db01 mysql:latest ... db
&lt;/code>&lt;/pre>&lt;p>Now we can look at the hosts available on our container:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang cat /etc/hosts
127.0.0.1 localhost
::1 localhost ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
172.17.0.2 db 47f91343db01 # linking magic!!
172.17.0.3 ac9449d3d552
&lt;/code>&lt;/pre>&lt;p>Remember how &lt;code>docker exec&lt;/code> works? Choose a container name and then whatever follows is the command you'll execute on the container, in our case &lt;code>cat /etc/hosts&lt;/code>.&lt;/p>
&lt;p>OK the hosts file doesn't have the &lt;code># linking magic!!&lt;/code> comment, that's so you can see - docker has added &lt;code>db&lt;/code> to our hosts file so we can refer to the linked container by hostname. This is one consequence of linking. Here's the other:&lt;/p>
&lt;pre>&lt;code>docker exec trusting_jang printenv | grep DB
DB_PORT=tcp://172.17.0.2:3306
DB_PORT_3306_TCP=tcp://172.17.0.2:3306
DB_PORT_3306_TCP_ADDR=172.17.0.2
DB_PORT_3306_TCP_PORT=3306
DB_PORT_3306_TCP_PROTO=tcp
DB_NAME=/trusting_jang/db
&lt;/code>&lt;/pre>&lt;p>From this command we can also see that when docker links a container, it also provides a set of environment variables with some helpful information. We know the host, tcp port and container name.&lt;/p>
&lt;p>That's step 3 complete - we have a MySQL database running happily in a container, we have a node.js microservice which we can run locally or in a container of its own, and we know how to link them together.&lt;/p>
&lt;p>You can check out how the code looks at this stage by going to the &lt;a href="https://github.com/dwmkerr/node-docker-microservice/tree/step3">step3&lt;/a> branch.&lt;/p>
&lt;h1 id="step-4-integration-testing-the-environment">Step 4: Integration Testing the Environment&lt;/h1>
&lt;p>We can now write an integration test which calls the actual server, running as a docker container, calling the containerised test database.&lt;/p>
&lt;p>Writing the integration test can be done in whatever language or on whatever platform you want, within reason, but to keep things simple I'm using Node.js as we've already seen Mocha and Supertest in our project.&lt;/p>
&lt;p>In a new folder, called &lt;code>integration-tests&lt;/code> we've got a single &lt;code>index.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;supertest&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">should&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;should&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">describe&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;users-service&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">api&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">supertest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;http://localhost:8123&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">it&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;returns a 200 for a known user&amp;#39;&lt;/span>, (&lt;span style="color:#a6e22e">done&lt;/span>) =&amp;gt; {
&lt;span style="color:#a6e22e">api&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/search?email=homer@thesimpsons.com&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">expect&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>, &lt;span style="color:#a6e22e">done&lt;/span>);
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will check an API call and show the results of the test&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>As long as your &lt;code>users-service&lt;/code> and &lt;code>test-database&lt;/code> are running, the tests will pass. However, at this stage the services are getting a little harder to handle:&lt;/p>
&lt;ol>
&lt;li>We have to use a shell script to start and stop the database&lt;/li>
&lt;li>We have to remember a sequence of commands to start the users service against the database&lt;/li>
&lt;li>We have to use node directly to run the integration tests&lt;/li>
&lt;/ol>
&lt;p>Now that we're a little more familiar with Docker we can fix these issues.&lt;/p>
&lt;h3 id="simplifiying-the-test-database">Simplifiying the Test Database&lt;/h3>
&lt;p>Currently we have the following files for the test database:&lt;/p>
&lt;pre>&lt;code>/test-database/start.sh
/test-database/stop.sh
/test-database/setup.sql
&lt;/code>&lt;/pre>&lt;p>Now that we're more familar with Docker, we can improve on this. Looking into the &lt;a href="https://hub.docker.com/_/mysql/">mysql image documentation&lt;/a> on Docker Hub there's a note which tells us any &lt;code>.sql&lt;/code> or &lt;code>.sh&lt;/code> file added to the image's &lt;code>/docker-entrypoint-initdb.d&lt;/code> folder will be executed when setting up the DB.&lt;/p>
&lt;p>This means we can replace our &lt;code>start.sh&lt;/code> and &lt;code>stop.sh&lt;/code> scripts with a &lt;code>Dockerfile&lt;/code>:&lt;/p>
&lt;pre>&lt;code>FROM mysql:5
ENV MYSQL_ROOT_PASSWORD 123
ENV MYSQL_DATABASE users
ENV MYSQL_USER users_service
ENV MYSQL_PASSWORD 123
ADD setup.sql /docker-entrypoint-initdb.d
&lt;/code>&lt;/pre>&lt;p>Now to run our test database it is just:&lt;/p>
&lt;pre>&lt;code>docker build -t test-database .
docker run --name db test-database
&lt;/code>&lt;/pre>&lt;h3 id="composing">Composing&lt;/h3>
&lt;p>Building and running each container is still somewhat time consuming. We can take things a step further with the &lt;a href="https://docs.docker.com/compose/">Docker Compose&lt;/a> tool.&lt;/p>
&lt;p>Docker Compose lets you create a file which defines each container in your system, the relationships between them, and build or run them all.&lt;/p>
&lt;p>First, &lt;a href="https://docs.docker.com/compose/install/">install Docker Compose&lt;/a>. Now create a new file in the root of your project called &lt;code>docker-compose.yml&lt;/code>:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>Now check this out:&lt;/p>
&lt;pre>&lt;code>docker-compose build
docker-compose up
&lt;/code>&lt;/pre>&lt;p>Docker Compose has built all of the images needed for our application, created containers fromthem, run them in the correct order and started the whole stack!&lt;/p>
&lt;p>The &lt;code>docker-compose build&lt;/code> command builds each image which is listed in the &lt;code>docker-compose.yml&lt;/code> file:&lt;/p>
&lt;pre>&lt;code>version: '2'
services:
users-service:
build: ./users-service
ports:
- &amp;quot;8123:8123&amp;quot;
depends_on:
- db
environment:
- DATABASE_HOST=db
db:
build: ./test-database
&lt;/code>&lt;/pre>&lt;p>The &lt;code>build&lt;/code> value for each of our services tells docker where to go to find the &lt;code>Dockerfile&lt;/code>. When we run &lt;code>docker-compose up&lt;/code>, docker starts all of our services. Notice from the &lt;code>Dockerfile&lt;/code> we can specify ports and dependencies. Actually, there's a whole bunch of config we can change here.&lt;/p>
&lt;p>In another terminal, run &lt;code>docker compose down&lt;/code> to gracefully shut down the containers.&lt;/p>
&lt;h1 id="winding-up">Winding Up&lt;/h1>
&lt;p>We've seen a lot of docker in this article, but there's a lot more to it. I hope this has shown some of the interesting and useful things that you can use docker for in your workflow.&lt;/p>
&lt;p>As usual, questions and comments are welcomed! I'd also strongly recommend the document &lt;a href="https://docs.docker.com/engine/understanding-docker/">Understanding Docker&lt;/a> to get a deeper understanding of how docker works.&lt;/p>
&lt;p>You can see the final source code for the project built in this article at &lt;a href="https://github.com/dwmkerr/node-docker-microservice">github.com/dwmkerr/node-docker-microservice&lt;/a>&lt;/p>
&lt;h1 id="notes">Notes&lt;/h1>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Copying everything is actually a bad idea, because we will also copy the node_modules folder. Generally it is a better idea explicitly list the files or folders you want to copy, or use a .dockerignore file, which works just like the .gitignore file. &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>If the server isn't running, it will actually show a rather annoying exception, due to a bug in supertest, see &lt;a href="https://github.com/visionmedia/supertest/issues/314">github.com/visionmedia/supertest/issues/314&lt;/a>. &lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Getting Started with React &amp; ES6</title><link>https://dwmkerr.com/getting-started-with-react/</link><pubDate>Mon, 07 Sep 2015 19:44:54 +0000</pubDate><guid>https://dwmkerr.com/getting-started-with-react/</guid><description>&lt;p>Feeling like having a go with Facebook's hugely popular &lt;a href="http://facebook.github.io/react/">React&lt;/a> framework but not sure where to start?&lt;/p>
&lt;p>In this post I'm going to build a simple React application from scratch - using &lt;a href="http://es6-features.org/">ECMAScript 6&lt;/a>.&lt;/p>
&lt;p>We'll put together the bare minimum skeleton of a site and keep the folder structure free of noise and clutter so that you can focus on the app code and not the tooling!&lt;/p>
&lt;p>The simple app we'll build is at &lt;a href="https://github.com/dwmkerr/react-es6-starter">github.com/dwmkerr/react-es6-starter&lt;/a>, or see &lt;a href="https://react-es6-starter.herokuapp.com">it live&lt;/a>.&lt;/p>
&lt;h2 id="building-the-code">Building the Code&lt;/h2>
&lt;p>Our goal will be to have a single &lt;code>index.html&lt;/code> file which includes our Javascript files. We're aiming for something like this:&lt;/p>
&lt;p>&lt;img src="images/Build-Process.png" alt="Build Process 1">&lt;/p>
&lt;p>But browsers don't handle ES6 yet. So our loose files, which reference each other, are going to have to be transpiled into ES5 and bundled into a single file. We need a build process:&lt;/p>
&lt;p>&lt;img src="images/Build-Process-2.png" alt="Build Process 2">&lt;/p>
&lt;p>&lt;a href="webpack.github.io">Webpack&lt;/a> can handle all of this for us. Given an entrypoint file, webpack will traverse all of the &lt;code>require&lt;/code> and &lt;code>import&lt;/code> statements and build a single bundle file. It also allows us to configure &amp;lsquo;loaders&amp;rsquo;, which let us pass these files through other tools:&lt;/p>
&lt;p>&lt;img src="images/Build-Process-3.png" alt="Build Process 3">&lt;/p>
&lt;p>We'll need the following libraries:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="webpack.github.io">Webpack&lt;/a> - the tool that handles the build process.&lt;/li>
&lt;li>&lt;a href="babeljs.io">Babel&lt;/a> - an excellent ES6/ES7/JSX to ES5 transpiler.&lt;/li>
&lt;li>&lt;a href="github.com/babel/babel-loader">Babel Loader&lt;/a> - the component which integrates Babel into our Webpack build.&lt;/li>
&lt;li>&lt;a href="github.com/ampedandwired/html-webpack-plugin">Html Webpack Plugin&lt;/a> - a simple Webpack plugin which will copy our index file to our build folder and add a link to our Webpack bundle.&lt;/li>
&lt;/ol>
&lt;p>Let's install these modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save webpack babel babel-loader html-webpack-plugin
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll also need a webpack config file. By default webpack expects a file named &lt;code>webpack.config.js&lt;/code> to be in the root of the project. But every tool under the sun wants to stick its config file in the root of our project, and most of the time they're just in the way.&lt;/p>
&lt;p>So let's put everything to do with our tooling in a &lt;code>tooling&lt;/code> folder instead. Create the file &lt;code>webpack.config.js&lt;/code> in a &lt;code>tooling&lt;/code> folder in the root of the project:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;path&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#75715e">// Defines the entrypoint of our application.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">entry&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src/app.js&amp;#39;&lt;/span>),
&lt;span style="color:#75715e">// Bundle to a ./build/public/bundle.js file.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">output&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">path&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../build/public&amp;#39;&lt;/span>),
&lt;span style="color:#a6e22e">filename&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;bundle.js&amp;#39;&lt;/span>
},
&lt;span style="color:#75715e">// Use babel for anything that is *.js or *.jsx.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">loaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;babel-loader&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">include&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src&amp;#39;&lt;/span>)
}
]
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>First we define our entry point - the first file which will actually be run if we run the final bundled script. This is the &lt;code>app.js&lt;/code> file we'll create shortly. If &lt;code>app.js&lt;/code> includes other modules, Webpack will pick them up, if those modules include other modules, they will be picked up and so on.&lt;/p>
&lt;p>Next we specify that everything should be bundled into a &lt;code>./build/public/bundle.js&lt;/code> file (we're going to use the convention that everything we can produce with our tools goes into &lt;code>./build&lt;/code>).&lt;/p>
&lt;p>Finally, we specify that every file in &lt;code>src&lt;/code> which matches the &lt;code>\.jsx?$&lt;/code> regex will go through the babel loader.&lt;/p>
&lt;h3 id="using-es6">Using ES6!&lt;/h3>
&lt;p>We've actually got enough now to use ES6. Create a file in &lt;code>src&lt;/code> called &lt;code>index.html&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&lt;span style="color:#75715e">&amp;lt;!DOCTYPE html&amp;gt;&lt;/span>
&amp;lt;&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">body&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">html&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then create a &lt;code>src/app.js&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">const&lt;/span> &lt;span style="color:#a6e22e">PI&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">3.14&lt;/span>;
&lt;span style="color:#66d9ef">let&lt;/span> &lt;span style="color:#a6e22e">vals&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>].&lt;span style="color:#a6e22e">map&lt;/span>(&lt;span style="color:#a6e22e">x&lt;/span> =&amp;gt; &lt;span style="color:#a6e22e">x&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>);
document.&lt;span style="color:#a6e22e">body&lt;/span>.&lt;span style="color:#a6e22e">innerText&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Pi is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">3.14&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and vals is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">vals&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Run the command &lt;code>./node_modules/.bin/webpack --config ./tooling/webpack.config.js&lt;/code> and our code is built, transpiled an moved to the build folder.&lt;/p>
&lt;p>Now we could serve this folder using any basic webserver. We are already using webpack, so the webpack dev server will do the trick. It uses exactly the same config file as the webpack tool:&lt;/p>
&lt;pre>&lt;code>npm install --save-dev webpack-dev-server
./node_modules/.bin/webpack-dev-server --config ./tooling/webpack.config --inline
&lt;/code>&lt;/pre>&lt;p>The inline reloads the page when the source changes. We don't need to tell the server where the files are, it knows that from the webpack config.&lt;/p>
&lt;p>Let's stick these commands in our &lt;code>package.json&lt;/code> for convenience:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">{
...
&lt;span style="color:#e6db74">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#34;start&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;webpack-dev-server --config ./tooling/webpack.config.js --inline --quiet&amp;#34;&lt;/span>,
&lt;span style="color:#e6db74">&amp;#34;webpack&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;webpack --config tooling/webpack.config.js&amp;#34;&lt;/span>
...
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we can manually build with &lt;code>npm run webpack&lt;/code> and start our dev server with &lt;code>npm start&lt;/code>.&lt;/p>
&lt;h3 id="adding-some-react">Adding some React&lt;/h3>
&lt;p>Let's add a React component. Create a folder under &lt;code>app&lt;/code> called &lt;code>home&lt;/code> and add a &lt;code>home.js&lt;/code> file:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">export&lt;/span> &lt;span style="color:#66d9ef">default&lt;/span> &lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#66d9ef">extends&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">Component&lt;/span> {
&lt;span style="color:#a6e22e">render&lt;/span> () {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">div&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">h1&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>&lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">ES6&lt;/span> &lt;span style="color:#a6e22e">Starter&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">h&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">1&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">p&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>&lt;span style="color:#a6e22e">Welcome&lt;/span> &lt;span style="color:#a6e22e">to&lt;/span> &lt;span style="color:#a6e22e">the&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">ES6&lt;/span> &lt;span style="color:#a6e22e">Starter&lt;/span> &lt;span style="color:#a6e22e">home&lt;/span> &lt;span style="color:#a6e22e">page&lt;/span>&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">p&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>
&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">/&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">d&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">i&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">v&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">&amp;gt;&lt;/span>&lt;span style="color:#960050;background-color:#1e0010">;&lt;/span>
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This is our first react component, which does nothing more than render some basic markup. We'll use this as the starting point for our application.&lt;/p>
&lt;p>We can now take our &lt;code>app.js&lt;/code> file and render our Home component into the div. Here's &lt;code>app.js&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react/addons&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;./home/home&amp;#39;&lt;/span>;
&lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">render&lt;/span>(&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>, document.&lt;span style="color:#a6e22e">body&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>That's all there is to it! We've got a clean and simple starting point to begin playing with React. Before we look into things like state management and routing, let's look into testing what we have so far.&lt;/p>
&lt;h3 id="testing">Testing&lt;/h3>
&lt;p>Even the most simple app would be incomplete without looking into how we will deal with the testing.&lt;/p>
&lt;p>Many will recommend the &lt;a href="https://facebook.github.io/jest/">Jest&lt;/a> framework to test React applications. However, it's a bit more to learn and has some problems with NodeJS v0.12, so until we get Node v4 I'm going to keep things simple.&lt;/p>
&lt;p>First, we'll install &lt;a href="http://karma-runner.github.io/">Karma&lt;/a> as a test runner. We'll use &lt;a href="http://jasmine.github.io/">Jasmine&lt;/a> as as framework to write test cases and &lt;a href="http://phantomjs.org/">PhantomJS&lt;/a> as a headless browser in which our tests will run. This means we'll need to add some more dev dependencies:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev karma jasmine karma-webpack karma-jasmine karma-phantomjs-launcher
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can now create a &lt;code>karma.config.js&lt;/code> file in our &lt;code>tooling&lt;/code> folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;path&amp;#39;&lt;/span>);
&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">exports&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">config&lt;/span>) {
&lt;span style="color:#a6e22e">config&lt;/span>.&lt;span style="color:#a6e22e">set&lt;/span>({
&lt;span style="color:#a6e22e">browsers&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;PhantomJS&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">files&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
&lt;span style="color:#75715e">// We need to polyfill as PhantomJS doesn&amp;#39;t support &amp;#39;bind&amp;#39;.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#e6db74">&amp;#39;../node_modules/babel-core/browser-polyfill.js&amp;#39;&lt;/span>,
&lt;span style="color:#e6db74">&amp;#39;../**/*.spec.js&amp;#39;&lt;/span>
],
&lt;span style="color:#a6e22e">frameworks&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;jasmine&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">preprocessors&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#39;../**/*.spec.js&amp;#39;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;webpack&amp;#39;&lt;/span>],
},
&lt;span style="color:#a6e22e">reporters&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;progress&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">singleRun&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>,
&lt;span style="color:#a6e22e">webpack&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">loaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;babel-loader&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">include&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">path&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">__dirname&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;../src&amp;#39;&lt;/span>)
}
],
}
},
&lt;span style="color:#a6e22e">webpackServer&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">noInfo&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>
}
});
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So here we are:&lt;/p>
&lt;ol>
&lt;li>Loading a polyfill from babel core (sorry guys, one more &lt;code>npm install --save-dev babel-core&lt;/code>) which gives PhantomJS the &lt;code>bind&lt;/code> function (along with some others). This is needed as some of the testing code in the browser needs these features.&lt;/li>
&lt;li>Specifying that anything that ends in &lt;code>.spec.js&lt;/code> should be loaded.&lt;/li>
&lt;li>Running anything that ends in &lt;code>.spec.js&lt;/code> through webpack.&lt;/li>
&lt;li>Telling webpack to use babel.&lt;/li>
&lt;/ol>
&lt;p>Quite a bit of config, but we're re-using the same webpack tooling as before. We run the code through webpack, which sends it through babel and builds ES5 we can test in the browser.&lt;/p>
&lt;p>With this in place, we can write a spec. Add &lt;code>home.spec.js&lt;/code> to the &lt;code>home&lt;/code> folder:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;react&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">$&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;jquery&amp;#39;&lt;/span>;
&lt;span style="color:#66d9ef">import&lt;/span> &lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#a6e22e">from&lt;/span> &lt;span style="color:#e6db74">&amp;#39;./home.js&amp;#39;&lt;/span>;
&lt;span style="color:#a6e22e">describe&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;Home&amp;#39;&lt;/span>, () =&amp;gt; {
&lt;span style="color:#a6e22e">it&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;should render to the DOM&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// Create the &amp;lt;Home /&amp;gt; react component.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">component&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">render&lt;/span>(&lt;span style="color:#f92672">&amp;lt;&lt;/span>&lt;span style="color:#a6e22e">Home&lt;/span> &lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>, document.&lt;span style="color:#a6e22e">body&lt;/span>);
&lt;span style="color:#75715e">// Find the DOM element for the created component.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">node&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">React&lt;/span>.&lt;span style="color:#a6e22e">findDOMNode&lt;/span>(&lt;span style="color:#a6e22e">component&lt;/span>);
&lt;span style="color:#75715e">// Check the DOM looks how we&amp;#39;d expect it to.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">expect&lt;/span>(&lt;span style="color:#a6e22e">$&lt;/span>(&lt;span style="color:#a6e22e">node&lt;/span>).&lt;span style="color:#a6e22e">children&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;h1&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">text&lt;/span>()).&lt;span style="color:#a6e22e">toEqual&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;React Redux Starter&amp;#34;&lt;/span>);
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>What's going on here? We just ask React to render our Home component directly into the DOM. We get a component back from this call. We can then ask React to give us the DOM associatefd with the component and use familiar tools (jQuery!) to test the shape of the generated DOM.&lt;/p>
&lt;p>All that's missing is the last of the dev dependencies we've missed:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev jquery phantomjs
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can run tests directly on a Mac or Unix with:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">./node_modules/.bin/karma start ./tooling/karma.config.js
&lt;/code>&lt;/pre>&lt;/div>&lt;p>For Windows use:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">node_modules&lt;span style="color:#ae81ff">\.&lt;/span>bin&lt;span style="color:#ae81ff">\k&lt;/span>arma start tooling&lt;span style="color:#ae81ff">\k&lt;/span>arma.config.js
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, we'll update our &lt;code>package.json&lt;/code> scripts so that this is the &lt;code>test&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#e6db74">&amp;#34;scripts&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#e6db74">&amp;#34;test&amp;#34;&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;./node_modules/.bin/karma start ./tooling/karma.config.js&amp;#34;&lt;/span>,
...
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Done! This means we can run tests on any platform with NodeJS&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> using the same command - &lt;code>npm test&lt;/code>.&lt;/p>
&lt;p>We now have a very simple setup which allows us to run tests. You can build on this - perhaps adding Jest later or a more sophisticated or React specific set of tools.&lt;/p>
&lt;h3 id="adding-code-coverage">Adding Code Coverage&lt;/h3>
&lt;p>You might want to add some code coverage information to your project. This can be a little tricky when using ES6, as we need to make sure we report coverage of the original ES6 code, rather than the actual transpiled code which is instrumented.&lt;/p>
&lt;p>Fortunately, with the clean and simple setup we have built, adding code coverage is a snap.&lt;/p>
&lt;p>Our test runner, Karma, is built to quickly integrate with the code coverage tool &lt;a href="https://github.com/gotwarlost/istanbul">Istanbul&lt;/a>, we just need to use the &lt;a href="https://github.com/karma-runner/karma-coverage">Karma Coverage&lt;/a> plugin. Let's install the two modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev istanbul karma-coverage
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now with a small addition to our &lt;code>karma.config.js&lt;/code> file we will get a nice HTML coverage report. We need to update our &lt;code>reporters&lt;/code> config to include &lt;code>coverage&lt;/code> and specify coverage options in the &lt;code>coverageReporter&lt;/code> config.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript"> &lt;span style="color:#a6e22e">reporters&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;progress&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;coverage&amp;#39;&lt;/span>],
&lt;span style="color:#a6e22e">coverageReporter&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">dir&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;../build/coverage/&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;html&amp;#39;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you run &lt;code>npm test&lt;/code> now, you'll get an HTML coverage report generated. The only problem is that it is for the transpiled code, which makes it almost useless. A customer instrumenter called isparta will help us here. We use isparta to get a report of the coverage of the original ES6 code. Two more modules:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install --save-dev isparta isparta-instrumenter-loader
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then in our karma config we pass the orignal code through the insrtrumenter, before babel transpiles it:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">webpack&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">module&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">preLoaders&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [
{
&lt;span style="color:#a6e22e">test&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">/\.jsx?$/&lt;/span>,
&lt;span style="color:#a6e22e">exclude&lt;/span>&lt;span style="color:#f92672">:&lt;/span> [&lt;span style="color:#e6db74">/node_modules/&lt;/span>, &lt;span style="color:#e6db74">/\.spec\.js/&lt;/span>],
&lt;span style="color:#a6e22e">loader&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;isparta-instrumenter-loader&amp;#39;&lt;/span>
},
],
&lt;span style="color:#75715e">// everything else stays the same...
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Anything that is not a spec or from &lt;code>node_modules&lt;/code> gets instrumented. Now we have a ES6 code coverage report:&lt;/p>
&lt;p>&lt;img src="images/CapturFiles_8.png" alt="Code Coverage Report">&lt;/p>
&lt;p>With this in place, you can go even further and integrate with other CI or publish to code quality systems (for example this repo integrates to &lt;a href="https://coveralls.io">coveralls.io&lt;/a>). This is often used to show badges for repos:&lt;/p>
&lt;p>&lt;a href="https://coveralls.io/github/dwmkerr/react-es6-starter?branch=master">&lt;img src="images/badge.svg" alt="Coverage Status">&lt;/a>&lt;/p>
&lt;p>Another use case is to gate checkins unless they maintain a certain code coverage threshhold.&lt;/p>
&lt;h3 id="wrapping-up">Wrapping Up&lt;/h3>
&lt;p>This provides a very lean starting point for learning React. There's no moving parts at the moment - no state management. We'll get into that in later articles but right now you have a playground.&lt;/p>
&lt;p>You can set up CI in a flash, just sign up for a &lt;a href="https://travis-ci.org/">Travis&lt;/a> account and use a &lt;code>travis.yml&lt;/code> like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yml" data-lang="yml">language: node_js
node_js:
- &lt;span style="color:#e6db74">&amp;#34;0.12&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This repo is all ready to push to &lt;a href="todo">Heroku&lt;/a>, no Procfile is needed. Check out &lt;a href="todo">react-es6-starter.herokuapp.com&lt;/a> to see the code in action.&lt;/p>
&lt;p>I hope you've found this article useful! Next time we'll be getting into the details of managing state in React.&lt;/p>
&lt;p>Please fork the repo and have a play, let me know of any suggestions or improvements!&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/react-es6-starter">github.com/dwmkerr/react-es6-starter&lt;/a>&lt;/p>
&lt;h3 id="glossary-of-conventions">Glossary of Conventions&lt;/h3>
&lt;p>There are a few conventions that I personally use in most Javascript projects. The conventions used in this article which I think are valuable to consider using in many projects are:&lt;/p>
&lt;h4 id="always-support-installteststart">Always support install/test/start&lt;/h4>
&lt;p>Everyone should always be able to checkout, install, test and run the code with the following commands:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">npm install &lt;span style="color:#75715e"># installs everything needed&lt;/span>
npm test &lt;span style="color:#75715e"># lets the user know the code works right on their system!&lt;/span>
npm start &lt;span style="color:#75715e"># starts the code, lets the user know what to do next&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Install should setup everything, and if code needs to be built to be testable, this should be a post-install hook.&lt;/p>
&lt;p>Test should be run next, as a user should be able to verify that the code works as expected on their system.&lt;/p>
&lt;p>Finally, when the user runs start, a dev server (as convention dictates we are in a dev mode by default (and production mode is set with a flag or environment variable) the server should start and a console message should show the user where to browse to.&lt;/p>
&lt;hr>
&lt;h5 id="footnotes">Footnotes&lt;/h5>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>&lt;a href="https://www-03.ibm.com/press/us/en/pressrelease/47474.wss">IBM Mainframes&lt;/a> anyone? &lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description><category>CodeProject</category></item><item><title>Manipulating JSON Web Tokens (JWTs)</title><link>https://dwmkerr.com/modifying-a-jwt-in-a-node-application/</link><pubDate>Tue, 24 Mar 2015 14:45:02 +0000</pubDate><guid>https://dwmkerr.com/modifying-a-jwt-in-a-node-application/</guid><description>&lt;p>I've been writing a couple of web services lately that use &lt;a href="https://auth0.com/">Auth0&lt;/a> for identity management. It's a great platform that makes working with different identity providers a breeze.&lt;/p>
&lt;p>One thing that I couldn't work out how to do at first was to quickly build a new JWT&lt;sup>&lt;a href="#fn1" id="ref1">1&lt;/a>&lt;/sup> from an existing token. I wanted to take my current token, add some more data to it and return it to the user. So here's a &amp;lsquo;why&amp;rsquo; and &amp;lsquo;how&amp;rsquo;.&lt;/p>
&lt;h2 id="why">Why?&lt;/h2>
&lt;p>Why would you want to do this? A use case would be when you want to associate your a session with some data. For example, imagine a library gateway which offers access to a whole bunch of University libraries. First we authenticate. Then we ask for all of the libraries in the system. Then we ask for authorisation to use a specific library. We could put the library name in the token and pass it for every call onwards.&lt;/p>
&lt;p>It might look like this:&lt;/p>
&lt;h4 id="1-authenticate">1. Authenticate&lt;/h4>
&lt;p>First, we authenticate, perhaps with a username and password.&lt;/p>
&lt;pre>&lt;code>POST libraries.com/api/authenticate
{&amp;quot;usename&amp;quot;:&amp;quot;calculon&amp;quot;,&amp;quot;password&amp;quot;:&amp;quot;dramatic...pause&amp;quot;}
&lt;/code>&lt;/pre>&lt;p>Then we can return a JWT if all is well:&lt;/p>
&lt;pre>&lt;code>{&amp;quot;jwt&amp;quot;:&amp;quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJjYWxjdWxvbiJ9.VWkAafAMCxazY7uBlPTJoQwCBdUIy3T1d-C4TfxhAZQ&amp;quot;}
&lt;/code>&lt;/pre>&lt;h4 id="2-work-with-the-service">2. Work with the Service&lt;/h4>
&lt;p>We can put this JWT in an &lt;code>Authorization&lt;/code> header and start asking for protected resources:&lt;/p>
&lt;pre>&lt;code>GET libraries.com/api/libraries
Authorization: Bearer eyJhb...AZQ
&lt;/code>&lt;/pre>&lt;p>giving us:&lt;/p>
&lt;pre>&lt;code>[
{&amp;quot;name&amp;quot;: &amp;quot;Mars University Libary&amp;quot;, &amp;quot;slug&amp;quot;:&amp;quot;mul&amp;quot;},
{&amp;quot;name&amp;quot;: &amp;quot;Coney Island State Library&amp;quot;, &amp;quot;slug&amp;quot;:&amp;quot;cis&amp;quot;}
]
&lt;/code>&lt;/pre>&lt;p>Two libraries we can choose from. Now I want to present this choice to a user, but once they've made their choice I don't want to change the libary again. I want to work with only one library in a session.&lt;/p>
&lt;h4 id="3-add-data-to-the-token">3. Add Data to the Token&lt;/h4>
&lt;p>A nice thing we can do here is just create &lt;em>another&lt;/em> authentication method, which attempts to see if we are authorised to use the given library:&lt;/p>
&lt;pre>&lt;code>POST libraries.com/api/libraries/mul/authorise
Authorization: Bearer eyJhb...AZQ
&lt;/code>&lt;/pre>&lt;p>If the token is valid, we can check to see if the user is allowed to use this library. If so, we can return a &lt;em>new&lt;/em> token, which is associated with a &lt;em>specific&lt;/em> library:&lt;/p>
&lt;pre>&lt;code>HTTP/1.1 200 OK
{&amp;quot;jwt&amp;quot;: &amp;quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJjYWxjdWxvbiIsImxpYnJhcnkiOiJtdWwifQ.NM2pqRMkIp65u9unZnGIoyxK6v2A18730lPwSMrK93Q&amp;quot;}
&lt;/code>&lt;/pre>&lt;p>This is a new token. Paste it into &lt;a href="https://jwt.io">jwt.io&lt;/a>, you'll see there's a library code in the payload.&lt;/p>
&lt;h4 id="4-work-with-the-service">4. Work with the service&lt;/h4>
&lt;p>Now I can call APIs like:&lt;/p>
&lt;pre>&lt;code>GET libaries.com/api/books
&lt;/code>&lt;/pre>&lt;p>And my server can check the library in my token. If I have one, I return books from the given library, otherwise I return a 401.&lt;/p>
&lt;h4 id="is-this-useful">Is this useful?&lt;/h4>
&lt;p>This specific example might not appeal, but you may well find as you write more complex services you want to at times add data to your token.&lt;/p>
&lt;p>The case above also shows how you can associate a session with a set of resources (in this case, a single library). This is useful if we know we'll only work with a subset of resources. I want to choose a library once and work with that only. If you need to work with multiple libraries, it wouldn't make sense.&lt;/p>
&lt;h2 id="how">How?&lt;/h2>
&lt;p>If we are using Auth0, then we almost certainly have our token generated for us. The helper library &lt;a href="https://github.com/auth0/express-jwt">express-jwt&lt;/a> will certainly let us make sure the token is valid, and put the payload of data on the &lt;code>request.user&lt;/code> object, but how can we create a new token &lt;em>from the existing one&lt;/em>?&lt;/p>
&lt;p>It turns out it's really pretty easy, as we would expect as we are using open standards. Here's the code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;jsonwebtoken&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">extendToken&lt;/span>(&lt;span style="color:#a6e22e">secret&lt;/span>, &lt;span style="color:#a6e22e">payload&lt;/span>, &lt;span style="color:#a6e22e">extend&lt;/span>) {
&lt;span style="color:#75715e">// Clone and extend the payload.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">body&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">parse&lt;/span>(&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">payload&lt;/span>));
&lt;span style="color:#66d9ef">for&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">prop&lt;/span> &lt;span style="color:#66d9ef">in&lt;/span> &lt;span style="color:#a6e22e">extend&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#a6e22e">extend&lt;/span>.&lt;span style="color:#a6e22e">hasOwnProperty&lt;/span>(&lt;span style="color:#a6e22e">prop&lt;/span>)) {
&lt;span style="color:#a6e22e">body&lt;/span>[&lt;span style="color:#a6e22e">prop&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">extend&lt;/span>[&lt;span style="color:#a6e22e">prop&lt;/span>];
}
}
&lt;span style="color:#75715e">// Sign the new token with our secret.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">jwt&lt;/span>.&lt;span style="color:#a6e22e">sign&lt;/span>(&lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">body&lt;/span>), &lt;span style="color:#a6e22e">secret&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We have a function which takes a secret, the payload of an existing token, an object containing data to extend and that's it. Here's how you could use it:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">expressJwt&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;express-jwt&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">mySecret&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">Buffer&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;walkinonsunshine&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;base64&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Middleware for protecting routes...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">requireAuth&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">expressJwt&lt;/span>({&lt;span style="color:#a6e22e">secret&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">mySecret&lt;/span>});
&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">post&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/libraries/:lib/authorise&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">requireAuth&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">req&lt;/span>, &lt;span style="color:#a6e22e">res&lt;/span>, &lt;span style="color:#a6e22e">next&lt;/span>) {
&lt;span style="color:#75715e">// get the library, check the user has access...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">lib&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">params&lt;/span>.&lt;span style="color:#a6e22e">lib&lt;/span>;
&lt;span style="color:#a6e22e">checkLib&lt;/span>(&lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>.&lt;span style="color:#a6e22e">sub&lt;/span>, &lt;span style="color:#a6e22e">lib&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>, &lt;span style="color:#a6e22e">ok&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">next&lt;/span>(&lt;span style="color:#a6e22e">err&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">ok&lt;/span>) &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">401&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Access Denied.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">res&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>(&lt;span style="color:#ae81ff">200&lt;/span>).&lt;span style="color:#a6e22e">send&lt;/span>({&lt;span style="color:#a6e22e">jwt&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">extendToken&lt;/span>(&lt;span style="color:#a6e22e">mySecret&lt;/span>, &lt;span style="color:#a6e22e">req&lt;/span>.&lt;span style="color:#a6e22e">user&lt;/span>, {&lt;span style="color:#a6e22e">library&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">lib&lt;/span>})});
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've extended the original token with some new data, resigned it and passed it back to the user. Future requests will automatically have the &lt;code>req.user.lib&lt;/code> field set (as the entire token payload is put by default on the &lt;code>req.user&lt;/code> object with the express-js middleware.&lt;/p>
&lt;p>Hopefully that'll be of some use if you ever need to extend the payload of a JWT token in a Node app.&lt;/p>
&lt;hr>
&lt;p>&lt;sup id="fn1">1. Json Web Token, read more at &lt;a href="http://jwt.io/">jwt.io&lt;/a>. &lt;a href="#ref1">↩&lt;/a>&lt;/sup>&lt;/p></description><category>CodeProject</category></item><item><title>The Best Module System for AngularJS Applications</title><link>https://dwmkerr.com/the-best-module-system-for-angularjs-applications/</link><pubDate>Wed, 18 Mar 2015 14:47:10 +0000</pubDate><guid>https://dwmkerr.com/the-best-module-system-for-angularjs-applications/</guid><description>&lt;p>I was working on a small and simple application built with AngularJS the other day. As with most applications like this, I start with a single JavaScript file caled &lt;code>app.js&lt;/code> and no module system.&lt;/p>
&lt;p>In the past I've used RequireJS with AngularJS. It's an awful mistake. It leads to a big jump in complexity with no benefts. Angular apps don't work well with AMDs, so really your are using RequireJS to combine files into one big file.&lt;/p>
&lt;p>I'm sure there's a good analogy with hammers and nails. Something like:&lt;/p>
&lt;blockquote>
&lt;p>It's like banging nails into your face with a hammer.&lt;/p>
&lt;/blockquote>
&lt;p>Maybe a bit extreme. But those who've used the two together may well be nodding sagely.&lt;/p>
&lt;p>I've also used Browserify. I prefer this approach, the syntax is cleaner. But it's still a pain.&lt;/p>
&lt;p>Ideally, I'd like to use ECMA6 modules. So another approach is to just use ECMA6 module syntax and then compile your code with something like Traceur. But that requires quite a bit of tooling, slows down your pipeline and you're still not &lt;em>really&lt;/em> using modules.&lt;/p>
&lt;p>I think the best approach is this one from &lt;a href="https://medium.com/@dickeyxxx">Jeff Dicky&lt;/a> on his post &lt;a href="https://medium.com/@dickeyxxx/best-practices-for-building-angular-js-apps-266c1a4a6917">Best Practices for Building Angular.js Apps&lt;/a>. Just forget all of the module stuff and concatenate only.&lt;/p>
&lt;p>Start with this:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Or whatever your preferred structure is. Then stick your main file in &lt;code>app/&lt;/code>:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- app.js
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Your &lt;code>app.js&lt;/code> file should define your main Angular module:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>, []);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now just go ahead and concatenate everything in your &lt;code>app/&lt;/code> folder. Structure it however you want:&lt;/p>
&lt;pre>&lt;code>myproject
- app/
- components/
- home/
- profile/
- app.js
- css/
- vendor/
- index.html
&lt;/code>&lt;/pre>&lt;p>Concat will put everything in the top level folder (i.e. &lt;code>app.js&lt;/code>) first. As long as you don't put anything else in your top level folder (that comes before &amp;lsquo;a&amp;rsquo; alphabetically) then it doesn't matter where you put your other files, as long as you define them without referencing any globals. So define your components like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>).&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;SomeController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// something
&lt;/span>&lt;span style="color:#75715e">&lt;/span>});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>No fuss no muss. No requires, no exports.&lt;/p>
&lt;p>If you need a new service, write it and save it. Same for directives or controllers or filters. Add the source file and it's included, no messing around.&lt;/p>
&lt;p>Keep it simple, don't force another module system on top of angular's, you don't get much benenfit. And wait patiently until ECMA6 moves more into the mainstream and we can start using native modules. There's less and less point in investing in some super-sophisticated complex fancy module system for a framework which in vNext will throw it all away and for a language which will finally get native modules.&lt;/p>
&lt;h3 id="words-for-gulpers">Words for Gulpers&lt;/h3>
&lt;p>If you are a gulp user, here's how a pipeline might look to concat your JavaScript:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">gulp&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">jshint&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-jshint&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">stylish&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;jshint-stylish&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">uglify&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-uglify&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">rename&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-rename&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">sourcemaps&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-sourcemaps&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">concat&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-concat&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">ngAnnotate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">require&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;gulp-ng-annotate&amp;#39;&lt;/span>);
&lt;span style="color:#75715e">// Hints and builds all JavaScript.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">task&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;js&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">src&lt;/span>([&lt;span style="color:#e6db74">&amp;#39;./client/app/**/*.js&amp;#39;&lt;/span>])
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>.&lt;span style="color:#a6e22e">reporter&lt;/span>(&lt;span style="color:#a6e22e">stylish&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">jshint&lt;/span>.&lt;span style="color:#a6e22e">reporter&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;fail&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">sourcemaps&lt;/span>.&lt;span style="color:#a6e22e">init&lt;/span>({&lt;span style="color:#a6e22e">loadMaps&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>}))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">concat&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app.js&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">dest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./client/dist&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">ngAnnotate&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">uglify&lt;/span>())
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">rename&lt;/span>({&lt;span style="color:#a6e22e">suffix&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;.min&amp;#39;&lt;/span>}))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">sourcemaps&lt;/span>.&lt;span style="color:#a6e22e">write&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./&amp;#39;&lt;/span>))
.&lt;span style="color:#a6e22e">pipe&lt;/span>(&lt;span style="color:#a6e22e">gulp&lt;/span>.&lt;span style="color:#a6e22e">dest&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;./client/dist/&amp;#39;&lt;/span>));
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Watch your app javascript folder and when it changes, you'll hint everything, concat into a single distribution folder, annotate and uglify, as well as building full sourcemaps.&lt;/p>
&lt;h3 id="what-about-other-stuff">What about other stuff?&lt;/h3>
&lt;p>For vendor code (jQuery, Bootstrap, whatever), don't bother trying to be smart and require or import it. Just include it in your app with script tags. I wouldn't go to the effort at trying to force some kind of smart module system on a language that doesn't really support it - uf you can get away with avoiding it, do so.&lt;/p>
&lt;p>This is not an encouragement to be sloppy, this is just the easiest way to deal with the issue. The number of hours I've wasted tracking down &amp;lsquo;bugs&amp;rsquo; which were subtle issues to do with require.js or type-os has definitely made the approach above my preferred approach.&lt;/p></description><category>CodeProject</category></item><item><title>Failures Connecting from Elastic Beanstalk servers to MongoDB on EC?</title><link>https://dwmkerr.com/failures-connecting-from-elastic-beanstalk-servers-to-mongodb-on-ec/</link><pubDate>Mon, 16 Mar 2015 10:34:04 +0000</pubDate><guid>https://dwmkerr.com/failures-connecting-from-elastic-beanstalk-servers-to-mongodb-on-ec/</guid><description>&lt;p>tl;dr?&lt;/p>
&lt;blockquote>
&lt;p>Check your mongodb.conf &lt;code>bind_ip&lt;/code> settings to make sure that you're not allowing connections only from localhost.&lt;/p>
&lt;/blockquote>
&lt;p>This may just end up being the first part of a wider troubleshooting guide, but this is one I've spent a few hours fixing, after assuming I was making terrible mistakes with my security groups.&lt;/p>
&lt;p>If you find you cannot connect to your MongoDB server from an EB app server (or anything for that matter), before you spend ages checking your Elastic IP, VPC and Security Group config, don't forget that you may have simply used &lt;code>bind_ip&lt;/code> in your config file.&lt;/p>
&lt;p>Check for:&lt;/p>
&lt;pre>&lt;code>bind_ip = 127.0.0.1
&lt;/code>&lt;/pre>&lt;p>Comment it out or remove it and restart:&lt;/p>
&lt;pre>&lt;code>service mongod restart
&lt;/code>&lt;/pre>&lt;p>Don't forget to make sure your firewall is still set up correctly - only allow connections from IPs or even better other security groups you trust.&lt;/p></description><category>CodeProject</category></item><item><title>Fixing Memory Leaks in AngularJS and other JavaScript Applications</title><link>https://dwmkerr.com/fixing-memory-leaks-in-angularjs-applications/</link><pubDate>Tue, 03 Mar 2015 14:35:36 +0000</pubDate><guid>https://dwmkerr.com/fixing-memory-leaks-in-angularjs-applications/</guid><description>&lt;p>Dealing with memory leaks in JavaScript applications can be a complex process. In this article I'm going to show you how to identify whether you have memory leaks, analyse them and ultimately resolve them.&lt;/p>
&lt;p>I'm using an AngularJS application to demonstrate the concepts and approaches, but much of this material applies to any JavaScript application.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="#understandingmemoryleaks">Understanding Memory Leaks&lt;/a>
&lt;ul>
&lt;li>What is a Memory Leak?&lt;/li>
&lt;li>Why is a Memory Leak Bad?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#identifyingmemoryleaks">Identifying Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Method 1: The Wrong Way&lt;/li>
&lt;li>Method 2: The Timeline&lt;/li>
&lt;li>Method 3: Recording Heap Allocations&lt;/li>
&lt;li>Method 4: Heap Snapshots&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#analysingmemoryleaks">Analysing Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Analysing the leak in Scenario 2&lt;/li>
&lt;li>More on Graphs&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#fixingmemoryleaks">Fixing Memory Leaks&lt;/a>
&lt;ul>
&lt;li>Three golden rules&lt;/li>
&lt;li>Anti-patterns to avoid&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#thefuture">The Future&lt;/a>
&lt;ul>
&lt;li>Weak Maps&lt;/li>
&lt;li>AngularJS 2&lt;/li>
&lt;li>Even Better Browsers&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#appendices">Appendices&lt;/a>
&lt;ul>
&lt;li>Thanks&lt;/li>
&lt;li>Mysteries&lt;/li>
&lt;li>Futher Reading&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="understanding-memory-leaks">Understanding Memory Leaks&lt;/h2>
&lt;p>If you've dealt with memory leaks before, or the patterns of memory usage we sometimes call memory leaks in memory managed applications, then you can probably skip to &lt;a href="#identifyingmemoryleaks">Identifying Memory Leaks&lt;/a>.&lt;/p>
&lt;p>If not let's start with some theory.&lt;/p>
&lt;h3 id="what-is-a-memory-leak">What is a Memory Leak?&lt;/h3>
&lt;p>A memory leak, at least in the world of unmanaged applications, is what occurs when you allocate memory and forget to free it. In pseudo-code&lt;sup>&lt;a href="#fn1" id="ref1">1&lt;/a>&lt;/sup>:&lt;/p>
&lt;pre>&lt;code>void leaky()
{
void* memory;
memory = malloc(1000);
/* malloc just gave us some memory, use it! */
}
&lt;/code>&lt;/pre>&lt;p>&lt;code>memory&lt;/code> will hold the address of the memory we've allocate. We use the memory, then the function ends. &lt;code>memory&lt;/code> goes out of scope and whatever address it held is lost - but we didn't free the memory! Not only that, we've lost the address of it so can't ever free it in the future - it's &lt;em>leaked&lt;/em>.&lt;/p>
&lt;p>This memory is lost to the application - we can't release it. Only terminating the process will release it back to the operating system.&lt;/p>
&lt;blockquote>
&lt;p>When we allocate memory and don't release it when we are done, we have &amp;lsquo;leaked&amp;rsquo; that memory.&lt;/p>
&lt;/blockquote>
&lt;p>So how do we get memory leaks in JavaScript applications? We don't allocate memory directly, the engine does it for us, and it cleans it up afterwards as well&lt;sup>&lt;a href="#fn2" id="ref2">2&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>If we hold on to objects longer than we need to, that will give us similar results. Let's look at some code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">ChessManager&lt;/span>() {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">moves&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [];
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">makeMove&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">move&lt;/span>) {
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">moves&lt;/span>.&lt;span style="color:#a6e22e">push&lt;/span>(&lt;span style="color:#a6e22e">move&lt;/span>);
};
&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">newGame&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">moves&lt;/span>.&lt;span style="color:#a6e22e">clear&lt;/span>();
};
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we've got a bug - the &lt;code>newGame&lt;/code> function doesn't clear the &lt;code>ChessManager&lt;/code>'s moves, it just throws a null reference exception. But we could use this class in our code. In theory if we keep on calling &lt;code>makeMove&lt;/code> we'll just grow and grow the &lt;code>moves&lt;/code> array. This is a bug leading to memory that can't be freed, even though we don't need it.&lt;/p>
&lt;p>That's a contrived example of a JavaScript memory leak.&lt;/p>
&lt;blockquote>
&lt;p>When we are finished with memory but don't allow the garbage collector to clean it up, that's a memory leak.&lt;/p>
&lt;/blockquote>
&lt;p>At least for the purposes of this discussion. We'll see it's a very easy thing to do.&lt;/p>
&lt;h3 id="why-is-a-memory-leak-bad">Why is a Memory Leak bad?&lt;/h3>
&lt;p>It might seem obvious but let's just make sure we're explicit with everything. As we said in the initial definition, we allocate memory but don't deallocate it.&lt;/p>
&lt;p>In &lt;em>some&lt;/em> circumstances, this is not necessarily a disaster, if we don't leak too much too often, but there are circumstances where this is very serious.&lt;/p>
&lt;p>Memory leaks cause performance problems, slow down applications and can lead to a process terminating. There are some times when that's really not good.&lt;/p>
&lt;p>Servers and high performance applications shouldn't leak, especially as many should be expected to run for long periods of time. Mobile apps or apps for embedded systems will need to deal with fewer resources and will suffer if they leak. Any application an end user is expecting to use for a long time will cause a lot of frustration if it leaks.&lt;/p>
&lt;p>That's enough theory, let's actually start looking at identifying memory leaks in the context of an AngularJS application.&lt;/p>
&lt;h2 id="identifying-memory-leaks">Identifying Memory Leaks&lt;/h2>
&lt;p>I've created a sample app for showing photo albums which is leaky in parts. The app is at:&lt;/p>
&lt;p>&lt;a href="http://dwmkerr.github.io/angular-memory-leaks/">dwmkerr.github.io/angular-memory-leaks&lt;/a>&lt;/p>
&lt;p>It's a very basic app with a fairly common set of components; Bootstrap, jQuery and AngularJS. We're going to take a look at how we can identify whether this app suffers from memory leaks.&lt;/p>
&lt;p>You can run the app in your browser, or run it locally with the commands:&lt;/p>
&lt;pre>&lt;code>git clone https://github.com/dwmkerr/angular-memory-leaks.git
cd angular-memory-leaks
npm install &amp;amp;&amp;amp; bower install
gulp
&lt;/code>&lt;/pre>&lt;p>Running gulp will serve the app, lint, and reload the browser when you change the code. The project page is at &lt;a href="https://github.com/dwmkerr/angular-memory-leaks">github.com/dwmkerr/angular-memory-leaks&lt;/a>.&lt;/p>
&lt;h3 id="method-1-the-wrong-way">Method 1: The Wrong Way&lt;/h3>
&lt;p>First, just be aware that the wrong way to look for leaks is by examing the memory usage of the Chrome process. While an increasing amount of memory usage &lt;em>can&lt;/em> indicate a leak, it is not reliable. Why?&lt;/p>
&lt;p>Well browsers can allocate memory and use it how they want to. A page it is rendering may no longer need as much memory as it needed before, but that doesn't mean the browser needs to release it to the OS. It may just keep it to avoid having to re-allocate it later on.&lt;/p>
&lt;h3 id="method-2-the-timeline">Method 2: The Timeline&lt;/h3>
&lt;p>Open the Chrome developer tools. Go to &amp;lsquo;Timeline&amp;rsquo; select &amp;lsquo;Memory&amp;rsquo; and hit &amp;lsquo;Record&amp;rsquo;.&lt;/p>
&lt;p>&lt;img src="images/StartRecording.png" alt="Start Recording">&lt;/p>
&lt;p>Now start using your application. After you are done, stop recording. You'll see a graph of memory usage.&lt;/p>
&lt;p>&lt;img src="images/MemoryUsage.png" alt="Memory Usage">&lt;/p>
&lt;p>This is &lt;strong>almost&lt;/strong> exactly what we need. I'll explain the almost shortly, but lets take a look at this graph.&lt;/p>
&lt;ol>
&lt;li>We see a &lt;em>Used JS Heap&lt;/em> in blue. &lt;em>Used&lt;/em> is important here - Chrome is telling us that there may be more heap usage than shown in its actual process, but what we are seeing here is what is actually used by the page.&lt;/li>
&lt;li>We see documents (in this case a steady value of one document).&lt;/li>
&lt;li>We see DOM nodes. As I use the app the nodes increase, up until a certain point and then they drop.&lt;/li>
&lt;li>We see Listeners (i.e. even handlers). Again, these increase as I use the app and then drop.&lt;/li>
&lt;/ol>
&lt;p>So what should we be looking for in this graph? That depends on what our app is doing. But let's imagine the we are navigating through different photo albums in the albums app. We'll need more memory to see each album, but once we leave an album we don't need that memory any more. So we should get a healthy saw-tooth pattern&lt;sup>&lt;a href="#fn3" id="ref3">3&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/TimelineSawtooth.png" alt="Timeline Sawtooth">&lt;/p>
&lt;p>Here we see that we use more and more memory, up until the point that Chrome garbage collects, then goes back to where we started. This is repeated again and again. This is a good sign - when Chrome garbage collects we go back to the same place we started, a strong indication we are not leaking much memory.&lt;/p>
&lt;p>If we are doing some work which simply needs more and more memory, and we don't release it, we would expect to see steps instead&lt;sup>&lt;a href="#fn4" id="ref4">4&lt;/a>&lt;/sup>:&lt;/p>
&lt;p>&lt;img src="images/TimelineSteps-1.png" alt="Timeline Steps">&lt;/p>
&lt;p>An example of this might be an infinite scroll situation. I'm looking through a vast photo album, and when I get to the bottom of the screen I load more images automatically. The ones I've loaded are still in the DOM so cannot be released. We see no saw-tooth because there's no release of memory. However, this is not a memory leak - it's just increasing memory usage. It does mean that if we allow the user to scroll too much we may run out of resources though.&lt;/p>
&lt;p>The &lt;strong>dangerous&lt;/strong> case is the one below:&lt;/p>
&lt;p>&lt;img src="images/TimelineLeakySawtooth.png" alt="Leaky Sawtooth">&lt;/p>
&lt;p>Let's imaging we're using the application, navigating through albums, returning the the home page, looking through some more albums and so on. We keep using memory, and Chrome keeps on garbage collecting, but we never quite get back to where we started. We are trending towards increasing memory usage. This indicates we &lt;em>might&lt;/em> be leaking memory.&lt;/p>
&lt;p>&lt;em>Might&lt;/em> is not going to cut the mustard, we need to know categorically what is going on and whether we have a leak.&lt;/p>
&lt;blockquote>
&lt;p>You said this is &amp;lsquo;almost&amp;rsquo; exactly what we need?&lt;/p>
&lt;/blockquote>
&lt;p>Unfortunately, you cannot always trust this graph. See Mystery 1 for the ugly details. Suffice to say that what we're seeing here is an indicator only, but for more detail we need to look at Method 3.&lt;/p>
&lt;h3 id="method-3-recording-heap-allocations">Method 3: Recording Heap Allocations&lt;/h3>
&lt;p>Let's look at a different way of seeing if we've got a leak, the &amp;lsquo;Heap Allocations&amp;rsquo; view. In the developer tools, go to &amp;lsquo;Profiles&amp;rsquo; and &amp;lsquo;Record Heap Allocations&amp;rsquo;:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocations.png" alt="Record Heap Allocations">&lt;/p>
&lt;p>When we record heap allocations we get a chart showing us spikes as we allocate memory. These spikes are initially blue (meaning Chrome is using the memory), then change to grey once the memory is freed. If we see spikes or sections of spikes that remain blue, we may have a problem.&lt;/p>
&lt;p>Try this, go to the Ablums app and start recording. Click on the &amp;lsquo;India&amp;rsquo; album, then go back to the home page. You should see a chart like this:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx1.png" alt="Heap Allocations Example 1">&lt;/p>
&lt;p>So we start recording and nothing is being allocated. Then we click on the &amp;lsquo;India&amp;rsquo; album (point 1) and we get a few spikes, as chrome allocates memory needed for the content in the new page. Then we click back on the home page (point 2). Some of the memory used in the India album is released (it looks like about half). One spike of memory used for the home page is still in use (what we'd expect) and another spike or two seem to be freed. These other spikes might be memory used for the actual transition, for example in logic in the router.&lt;/p>
&lt;p>So this looks like we may have a problem in the album page. In fact, we can drag a selection box around those first three spikes and see what is &lt;em>still&lt;/em> in memory (i.e. what might be a potential leak) in the view below:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx2.png" alt="Heap Allocations Example 2">&lt;/p>
&lt;p>Dissecting this view we have:&lt;/p>
&lt;ol>
&lt;li>A subset of the data, the blue spike from the album page which is still in use.&lt;/li>
&lt;li>The &amp;lsquo;Heap View&amp;rsquo;, which shows us different &lt;em>types&lt;/em> of data in memory. Don't worry, we'll see a lot more on this later.&lt;/li>
&lt;li>An instance of a specific type of data, in this case an instance of a JavaScript object.&lt;/li>
&lt;li>The retainers graph for the specific object.&lt;/li>
&lt;/ol>
&lt;p>We're going to look into what all of this means in a lot of detail as we go through the article. For now, I'll simply state what we're seeing, by the end of the article you'll be able to analyse this (and much more) yourself.&lt;/p>
&lt;p>In this snapshot we see a small amount of data still in use. A quick look through the data reveils we have data still in use which relats to the AngularJS template cache.&lt;/p>
&lt;p>This is good! It means this is probably not a leak. When I first visit the album page AngularJS is caching the template used to render it, so of course it stays in memory.&lt;/p>
&lt;blockquote>
&lt;p>When analysing memory usage remember that caching, preloading and other optimisation techniques may cause some noise.&lt;/p>
&lt;/blockquote>
&lt;p>So if we have the albums page in a cache, in theory the next time we visit the page and then return to the home page, we should free a lot more of the memory (because the &lt;em>new&lt;/em> memory we allocate will be just for the page itself, not the cache which is already set up). Let's try it. We'll record going to the album page, back to the homepage, then the album page and back again:&lt;/p>
&lt;p>&lt;img src="images/HeapAllocationsEx3.png" alt="Heap Allocations Example 3">&lt;/p>
&lt;p>This is looking good.&lt;/p>
&lt;ol>
&lt;li>We go to the &amp;lsquo;India&amp;rsquo; album. Some memory used is now freed, but much is still in use. As we saw, at least some of that is the template cache.&lt;/li>
&lt;li>We go back to the home page, lots of memory is used but by the time we're done recording it's almost entirely freed.&lt;/li>
&lt;li>We visit the India album a second time, requiring some memory almost all of which is freed.&lt;/li>
&lt;li>We go back to the home page. Some memory is used during the transition and to render the page, some of that is still in use (which is expected as the page is still open).&lt;/li>
&lt;/ol>
&lt;p>The heap allocations chart is exceptionally useful in identifying memory leaks, it has already led to some insights:&lt;/p>
&lt;ol>
&lt;li>Initial loading of pages increases our &amp;lsquo;baseline&amp;rsquo; memory footprint due to data being added to caches (such as the AngularJS template cache).&lt;/li>
&lt;li>Subsequent loading of pages requires memory, but the vast majority of it is freed.&lt;/li>
&lt;/ol>
&lt;p>One thing we noticed from this brief analysis was that the initial result was slightly misleading. With the heap allocations view repeated operations can help you identify trends. In the Albums application I've actually set up part of the app to run repeated operations, so we can try to consistently test scenarions. The &amp;lsquo;scenarios&amp;rsquo; menu lets us run them. Let's try running scenario 1.&lt;/p>
&lt;p>&lt;img src="images/Scenario1.png" alt="Scenario 1">&lt;/p>
&lt;p>This scenario will navigate from &lt;code>/&lt;/code> (the home page) to &lt;code>/nowhere&lt;/code> ten times. &lt;code>/nowhere&lt;/code> isn't matched by the router so takes us back to the home page. This has the effect of reloading the home page 20 times (just reloading doesn't work, the router is smart enough to realise we're staying on the same page).&lt;/p>
&lt;p>&lt;img src="images/Scneario1HeapAllocations.png" alt="Scenario 1 Heap Allocations">&lt;/p>
&lt;p>While you are recording the chart you can see peaks go from blue to grey as memory is freed. Let's see what we've got.&lt;/p>
&lt;ol>
&lt;li>Shows our first navigation, some memory is not freed. Everything before this is setup code.&lt;/li>
&lt;li>Our last navigation. Some memory still in use (as expected).&lt;/li>
&lt;li>A glance at memory in use shows some compiled code and system data (more on this later). At this stage we don't need to worry, Chrome will allocate data like this when it needs to.&lt;/li>
&lt;li>It looks like the 11th page load didn't free all of it's memory. This is potential cause for worry.&lt;/li>
&lt;/ol>
&lt;p>Altogether this a very healthy looking scenario. The huge majority of what we allocate is freed, as we would hope. Small amounts of memory stay in use (mostly used under the hood by Chrome) and a small amount of memory after the 11th reload is not freed (a quick look suggests a timing issue, definitely something we'd want to investigate further in a real-world app). Our allocations are in the 50 KB to 100 KB range and we're looking good.&lt;/p>
&lt;p>Before we say goodbye to the Heap Allocations view (for now) let's do the same for Scenario 2 (moving from the home page to the top rated page 10 times).&lt;/p>
&lt;p>&lt;img src="images/Scenario2HeapAllocations.png" alt="Scenario 2 Heap Allocations">&lt;/p>
&lt;p>We are not going to analyse this issue (yet!) but this is an example of a much less healthy chart. In this chart we seem to be allocating memory for each page view and not releasing it. This kind of chart definitely indicates that there could be problems.&lt;/p>
&lt;p>So we've seen the Heap Allocations view, which is a bit more sophisticated than the memory usage graph. Let's look at the last way to analyse memory leaks - snapshots.&lt;/p>
&lt;h3 id="method-4-heap-snapshots">Method 4: Heap Snapshots&lt;/h3>
&lt;p>The final method of identifying memory leaks is the most sophisticated and finely controlled. We will take snapshots at specific points in time and analyse the differences between them. To take a snapshot, we go to the Profiles view and choose &amp;lsquo;Take Heap Snapshot&amp;rsquo;:&lt;/p>
&lt;p>&lt;img src="images/TakeHeapSnapshot.png" alt="Take Heap Snapshot">&lt;/p>
&lt;p>When we take a heap snapshot Chrome simply records the details of all memory allocated.&lt;/p>
&lt;blockquote>
&lt;p>Remember: Taking a Snapshot &lt;strong>always&lt;/strong> runs garbage collection first.&lt;/p>
&lt;/blockquote>
&lt;p>A heap snapshot shows you exactly the same kind of data you get in the Heap Allocations view, except that you are seeing ALL memory in use, not just objects which were allocated and are still alive:&lt;/p>
&lt;p>&lt;img src="images/HeapSnapshot1.png" alt="A Heap Snapshot">&lt;/p>
&lt;p>This view is very complete but not necessarily very useful. There's some extra ways to see the data (if you change from &amp;lsquo;Summary&amp;rsquo; to another view or change &amp;lsquo;All Objects&amp;rsquo; but we'll see that later).&lt;/p>
&lt;p>Staying on topic, we'll not yet look in detail at what the data is that we are seeing, we'll first look into identifying whether there are memory leaks - then we'll look into tracking them down.&lt;/p>
&lt;p>Indivdiual snapshots are not so helpful for checking for leaks, but what is very helpful is the ability to compare memory used between snapshots.&lt;/p>
&lt;p>Let's take some snapshots, try this:&lt;/p>
&lt;ol>
&lt;li>Open the app.&lt;/li>
&lt;li>Navigate to the top rated page (caches should now be set up).&lt;/li>
&lt;li>Navigate to the home page. Take a snapshot.&lt;/li>
&lt;li>Navigate to the top rated page. Take a snapshot.&lt;/li>
&lt;li>Navigate to the home page. Take a snapshot.&lt;/li>
&lt;/ol>
&lt;p>Now we can do something really cool. Select snapshot 3, and choose to view data allocated between snapshot 1 and 2. This means we're seeing data allocated for the top rated page, which is &lt;em>still&lt;/em> in use when we go back to the home page, i.e. probably leaked.&lt;/p>
&lt;p>&lt;img src="images/SnapshotComparison.png" alt="Snapshot Comparison">&lt;/p>
&lt;p>So what are we seeing now?&lt;/p>
&lt;ol>
&lt;li>We have three snapshots. The size of each one is shown. &lt;em>Sometimes&lt;/em> the very first one seems overly high. See Mystery 2. We have selected the 3rd snapshot and are therefore only able to see data still present in this snapshot.&lt;/li>
&lt;li>We are chosing to show only objects allocated between Snapshot 1 and 2, i.e. objects allocated to present the page. But we're &lt;strong>in&lt;/strong> snapshot 3, so we're seeing those objects which were allocated and are still present.&lt;/li>
&lt;li>Objects allocated are looking suspicious - we've got DOM elements. This doesn't look good!&lt;/li>
&lt;/ol>
&lt;p>This is the best way to identify memory leaks. So now that we've seen how to identify whether we have memory leaks, or at least that we have a potential problem to analyse we can move onto step 2 - Analysing Memory Leaks.&lt;/p>
&lt;h2 id="analysing-memory-leaks">Analysing Memory Leaks&lt;/h2>
&lt;p>If we think we have a memory leak, we need to be able to look at the heap data and see what's going on. Whether we are seeing heap data from a selection of allocations from the Heap Allocations view or from the Heap Snapshots, we see the same kind of information:&lt;/p>
&lt;p>&lt;img src="images/HeapData.png" alt="Heap Data">&lt;/p>
&lt;p>Starting from the left we have the &amp;lsquo;Constructor&amp;rsquo; column. This is the type of object we have. Some of these objects we can see are JavaScript classes (constructed with a &lt;code>new&lt;/code> call to a function), such as &lt;code>Scope&lt;/code>. As well as our own classes, we have some special classes of data:&lt;/p>
&lt;ul>
&lt;li>(compiled code): Represents JavaScript code compiled by Chrome. Consider this internal - we have no control over it.&lt;/li>
&lt;li>(array): Internally used array object. Again, internal.&lt;/li>
&lt;li>Array: A JavaScript array. Often we have a &lt;em>lot&lt;/em> of data in arrays.&lt;/li>
&lt;li>Object: A plain old JavaScript object.&lt;/li>
&lt;li>(closure): A closure.&lt;/li>
&lt;li>system / Context: The underlying data require to call a function, for example the actual data used by a closure.&lt;/li>
&lt;li>system: Internally used data.&lt;/li>
&lt;/ul>
&lt;p>There are also plenty of objects that are created by Chrome, such as &lt;code>HTMLDivElement&lt;/code>, which is a wrapper around the internally used (native) DOM object.&lt;/p>
&lt;p>Let's dissect some of these objects in detail. Running &lt;strong>Scenario 3&lt;/strong> allocates some data and puts it on the &lt;code>window&lt;/code> object. This is really trivial data but shows a lot. You can use the Heap Allocations View or Heap Snapshots to see the data. I've taken three snapshots (once before pressing OK, once after the data is allocated, and the final one when the last modal is closed):&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis2.png" alt="Heap Data Analysis Part 1">&lt;/p>
&lt;p>This data has come from the code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// Create a class which will hold heap data. Makes it easier
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to find the data in Chrome.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">HeapData&lt;/span>() {}
&lt;span style="color:#75715e">// Create a heap data object.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">HeapData&lt;/span>();
&lt;span style="color:#75715e">// Create a function that multiplies two numbers.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">multiply&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>, &lt;span style="color:#a6e22e">b&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">a&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#a6e22e">b&lt;/span>;
}
&lt;span style="color:#75715e">// Create a &amp;#39;multiply by&amp;#39; function, which curries the above
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to generate a function which multiplies by a constant. This
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// will involve closures.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">b&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">multiply&lt;/span>(&lt;span style="color:#a6e22e">a&lt;/span>, &lt;span style="color:#a6e22e">b&lt;/span>);
}
};
&lt;span style="color:#75715e">// Add some data to our heap data object.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">fry&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Philip J. Fry&amp;#34;&lt;/span>;
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">zoidberb&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;John &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Zoidberg&amp;#34;&lt;/span>;
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">character&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">firstName&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Amy&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">secondName&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Wong&amp;#34;&lt;/span>
};
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#66d9ef">double&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span>(&lt;span style="color:#ae81ff">2&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multiplyBy100&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">multiplyBy&lt;/span>(&lt;span style="color:#ae81ff">100&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">doubledNumber&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#66d9ef">double&lt;/span>(&lt;span style="color:#ae81ff">18&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multipliedNumber&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">multiplyBy100&lt;/span>(&lt;span style="color:#ae81ff">15&lt;/span>);
&lt;span style="color:#a6e22e">heapData&lt;/span>.&lt;span style="color:#a6e22e">div&lt;/span> &lt;span style="color:#f92672">=&lt;/span> document.&lt;span style="color:#a6e22e">createElement&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;div&amp;#34;&lt;/span>);
&lt;span style="color:#75715e">// Put the heap data on the window, it is now pinned to a GC root.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>window.&lt;span style="color:#a6e22e">heapData&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">heapData&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've got a little bit of everything here, some code, some closures, some objects and a DOM element.&lt;/p>
&lt;p>As we've put most of this data on the &lt;code>heapData&lt;/code> object, which is an instance of &lt;code>HeapData&lt;/code> we can easily find the object:&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis3.png" alt="Heap Data Analysis 3">&lt;/p>
&lt;p>So we can see the &lt;code>HeapData&lt;/code> constructor, expanding it we see an &lt;em>instance&lt;/em> of &lt;code>HeapData&lt;/code>. The &lt;code>@420269&lt;/code> is a unique ID assigned by Chrome. If we have lots of heap data objects, we can use this to distinguish between them when we're looking at other parts of the snapshot. What else do we see?&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Distance&lt;/strong>. How far the instance is from a GC Root. A GC root is anything that can &amp;lsquo;pin&amp;rsquo; objects, for example the &lt;code>window&lt;/code> object which holds globals. If put something on &lt;code>window&lt;/code> it will never be freed, this is what makes it a GC root. Our distance is 2 as we have &lt;code>HeapData&lt;/code> (constructor) to &lt;code>heapData&lt;/code> (instance) to &lt;code>window&lt;/code>.&lt;/li>
&lt;li>&lt;strong>Objects count&lt;/strong>. Only valid for the top level nodes, this shows us how many objects of the specified type we have. We have 1 &lt;code>HeapData&lt;/code> object.&lt;/li>
&lt;li>&lt;strong>Shallow Size&lt;/strong>. The size of the data that is directly allocated for the object. Compare this to &lt;em>Retained Size&lt;/em>.&lt;/li>
&lt;li>&lt;strong>Retained Size&lt;/strong>. The size of data this object is retaining. For example, out &lt;code>heapData&lt;/code> instance holds a reference to an object which contains two fields &lt;code>firstName&lt;/code> and &lt;code>secondName&lt;/code>. Our shallow size includes enough data for the reference, the retained size includes the full retained size of the retained object.&lt;/li>
&lt;/ol>
&lt;p>Notice that our instance of &lt;code>HeapData&lt;/code> is highlighted in yellow? That's a convenience from Chrome, it's showing us objects which are &lt;strong>directly accessible&lt;/strong> from JavaScript. Our object can be accessed via &lt;code>window.heapData&lt;/code>, therefore it's directly accessible. Other objects we've created might not be (for example, a variable used in a closure exists and is on the heap, but not directly accessible).&lt;/p>
&lt;p>Let's see some other data we allocated:&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis4-1.png" alt="Heap Data Analysis 4">&lt;/p>
&lt;p>Now we're looking at closures. We have two closures in yellow next to each other, clicking on one shows the retainer graph. What is going on here?&lt;/p>
&lt;ol>
&lt;li>Our closure is not a simple thing. It has code (of course), which takes up memory. We won't look into this in detail. It has shared function data (again, internally used and not worth looking into). We also have a reference to a &lt;code>__proto__&lt;/code> (a function object has a prototype!). Finally, we have the context, which contains enough data to call the function. If we look in to the context we will not see much, as our function contains numbers which Chrome can simply store in the code. However, if we use references in closures we'll actually see them in the context.&lt;/li>
&lt;li>We also have the retainers. Our closure is referenced via a variable called &lt;code>multiplyBy100&lt;/code>, which itself is referenced by &lt;code>heapData&lt;/code>, which if referenced by the &lt;code>window&lt;/code> GC root.&lt;/li>
&lt;li>The &lt;code>multiplyBy100&lt;/code> variable is &lt;em>also&lt;/em> dominated by the second element of an array with id &lt;code>@227339&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>The last thing we'll look at in this snapshot is the div element.&lt;/p>
&lt;p>&lt;img src="images/HeapDataAnalysis5.png" alt="Heap Data Analyis 5">&lt;/p>
&lt;p>We can see the div element is retained by the &lt;code>div&lt;/code> variable in the &lt;code>heapData&lt;/code> object. We can also see it is made up of a prototype and some native object. The native object shows no size - don't be fooled. That just means its taking up no JavaScript heap memory. It is still using memory (just in V8 engine not the JavaScript code).&lt;/p>
&lt;p>What's important to note here is that the element is shown in red. This means it's &lt;strong>detached&lt;/strong>. So it exists, is referenced (and therefore cannot be garbage collected) but is not in the DOM. This is not necessarily a problem, but lots of detached DOM elements is often a bad sign, especially if the number is increasing.&lt;/p>
&lt;p>The rest of the data you can look through yourself. You'll notice some interesting things, such as how concatenated strings work, but the important stuff we've now seen.&lt;/p>
&lt;p>Let's move on to analyising the first potential memory leak we discovered - the transition to the Top Rated page of the albums app.&lt;/p>
&lt;h3 id="analysing-the-leak-in-scenario-2">Analysing the leak in Scenario 2&lt;/h3>
&lt;p>We saw that &lt;strong>Scenario 2&lt;/strong> (switching to and from the &amp;lsquo;top rated&amp;rsquo; view) seemed to leak memory. Let's use the heap snapshot comparison view to analyse this further. The steps are:&lt;/p>
&lt;ol>
&lt;li>Navigate to the home page.&lt;/li>
&lt;li>Navigate to the top rated page (setting up the cache).&lt;/li>
&lt;li>Navigate to the home page, take a snapshot.&lt;/li>
&lt;li>Navigate to the top rated page, take a snapshot.&lt;/li>
&lt;li>Navigate to the home page, take a snapshot.&lt;/li>
&lt;/ol>
&lt;p>We can now look at the memory allocated between 1 and 2 which is present in 3 (i.e. what we allocated for the top rated view and potentially leaked):&lt;/p>
&lt;p>&lt;img src="images/Scenario2Snapshot1.png" alt="Scenario 2 Snapshot 1">&lt;/p>
&lt;p>Some things jump out immediately:&lt;/p>
&lt;ol>
&lt;li>We have gone from 7.5 to 8.4 to 8.5 MB. We are changing from one view to another - and ending in the same place that we started. We &lt;strong>should&lt;/strong> be going back to 7.5 MB.&lt;/li>
&lt;li>We've got a lot of objects still hanging around, not just system data like compiled code, but HTML elements, detached DOM elements, &lt;code>Promise&lt;/code> objects, &lt;code>n.fn.init&lt;/code> objects and so on.&lt;/li>
&lt;/ol>
&lt;p>This looks like a classic leak situation. Let's start by looking at some objects we recognise. There are some &lt;code>Scope&lt;/code> objects near the top of the chart, let's look at those.&lt;/p>
&lt;p>&lt;img src="images/Scenario1Part2.png" alt="Scenario 2 Part 2">&lt;/p>
&lt;p>We've got some &lt;code>Scope&lt;/code> objects, three in fact. These objects contain the usual AngularJS fields such as &lt;code>$parent&lt;/code>, the only field which distinguishes this scope is the &lt;code>album&lt;/code> field. If we look at out &lt;code>aml-rated-album&lt;/code> directive it looks like it could be the isolated scope for this directive:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">.&lt;span style="color:#a6e22e">directive&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;amlRatedAlbum&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;span style="color:#a6e22e">restrict&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;E&amp;#34;&lt;/span>,
&lt;span style="color:#a6e22e">scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">album&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;=&amp;#34;&lt;/span>
} &lt;span style="color:#75715e">// etc
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This scope has an &lt;code>album&lt;/code> field. There are three albums so it looks likely these are the three albums in the top rated page, the scopes stil in memory. What retains them?&lt;/p>
&lt;p>Looking at the retainers (at &lt;strong>2&lt;/strong>) we don't see much. We're retained by a &lt;code>$$ChildScope&lt;/code>, which also retained by a &lt;code>$$ChildScope&lt;/code> object. In fact we have quite a complex graph of objects.&lt;/p>
&lt;blockquote>
&lt;p>When we leak a scope in AngularJS, we leak a huge graph of objects.&lt;/p>
&lt;/blockquote>
&lt;p>Scopes know about their parents. They also know about their children, and siblings. If we inadvertantly pin a scope to a GC root, we &lt;strong>will probably leak almost all of the scopes in the page&lt;/strong>.&lt;/p>
&lt;p>Why? The graph below should show why. I &amp;lsquo;leak&amp;rsquo; a scope, and by doing so I retain all of the other scopes, because they are connected. Having a connected graph of scopes is required for angular to work, but it means that we we are extremely susceptible to leaking a &lt;strong>lot&lt;/strong> of data.&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph1.png" alt="Scope leak graph">&lt;/p>
&lt;p>This graph shows &lt;code>$parent&lt;/code> retained relationships, but don't forget scopes also know about their children and their siblings, so real graph is even more highly connected.&lt;/p>
&lt;p>So just grabbing a specific scope is not good enough. We need to try and be a little bit more specific. Let's try starting from an element instead. Here we take a look at a div element and its retainers:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part3.png" alt="Scenario 2 Part 3">&lt;/p>
&lt;p>Resting the mouse over the instance of a leaked &lt;code>HTMLElement&lt;/code> shows a bit of data about it, it's a &lt;code>aml-rated-album&lt;/code> and it is detached. Definitely a symptom of our leak. Let's see the retainers:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part4-1.png" alt="Scenario 2 Part 4">&lt;/p>
&lt;p>Ouch. This is nasty. Again, we are not seeing much that is particularly useful. We have a long graph of retainers starting with the &lt;code>compileNode&lt;/code> function, we also have an array in a &lt;code>n.fn.init&lt;/code> function. To cut a long story short, we're are not going to easily find the root cause here. But I will share some hints.&lt;/p>
&lt;blockquote>
&lt;p>jQuery isn't leaking.&lt;/p>
&lt;/blockquote>
&lt;p>We will end up seeing so much jQuery stuff it is natural to wonder whether jQuery is leaking. Almost certainly not. In the graph about &lt;code>n.fn.init&lt;/code> is just a jQuery selector, held onto by &lt;code>$$element&lt;/code>. No surprise - all angular elements are jQuery or jQuery light objects. We've leaked an element, it just happens to be wrapped in a jQuery selector. (You might see a different type of graph, probably due to the jQuery 1 + AngularJS 1.2 combination, we'll see it later).&lt;/p>
&lt;p>You may see low level arrays containing data associated with a scope in jQuery, again, don't worry. It's the jQuery data cache (which we'll also see later), which is associating elements to scopes.&lt;/p>
&lt;p>We can try and work through this graph, but let's try another tack.&lt;/p>
&lt;p>It looks like we're probably leaking the whole of the top rated view. We're probably leaking the main scope for the view, created by the &lt;code>TopRatedController&lt;/code>. Let's see if we can find it.&lt;/p>
&lt;blockquote>
&lt;p>You can find objects you think are leaking by tagging them with classes!&lt;/p>
&lt;/blockquote>
&lt;p>This is a neat trick. Let's add a couple of lines to our top rated controller:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;app&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;TopRatedController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$interval&lt;/span>) {
&lt;span style="color:#75715e">// Create a class, assign it to the scope. This&amp;#39;ll help us
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// see if $scope is leaked.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">TopRatedControllerTag&lt;/span>() {}
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">__tag&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">TopRatedControllerTag&lt;/span>();
&lt;span style="color:#75715e">// etc...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now when we run the analysis again, we can search in the snapshot for &lt;code>TopRatedControllerTag&lt;/code>:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part5.png" alt="Scenario 2 Part 5">&lt;/p>
&lt;ol>
&lt;li>We search for &amp;lsquo;Tag&amp;rsquo;, finding one instance of the &lt;code>TopRatedControllerTag&lt;/code>.&lt;/li>
&lt;li>Bingo - it is retained by a Scope, with id &lt;code>@534851&lt;/code>&lt;/li>
&lt;/ol>
&lt;p>Let's look at this scope in more detail. Right click on it and choose &amp;lsquo;Review in Summary View&amp;rsquo;, so we can see what is retaining it:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part6.png" alt="Scenario 2 Part 6">&lt;/p>
&lt;ol>
&lt;li>We can now see the root scope for the actual view.&lt;/li>
&lt;li>We can see the usual pattern of &lt;code>$$ChildScope&lt;/code> and &lt;code>$parent&lt;/code> properties, but what else have we got?&lt;/li>
&lt;/ol>
&lt;p>Intestingly we can see that our scope is also retained by a &lt;strong>context variable called $scope&lt;/strong>. How do I know it is a context variable? It's in blue, part of the colour coding (see Mystery 3).&lt;/p>
&lt;p>What is a context variable?&lt;/p>
&lt;blockquote>
&lt;p>A &lt;strong>closure&lt;/strong> is a function which refers to a variable outside of its definition. A &lt;strong>context variable&lt;/strong> is the variable stored in a function context. A &lt;strong>function context&lt;/strong> contains the environment for a closure, which is the data required to execute it.&lt;/p>
&lt;/blockquote>
&lt;p>So basically we have a closure which refers to a variable called &lt;code>$scope&lt;/code>, which is the root scope of our view. We can see in detail the closure:&lt;/p>
&lt;p>&lt;img src="images/Scenario2Part7.png" alt="Scenario 2 Part 7">&lt;/p>
&lt;ol>
&lt;li>&lt;code>$scope&lt;/code> is retained by a &lt;code>context&lt;/code> for a closure.&lt;/li>
&lt;li>The closure is in the &lt;code>refresh&lt;/code> function (this is why the &lt;code>context&lt;/code> is retained by &lt;code>refresh&lt;/code>).&lt;/li>
&lt;/ol>
&lt;p>We can open the function and examine it for issues. There's an &lt;code>$http.get&lt;/code> which has as closure which uses &lt;code>$scope&lt;/code>, but alarmingly there is an &lt;code>$interval&lt;/code> registered to run every 10 seconds, which is never deregistered. The interval callback uses another &lt;code>$http.get&lt;/code>, with a closure that uses &lt;code>$scope&lt;/code>. This is the problem.&lt;/p>
&lt;p>A simple timeout we forgot to deregister has a closure on &lt;code>$scope&lt;/code>. &lt;code>$scope&lt;/code> can therefore never be cleaned up, because it is retained by a context.&lt;/p>
&lt;p>Some important takeaways:&lt;/p>
&lt;ol>
&lt;li>The framework hides implementation details. Often useful, but in this case it made finding the leak a problem.&lt;/li>
&lt;li>This example seems contrived, but how how often do you have a closure using &lt;code>$scope&lt;/code> in a controller? In real world apps all of the time time, callbacks to ajax requests, event handlers, promise functions etc.&lt;/li>
&lt;li>A leak of a small object that contains the &lt;strong>data&lt;/strong> for three albums has leaked a &lt;strong>large graph&lt;/strong> of other objects, and even &lt;strong>DOM elements&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Leaks are not incremental. You don't get an accumulation of small leaks, one small leak can retain a huge graph.&lt;/p>
&lt;/blockquote>
&lt;p>Let's talk about this a bit more.&lt;/p>
&lt;h3 id="dealing-with-object-graphs">Dealing with Object Graphs&lt;/h3>
&lt;p>We saw before that a chain of retainers can pin an object, such as a scope, to a GC root. We also saw that AngularJS scopes are part of a highly connected graph, meaning that if we leak part of it, we probably leak it all:&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph1-1.png" alt="Scope Leak Graph 1">&lt;/p>
&lt;p>However, things can get worse. Remember how in an angular app you can get the scope for an element with &lt;code>$(selector).scope()&lt;/code>? This connection between a scope an an element is maintained in the jQuery data cache. This lets us associate arbitrary data with an element. This introduces another layer of connectivity:&lt;/p>
&lt;p>&lt;img src="images/ScopeLeakGraph2.png" alt="Scope Leak Graph 2">&lt;/p>
&lt;p>In this graph, we see the jQuery data cache entries (in grey) associating DOM elements to scopes, introducing more connectivity.&lt;/p>
&lt;p>We can see here an alarming increase in the size and potential complexity of the graph. We've got DOM elements in play now. The chances are that if you are reading this you are dealing with a memory leak in your app, if it's noticable enough for you to deal with it, you probably have a non-trivial graph.&lt;/p>
&lt;p>So how do we fix memory leaks? I'll show three general approaches and how to use each one.&lt;/p>
&lt;h2 id="fixing-memory-leaks">Fixing Memory Leaks&lt;/h2>
&lt;p>Fixing memory leaks is hard. As we have seen our problem is highly connected graphs. If we have a part of the graph we want to free for garbage collection (such as a scope and all of it's children, such as a view or directive) then we must not retain that graph of objects. This means if you have (for example) three problems that lead to retaining a graph, you have to fix &lt;strong>all of the problems&lt;/strong> before the leak goes away.&lt;/p>
&lt;p>Let's generalise the best practices first into three rules, see patterns we should follow for each of them and then look at anti-patterns to avoid.&lt;/p>
&lt;h3 id="three-golden-rules">Three Golden Rules&lt;/h3>
&lt;blockquote>
&lt;p>Rule 1: Understand the framework and lifecycle.&lt;/p>
&lt;/blockquote>
&lt;p>If you are using a framework like AngularJS, you &lt;strong>must&lt;/strong> understand the lifecycle of the objects you are dealing with. Unless you understand how the framework tries to clean up, you may make mistakes that stop it from working.&lt;/p>
&lt;blockquote>
&lt;p>Rule 2: Be careful at the interface between short and long lived objects.&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you see an interface between a short and long lived object, be extra careful. For example, if you have a directive talking to a service, make sure the service cannot retain the directive through closures, callbacks or any references. Services will last for the lifetime of the application, so they are the sort of object which can inadvertantly retain short lived objects.&lt;/p>
&lt;p>Other long lived objects exist but may be more subtle, the interface between AngularJS and other libraries can be a risky area, if other libraries maintain long lived state.&lt;/p>
&lt;p>Finally, consider this. The isolated scope for a directive (for example) may inadvertantly be long lived - if it is leaked. That leads us to Rule 3.&lt;/p>
&lt;blockquote>
&lt;p>Rule 3: Disconnect the graph.&lt;/p>
&lt;/blockquote>
&lt;p>You can be defensive by manually disconnecting graphs of objects. This can aid if you have a memory leak you cannot resolve. By disconnecting the graph, the garbage collector will at least be able to attempt to clean up parts of it.&lt;/p>
&lt;p>AngularJS should attempt to do this for you, for example when scopes are destroyed the links to other scopes are severed. But you can also do this yourself. Disconnecting the graph is not always as simple as emptying arrays or nulling objects, it can mean nulling closures and context variables too&lt;sup>&lt;a href="#fn5" id="ref5">5&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>The anti-patterns which follow are all violations of these rules.&lt;/p>
&lt;h3 id="anti-patterns-to-avoid">Anti-Patterns to Avoid&lt;/h3>
&lt;p>Whether or not your app is suffering from memory leaks, avoid these patterns.&lt;/p>
&lt;h4 id="poorly-managed-event-handlers">Poorly Managed Event Handlers&lt;/h4>
&lt;p>Consider a trivial example in a directive link:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">scope&lt;/span>, &lt;span style="color:#a6e22e">element&lt;/span>, &lt;span style="color:#a6e22e">attrs&lt;/span>) {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;click&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">selected&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
});
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We register an event handler. We've now built a closure which will have a context, which retains the &lt;code>scope&lt;/code>. If we don't deregister this event handler, we retain the closure, the context, the scope, and then basically everything in the universe.&lt;/p>
&lt;p>&lt;strong>The Fix&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">scope&lt;/span>, &lt;span style="color:#a6e22e">element&lt;/span>, &lt;span style="color:#a6e22e">attrs&lt;/span>) {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;click&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">selected&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
});
&lt;span style="color:#a6e22e">scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;$destroy&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">element&lt;/span>.&lt;span style="color:#a6e22e">off&lt;/span>(); &lt;span style="color:#75715e">// deregister all event handlers
&lt;/span>&lt;span style="color:#75715e">&lt;/span> })&lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;em>Note:&lt;/em> Angular &lt;em>should&lt;/em> handle this. It is supposed to deregister event handlers on elements it manages. In my experience this isn't always the case, although it seems cases when this doesn't happen are fewer and fewer as bugs get fixed in the framework. Anyway, Rule 3 - disconnect.&lt;/p>
&lt;h4 id="poorly-managed-watchers">Poorly Managed Watchers&lt;/h4>
&lt;p>Watchers or angular event handlers, basically the same as above.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;someEvent&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">refresh&lt;/span>();
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Again, Angular should clean this up if you forget to, but the advice is always do it yourself. Angular watchers return a deregister function.&lt;/p>
&lt;p>&lt;strong>The Fix&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">cleanup&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;someEvent&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">refresh&lt;/span>();
});
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;$destroy&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">cleanup&lt;/span>();
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Rule 1 - know the framework and how lifecycle is handled. &lt;code>$destroy&lt;/code> is sent to a scope specifically to allow it to be cleaned up.&lt;/p>
&lt;h4 id="callback-functions-on-services">Callback Functions on Services&lt;/h4>
&lt;p>Services (or other long lived objects) should typically not take callback functions. Imagine a &amp;lsquo;user service&amp;rsquo;, allowing a scope to discover if the user has changed their name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#a6e22e">UserService&lt;/span>.&lt;span style="color:#a6e22e">onNameChange&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">newName&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">userName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">newName&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now the service (a long lived object) takes a closure with a context to a short lived object, the scope. Unless the service is written absolutely correctly, we run the risk of the service retaining the scope. Remember, services are singletons and as such the interface between services and scopes is one that requires careful management.&lt;/p>
&lt;p>There are two fixes I would suggest.&lt;/p>
&lt;p>&lt;strong>Fix 1: For a one-off operation, use a promise&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// change and name and wait for the result
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">UserService&lt;/span>.&lt;span style="color:#a6e22e">changeName&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Fry&amp;#34;&lt;/span>).&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">newName&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">newName&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The notification service returns a promise (a short lived object) which holds the closure. If we get things wrong, we are less likely to leak the scope. Plus, promises are typically easy to work with once you've got the hang of them&lt;sup>&lt;a href="#fn6" id="ref6">6&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>&lt;strong>Fix 2: For notifications, use broadcasts&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="color:#75715e">// more like our original example
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">$on&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NotificationService:ChangeName&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">data&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">data&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Some will say to not overuse broadcasts as they can be expensive. They can, so use them judiciously. But remember, they're provided by the framework, typically lead to fairly loose coupling and are probably managing clean up as well or better than a hand-rolled mechanism in a service. Rule 2 - don't tie short lived objects to long lived objects.&lt;/p>
&lt;h2 id="the-future">The Future&lt;/h2>
&lt;p>That's a wrap. Hopefully this article will grow and improve with feedback from the community. To wind up, lets look at a few things that are on their way which will touch on these issues.&lt;/p>
&lt;h3 id="weak-maps">Weak Maps&lt;/h3>
&lt;p>Finally, in ECMAScript 6 we will get a WeakMap&lt;sup>&lt;a href="#fn7" id="ref7">7&lt;/a>&lt;/sup> object. This is &lt;em>ideal&lt;/em> for something like the jQuery data cache. A weak map uses weak references (not natively supported in JavaScript). This means that we can map a DOM element to a scope in a weak map, but the map entry doesn't retain the element or scope. If the element or scope is cleaned up, the map entry is removed. This means internal structures to aid with frameworks don't need to necessarily retain object graphs.&lt;/p>
&lt;h3 id="angularjs-2">AngularJS 2&lt;/h3>
&lt;p>Simplifications to the framework in 2.0 and usage of native features like web components mean less complex framework code and less scope for issues. Consider even the usage of classes in Angular 2.0. We don't decorate a scope object (of type &lt;code>Object&lt;/code>) we create an instance of a class. Easier to see in the heap view.&lt;/p>
&lt;h3 id="even-better-browsers">Even Better Browsers&lt;/h3>
&lt;p>SPA frameworks are driving improvements to browsers. Frameworks like Angular lead to more SPAs. More SPAs mean we find more bugs and edge cases in browsers. Many memory leak issues in AngularJS have led to fixes in V8.&lt;/p>
&lt;h2 id="appendices">Appendices&lt;/h2>
&lt;p>Beware any write up long enough to need appendices.&lt;/p>
&lt;h3 id="thanks">Thanks&lt;/h3>
&lt;p>Much of my understanding here came from working with others on real-world issues. I would like to thank the following people for their advice and insights:&lt;/p>
&lt;p>James Denning, Shaun Bohannon, Arnaud Rebts, Colin Montgomery, Jon Hamshaw, Christian Lilley, Maarten De Wilde&lt;/p>
&lt;p>There are others I have worked on with in this area, if I have forgotten to mention you please let me know.&lt;/p>
&lt;h3 id="mysteries">Mysteries&lt;/h3>
&lt;p>After a large amount of time spent investigating memory leaks, there are still some things which to me are a mystery. If anyone can shed some light, I'd be interested to know.&lt;/p>
&lt;p>&lt;strong>Mystery 1: False Charts&lt;/strong>&lt;/p>
&lt;p>As mentioned earlier we cannot always trust the timeline, it is not uncommon to see the memory usage in the timeline increase, even though the size of snapshots seems to be staying constant. This may be related to AngularJS Issue &lt;a href="https://github.com/angular/angular.js/issues/4864">DOM Nodes Leaking&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Mystery 2: Odd Snapshot Sizes&lt;/strong>&lt;/p>
&lt;p>It is not uncommon for the first snapshot to be large, and then subsequent snapshots to all be a bit smaller (even without any state changes). Why this is the case I do not know. To test, run an angular app and take some snapshots without doing anything in between. You'll normally see (for example) 9 MB, 9MB, 9MB. However, it is not uncommon to see 15 MB, 9MB, 9MB.&lt;/p>
&lt;p>&lt;strong>Mystery 3: Where's the colour coding documentation?&lt;/strong>&lt;/p>
&lt;p>The Chrome documentation states that the colour coding key for elements in the heap snapshot is available in the tool. I can't find it anywhere, so had to research to find the details.&lt;/p>
&lt;h3 id="further-reading">Further Reading&lt;/h3>
&lt;p>Still not had enough? Try these.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/heap-profiling#basics">Profiling Memory Performance&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/memory-analysis-101">Memory Analysis 101&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/heap-profiling-containment">Heap profile containment&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/tips-and-tricks">Dev tools tips &amp;amp; tricks&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.chrome.com/devtools/docs/javascript-memory-profiling">JavaScript Memory Profiling&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management">Memory Management&lt;/a>&lt;/li>
&lt;li>&lt;a href="http://addyosmani.com/blog/taming-the-unicorn-easing-javascript-memory-profiling-in-devtools/">Taming the Unicorn&lt;/a>&lt;/li>
&lt;/ol>
&lt;hr>
&lt;p>&lt;sup id="fn1">1. This is C actually, but the syntax isn't important, just the logic of what we're doing.&lt;a href="#ref1">↩&lt;/a>&lt;/sup>
&lt;sup id="fn2">2. In JavaScript as in most managed languages, the mechanism by which this happens is reference counting and garbage collection. There's a superb description at &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management">JavaScript Memory Management&lt;/a>.&lt;a href="#ref2">↩&lt;/a>&lt;/sup>
&lt;sup id="fn3">3. Try it yourself with this &lt;a href="http://jsfiddle.net/dwmkerr/2LzxgLb4/">fiddle for a sawtooth pattern&lt;/a>.&lt;a href="#ref3">↩&lt;/a>&lt;/sup>
&lt;sup id="fn4">4. Try it yourself with this &lt;a href="http://jsfiddle.net/dwmkerr/9dmpp5te/">fiddle for a &amp;lsquo;steps&amp;rsquo; pattern&lt;/a>.&lt;a href="#ref4">↩&lt;/a>&lt;/sup>
&lt;sup id="fn5">5. See &lt;a href="https://github.com/dwmkerr/angular-modal-service/commit/79998ca98101798608bdb914aecbd44f3ccbaa7a">this commit&lt;/a> in my Angular Modal Service for an example of how nulling context variables (i.e. disconnecting the graph) solved a memory leak. This is a good example of how are it can be, after large amounts of analysis I still haven't discovered &lt;strong>why&lt;/strong> this was needed, but it solved the problem. It may relate to Mystery 4.&lt;a href="#ref5">↩&lt;/a>&lt;/sup>
&lt;sup id="fn6">6. See my article &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">Promises in AngularJS - The Definitive Guide&lt;/a> if you are not sure how to use them.&lt;a href="#ref6">↩&lt;/a>&lt;/sup>
&lt;sup id="fn7">7. More details at &lt;a href="https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/WeakMap">https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/WeakMap&lt;/a>&lt;a href="#ref7">↩&lt;/a>&lt;/sup>&lt;/p></description><category>CodeProject</category></item><item><title>The Only AngularJS Modal Service You'll Ever Need</title><link>https://dwmkerr.com/the-only-angularjs-modal-service-youll-ever-need/</link><pubDate>Mon, 16 Jun 2014 00:48:12 +0000</pubDate><guid>https://dwmkerr.com/the-only-angularjs-modal-service-youll-ever-need/</guid><description>&lt;p>If you need modals in an AngularJS application, look no further. I'll show you how to use the &lt;a href="https://github.com/dwmkerr/angular-modal-service">Angular Modal Service&lt;/a> to add Bootstrap Modals or your own custom modals to your application.&lt;/p>
&lt;p>&lt;a href="http://jsfiddle.net/dwmkerr/8MVLJ/">See it in a fiddle&lt;/a> or check out &lt;a href="http://dwmkerr.github.io/angular-modal-service">a full set of samples online&lt;/a>.&lt;/p>
&lt;h4 id="contents">Contents&lt;/h4>
&lt;ol>
&lt;li>[Using the Angular Modal Service](#UsingTheAngular ModalService)&lt;/li>
&lt;li>&lt;a href="#AQuickExample">A Quick Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="#DesignGoals">Design Goals&lt;/a>&lt;/li>
&lt;li>&lt;a href="#HowItWorks">How It Works&lt;/a>&lt;/li>
&lt;li>&lt;a href="#WrappingUp">Wrapping Up&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="using-the-angular-modal-service">Using the Angular Modal Service&lt;/h2>
&lt;p>Here's how you can use the Angular Modal Service to add a bootstrap modal to your application.&lt;/p>
&lt;h4 id="step-1-install-with-bower">Step 1: Install with Bower&lt;/h4>
&lt;p>Install the service with bower:&lt;/p>
&lt;pre>&lt;code>bower install angular-modal-service --save
&lt;/code>&lt;/pre>&lt;p>If you don't use bower, just get the source directly from the &lt;a href="https://github.com/dwmkerr/angular-modal-service/tree/master/dst">&lt;code>dst&lt;/code>&lt;/a> folder of the repo.&lt;/p>
&lt;h4 id="step-2-include-the-javascript">Step 2: Include the JavaScript&lt;/h4>
&lt;p>Include the JavaScript from the &lt;code>dst&lt;/code> folder or require it with require.js:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;bower_components\angular-modal-service\dst\angular-modal-service.min.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="step-3-add-it-as-a-dependency">Step 3: Add it as a dependency&lt;/h4>
&lt;p>Make sure the &lt;code>angularModalService&lt;/code> module is listed as a required module for your application:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">app&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;myApp&amp;#39;&lt;/span>, [&lt;span style="color:#e6db74">&amp;#39;angularModalService&amp;#39;&lt;/span>]);
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="step-4-show-the-modal">Step 4: Show the Modal&lt;/h4>
&lt;p>Inject &lt;code>ModalService&lt;/code> into any controller, directive or service and call the &lt;code>showModal&lt;/code> function to show a modal:&lt;/p>
&lt;pre>&lt;code class="language-language" data-lang="language">app.controller('SampleController', function($scope, ModalService) {
ModalService.showModal({
templateUrl: &amp;quot;template.html&amp;quot;,
controller: &amp;quot;ModalController&amp;quot;
}).then(function(modal) {
//it's a bootstrap element, use 'modal' to show it
modal.element.modal();
modal.close.then(function(result) {
console.log(result);
});
});
);
&lt;/code>&lt;/pre>&lt;p>This code loads the HTML from &lt;code>template.html&lt;/code>, adds it to the DOM, creates a scope for it and creates an instance of a &lt;code>ModalController&lt;/code>.&lt;/p>
&lt;p>When this is done, the promise returned by the &lt;code>showModal&lt;/code> function resolves and you get a &lt;code>modal&lt;/code> object. This object contains the element created. If it's a Bootstrap modal just call &lt;code>modal&lt;/code> to show it, if it's a custom one you can show it by changing its CSS styles or using whatever APIs are provided. There's an example ofa custom modal in &lt;a href="http://dwmkerr.github.io/angular-modal-service/">the samples&lt;/a>.&lt;/p>
&lt;h4 id="step-5-close-the-modal">Step 5: Close the Modal&lt;/h4>
&lt;p>The controller that is created always has one extra parameter injected into it - a function called &lt;code>close&lt;/code>. Call this function to close the modal, anything you pass to it is passed to the caller as the &lt;code>result&lt;/code> object.&lt;/p>
&lt;pre>&lt;code class="language-language" data-lang="language">app.controller('ModalController', function($scope, close) {
// when you need to close the modal, call close
close(&amp;quot;Success!&amp;quot;);
});
&lt;/code>&lt;/pre>&lt;p>You can pass a number of milliseconds to wait before destroying the DOM element as an optional second parameter to &lt;code>close&lt;/code> - this is useful if the closing of the modal is animated and you don't want it to disappear before the animation completes.&lt;/p>
&lt;h2 id="a-quick-example">A Quick Example&lt;/h2>
&lt;p>Here's a fiddle of the modal service in action:&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/8MVLJ/embedded/result,js,html" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>One thing to note in this examples is that the template is just declared in the DOM - this works fine because the service always checks the template cache before attempting to load it from the server.&lt;/p>
&lt;p>There are more examples at &lt;a href="http://dwmkerr.github.io/angular-modal-service/">dwmkerr.github.io/angular-modal-service&lt;/a>.&lt;/p>
&lt;h2 id="design-goals">Design Goals&lt;/h2>
&lt;p>There are some other services for handling modals out there, notably &lt;a href="https://github.com/Fundoo-Solutions/angularjs-modal-service">Fundoo's Modal Service&lt;/a> and a few others. However, the design goals for my service were slightly different:&lt;/p>
&lt;ol>
&lt;li>&lt;strong>No link to bootstrap&lt;/strong>. Bootstrap modals are complex with lots of options - if you want to use them then that's great, the service should work with them, but the complexity of the options for Bootstrap Modals should not increase the complexity of the service.&lt;/li>
&lt;li>&lt;strong>Extremely simple code&lt;/strong>. It's rare you'll write something that it will suit everyone's need. Rather than trying to please everyone, I want a service that is simple enough to understand so that it can be easily adapted by others.&lt;/li>
&lt;/ol>
&lt;p>So the core goal here is simplicity - if others can understand the code, then they can more effectively decide whether it's what they need, or build upon it.&lt;/p>
&lt;p>With these design goals in mind I built the angular modal service.&lt;/p>
&lt;h2 id="how-it-works">How It Works&lt;/h2>
&lt;p>I'm going to walk through a slightly simplified version of the code because it actually illustrates quite a few important concepts when working with AngularJS.&lt;/p>
&lt;p>One of the things that's useful to know is that this service creates a DOM element, builds a scope for it and instantiates a controller for it - what we're doing is &lt;em>very&lt;/em> similar to what AngularJS does behind the scenes when a directive is created.&lt;/p>
&lt;p>So let's dive in. We're going to define a service, so we need a module.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">module&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">module&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;angularModalService&amp;#39;&lt;/span>, []);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we have our module, we can define our service. I tend to write services in the form of classes, but this is a personal choice - it's just as valid to return a javascript object that contains functions and data.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">module&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ModalService&amp;#39;&lt;/span>, [&lt;span style="color:#e6db74">&amp;#39;$document&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$compile&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$controller&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$http&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$rootScope&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$q&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;$timeout&amp;#39;&lt;/span>,
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$document&lt;/span>, &lt;span style="color:#a6e22e">$compile&lt;/span>, &lt;span style="color:#a6e22e">$controller&lt;/span>, &lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$rootScope&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>, &lt;span style="color:#a6e22e">$timeout&lt;/span>) {
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I need a lot of injected components, we'll see why as we continue. I also use the explicit form of the function which takes the parameters as strings - this is the only safe way to write an injected function if you are minifying code.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">body&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$document&lt;/span>.&lt;span style="color:#a6e22e">find&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;body&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">ModalService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>I use the &lt;code>$document&lt;/code> object to get the body element, which the modal will be appended to. I then create a class function and record &lt;code>this&lt;/code> as self, so that I can refer to the class instance in callbacks and so on.&lt;/p>
&lt;p>The next part of the code creates a function that will return the template, given either a raw template string or a template url. The reason we wrap this function like this is that the operation will either be synchronous or asynchronous, and I don't want the caller to care. So we use promises to wrap the logic.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">getTemplate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>, &lt;span style="color:#a6e22e">templateUrl&lt;/span>) {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>);
} &lt;span style="color:#66d9ef">else&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">templateUrl&lt;/span>) {
&lt;span style="color:#a6e22e">$http&lt;/span>({&lt;span style="color:#a6e22e">method&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;GET&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">url&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">templateUrl&lt;/span>, &lt;span style="color:#a6e22e">cache&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>);
});
} &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;No template or templateUrl has been specified.&amp;#34;&lt;/span>);
}
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If any of this seems confusing, check out my article &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">AngularJS Promises - The Definitive Guide&lt;/a>.&lt;/p>
&lt;p>Now to the main function.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">showModal&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>) {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>showModal&lt;/code> function is going to have to do all sorts of async work - loading the template from the server and so on. So we are going to create a &lt;code>deferred&lt;/code> object and build a promise to return to the caller.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">controller&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#f92672">!&lt;/span>&lt;span style="color:#a6e22e">controller&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;No controller has been specified.&amp;#34;&lt;/span>);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we validate that a controller has been passed in as part of the options. Notice how just like in &lt;code>getTemplate&lt;/code> we use the &lt;code>reject&lt;/code> function to deal with error cases. Again, if error handling with promises seems unfamiliar, check out &lt;a href="http://www.dwmkerr.com/promises-in-angularjs-the-definitive-guide/">AngularJS Promises - The Definitive Guide&lt;/a>.&lt;/p>
&lt;p>Next we deal with the template.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">getTemplate&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">template&lt;/span>, &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">templateUrl&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>) {
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We've used the &lt;code>getTemplate&lt;/code> function to get the template, sync or async it doesn't matter, our logic is the same.&lt;/p>
&lt;p>Now we can build a new scope for our modal.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$rootScope&lt;/span>.&lt;span style="color:#a6e22e">$new&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll refer to this a lot later on. Now for some cleverness.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">closeDeferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">inputs&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">$scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span>,
&lt;span style="color:#a6e22e">close&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>, &lt;span style="color:#a6e22e">delay&lt;/span>) {
&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#66d9ef">undefined&lt;/span> &lt;span style="color:#f92672">||&lt;/span> &lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">===&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>) &lt;span style="color:#a6e22e">delay&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;span style="color:#a6e22e">$timeout&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span> () {
&lt;span style="color:#a6e22e">closeDeferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>);
}, &lt;span style="color:#a6e22e">delay&lt;/span>);
}
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This requires some explanation. First, we create a new &lt;code>deferred&lt;/code> object. This is going to be used to build a promise that is resolved when the modal closes.&lt;/p>
&lt;p>Now we build an &lt;code>input&lt;/code> object. This contains parameters we want to inject to the controller we're going to create. Any parameters the controller needs, such as &lt;code>$element&lt;/code>, &lt;code>$timeout&lt;/code> or whatever will be injected by angular. We're just going to make sure that the &lt;code>$scope&lt;/code> that is injected is the one we've just created, and that we also inject a function called &amp;lsquo;close&amp;rsquo;. This function simply resolves the promise we've created after a specified timeout.&lt;/p>
&lt;p>This means that any controller for a modal can take &lt;code>close&lt;/code> as a parameter, and we'll inject the function that resolves the promise. This promise is returned to the consumer so that they can take action when the modal closes. We also allow the controller to pass a variable to &lt;code>close&lt;/code> which is passed to the &lt;code>resolve&lt;/code> function as well.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>) {
&lt;span style="color:#66d9ef">for&lt;/span>(&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">inputName&lt;/span> &lt;span style="color:#66d9ef">in&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>) {
&lt;span style="color:#a6e22e">inputs&lt;/span>[&lt;span style="color:#a6e22e">inputName&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">options&lt;/span>.&lt;span style="color:#a6e22e">inputs&lt;/span>[&lt;span style="color:#a6e22e">inputName&lt;/span>];
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Without the this code, the service is close to useless. What we do here is allow the caller to provide extra inputs to the controller. Imagine we have a list of items, maybe books for a library program, and when the use clicks on one we want to show a modal. The code that shows the modal needs to pass the selected book to the modal controller - by adding it to the &lt;code>inputs&lt;/code> object, the book can be injected into the controller. This allows to client to pass data &lt;strong>to&lt;/strong> the controller, with the parameter of the &lt;code>close&lt;/code> function used to return data &lt;strong>from&lt;/strong> the controller.&lt;/p>
&lt;p>Ready for some lower level Angular?&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalController&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$controller&lt;/span>(&lt;span style="color:#a6e22e">controller&lt;/span>, &lt;span style="color:#a6e22e">inputs&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalElementTemplate&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">angular&lt;/span>.&lt;span style="color:#a6e22e">element&lt;/span>(&lt;span style="color:#a6e22e">template&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">linkFn&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$compile&lt;/span>(&lt;span style="color:#a6e22e">modalElementTemplate&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modalElement&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">linkFn&lt;/span>(&lt;span style="color:#a6e22e">modalScope&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Four innocuous lines that are actually quite complex.&lt;/p>
&lt;ol>
&lt;li>First, we create an instance of the controller with name &lt;code>controller&lt;/code>. Regardless of what AngularJS injects, we provide &lt;code>inputs&lt;/code> to be injected as well.&lt;/li>
&lt;li>Now we turn our raw template html into an AngularJS DOM element. AngularJS always works with jQuery or jQuery Lite elements, the &lt;code>angular.element&lt;/code> function takes raw HTML and turns it into a DOM element we can work with.&lt;/li>
&lt;li>Now we &lt;code>$compile&lt;/code> the element. This step goes over the DOM and expands all directives. We're turning raw DOM elements into elements that are expanded into directives, but we haven't yet linked this set of elements into a scope. This is the first step of the compile/link process.&lt;/li>
&lt;li>Finally, we can link the element. The &lt;code>$compile&lt;/code> function returns a link function which we call with a scope to link the DOM elements (fully expanded) to the specified scope.&lt;/li>
&lt;/ol>
&lt;p>This is very similar to AngularJS actually handles directives itself - creating a scope, loading a template, turning it into an element, compiling it and linking it.&lt;/p>
&lt;p>Why are compile and link separate steps? Think of it like this, the work that is done in compile is actually identical for each instance of a directive (or modal in our case). It's not related to an &lt;em>instance&lt;/em> of a directive or modal, it's just expanding the elements and directives. So this work can be done once only, saving a lot of time - then we just call link to create an &lt;em>instance&lt;/em> of our element, bound to a specific scope. So link logic is always per instance (you have a scope, you can &lt;code>$watch&lt;/code> and so on) whereas compile logic is per &lt;em>type&lt;/em> of directive.&lt;/p>
&lt;p>Based on this, we could in fact cache the results of the compile function on a per-template basis, as they can be reused and linked to a scope as necessary. However this is an optimisation that is currently left out.&lt;/p>
&lt;p>Now we can add the fully built element to the DOM and build our return object.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">body&lt;/span>.&lt;span style="color:#a6e22e">append&lt;/span>(&lt;span style="color:#a6e22e">modalElement&lt;/span>);
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">modal&lt;/span> &lt;span style="color:#f92672">=&lt;/span> {
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalController&lt;/span>,
&lt;span style="color:#a6e22e">scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalScope&lt;/span>,
&lt;span style="color:#a6e22e">element&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">modalElement&lt;/span>,
&lt;span style="color:#a6e22e">close&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">closeDeferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We return the four things the caller might need - the controller, scope, element and close promise. When the close promise is resolved, we also want to clean up:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">modal&lt;/span>.&lt;span style="color:#a6e22e">close&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">modalScope&lt;/span>.&lt;span style="color:#a6e22e">$destroy&lt;/span>();
&lt;span style="color:#a6e22e">modalElement&lt;/span>.&lt;span style="color:#a6e22e">remove&lt;/span>();
});
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">modal&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So when &lt;code>close&lt;/code> is resolved, whatever happens we'll destroy the scope and clean up the DOM. Now we can resolve our promise with the &lt;code>modal&lt;/code> object we've built&amp;hellip;&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> .&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip;and we can pass errors that occured during &lt;code>getTemplate&lt;/code> to the caller and finally return the promise we've built.&lt;/p>
&lt;p>That's it! With this design we handle errors correctly, can pass data to and from the modal, clean up after ourselves and make sure that units of asynchronous work are handled with the standard pattern of promises.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>I hope you've found the service and some of the details of the code useful, as always comments are welcome, fork the code and have a play - let me know if you think of improvements or have questions,&lt;/p></description><category>CodeProject</category></item><item><title>Practical AngularJS Part 2 – Components of an AngularJS Application</title><link>https://dwmkerr.com/practical-angularjs-part2/</link><pubDate>Wed, 07 May 2014 14:55:25 +0000</pubDate><guid>https://dwmkerr.com/practical-angularjs-part2/</guid><description>&lt;p>Welcome to Part 2 of Practical AngularJS. I’m going to introduce you to some of the core components of an angular app. These are:&lt;/p>
&lt;ul>
&lt;li>Controllers&lt;/li>
&lt;li>Filters&lt;/li>
&lt;li>Directives&lt;/li>
&lt;li>Services&lt;/li>
&lt;li>Views &amp;amp; Routes&lt;/li>
&lt;/ul>
&lt;p>We’re not going to be going into detail – just taking a look at what each of these components are and where they fit into the structure of an app. We’ll be going into detail for each of them in later articles.&lt;/p>
&lt;h2 id="controllers">Controllers&lt;/h2>
&lt;p>Controllers are objects that manage the state of part of a page. The state is stored in the scope - the scope is an object that holds all of the state needed to render the page. We use a controller to add state and functionality to the scope, it's that simple.&lt;/p>
&lt;p>A controller is normally going to be written for a logical chunk of the user interface of an application, such as a &amp;lsquo;Create Something&amp;rsquo; form, &amp;lsquo;Edit Something&amp;rsquo; popup and so on.&lt;/p>
&lt;p>Controllers are dealt with in Practical &lt;a href="http://www.dwmkerr.com/practical-angularjs-part1/">AngularJS Part 1 - Introducing AngularJS&lt;/a> but let's have a quick refresh. Here's a controller for the UI for a list of cartoon characters.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/8Ts9u/embedded/js,html,result" width="100%" height="300">&lt;/iframe>
&lt;p>Here's the points that you should take from the refresher:&lt;/p>
&lt;ul>
&lt;li>Controllers create state on the $scope&lt;/li>
&lt;li>Controllers expose functionality by adding functions to the $scope&lt;/li>
&lt;li>Controllers are written for a logical portion of the UI&lt;/li>
&lt;/ul>
&lt;h3 id="a-note-on-the-controller-as-syntax">A Note on the Controller &amp;lsquo;as&amp;rsquo; Syntax&lt;/h3>
&lt;p>As of Angular 1.2 it is possible to use a controller with the &amp;lsquo;as&amp;rsquo; syntax, such as:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">ng-controller&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;CharacterController as controller&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">p&lt;/span> &lt;span style="color:#a6e22e">ng-text&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;controller.something&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">p&lt;/span>&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">div&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The only problem is with approach is that it's not just a decision you have to make on the view, but also in the controller. Normal controllers add to the $scope, controllers used with the &amp;lsquo;as&amp;rsquo; syntax add to themselves and the controller itself is added to the scope with the given name.&lt;/p>
&lt;p>My personal preference is for the &amp;lsquo;as&amp;rsquo; syntax - it makes directives less ambiguous when there are nested scopes. However, until the feature is set up so that the coder can use &amp;lsquo;as&amp;rsquo; or not without having to change the controller code, I suggest that you pick one approach or the other and stick to it.&lt;/p>
&lt;h3 id="quick-tips-for-controllers">Quick Tips for Controllers&lt;/h3>
&lt;p>Don't put everything on &lt;code>$scope&lt;/code> - only put functions and data you want to expose to the view on &lt;code>$scope&lt;/code> and keep all other data private to the controller.
Keep your controllers focused, if they get very large you probably need to break it into smaller controllers.&lt;/p>
&lt;h2 id="filters">Filters&lt;/h2>
&lt;p>Filters are simple units of logic that format data, let's see some:&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/XPqL8/embedded/html,result" width="100%" height="150">&lt;/iframe>
&lt;p>You can use filters in any expression - you pass a value through a filter by using the vertical pipe symbol. Filters can also take parameters, which come after the colon. AngularJS has a bunch of built in filters that are very useful, such as date, currency, orderBy and sortBy.&lt;/p>
&lt;p>Let's create our own filter now. Assume that in our app we are showing statuses in lots of places - either Success, Warning or Error. But in our app our statuses come back as numbers, 0 is error, 1 is warning and 2 is success. Here's how we could write a filter to show the text:&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/DVb9B/embedded/html,js,result" width="100%" height="150">&lt;/iframe>
&lt;p>Filters are simple and they're really useful. They'll become an important part of your angular toolkit. They also lead us nicely onto Directives.&lt;/p>
&lt;h3 id="quick-tips-for-filters">Quick Tips for Filters&lt;/h3>
&lt;ul>
&lt;li>Learn the out-of-the box filters, particularly date, currency and number.&lt;/li>
&lt;li>Filters can take any number of parameters.&lt;/li>
&lt;li>Although filters can take parameters and are highly adaptable, if you're doing more than what is essentially formatting then you should probably be using a directive.&lt;/li>
&lt;/ul>
&lt;h2 id="directives">Directives&lt;/h2>
&lt;p>Directives are powerful re-usable units of logic and UI that can be dropped into your application. A directive is written in the HTML of your page, it can be an element, class or attribute. Angular then compiles these directives by adding HTML for them and linking in functionality.&lt;/p>
&lt;p>Let's take a look at our earlier example, we have a number which represents a status. We'll make a &amp;lsquo;status&amp;rsquo; directive that shows the status text, in an appropriate colour.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/3T2W6/embedded/html,js,css,result" width="100%" height="300">&lt;/iframe>
&lt;p>Let's break down what we've got here.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">app-status&lt;/span> &lt;span style="color:#a6e22e">status-value&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;0&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">app-status&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>First we have the directive in HTML - Angular knows that it can map hyphens to camel-case, so we can use &amp;lsquo;appStatus&amp;rsquo; as the directive name.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">.&lt;span style="color:#a6e22e">directive&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;appStatus&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> {
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we actually create the directive. A directive is normally just a function that returns an object with a specific format.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">restrict&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;E&amp;#39;&lt;/span>,
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;lsquo;Restrict&amp;rsquo; allows us to state that the directive can only be used in certain ways. E is for element, A for attribute and C for class.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">template&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;lt;div ng-class=&amp;#34;statusClass&amp;#34;&amp;gt;{{statusValue | status}}&amp;lt;/div&amp;gt;&amp;#39;&lt;/span>,
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The template just contains that HTML to use for the directive. It can contain filters. You can also use &amp;lsquo;templateHtml&amp;rsquo; and specify a path to an HTML file if that's more convenient.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">scope&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">statusValue&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;=&amp;#39;&lt;/span>
},
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Slightly more complex - &amp;lsquo;scope&amp;rsquo; lets us determine what values we want on the scope and where they come from. Using the equals sign means perform a two-way databind to the property with the same name as is on the parent scope. You can use an ampersand for one-way binding.&lt;/p>
&lt;p>In this directive we're using the scope to allow us to pass the status as an attribute. We'll see a lot more of this in later tutorials, so don't worry if it seems a bit cryptic at the moment.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">link&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>) {
&lt;span style="color:#66d9ef">switch&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">statusValue&lt;/span>) {
&lt;span style="color:#66d9ef">case&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">statusClass&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;red&amp;#34;&lt;/span>; &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;span style="color:#66d9ef">case&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">statusClass&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;orange&amp;#34;&lt;/span>; &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;span style="color:#66d9ef">case&lt;/span> &lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">statusClass&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;green&amp;#34;&lt;/span>; &lt;span style="color:#66d9ef">break&lt;/span>;
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Link is the function that is called when the HTML elements have been created - you can use this function to add data to the scope, work with the generated elements or attributes. Again, we'll be seeing more of this later.&lt;/p>
&lt;p>The more you work with angular, the more you'll see how directives allow you to create re-usable user interface components. We're going to see them again and again in this series, but for now it's sufficient to know that they are there and what they can be used for.&lt;/p>
&lt;h3 id="quick-tips-for-directives">Quick Tips for Directives&lt;/h3>
&lt;ul>
&lt;li>If you need to include content in your directive tags, look into transclude.&lt;/li>
&lt;li>If you need the actually DOM tree element generated, you can get it in the link function.&lt;/li>
&lt;li>Learn the syntax for &amp;lsquo;scope&amp;rsquo; on a directive - it's important to use the right binding mechanisms for everything you bring into the scope.&lt;/li>
&lt;li>Learn, learn, learn, we've only glimpsed at directives, writing directives is a large part of angular development.&lt;/li>
&lt;/ul>
&lt;h2 id="services">Services&lt;/h2>
&lt;p>Services let you define logic that can be shared between different components. You can inject services into controllers, directives and other components.&lt;/p>
&lt;p>Let's say that we want to monitor from the client how long it's taking to get to the server, by sending a request every second. If the round trip time gets too low, we want to show a warning. Now if we implemented this logic in a controller, it would be tied to some UI. But actually, the logic isn't associated with any UI at all - we want an isolated component that is responsible for getting this information, that can expose it to any other component on the client.&lt;/p>
&lt;p>Here's how such a service would look in an angular application. Note: jsfiddle takes about 10 seconds to handle the first ajax ping request.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/YZF4T/embedded/html,js,result" width="100%" height="300">&lt;/iframe>
&lt;p>Although the output is not very impressive, what's important to remember is that all of the state and logic relating to the ping mechanism can be kept with the service - and used from any component. Well designed services will greatly improve the structure of your code and its testability.&lt;/p>
&lt;h3 id="service-quick-tips">Service Quick Tips&lt;/h3>
&lt;ul>
&lt;li>Services are singletons.&lt;/li>
&lt;li>Services don't have to be classes as I've defined.&lt;/li>
&lt;li>Services shouldn't need to ever think about the DOM - if they do, you should probably be writing a directive.&lt;/li>
&lt;/ul>
&lt;h2 id="views--routes">Views &amp;amp; Routes&lt;/h2>
&lt;p>AngularJS has a routing mechanism that allows you to create deep linking in your site. You can configure the $routeProvider service to specify what urls will go to which pages. Here's a brief example:&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/sQZ6J/embedded/html,js,result" width="100%" height="300">&lt;/iframe>
&lt;p>Typically the views are not defined as script elements in the main page, I'm just doing it like this to get past the fact that jsfiddle only has one HTML page. Every time the user clicks on a url, angular checks to see if it can match it in the route provider. If it can, it creates the appropriate view and a new instance of the controller. If it can't, it uses the &amp;lsquo;otherwise&amp;rsquo; route.&lt;/p>
&lt;p>Let's take a look at the route provider in a bit more detail:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// Configure the route provider.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">config&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$routeProvider&lt;/span>) {
&lt;span style="color:#a6e22e">$routeProvider&lt;/span>.
&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">template&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;lt;h2&amp;gt;Home&amp;lt;/h2&amp;gt;&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;HomeController&amp;#39;&lt;/span>
}).
&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/contact&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">template&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;lt;h2&amp;gt;Contact&amp;lt;/h2&amp;gt;&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ContactController&amp;#39;&lt;/span>
}).
&lt;span style="color:#a6e22e">otherwise&lt;/span>({
&lt;span style="color:#a6e22e">redirectTo&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>You'll typically not use &amp;lsquo;template&amp;rsquo; but &amp;lsquo;templateUrl&amp;rsquo; instead. &amp;lsquo;templateUrl&amp;rsquo; lets you specify an HTML file for your template. Routes can be more complicated - they can contain parameters which are accessible from the controller. This means your routes could include entity ids and other data, and the controller can load the data it needs to based on the route. This makes handling deep linking a bit more straightforward.&lt;/p>
&lt;h3 id="view-and-route-quick-tips">View and Route Quick Tips&lt;/h3>
&lt;p>The routing capabilities of angular are powerful - you can build complex routes with many parameters.
You can get data about the current route with the $route service.&lt;/p>
&lt;h2 id="thats-it">That's It&lt;/h2>
&lt;p>For now. We've seen the essential components of angular apps - much more in one go would be overload. Next we'll be taking a look at the structure of an angular app. We'll be seeing more of all these components in the articles to come.&lt;/p></description><category>CodeProject</category></item><item><title>Practical AngularJS</title><link>https://dwmkerr.com/practical-angularjs/</link><pubDate>Wed, 07 May 2014 14:48:54 +0000</pubDate><guid>https://dwmkerr.com/practical-angularjs/</guid><description>&lt;p>This series focuses on building applications with AngularJS. It assumes no prior knowledge.&lt;/p>
&lt;p>&lt;a href="https://dwmkerr.com/practical-angularjs-part1">Part 1 – Introducing AngularJS&lt;/a>&lt;/p>
&lt;p>What is AngularJS? What’s it for and when should we use it? We look into the basics of AngularJS – controllers, models and scopes, as well as how to use common directives like ng-model and ng-repeat. We see how client side logic is improved with AngularJS and how we can handle unit testing.&lt;/p>
&lt;p>&lt;a href="https://dwmkerr.com/practical-angularjs-part2">Part 2 – Components of an AngularJS Application&lt;/a>&lt;/p>
&lt;p>We take a look into what is in the AngularJS developers toolkit- filters, controllers, services, directives and routing.&lt;/p>
&lt;h4 id="useful-links">Useful Links&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://dwmkerr.com/pratical-angularjs-cheatsheet">Cheat Sheet&lt;/a> – Useful tips for angular&lt;/li>
&lt;li>&lt;a href="https://angularjs.org/">AngularJS&lt;/a> – The AngularJS Home Page&lt;/li>
&lt;li>&lt;a href="http://jasmine.github.io/">Jasmine&lt;/a> – The Jasmine Home Page&lt;/li>
&lt;/ul>
&lt;h4 id="community">Community&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://twitter.com/dwmkerr">@dwmkerr&lt;/a> – This is me!&lt;/li>
&lt;li>&lt;a href="https://twitter.com/angularjs">@angularjs&lt;/a> – Official AngularJS Twitter&lt;/li>
&lt;li>&lt;a href="https://twitter.com/search?q=%23angularjs&amp;amp;src=typd">#angularjs&lt;/a> – Hashtag for all things Angular&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>AngularJS Promises - The Definitive Guide</title><link>https://dwmkerr.com/promises-in-angularjs-the-definitive-guide/</link><pubDate>Wed, 07 May 2014 12:06:55 +0000</pubDate><guid>https://dwmkerr.com/promises-in-angularjs-the-definitive-guide/</guid><description>&lt;p>Promises are a core feature of AngularJS - whether you understand them or not, if you use AngularJS you've almost certainly been using them for a while.&lt;/p>
&lt;p>In this post I'm going to explain what promises are, how they work, where they're used and finally how to use them effectively.&lt;/p>
&lt;p>Once we've got the core understanding of promises, we'll look at some more advanced functionality - chaining and resolving promises when routing.&lt;/p>
&lt;h4 id="contents">Contents&lt;/h4>
&lt;ol>
&lt;li>&lt;a href="#whatarepromises">What are Promises?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#howdopromiseswork">How do Promises Work?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#arealworldexample">A Real World Example&lt;/a>&lt;/li>
&lt;li>&lt;a href="#promisessuccesserrorthen">Promises - Success, Error, Then&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromiseschaining">Advanced Promises - Chaining&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromisesrouting">Advanced Promises - Routing&lt;/a>&lt;/li>
&lt;li>&lt;a href="#advancedpromisestipstricks">Advanced Promises - Tips &amp;amp; Tricks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#thefutureofpromises">The Future of Promises&lt;/a>&lt;/li>
&lt;li>&lt;a href="#wrappingup">Wrapping Up&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="what-are-promises">What are Promises?&lt;/h2>
&lt;p>I'm going to try and be as succinct as possible - if anyone has a shorter, clearer description, let me know!&lt;/p>
&lt;blockquote>
&lt;p>A promise represents the eventual result of an operation. You can use a promise to specify what to do when an operation eventually succeeds or fails.&lt;/p>
&lt;/blockquote>
&lt;p>So let's see this in action. Look at the code below:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This code uses the &lt;code>$http&lt;/code> service to perform an HTTP GET on the url &amp;lsquo;/api/my/name&amp;rsquo;. Let's say that this is an api we've implemented on our server that returns the name of the logged in user.&lt;/p>
&lt;p>Now a common mistake for JavaScript newcomers might be to assume that the function returns the name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// The WRONG way!
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>It doesn't - and in fact it can't. An HTTP request has to be executed, it'll take a while before it returns - it might not return at all if there are errors. Remember, when we make requests in JavaScript we're using &lt;strong>ajax&lt;/strong> which is &lt;em>&lt;strong>asynchronous&lt;/strong> javascript and xml&lt;/em>. The key word here is asynchronous - we return control to the browser, let it make a request and give it a function to call when the request completes.&lt;/p>
&lt;p>So let's see how you actually make the request.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>);
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
});
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we use the promise object to specify what to do when the request succeeds, or when it fails. Remember, the functions we pass to &lt;code>success&lt;/code> or &lt;code>error&lt;/code> will be called later - when this block is finished executing we don't have the name, we've just specified what to do when we &lt;em>do&lt;/em> eventually get it - or what to do if we fail to get it.&lt;/p>
&lt;p>As a convenience, the &lt;code>success&lt;/code> and &lt;code>error&lt;/code> functions actually just return the promise, so we can simplify the code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>In fact, &lt;code>success&lt;/code> and &lt;code>error&lt;/code> are special functions added to a promise by &lt;code>$http&lt;/code> - normally with promises we just use &lt;code>then&lt;/code>, which takes the success function as the first parameter and the error function as the second:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(
&lt;span style="color:#75715e">/* success */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
},
&lt;span style="color:#75715e">/* failure */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We'll see more about the difference between &lt;code>success&lt;/code>, &lt;code>error&lt;/code> and &lt;code>then&lt;/code> later.&lt;/p>
&lt;p>That's all there is to it - a promise lets us specify what to do as the result of an operation.&lt;/p>
&lt;h2 id="how-do-promises-work">How do Promises Work?&lt;/h2>
&lt;p>Promises are not actually complicated, they're objects that contain a reference to functions to call when something fails or succeeds.&lt;/p>
&lt;p>Under the hood, AngularJS actually wires up a promise for an HTTP request in a way a bit like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">request&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">XMLHttpRequest&lt;/span>();
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">addEventListener&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;load&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// complete the promise
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}, &lt;span style="color:#66d9ef">false&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">addEventListener&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;error&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// fail the promise
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}, &lt;span style="color:#66d9ef">false&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">open&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;GET&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>, &lt;span style="color:#66d9ef">true&lt;/span>);
&lt;span style="color:#a6e22e">request&lt;/span>.&lt;span style="color:#a6e22e">send&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>this is pseudo-code, but the idea is that its the browser that calls us back, via the event listeners, then AngularJS can just call the appropriate method on the promise.&lt;/p>
&lt;p>Now in AngularJS, the promises are created with the &lt;code>$q&lt;/code> service (we'll see exactly how to do this shortly), but why &lt;code>$q&lt;/code>?&lt;/p>
&lt;p>The reason the service is named &lt;code>$q&lt;/code> is that AngularJS&amp;rsquo; promise implementation is based on Kris Kowal's promise mechanism, which is called &amp;lsquo;Q&amp;rsquo;. You can see the library at &lt;a href="https://github.com/kriskowal/q">github.com/kristkowal/q&lt;/a>.&lt;/p>
&lt;p>This was a deliberate decision, as the Q library is widely used and well understood by the community. We're going to see a little bit later what the future of promises is in AngularJS and actually in ECMAScript 6.&lt;/p>
&lt;h3 id="a-real-world-example">A Real World Example&lt;/h3>
&lt;p>In this example we'll create a service that gets the user's name, just like in our examples. However, to make it interesting, we'll set our service up so that the first time we get the name from the server, and then afterwards we'll return a cached copy.&lt;/p>
&lt;p>This means we'll have to build our code to deal with the asynchronous case (the first one) and the more trivial synchronous case (getting the name from the cache).&lt;/p>
&lt;p>Let's look at a pure asynchronous implementation.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NameService&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>) {
&lt;span style="color:#75715e">// Create a class that represents our name service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;span style="color:#75715e">// getName returns a promise which when
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// fulfilled returns the name.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/my/name&amp;#39;&lt;/span>);
};
}
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>();
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here's how it looks in a fiddle - just click &amp;lsquo;Result&amp;rsquo; to see it working. You can click on &amp;lsquo;Update&amp;rsquo; name to get the name, but each time it sends a request. This is what we'll change next.&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/4GjtR/embedded/js,html,result" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>Now let's update our service so that we hit the server only if we haven't already cached the name. I'll build the service blow by blow, then we can see a fiddle of it working.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">factory&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;NameService&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$http&lt;/span>, &lt;span style="color:#a6e22e">$q&lt;/span>) {
&lt;span style="color:#75715e">// Create a class that represents our name service.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>() {
&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">this&lt;/span>;
&lt;span style="color:#75715e">// Initially the name is unknown....
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>so first we create a service which is in the form of a class. It has a name field which is initially null.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#75715e">// Create a deferred operation.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">$q&lt;/span>.&lt;span style="color:#a6e22e">defer&lt;/span>();
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now in the &lt;code>getName&lt;/code> function we start by creating a &lt;code>deferred&lt;/code> object, using the &lt;code>$q&lt;/code> service. This object contains the promise we'll return, and has some helper functions to let us build the promise.&lt;/p>
&lt;p>We create a deferred object because whether we use ajax or not, we want the consumer to use the promise - even if we &lt;em>can&lt;/em> return straightaway in some circumstances (when we have the name) we can't in all - so the caller must always expect a promise.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">if&lt;/span>(&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">!==&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; (from Cache!)&amp;#34;&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If we already have the name, we can just &lt;code>resolve&lt;/code> the deferred object immediately - this is the easy case. I've added &amp;lsquo;from cache&amp;rsquo; to the name so we can see when it comes from the cache compared to the server.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Tip:&lt;/strong> You can resolve a promise even before you return it. It still works fine for the consumer.&lt;/p>
&lt;/blockquote>
&lt;p>Finally, we can handle the case if we don't already have the name:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">else&lt;/span> {
&lt;span style="color:#75715e">// Get the name from the server.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/my/name/&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">self&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">resolve&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; (from Server!)&amp;#34;&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">reject&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>);
});
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>So if we get success from the server, we can &lt;code>resolve&lt;/code> the promise. Otherwise, we &lt;code>reject&lt;/code> it, which means failure.&lt;/p>
&lt;blockquote>
&lt;p>Call &lt;code>resolve&lt;/code> on a deferred object to complete it successfully, call &lt;code>reject&lt;/code> to fail it with an error.&lt;/p>
&lt;/blockquote>
&lt;p>Finally, we just return the promise we've built with &lt;code>deferred&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js"> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">deferred&lt;/span>.&lt;span style="color:#a6e22e">promise&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>And that's it! You can see it in action below, press &amp;lsquo;Update Name&amp;rsquo; a few times and you'll see it uses the cache.&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/LeZU4/embedded/result,html,js" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>How do we use this? We'll it's simple, here's a controller that uses the service we've built:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span> (&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#75715e">// We have a name on the code, but it&amp;#39;s initially empty...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>;
&lt;span style="color:#75715e">// We have a function on the scope that can update the name.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">updateName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>()
.&lt;span style="color:#a6e22e">then&lt;/span>(
&lt;span style="color:#75715e">/* success function */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
},
&lt;span style="color:#75715e">/* error function */&lt;/span>
&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Failed to get the name, result is &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">result&lt;/span>);
});
};
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now there's something different here. Before, we might have used the &lt;code>error&lt;/code> or &lt;code>success&lt;/code> function of the promise. But here we use &lt;code>then&lt;/code>. Why is that?&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>success&lt;/code> and &lt;code>error&lt;/code> are functions on a promise that AngularJS adds for us when using &lt;code>$http&lt;/code> or &lt;code>$resource&lt;/code>. They're not standard, you won't find them on other promises.&lt;/p>
&lt;/blockquote>
&lt;p>So we've seen how promises work, what they are and so on, now we'll look into this success/error/then stuff.&lt;/p>
&lt;h2 id="promises---success-error-then">Promises - Success, Error, Then&lt;/h2>
&lt;p>Now we know that &lt;code>$http&lt;/code> returns a promise, and we know that we can call &lt;code>success&lt;/code> or &lt;code>error&lt;/code> on that promise. It would be sensible to think that these functions are a standard part of promise - but they're not!&lt;/p>
&lt;p>When you are using a promise, the function you should call is &lt;code>then&lt;/code>. &lt;code>then&lt;/code> takes two parameters - a callback function for success and a callback function for failure. Taking a look at our original &lt;code>$http&lt;/code> example, we can rewrite it to use this function.
So this code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">success&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>);
})
.&lt;span style="color:#a6e22e">error&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>, &lt;span style="color:#a6e22e">status&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed with response &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#e6db74">&amp;#34; and status code &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">status&lt;/span>);
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>becomes:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;/api/my/name&amp;#34;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;Your name is: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>);
}, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">result&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The request failed: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">result&lt;/span>);
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We &lt;strong>can&lt;/strong> use &lt;code>success&lt;/code> or &lt;code>error&lt;/code> when using &lt;code>$http&lt;/code> - it's convenient. For one thing, the &lt;code>error&lt;/code> function gives us a response and status (and more) and the &lt;code>success&lt;/code> function gives us the response data (rather than the full response object).&lt;/p>
&lt;p>But remember that it's not a standard part of a promise. You can can add your own versions of these functions to promises you build yourself if you want:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">success&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">fn&lt;/span>) {
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">fn&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">headers&lt;/span>, &lt;span style="color:#a6e22e">config&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">error&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">fn&lt;/span>) {
&lt;span style="color:#a6e22e">promise&lt;/span>.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">null&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#a6e22e">fn&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">status&lt;/span>, &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">headers&lt;/span>, &lt;span style="color:#a6e22e">config&lt;/span>);
});
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">promise&lt;/span>;
};
&lt;/code>&lt;/pre>&lt;/div>&lt;p>this is exactly how angular does it.&lt;/p>
&lt;p>So what's the advice?&lt;/p>
&lt;blockquote>
&lt;p>Use &lt;code>success&lt;/code> or &lt;code>error&lt;/code> with &lt;code>$http&lt;/code> promises if you want to - just remember they're not standard, and the parameters are different to those for &lt;code>that&lt;/code> callbacks.&lt;/p>
&lt;/blockquote>
&lt;p>So if you change your code so that your promise is not returned from &lt;code>$http&lt;/code>, as we did in the earlier example when we load data from a cache, your code will break if you expect &lt;code>success&lt;/code> or &lt;code>error&lt;/code> to be there.&lt;/p>
&lt;p>A safe approach is to use &lt;code>then&lt;/code> wherever possible.&lt;/p>
&lt;h2 id="advanced-promises---chaining">Advanced Promises - Chaining&lt;/h2>
&lt;p>If you've had your fill of promises for now, you can skip to &lt;a href="#thefutureofpromises">The Future of Promises&lt;/a> or &lt;a href="#wrappingup">Wrapping Up&lt;/a>.&lt;/p>
&lt;p>One useful aspect of promises is that the &lt;code>then&lt;/code> function returns the promise itself. This means that you can actually &lt;em>chain&lt;/em> promises, to create conscise blocks of logic that are executed at the appropriate times, without lots of nesting.&lt;/p>
&lt;p>Let's consider an example where we need to fetch the user's name from the backend, but we have to use separate requests to get their profile information and then their application permissions.&lt;/p>
&lt;p>Here's an example:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span> {
&lt;span style="color:#a6e22e">username&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>,
&lt;span style="color:#a6e22e">profile&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>,
&lt;span style="color:#a6e22e">permissions&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>
};
&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/user/name&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the username, get the profile.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/profile/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the profile, now get the permissions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">profile&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/security/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the permissions
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">permissions&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The full user details are: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">details&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now we have a series of asynchronous calls that we can coordinate without having lots of nested callbacks.&lt;/p>
&lt;p>We can also greatly simplify error handling - let's see the example again, with an exception thrown in:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/user/name&amp;#39;&lt;/span>)
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the username, get the profile.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">$http&lt;/span>.&lt;span style="color:#a6e22e">get&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/api/profile/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">username&lt;/span>);
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the profile, now get the permissions.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">profile&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#66d9ef">throw&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Oh no! Something failed!&amp;#34;&lt;/span>;
})
.&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">response&lt;/span>) {
&lt;span style="color:#75715e">// Store the permissions
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">details&lt;/span>.&lt;span style="color:#a6e22e">permissions&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">response&lt;/span>.&lt;span style="color:#a6e22e">data&lt;/span>;
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;The full user details are: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">JSON&lt;/span>.&lt;span style="color:#a6e22e">stringify&lt;/span>(&lt;span style="color:#a6e22e">details&lt;/span>);
})
.&lt;span style="color:#66d9ef">catch&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">error&lt;/span>) {
&lt;span style="color:#a6e22e">console&lt;/span>.&lt;span style="color:#a6e22e">log&lt;/span>(&lt;span style="color:#e6db74">&amp;#34;An error occured: &amp;#34;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#a6e22e">error&lt;/span>);
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We can use &lt;code>catch(callback)&lt;/code> - which is actually just shorthand for &lt;code>then(null, callback)&lt;/code>. There's even a &lt;code>finally&lt;/code> - which is executed whether or not the operations fail or succeed.&lt;/p>
&lt;blockquote>
&lt;p>Use &lt;code>catch&lt;/code> and for error handling with promises - and use &lt;code>finally&lt;/code> for logic that's executed after success OR failure.&lt;/p>
&lt;/blockquote>
&lt;p>The composition of promises can simplify complicated code - particularly when you add in error handling!&lt;/p>
&lt;p>One final point to make which is not quite related to chaining but does relate to multiple promises is &lt;code>$q.all&lt;/code>. &lt;code>all&lt;/code> can be used to build a single promise from a set of promises.&lt;/p>
&lt;p>You can pass an array of promises to &lt;code>all&lt;/code> and you get back a single promise - which is resolved when all of the promises it contains resolve. This can be useful if you are building complex methods that may have to perform multiple asynchronous tasks - such as multiple ajax calls.&lt;/p>
&lt;h2 id="advanced-promises---routing">Advanced Promises - Routing&lt;/h2>
&lt;p>There's a particular area of AngularJS that uses promises to great effect, and that's the router.&lt;/p>
&lt;p>Let's imagine we have a router like the following:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;home.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>
})
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we have two routes. The home route takes us to the home page, with the &lt;code>MainController&lt;/code>, and the profile route takes us to the user's profile page.&lt;/p>
&lt;p>Our ProfileController uses our funky name service:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>().&lt;span style="color:#a6e22e">then&lt;/span>(&lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
});
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The problem is, &lt;strong>until the name service gets the name from the backend, the name is null&lt;/strong>. This means if our view binds to the name, it'll flicker - first it's empty then its set.&lt;/p>
&lt;p>What we'd like to do is actully say to the router - &amp;ldquo;I'm going to go to this view, but only when you can tell me my name&amp;rdquo;.&lt;/p>
&lt;p>We can do this with the &lt;em>resolves&lt;/em> in the router, here's how it works:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#75715e">// Create a function that uses the NameService
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// to return the getName promise.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">NameService&lt;/span>) {
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#a6e22e">NameService&lt;/span>.&lt;span style="color:#a6e22e">getName&lt;/span>();
};
&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/home&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/home.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;MainController&amp;#39;&lt;/span>
})
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>,
&lt;span style="color:#75715e">/* only navigate when we&amp;#39;ve resolved these promises */&lt;/span>
&lt;span style="color:#a6e22e">resolve&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">name&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span>
}
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>so now we have a &lt;em>resolve&lt;/em> on the route - when we go to the profile page the router will wait until the promise returned by &lt;code>getName&lt;/code> resolves, then it will pass the result into the controller, as the parameter called &lt;code>name&lt;/code>. Now our controller looks like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">app&lt;/span>.&lt;span style="color:#a6e22e">controller&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>, &lt;span style="color:#66d9ef">function&lt;/span>(&lt;span style="color:#a6e22e">$scope&lt;/span>, &lt;span style="color:#a6e22e">name&lt;/span>) {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">name&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">name&lt;/span>;
});
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Much better! And also &lt;strong>much&lt;/strong> more testable.&lt;/p>
&lt;p>One thing you may wonder - why do I use &lt;code>getName&lt;/code> as the resolve function instead of just using &lt;code>NameService.getName&lt;/code> directly?&lt;/p>
&lt;p>That's because the route is set up in a &lt;code>config&lt;/code> function - and that function cannot have services injected. However, a resolve function &lt;strong>can&lt;/strong>, so we just use a function and let AngularJS inject the &lt;code>NameService&lt;/code> for us.&lt;/p>
&lt;p>Now for an important statement:&lt;/p>
&lt;blockquote>
&lt;p>If the first thing your controller does is fetch data from the server, it's probably wrong.&lt;/p>
&lt;/blockquote>
&lt;p>Why? Because if your controller needs data, inject it - let the router ensure the data is ready. Then you don't have controllers in an invalid state as they're loading - and your controllers become easier to test.&lt;/p>
&lt;p>Be aware of &lt;code>resolve&lt;/code> for routes - it's a great way to handle loading of required data, authentication and other things that you might be putting into the wrong place.&lt;/p>
&lt;p>You can see the example above in action here:&lt;/p>
&lt;iframe width="100%" height="300" src="http://jsfiddle.net/dwmkerr/m29pe/embedded/result,js,html" allowfullscreen="allowfullscreen" frameborder="0">&lt;/iframe>
&lt;p>What's cool is we can also see our caching logic by going to and from the Home and Profile pages. The promises are keeping our code clean and testable.&lt;/p>
&lt;p>As a final note on promises when routing, you can specify multiple resolves if you need to:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$routeProvider&lt;/span>
.&lt;span style="color:#a6e22e">when&lt;/span>(&lt;span style="color:#e6db74">&amp;#39;/profile&amp;#39;&lt;/span>, {
&lt;span style="color:#a6e22e">templateUrl&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;/profile.html&amp;#39;&lt;/span>,
&lt;span style="color:#a6e22e">controller&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;ProfileController&amp;#39;&lt;/span>,
&lt;span style="color:#75715e">/* only navigate when we&amp;#39;ve resolved these promises */&lt;/span>
&lt;span style="color:#a6e22e">resolve&lt;/span>&lt;span style="color:#f92672">:&lt;/span> {
&lt;span style="color:#a6e22e">name&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getName&lt;/span>,
&lt;span style="color:#a6e22e">profile&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getProfile&lt;/span>,
&lt;span style="color:#a6e22e">anythingElse&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">getAnythingElse&lt;/span>
}
})
&lt;/code>&lt;/pre>&lt;/div>&lt;p>in this case each resolve is injected into the controller.&lt;/p>
&lt;h2 id="advanced-promises---tips--tricks">Advanced Promises - Tips &amp;amp; Tricks&lt;/h2>
&lt;p>This section just contains some tips and tricks you might find useful when working with promises.&lt;/p>
&lt;ol>
&lt;li>Promises in directives are not resolved automatically since AngularJS 1.2. Previously, if you passed a promise to a directive with an &amp;lsquo;=&amp;rsquo; binding, AngularJS would resolve the promise for you, this is no longer the case.&lt;/li>
&lt;/ol>
&lt;h2 id="the-future-of-promises">The Future of Promises&lt;/h2>
&lt;p>So promises are a core part of AngularJS and to use the framework effectively, you must understand how to use them and how they work. But what is the future of promises?&lt;/p>
&lt;p>It's almost certain that promises are going to become a &lt;strong>native&lt;/strong> feature of JavaScript, they are part of the proposed ECMAScript 6 specification.&lt;/p>
&lt;p>The functionality of the &lt;code>q&lt;/code> library and AngularJS&amp;rsquo; implementation of promises are very similar indeed to the proposed specification, but be aware that when promises become standard, AngularJS is most likely to adapt their own promises to work like native promises.&lt;/p>
&lt;p>You can read more at &lt;a href="http://www.html5rocks.com/en/tutorials/es6/promises/">html5rocks.com/en/tutorials/es6/promises/&lt;/a>.&lt;/p>
&lt;p>Just be aware that you'll see promises more and more, in other frameworks and in vanilla JavaScript.&lt;/p>
&lt;h2 id="wrapping-up">Wrapping Up&lt;/h2>
&lt;p>I hope this post has been useful to understanding promises. Any feedback is always good, so let me know if anything is unclear or could be improved. To finish this article, here are some useful links:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>The Q library&lt;/strong> &lt;a href="https://github.com/kriskowal/q">github.com/kriskowal/q&lt;/a>&lt;/li>
&lt;li>&lt;strong>The AngularJS &lt;code>$q&lt;/code> Service&lt;/strong> &lt;a href="https://docs.angularjs.org/api/ng/service/$q">docs.angularjs.org/api/ng/service/$q&lt;/a>&lt;/li>
&lt;li>&lt;strong>Promises in ECMAScript 6&lt;/strong> &lt;a href="http://www.html5rocks.com/en/tutorials/es6/promises/">html5rocks.com/en/tutorials/es6/promises/&lt;/a>&lt;/li>
&lt;li>&lt;strong>XmlHttpRequest, which we used in an example&lt;/strong> &lt;a href="https://developer.mozilla.org/en/docs/Web/API/XMLHttpRequest">developer.mozilla.org/en/docs/Web/API/XMLHttpRequest&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>And also some interesting discussions:&lt;/p>
&lt;p>&lt;a href="http://spion.github.io/posts/why-i-am-switching-to-promises.html">Why I am switching to promises&lt;/a> - Written by Gorgi Kosev, great article describing why a switch from callbacks to promises can be a very good thing in NodeJS applications.&lt;/p>
&lt;p>&lt;a href="http://blog.ometer.com/2011/07/24/callbacks-synchronous-and-asynchronous/">Callbacks, sychronous and asynchronous&lt;/a> - From Havoc, this post contains many useful points for API writers who are using callbacks or promises. One key takeaway is to &lt;strong>never&lt;/strong> do what a sample in this article does which is resolve a promise either synchronously or asynchronously, as it leads to code which can be difficult to reason about. I'll be mentioning this more in a later update which will explain the problem and solution.&lt;/p>
&lt;p>&lt;a href="http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony">Designing for Asynchrony&lt;/a> - Written by Isaac Z. Schlueter, this post is another great one for API designers that takes a look into asynchrony.&lt;/p></description><category>CodeProject</category></item><item><title>Better Specifications</title><link>https://dwmkerr.com/better-specifications/</link><pubDate>Mon, 05 May 2014 14:58:43 +0000</pubDate><guid>https://dwmkerr.com/better-specifications/</guid><description>&lt;p>Specifications are absolutely key to the success of a project.&lt;/p>
&lt;p>Unless you have a good definition of what your project is &lt;em>supposed to be&lt;/em>, there's no way you can deliver it. A specification is the contract between you and the client, the basis for technical designs, quality assurance test plans, operational readiness, and much more.&lt;/p>
&lt;p>I'm not going to talk about how different teams do specs, what works and what doesn't work. I'm going to make the statement that &lt;strong>the better that specifications are handled, understood and controlled, the better for everyone&lt;/strong> - Project Managers, developers, testers, operational teams and customers.&lt;/p>
&lt;p>If there's anyone who's on the fence about whether specifications are important or not, &lt;a href="http://www.joelonsoftware.com/articles/fog0000000036.html">Joel Spolsky's series on Painless Specifications&lt;/a> is a must read, he makes the point exceedingly well and I'd definitely recommend reading the articles.&lt;/p>
&lt;p>I'm going to describe an approach to functional specifications that I think has a lot going for it. To developers it should look very familiar and (hopefully) appealing. To non-developers, the approach may not be so familiar, but the potential benefits should speak for themselves.&lt;/p>
&lt;h3 id="specs-right-now">Specs Right Now&lt;/h3>
&lt;p>OK - the introductions have been made. So how do we represent specs at the moment? Here are some common ways.&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Text files&lt;/strong>. Specs are text? Well, sometimes. They might also be images, sometimes diagrams help too. But text can work.&lt;/li>
&lt;li>&lt;strong>Word documents&lt;/strong>. A little like the above, but with the facility to use tables and images and so on.&lt;/li>
&lt;li>&lt;strong>Web Pages&lt;/strong>. Perhaps more common nowadays, specs can be written on online systems like Sharepoint (just documents really, but with better multi-user support), Google Docs or Bug Tracking/Wiki type systems.&lt;/li>
&lt;li>&lt;strong>BDD Tools&lt;/strong>. Whether using tools or not, BDD specs are files that state functionality in a more strongly defined format.&lt;/li>
&lt;li>&lt;strong>Tests&lt;/strong>. Kind of similar to the above - depending on what you're writing or the tech expertise of team members, some teams opt for the bulk of their specs in the form of tests.&lt;/li>
&lt;/ol>
&lt;p>All of these systems have pros and cons. Some have many more cons, and some balance out better on different types of projects.&lt;/p>
&lt;h2 id="a-better-way">A Better Way&lt;/h2>
&lt;p>So here's a suggestion of a better way.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Specs are markdown files in a repository. That's it.&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;p>Now I'm going to show you why this is a good idea.&lt;/p>
&lt;h3 id="specs-are-text-ish">Specs are text. Ish.&lt;/h3>
&lt;p>Pure plain text is a bit hard for specs - it can be helpful to have bullet points, headings and so on. But word processing tools are not always the best answer - you're tied to a specific tool, and unless you're working with people who all know how styles, track changes or the specifics of the tool work, you can spend more time messing around with formatting than you'd like.&lt;/p>
&lt;p>Try comparing and rationalising two versions of a complex document that have gone out of sync, it's a nightmare.&lt;/p>
&lt;p>Here's a snippet of a markdown spec:&lt;/p>
&lt;pre>&lt;code>Overview
--------
This spec is for the login screen of the application. The overall design of
the screen is in the file 'mockup.png'.
The Controls
------------
* The 'username' box accepts alphanumeric characters.
* The limit of the 'username' box is 120 characters.
* The tooltip for the username box is 'Enter Username'.
* The password box accepts any characters and is limited to 120 characters.
* The tooltip for the password box is 'Enter password'.
&lt;/code>&lt;/pre>&lt;p>It's readable in it's raw form. This is how it looks on GitHub:&lt;/p>
&lt;p>&lt;img src="images/LoginScreenSpec.png" alt="Login Screen Spec">&lt;/p>
&lt;p>See the real thing at &lt;a href="https://github.com/dwmkerr/better-specs/blob/master/login/login.md">github.com/dwmkerr/better-specs/blob/master/login/login.md&lt;/a>.&lt;/p>
&lt;p>(These specs are just made up ones for this article).&lt;/p>
&lt;p>The formatting is readable even in plain text mode, but many modern day tools understand how to show markdown in a slightly nicer way (I'm writing this post in markdown - &lt;a href="https://ghost.org/">Ghost&lt;/a> uses markdown for blog posts). You can print it and understand it, email it to recipients in plain text mode, and importantly there's no fiddling with formatting.&lt;/p>
&lt;p>If you haven't used markdown before, give it a try on &lt;a href="https://stackedit.io/">StackEdit&lt;/a>, it's an online markdown editor - you can have a play with it.&lt;/p>
&lt;h3 id="specs-are-version-controlled">Specs are Version Controlled&lt;/h3>
&lt;p>Specs need to be version controlled. You need to be able to see a history of a spec, who changed it, when they changed it and what the change was.&lt;/p>
&lt;p>Even more useful - you should be able to diff specs - what changed between two versions? This is hard to do with programs like word, with version control systems like git, it's a piece of cake. Take a look:&lt;/p>
&lt;p>&lt;img src="images/LoginScreenDiff.png" alt="">&lt;/p>
&lt;p>We can see easily who changed this spec and when, we can compare revisions.&lt;/p>
&lt;p>This not just a powerful feature - it's a required one. Developers and testers can see what has been added, removed or modified. So can project managers.&lt;/p>
&lt;p>This is a diff that developers will understand - the red and green make it clear for non-devs too. Modern systems like GitHub can take it further:&lt;/p>
&lt;p>&lt;img src="images/LoginNiceDiff.png" alt="">&lt;/p>
&lt;p>Pretty clear what's going on.&lt;/p>
&lt;h3 id="pull-requests">Pull Requests&lt;/h3>
&lt;p>Let's take the version control aspect further. A spec should have one owner, one person who can press the button and say &amp;lsquo;yes, this is in&amp;rsquo;. There needs to be one owner, because a change to a spec is like a change to a contract - it could represent hours of developer time, cost increases, release date issues and more. There's impact, there are consequences.&lt;/p>
&lt;p>So using services like GitHub or Bitbucket can help here. Anyone can make changes to a spec, but a single approver has to review those changes and decide whether to bring them in.&lt;/p>
&lt;p>&lt;img src="images/LockoutLogic.png" alt="">&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/better-specs/pull/1/files?short_path=d645d03#diff-d645d03c7459b43c1e030eeb13d1245b">See this pull request on GitHub&lt;/a>&lt;/p>
&lt;p>Pull requests support comments, discussions, diffs and all sorts of useful things. No one can get something into the spec until the approver has OK'd it.&lt;/p>
&lt;p>It also gives the approver a single point where they can action the changes, perhaps raising a task for a developer to work on the changes.&lt;/p>
&lt;p>That pull request can also be &lt;em>linked to&lt;/em> later - in the bug tracking or feature management system, an issue to implement the changes in the pull request can be made - and the implementer always has a link to the &lt;em>exact&lt;/em> change.&lt;/p>
&lt;blockquote>
&lt;p>Don't put the change to a spec in a work item. A work item &lt;em>refers&lt;/em> to a change in the spec.&lt;/p>
&lt;/blockquote>
&lt;p>This is very useful. In the pull request shown (which you can &lt;a href="https://github.com/dwmkerr/better-specs/pull/1/files?short_path=d645d03#diff-d645d03c7459b43c1e030eeb13d1245b">see here&lt;/a>) has one innocuous extra line (which we see in green) stating that the user is locked out after three failed password attempts. This isn't in the spec, not until we accept the pull request. And in this case instead we can comment to the person who raised it:&lt;/p>
&lt;p>&lt;img src="images/LoginPullReqComments.png" alt="">&lt;/p>
&lt;p>I had to make a contrived example and fake a discussion between myself and myself, but I think seeing how this looks helps make the point.&lt;/p>
&lt;h3 id="branches">Branches&lt;/h3>
&lt;p>Another great thing about keeping specs as plain text and using a version control system is that you can take advantage of branching. This means that different people can be working on proposed changes to specs or new features in their own isolated branches - the work they're doing won't be interfered with by others.&lt;/p>
&lt;p>When the time comes to bring the proposal into the spec, again a pull request can be made and the coordinator can deal with any conflicts that may have arisen since the branch was made.&lt;/p>
&lt;p>At the time the BA or whoever it might be is working on their specs, they still have full version control, a history and so on, but are not interfering with the &amp;lsquo;master&amp;rsquo; version of the specs that others in the project see.&lt;/p>
&lt;h3 id="what-about-rich-media">What About Rich Media?&lt;/h3>
&lt;p>Keep your rich media. Keep images, tables and diagrams - just check them in alongside the spec and link to them from the spec. You still get version control, pull requests and a history. Depending on the media you might even get a nice diff representation - check out this commit:&lt;/p>
&lt;p>&lt;img src="images/LoginImageDiff.png" alt="">&lt;/p>
&lt;p>&lt;a href="https://github.com/dwmkerr/better-specs/commit/8a1224812db2ae4909dfb5a30f8483b1ca96ed18?diff-0=0-100">See the actual commit here&lt;/a>&lt;/p>
&lt;p>You can see the image before, after or even use the slider to see what has changed. The rich media is &lt;em>supporting&lt;/em> media - it's still the spec that's boss.&lt;/p>
&lt;p>Don't throw away your powerpoint presentations, visio files or anything else, but make the spec king and these files support it. Got a big table of information? Do it in excel or google sheets, that's the right tool for the job - but version control it with the spec.&lt;/p>
&lt;h3 id="persuading-others">Persuading Others&lt;/h3>
&lt;p>The hard thing about this approach might be persuading those who are not used to it to use it.&lt;/p>
&lt;p>To developers, I imagine this approach has immediate appeal. We know that an email chain of timestamped word documents or powerpoint presentations is a nightmare to maintain as it evolves, and that versin control systems are critical to managing shared work.&lt;/p>
&lt;p>To business people who are not used to version control or markdown, it might seem like a nerdy, inefficient way of doing things. But the points above are quite compelling. If you have strong arguments for or against, comment and I'll update the article.&lt;/p>
&lt;h3 id="useful-resources">Useful Resources&lt;/h3>
&lt;p>It's worth pulling together some useful further reading.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://www.joelonsoftware.com/articles/fog0000000036.html">Joel Spolsky's series on Painless Specifications&lt;/a> - A well written series on why specs are so important.&lt;/li>
&lt;li>&lt;a href="http://daringfireball.net/projects/markdown/">Markdown&lt;/a> - The official homepage&lt;/li>
&lt;li>&lt;a href="https://stackedit.io/">StackEdit&lt;/a> - Have a play writing markdown and see it rendered.&lt;/li>
&lt;/ul>
&lt;h2 id="final-thoughts">Final Thoughts&lt;/h2>
&lt;p>I've never used this approach in a team - I am writing specs for a side project like this at the moment, but this is a one-man project (for now).&lt;/p>
&lt;p>Have you tried this approach? Any success stories or experiences of it failing? I'd love to know, so comment if you've got some experience on this one.&lt;/p>
&lt;p>P.S. - This page was written with markdown!&lt;/p></description><category>CodeProject</category></item><item><title>Blogging with Ghost</title><link>https://dwmkerr.com/blogging-with-ghost/</link><pubDate>Mon, 05 May 2014 04:35:09 +0000</pubDate><guid>https://dwmkerr.com/blogging-with-ghost/</guid><description>&lt;blockquote>
&lt;p>&lt;strong>tl;dr&lt;/strong> &lt;a href="https://ghost.org/">Ghost&lt;/a> is a blogging platform well worth considering if your blog is all about development.&lt;/p>
&lt;/blockquote>
&lt;p>I've been having some gripes with WordPress as a platform for blogging lately. For development focused blogs like this one, there are some things about it that make writing posts just a little bit clunky. For example:&lt;/p>
&lt;ol>
&lt;li>Syntax Higlightling is always going to use plugins with various shortcode formats. This works, but your raw blog text becomes quite specific to a certain implementation.&lt;/li>
&lt;li>It's kind of slow, unless you use a theme that's loading as much content as possible with Ajax.&lt;/li>
&lt;li>There aren't a great number of simple, content focused themes that appeal to dev type blogs.&lt;/li>
&lt;/ol>
&lt;p>The final point - I want to blog in &lt;a href="https://daringfireball.net/projects/markdown/">Markdown&lt;/a> its a simple syntax that doesn't require a fancy editor and I use it every day for work.&lt;/p>
&lt;h2 id="enter-ghost">Enter Ghost&lt;/h2>
&lt;p>A little bit of research led me to &lt;a href="https://ghost.org/">Ghost&lt;/a>. It's a fairly new, simple blogging platform with few features, but the features it has it does well. You write your posts in Markdown. If you need fancy syntax highlighting, you can have it, over and above that there's not much to it.&lt;/p>
&lt;p>Ghost runs on Node.js, so it's simple to install. The data is stored in SqlLite and the blog is ajaxy - without many full page loads.&lt;/p>
&lt;p>There are no comments, but you can easily integrate &lt;a href="http://disqus.com/">Disqus&lt;/a> into your blog if you feel you need them.&lt;/p>
&lt;p>I'm hosting my old WordPress blog at &lt;a href="http://oldblog.dwmkerr/com">oldblog.dwmkerr.com&lt;/a> and currently migrating things over.&lt;/p>
&lt;h2 id="installing-on-iis">Installing on IIS&lt;/h2>
&lt;p>This server is actually running IIS, unlike my droplets on Digital Ocean. If you're installing Ghost on IIS, I strongly recommend &lt;a href="http://www.saotn.org/how-to-set-up-nodejs-iisnode-module-ghost-on-windows-server-2012-iis-80/">How to set up Node.js, iisnode and Ghost on IIS&lt;/a> - it was this post that had the clearest and most up to date instructions.&lt;/p>
&lt;h2 id="final-thoughts">Final Thoughts&lt;/h2>
&lt;p>Before you consider the leap, be aware that Ghost is quite new - features are changing or being added, and if you need lots of complicated stuff you might not find it up to the job. However there's already an active community and it looks like its only getting better.&lt;/p>
&lt;p>If it's markdown you want - you &lt;em>can&lt;/em> use it in WordPress, just find the right plugin and you're done.&lt;/p></description><category>CodeProject</category></item><item><title>Practical AngularJS Part 1 – Introducing AngularJS</title><link>https://dwmkerr.com/practical-angularjs-part1/</link><pubDate>Sat, 03 May 2014 14:48:23 +0000</pubDate><guid>https://dwmkerr.com/practical-angularjs-part1/</guid><description>&lt;p>In this series of articles I'm going to be working with AngularJS, a fantastic framework from Google that helps you rapidly build web applications. We'll see how AngularJS can be used to speed up your development and help you write cleaner, more testable code.&lt;/p>
&lt;p>&lt;img src="images/AngularJSLargeLogo.png" alt="">&lt;/p>
&lt;h2 id="introducing-angularjs">Introducing AngularJS&lt;/h2>
&lt;p>First of all an introduction is in order.&lt;/p>
&lt;p>AngularJS is a lightweight JavaScript framework, primarily for building single page web applications. The idea behind applications like these is that rather than the &amp;lsquo;traditional&amp;rsquo; way of writing web applications which would involve using server side technologies to render the user interface and send it to the user, we handle all of the presentation logic on the client side.&lt;/p>
&lt;p>This means if we're showing a list of blog posts, we don't have the server render the posts as html and send them to the client, but instead send a simple page, very quickly, and then use JavaScript in the client to load the posts as JSON from the server, and add them to the page itself - presenting them in the way we choose.&lt;/p>
&lt;p>The server doesn't send back posts as html with formatting, it sends back posts as data (in the form of JSON) and the client code decides how to render them. Selecting a post wouldn't ask the server for a new page with the post contents to be rendered, just ask the server for the post data, and then render it itself.&lt;/p>
&lt;p>We don't strictly have to be a single page application entirely to get benefit from this, but we're looking to:&lt;/p>
&lt;p>Make our back end servers deal with data not html, so that they can be consumed from a variety of sources.
Keep HTML and DOM logic in the client.
Let the client talk to the server quickly and frequently to keep itself up to date.
Cut down on full round trips to reload entire pages.
Keep presentation logic in client side code, not server side code.
We'll see in this first article how AngularJS can help write applications like this.&lt;/p>
&lt;p>As we learn about AngularJS, key statements are marked like this:&lt;/p>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> All tips like this are in the Angular Cheat Sheet.&lt;/p>
&lt;/blockquote>
&lt;p>These statements are in the Angular Cheat Sheet. The cheat sheet is a quick guide that you can open or print as a fast reference for core info and terminology.&lt;/p>
&lt;h3 id="the-problem">The Problem&lt;/h3>
&lt;p>Before I start to advocate the use of a library or framework, I need to demonstrate a need for it. Unless we're just coding for fun or specifically to learn, the reason we choose to use a library or framework is that we have a problem, or problems to solve.&lt;/p>
&lt;p>So as a way of introducing angular, I'm going to start with a trivial task, see how it quickly gets harder, identify problems and demonstrate how angular is a good choice as something that can mitigate these problems.&lt;/p>
&lt;h3 id="our-task">Our Task&lt;/h3>
&lt;p>Here's our initially trivial task.&lt;/p>
&lt;p>We need to come up with a super-simple proof of concept page that allows a user to write a list of URLs, and have a system check how long it takes to fetch them. That's all. We'll call it Speedmonitor. Imagine that we've been told we're just a proof of concept phase, our graphic designers have some nice visuals and we don't need it to be fully functional, but we to be able to have a play with it. We don't need to have the request send, for the moment a faked time is fine.&lt;/p>
&lt;p>The first thing we do is understand the requirements. At this stage, a diagram on a piece of paper suffices. We can make a quick mock up.&lt;/p>
&lt;h3 id="speedmeter">Speedmeter&lt;/h3>
&lt;p>&lt;img src="images/Speedmeter.jpg" alt="">&lt;/p>
&lt;p>[Note: I apologise deeply for my awful handwriting. And drawing. To be fair, these are far from the worst requirements I've had.]&lt;/p>
&lt;p>We've now got enough to get started.&lt;/p>
&lt;h3 id="the-task---first-cut">The Task - First Cut&lt;/h3>
&lt;p>Here's what we come up with first.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/57AQV/embedded/html,js,result" width="100%" height="300">&lt;/iframe>
&lt;p>Looking at the code, we can see we've got a whole series of issues.&lt;/p>
&lt;ul>
&lt;li>There's a lot of JavaScript that's only there to maintain the state of the DOM.&lt;/li>
&lt;li>We've got an in-memory representation of the state, but also a DOM representing the state too, and we must keep the two in sync.&lt;/li>
&lt;li>The table is always shown, even if we have no items in it.&lt;/li>
&lt;li>The formatting of the milliseconds is awful.&lt;/li>
&lt;/ul>
&lt;p>This is just the beginning. A large part of our code depends heavily on the HTML - the ids must be correct, we need to know about the form and so on.&lt;/p>
&lt;p>Imagine that we're now asked to make the URLs in the table links - we now have to change our JavaScript to add an &amp;lsquo;a&amp;rsquo; tag. If the designers ask us to apply a CSS class to the load speed cells, again, we have to change our JavaScript just for a simple HTML change. And this will get worse and worse.&lt;/p>
&lt;p>As we add more features, this code will grow and grow and will get harder to maintain. We can do all of this with raw JavaScript, and we can improve the access to the DOM with a library like jQuery, but the fundamental problem remains the same - our logic is heavily tied in to our HTML. Unit testing this is essentially impossible, we need a browser and webserver to run the JS and test the resulting HTML, and this is not easy (it's also not a unit test - it's an integration test, integration tests are great but we want to test smaller units first).&lt;/p>
&lt;h3 id="the-task---second-cut">The Task - Second Cut&lt;/h3>
&lt;p>After the first cut, we decide to limit ourselves to just improving a few issues:&lt;/p>
&lt;ul>
&lt;li>After adding an url, we need to clear the selection.&lt;/li>
&lt;li>The urls must be links.&lt;/li>
&lt;li>The round trip times must show in red if they're greater than 100ms.&lt;/li>
&lt;li>There must be no decimal points in the milliseconds.&lt;/li>
&lt;li>The submit button must be disabled if there is no value in the url textbox.&lt;/li>
&lt;/ul>
&lt;p>The HTML is almost the same, so I'm highlighting the JavaScript this time. It's starting to look pretty clunky by this point:&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/v2bSe/embedded/js,html,result" width="100%" height="300">&lt;/iframe>
&lt;p>We're building raw html, we're referencing css class names, we're having to use more events from the dom (such as the key up event), it's simple stuff but it's going to get increasingly difficult to maintain, let alone test.&lt;/p>
&lt;p>At this stage, we've been told we need to do the following:&lt;/p>
&lt;ul>
&lt;li>Show a visual indicator to the user that the check is being performed on the page load time for newly added urls.&lt;/li>
&lt;li>Hide the table when there are no urls and show a hint saying to add one to get started.&lt;/li>
&lt;/ul>
&lt;p>I'm not going to implement this, we've already seen that vanilla js is not giving us much to work with and we're getting increasingly complex as we add features.&lt;/p>
&lt;p>So what are the problems?&lt;/p>
&lt;ul>
&lt;li>We have too much code managing the DOM.&lt;/li>
&lt;li>We can't unit test the client side logic.&lt;/li>
&lt;li>Changes to the HTML of the page require changes to our JavaScript.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>The Solution - We do the logic, AngularJS does the grunt work&lt;/strong>&lt;/p>
&lt;p>AngularJS is not the solution, it's a tool. It's a framework that'll let us write the solution and do the repetitive and tedious DOM stuff for us. We'll find out through the series that it can do a lot more as well.&lt;/p>
&lt;p>AngularJS is ideal for helping with problems like these. What AngularJS allows us to do is build a controller to control the state of the system (which is the model), and bind the view (the raw HTML) to parts of that model. As the model changes, the view will automatically be updated to represent that state. This will remove our code to manage the DOM.&lt;/p>
&lt;p>We can then extend the controller to handle the more complicated cases we need, and not have to worry about synchronisation between the view and the model - it's handled for us. As our controller is a simple JavaScript object, we'll also be able to write unit tests against it. This will allow us to write effective unit tests.&lt;/p>
&lt;p>Because AngularJS is declarative in the HTML (we'll see what this means shortly), we can modify the HTML to our hearts content, without worrying about the JavaScript. This means changes to the HTML are done in HTML, not JavaScript.&lt;/p>
&lt;p>If we can show in our small example that this is true, we've solved the problem.&lt;/p>
&lt;h3 id="the-task-with-angular---first-cut">The Task with Angular - First Cut&lt;/h3>
&lt;p>I'm going to show right away the first cut of our app, using AngularJS. We'll go through the new code line by line afterwards to learn how it works, but what's interesting about this is that we almost don't have to. Look at the html - anything that starts with an &amp;lsquo;ng&amp;rsquo; is Angular. Look at the JavaScript - it's almost entirely vanilla - the only bit of magic we have is the &amp;lsquo;$scope&amp;rsquo; parameter, which is the glue between the view and the controller (we'll learn about this shortly).&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/TXEf6/embedded/html,js,result" width="100%" height="300">&lt;/iframe>
&lt;p>Now it's time to go through the code and see what's going on. We'll look at the JavaScript first and then the HTML.&lt;/p>
&lt;h3 id="the-controller">The Controller&lt;/h3>
&lt;p>Let's take a look at the controller again.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/TXEf6/embedded/js" width="100%" height="300">&lt;/iframe>
&lt;p>A controller is where we put the logic for our application. The first thing we do on our controller is define two variables. One is a string, it's the current url that the user will edit. The second is an array of urls that we maintain.&lt;/p>
&lt;p>Each of these variables is defined on the $scope object. The scope is our context, it's what we can add model data to and it's what the view can bind to.&lt;/p>
&lt;p>We also create a function on the scope that adds a new url (based on the current url) and clears the current url afterwards. The last function on the scope can be used to remove a url. More important stuff here - scopes can contain variables and functions.&lt;/p>
&lt;p>Our controller logic is trivial, and already much easier to follow than the previous one.&lt;/p>
&lt;p>We've seen the controller in detail, let's look at the view.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/TXEf6/embedded/html" width="100%" height="300">&lt;/iframe>
&lt;p>The first thing we have a link to the angular library. This should always go at the top of the page, normally in the head (above we have a jsfiddle which makes the head for us so it's right at the top of the body).&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">script&lt;/span> &lt;span style="color:#a6e22e">src&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;https://ajax.googleapis.com/ajax/libs/angularjs/1.2.0/angular.min.js&amp;#34;&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">script&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Include Angular in the &lt;code>&amp;lt;head&amp;gt;&lt;/code>, not at the end of the file.&lt;/p>
&lt;/blockquote>
&lt;p>What do we notice first? ng-app. The ng-app directive tells angular that everything that's in this element should be handled by angular. Angular will only pay attention to directives inside an element that's an app.&lt;/p>
&lt;p>What's a directive? A directive is a marker in the HTML that tells Angular it needs to do something. It may indicate that something needs to be bound, that an event handler needs to be wired up, or it can even be completely custom - you can write simple directives in the forms of elements or attributes that expand into rich and complex parts of a page, or handle advanced functionality.&lt;/p>
&lt;p>The most common place to put an ng-app directive for an application is often directly in the html element - telling angular our whole page is controlled by angular. Like this:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">html&lt;/span> &lt;span style="color:#a6e22e">ng-app&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Angular will work for everything within an element with the &lt;code>ng-app&lt;/code> directive.&lt;/p>
&lt;/blockquote>
&lt;p>Following this we have an ng-controller directive. This tells angular that it needs to create an instance of the controller specified (which is our main controller we've already defined) use the controller to control the scope of all child elements.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">div&lt;/span> &lt;span style="color:#a6e22e">ng-controller&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;SpeedmonitorController&amp;#34;&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> The &lt;code>ng-controller&lt;/code> directive specifies the controller to use.&lt;/p>
&lt;/blockquote>
&lt;p>The first thing we do is bind the submit event of the form to the &lt;code>addUrl()&lt;/code> function. Then we bind the input to the &lt;code>currentUrl&lt;/code> field. This has shown us two new directives:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">form&lt;/span> &lt;span style="color:#a6e22e">ng-submit&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;addUrl()&amp;#34;&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">label&lt;/span> &lt;span style="color:#a6e22e">for&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;url&amp;#34;&lt;/span>&amp;gt;Url&amp;lt;/&lt;span style="color:#f92672">label&lt;/span>&amp;gt;
&amp;lt;&lt;span style="color:#f92672">input&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;url&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;text&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">ng-model&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;currentUrl&amp;#34;&lt;/span> /&amp;gt;
&amp;lt;&lt;span style="color:#f92672">input&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;submit&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;submit&amp;#34;&lt;/span> /&amp;gt;
&amp;lt;/&lt;span style="color:#f92672">form&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> The ng-submit directive evaluates the provided expression when a form is submitted.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> The ng-model is used to bind an input to a model property.&lt;/p>
&lt;/blockquote>
&lt;p>The final part of the html is perhaps the most interesting and where we're really starting to see the power of AngularJS.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">tr&lt;/span> &lt;span style="color:#a6e22e">ng-repeat&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;url in urls&amp;#34;&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here we use an ng-repeat directive to iterate through a collection. Angular will loop through every item in the urls array and create whatever is contained in the element with the ng-repeat tag for each item. Now we can reference the properties of the item using the name we gave it (&amp;lsquo;url&amp;rsquo; in our case). We can also see that the handlebars syntax {{something.else}} can be used to simply write out a value into the html.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">td&lt;/span>&amp;gt;{{url.loadSpeed}} ms&amp;lt;/&lt;span style="color:#f92672">td&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Use &lt;code>ng-repeat=&amp;quot;item in set&amp;quot;&lt;/code> to create html for multiple items in a collection. Use $index, $first, $last (and more) special variables for extra control.&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Use {{handlebars}} to write out the value of an expression.&lt;/p>
&lt;/blockquote>
&lt;p>The final part of the html is where we have the ng-click directive. When the element is clicked on, angular evaluates the expression - and the expression is the removeUrl function called with the $index special property. $index is provided by angular inside the ng-repeat template and evaluates to the index in the array.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">td&lt;/span>&amp;gt;&amp;lt;&lt;span style="color:#f92672">a&lt;/span> &lt;span style="color:#a6e22e">ng-click&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;removeUrl($index)&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">href&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;javascript:void(0)&amp;#34;&lt;/span>&amp;gt;Delete&amp;lt;/&lt;span style="color:#f92672">a&lt;/span>&amp;gt;&amp;lt;/&lt;span style="color:#f92672">td&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> ng-click evaluates the provided expression when the element is clicked on.&lt;/p>
&lt;/blockquote>
&lt;h3 id="the-task-with-angular-second-cut">The Task with Angular: Second Cut&lt;/h3>
&lt;p>In our first attempt, without angular, we then decided to fix the following issues:&lt;/p>
&lt;ul>
&lt;li>After adding an url, we need to clear the selection.
The urls must be links.&lt;/li>
&lt;li>The round trip times must show in red if they're greater than 100ms.&lt;/li>
&lt;li>There must be no decimal points in the milliseconds.&lt;/li>
&lt;li>The submit button must be disabled if there is no value in the url textbox.&lt;/li>
&lt;/ul>
&lt;p>With the arrangement we've got now, the changes become trivial. Let's do them one by one.&lt;/p>
&lt;h4 id="item-1-after-adding-an-url-we-need-to-clear-the-selection">Item 1: After adding an url, we need to clear the selection.&lt;/h4>
&lt;p>We can make the following change in the controller, highlighted in bold.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-js" data-lang="js">&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">addUrl&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#66d9ef">function&lt;/span>() {
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">urls&lt;/span>.&lt;span style="color:#a6e22e">push&lt;/span>({&lt;span style="color:#a6e22e">url&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">currentUrl&lt;/span>, &lt;span style="color:#a6e22e">loadSpeed&lt;/span>&lt;span style="color:#f92672">:&lt;/span> Math.&lt;span style="color:#a6e22e">random&lt;/span>() &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">75&lt;/span> &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">50&lt;/span>});
&lt;span style="color:#a6e22e">$scope&lt;/span>.&lt;span style="color:#a6e22e">currentUrl&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>; &lt;span style="color:#75715e">// Now clear the current URL.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Notice that we didn't have to get the input element in the JavaScript? We update the model state, via the scope, and the view will update automatically.&lt;/p>
&lt;h4 id="item-2-the-urls-must-be-links">Item 2: The urls must be links.&lt;/h4>
&lt;p>Again, a trivial change. It's a change in the view, so we do it in the view. The updated code is in bold below:&lt;/p>
&lt;pre>&lt;code class="language-htmlo" data-lang="htmlo">&amp;lt;td&amp;gt;&amp;lt;a href=&amp;quot;{{url.url}}&amp;quot;&amp;gt;{{url.url}}&amp;lt;/a&amp;gt;&amp;lt;/td&amp;gt;
&lt;/code>&lt;/pre>&lt;p>Easy - we write the url value in the href of an &amp;lsquo;a&amp;rsquo; tag. And we do it in the view - not in the JS logic.&lt;/p>
&lt;h4 id="item-3-the-round-trip-times-must-show-in-red-if-theyve-over-100ms">Item 3: The round trip times must show in red if they've over 100ms.&lt;/h4>
&lt;p>We need to apply the &amp;lsquo;red&amp;rsquo; css class if the round trip time is greater than 100ms - where do we do this? In the view!&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">td&lt;/span>&amp;gt;&amp;lt;&lt;span style="color:#f92672">span&lt;/span> &lt;span style="color:#a6e22e">ng-class&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;{red: url.loadSpeed &amp;gt; 100}&amp;#34;&lt;/span>&amp;gt;{{url.loadSpeed}}&amp;lt;/&lt;span style="color:#f92672">span&lt;/span>&amp;gt; ms&amp;lt;/&lt;span style="color:#f92672">td&lt;/span>&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We use the ng-class directive here. It allows us to set CSS classes on an element conditionally, based on the result of an expression. Again - no CSS or HTML in the JavaScript to handle this, we do it in the view, where it belongs.&lt;/p>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Use ng-class to apply CSS classes to elements based on expressions.&lt;/p>
&lt;/blockquote>
&lt;h4 id="item-4-there-must-be-no-decimal-points-in-the-milliseconds">Item 4: There must be no decimal points in the milliseconds.&lt;/h4>
&lt;p>Oh so easy with Angular. Again - it's presentation logic, so it stays in the view.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">{{url.loadSpeed | number:0}} ms
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The vertical pipe character shows we're using a filter - this is something that can be used to format data. AngularJS comes with a bunch of filters, we use &lt;code>number:0&lt;/code> to format as a number with no decimal places.&lt;/p>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Use the | pipe to apply a filter.&lt;/p>
&lt;/blockquote>
&lt;h4 id="item-5-the-submit-button-must-be-disabled-if-there-is-no-value-in-the-url-textbox">Item 5: The submit button must be disabled if there is no value in the url textbox.&lt;/h4>
&lt;p>By now we're starting to see that this logic is very easy to apply in the view.&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-html" data-lang="html">&amp;lt;&lt;span style="color:#f92672">input&lt;/span> &lt;span style="color:#a6e22e">id&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;submit&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">type&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;submit&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">ng-disabled&lt;/span>&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;currentUrl.length == 0&amp;#34;&lt;/span> /&amp;gt;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>We use the ng-disabled directive to apply the disabled attribute to an input based on the value of an expression. AngularJS expressions are powerful ways to quickly apply logic like this.&lt;/p>
&lt;blockquote>
&lt;p>&lt;img src="images/AngularTip.png" alt=""> Use ng-disabled to disable an input based on an expression.&lt;/p>
&lt;/blockquote>
&lt;p>Here's the final fiddle for the task, with our new functionality.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/5X5CF/embedded" width="100%" height="300">&lt;/iframe>
&lt;p>We've added only one line to our JavaScript - we've kept the presentation logic in the view and we've done no extra DOM manipulation. I think we've now shown some progress with our problems:&lt;/p>
&lt;ul>
&lt;li>SOLVED: We have too much code managing the DOM.
We can't unit test the client side logic.&lt;/li>
&lt;li>SOLVED: Changes to the HTML of the page require changes to our JavaScript.&lt;/li>
&lt;/ul>
&lt;p>If we can run some kind of tests now, we've shown that AngularJS can help us greatly in this case.&lt;/p>
&lt;p>Unit Testing AngularJS Controllers&lt;/p>
&lt;p>Unit testing is a complicated topic, generally because we require extra libraries to write unit tests, run them and so on. We're going to keep things as simple as possible here. Unit testing is a bigger topic that'll be covered in detail in a later article, but for now let's build some trivial tests for our controller.&lt;/p>
&lt;p>The recommended approach for writing unit tests for AngularJS applications is to use Jasmine. Jasmine is a topic all on it's own and too much to go into in this introduction article, but I'll show you a quick fiddle that runs unit tests for our controller.&lt;/p>
&lt;iframe src="http://jsfiddle.net/dwmkerr/ThfE4/embedded/result,js" width="100%" height="300">&lt;/iframe>
&lt;p>We start with the controller - which in a real world test suite would be included or injected, then run a basic set of tests against it. You can check the JavaScript but what's key here is that we can test without a DOM or even a window, these are genuine unit tests.&lt;/p>
&lt;p>At this stage, let's look over our problems.&lt;/p>
&lt;ul>
&lt;li>SOLVED: We have too much code managing the DOM.&lt;/li>
&lt;li>SOLVED: We can't unit test the client side logic.&lt;/li>
&lt;li>SOLVED: Changes to the HTML of the page require changes to our JavaScript.&lt;/li>
&lt;/ul>
&lt;p>OK - the sceptics among you may need more persuasion on these points, but if you're interested we'll be seeing them again in later articles.&lt;/p>
&lt;h3 id="conclusions">Conclusions&lt;/h3>
&lt;p>We've shown in this article that there are certainly cases where AngularJS can help us write better client-side code. As we go through the series we'll see what else AngularJS can do and how we can even extend it to deal with our own application specific requirements.&lt;/p>
&lt;p>I hope you've found this article useful. If you've got any comments please let me know, it's early enough in the series for me to adapt it based on what people want!&lt;/p></description><category>CodeProject</category></item><item><title>Managing Vsix Deployments with Powershell</title><link>https://dwmkerr.com/managing-vsix-deployments-with-powershell/</link><pubDate>Sun, 30 Mar 2014 11:40:16 +0000</pubDate><guid>https://dwmkerr.com/managing-vsix-deployments-with-powershell/</guid><description>&lt;blockquote>
&lt;p>&lt;strong>tl;dr&lt;/strong> - &lt;a href="https://github.com/dwmkerr/vsix-tools">vsix-tools&lt;/a> fixes the &amp;lsquo;Invalid Multiple Files in VSIX&amp;rsquo; issue on the Visual Studio Gallery and lets you set vsix version numbers with Powershell.&lt;/p>
&lt;/blockquote>
&lt;p>I maintain a reasonably large project called SharpGL. This project contains two Vsix packages (Visual Studio Extensions), each of which contains project templates for Visual Studio.&lt;/p>
&lt;p>If you have ever worked with Vsix files before you might have noticed that the tools for them in Visual Studio seem a little flaky - but even more so is that Visual Studio Gallery site that you have to use to upload your extensions.&lt;/p>
&lt;p>Add more than one project template to your Vsix and try and upload it - this is what you'll see:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2014/03/InvalidMultipleZipFilesInVsix.jpg">&lt;img src="images/InvalidMultipleZipFilesInVsix.jpg" alt="InvalidMultipleZipFilesInVsix" width="263" />&lt;/a>&lt;/p>
&lt;p>It's a pain to solve this problem - basically you need to change the folder structure within the vsix file, then change the xml that describes it. Now this is not too much of a problem if you do it once or twice, but if you're in the situation where you want to be able to build a release of your code rapidly, including extensions, this will seriously slow you down.&lt;/p>
&lt;p>Enter &lt;a href="https://github.com/dwmkerr/vsix-tools">VsixTools&lt;/a>, a little Powershell script that lets you resolve this issue and as a bonus lets you set the version in the Vsix as well - very useful for scripts that build releases. You can use it like this:&lt;/p>
&lt;pre>&lt;code># Load vsix tools
. VsixTools.ps1
# Set the version number of 'MyPackage' and fix the zip issue for uploading to the gallery.
$vsixPath = &amp;quot;c:/MyPackage.vsix&amp;quot;
Vsix-SetVersion -VsixPath $vsixPath -Version &amp;quot;2.2.0.1&amp;quot;
Vsix-FixInvalidMultipleFiles -VsixPath $vsixPath&amp;lt;/pre&amp;gt;
&lt;/code>&lt;/pre>&lt;p>This Powershell script has no dependencies, it's just Powershell 2.0. Get the script at &lt;a href="https://github.com/dwmkerr/vsix-tools">github.com/dwmkerr/vsix-tools&lt;/a>.&lt;/p>
&lt;p>It works for package manifests of version 1 or 2 - for anyone who's lucky enough to have not had to delve into the internals of this that means that it works from Visual Studio 2010 onwards.&lt;/p></description><category>CodeProject</category></item><item><title>Practical AngularJS Part 2</title><link>https://dwmkerr.com/practical-angularjs-part-2/</link><pubDate>Wed, 19 Feb 2014 15:29:29 +0000</pubDate><guid>https://dwmkerr.com/practical-angularjs-part-2/</guid><description>&lt;p>I'm going to be working in F# almost exclusively for a short while, so before I throw myself into that I wanted to wind up my Practical AngularJS Part 2 article. It's ready to rock here:&lt;/p>
&lt;p>&lt;a title="Practical AngularJS Part 2 – Components of an AngularJS Application" href="http://www.dwmkerr.com/practical-angularjs-part2/">Practical AngularJS Part 2 - Components of an AngularJS Application&lt;/a>&lt;/p>
&lt;p>In this article we get a brief introduction to what's in the toolkit for an angular developers - filters, controllers, services, directives, views and routes. I don't go into too much detail, we're just seeing what the different components are. Spread the word, share the article and as always, comments are welcome.&lt;/p></description><category>CodeProject</category></item><item><title>Langton's Ant in Javascript</title><link>https://dwmkerr.com/langtons-ant-in-javascript/</link><pubDate>Sun, 15 Dec 2013 10:47:18 +0000</pubDate><guid>https://dwmkerr.com/langtons-ant-in-javascript/</guid><description>&lt;p>Langton's Ant is a great simulation to write to play with a language. Just today I've completed my Langton's Ant write up and published it on the CodeProject, you can see the article at &lt;a title="Learn Javascript Part 3 - AngularJS and Langton's Ant" href="http://www.codeproject.com/Articles/696943/Learn-JavaScript-Part-3-AngularJS-and-Langtons-Ant" target="_blank">Learn JavaScript Part 3 - Angularjs and Langton's Ant&lt;/a>.&lt;/p>
&lt;p>&lt;a title="Langton's Ant" href="http://www.dwmkerr.com/experiments/langtonsant/" target="_blank">&lt;img src="images/langtonsant.jpg" alt="Langton's Ant" width="640" />&lt;/a>&lt;/p>
&lt;p>There are some interesting things in the article for angular too - a look at using directives for custom elements, how to handle both the DOM and Angular loading correctly, and timers and intervals. This is the third part on my series on Learn Javascript, the next will focus on NodeJS. Enjoy, share, fork and comments are always welcome.&lt;/p>
&lt;p>The default configuration of the simulation is interesting - try a simulation of the form &amp;lsquo;left, left, right, right&amp;rsquo; for another type of behaviour.&lt;/p></description><category>CodeProject</category></item><item><title>A great read for JavaScript newcomers</title><link>https://dwmkerr.com/a-great-read-for-javascript-newcomers/</link><pubDate>Thu, 28 Nov 2013 06:10:16 +0000</pubDate><guid>https://dwmkerr.com/a-great-read-for-javascript-newcomers/</guid><description>&lt;p>A superb article by Colin Eberhardt has just been published on the CodeProject, called &amp;lsquo;Understanding JavaScript Object Creation Patterns&amp;rsquo;.&lt;/p>
&lt;p>This article should be on the reading list of anyone who's new to JavaScript or not familiar with how objects and prototypes work. It takes you step by step through the basics all the way to protoypes and classes.&lt;/p>
&lt;p>The article is at:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/Articles/687093/Understanding-JavaScript-Object-Creation-Patterns">&lt;a href="http://www.codeproject.com/Articles/687093/Understanding-JavaScript-Object-Creation-Patterns">http://www.codeproject.com/Articles/687093/Understanding-JavaScript-Object-Creation-Patterns&lt;/a>&lt;/a>&lt;/p>
&lt;p>I'd strongly recommend it!&lt;/p></description><category>CodeProject</category></item><item><title>Introducing Practical AngularJS</title><link>https://dwmkerr.com/introducing-practical-angularjs/</link><pubDate>Mon, 25 Nov 2013 16:16:09 +0000</pubDate><guid>https://dwmkerr.com/introducing-practical-angularjs/</guid><description>&lt;p>I was recently at Devoxx in Antwerp, primarily because I wanted to get involved in some of the sessions that were being hosted by guys from the AngularJS team at Google. I've had a chance to work a little with Backbone and KnockoutJS and had been recently deliberately holding off looking at AngularJS so I could hit the conference and workshops fresh and unencumbered with any preconceptions.&lt;/p>
&lt;p>The sessions were great, and since then I've been working on a couple of projects that use Angular. As I've always found writing about a topic a great way to really cement what you know about it, and to understand where the holes in your knowledge are, I've started a new series of articles called &amp;lsquo;&lt;a title="Practical AngularJS" href="http://www.dwmkerr.com/practical-angularjs/">Practical AngularJS&lt;/a>&amp;rsquo;.&lt;/p>
&lt;p>This series is a little different to others I'm working on at the moment (such as the seemingly &lt;a title=".NET Shell Extensions - Shell Context Menus" href="http://www.codeproject.com/Articles/512956/NET-Shell-Extensions-Shell-Context-Menus" target="_blank">endless SharpShell articles&lt;/a> and &lt;a title="Space Invaders" href="http://www.codeproject.com/Articles/681130/Learn-JavaScript-Part-2-Space-Invaders" target="_blank">Learn JavaScript&lt;/a> which is taking some time) as I'm writing it on my own blog rather than on the CodeProject. The reason behind this is purely push me into getting better at handling my blog (particularly the code samples) and because the code I'm writing doesn't need to be associated with download links and so on, it can all be in fiddles.&lt;/p>
&lt;p>Anyway, enough chatter - part one of Practical AngularJS is now finished. It's a new series, so it's early enough to have a say in where it goes, please comment and share and let me kn0w whether you find it useful, pointless, or anything in-between.&lt;/p>
&lt;p>As a short teaser, in &lt;a title="Practical AngularJS Part 1 – Introducing AngularJS" href="http://www.dwmkerr.com/practical-angularjs-part1" target="_blank">Practical AngularJS Part 1 - Introducing AngularJS&lt;/a> we take a look at what AngularJS is, why we'd consider using it and when. We start out with a trivial task for a web application, and see how it quickly becomes a bit sluggish and painful to do certain things, then see how using AnguarJS can ease that pain, letting us focus on the important stuff and it help out with the grunt work. We take our initially messy app and make it a lot more manageable, and look into how we can with our new structure start to write unit tests for the logic.&lt;/p>
&lt;p>So this is the bulk of Part 1. Unless there's a strong push for another topic, Part 2 will focus on testing. Testing is core to the development ideals of the AngularJS project and is something that it was built in mind for. We'll look into how quickly we can write unit tests, and the flexibility that we've got.&lt;/p>
&lt;p>Rather than advocating patterns such as BDD or TDD, we'll again shy away from theoretical discussions about what is conceptually the best paradigm and just dig in - playing with the code and seeing what works and what doesn't. By the end of it you'll have a good idea of the freedom you've got with testing - leaving it up to you to choose the pattern or process that fits your style, or the style of your team and project the best.&lt;/p></description><category>CodeProject</category></item><item><title>Space Invaders on the CodeProject</title><link>https://dwmkerr.com/space-invaders-on-the-codeproject/</link><pubDate>Thu, 21 Nov 2013 12:24:41 +0000</pubDate><guid>https://dwmkerr.com/space-invaders-on-the-codeproject/</guid><description>&lt;p>I'm currently writing a series of articles on the CodeProject called &amp;lsquo;Learn JavaScript&amp;rsquo; and am pleased to say that the latest article is available now!&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/Articles/681130/Learn-JavaScript-Part-2-Space-Invaders" target="_blank">Learn JavaScript Part 2 - Space Invaders&lt;/a>&lt;/p>
&lt;p>In this article we take a look at how to create the classic space invaders game with plain JavaScript and HTML - no libraries or frameworks. You can see it in action on the page &lt;a title="Space Invaders" href="http://www.dwmkerr.com/experiments/spaceinvaders/" target="_blank">experiments/spaceinvaders&lt;/a>. Check it out - as always, comments are welcome!&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/experiments/spaceinvaders/">&lt;img src="images/spaceinvaders.jpg" alt="spaceinvaders" width="640" />&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>SharpShell 2.0</title><link>https://dwmkerr.com/sharpshell-2-0/</link><pubDate>Sun, 15 Sep 2013 06:31:34 +0000</pubDate><guid>https://dwmkerr.com/sharpshell-2-0/</guid><description>&lt;p>I have just released SharpShell 2.0  - you can get the release from &lt;a title="SharpShell on CodePlex" href="http://sharpshell.codeplex.com" target="_blank">sharpshell.codeplex.com&lt;/a> or the new GitHub page at &lt;a title="SharpShell on GitHub" href="https://github.com/dwmkerr/sharpshell" target="_blank">github.com/dwmkerr/sharpshell&lt;/a>.&lt;/p>
&lt;p>This release has been primarily a bugfixing release, but there is one very useful new feature, the Server Registration Manager tool (srm.exe). This is a standalone application that can be used to install and uninstall SharpShell servers.&lt;/p>
&lt;pre>srm install server.dll -codebase
srm uninstall server.dll&lt;/pre>
&lt;p>This tool makes it much easier to deploy SharpShell servers. You can call the tool as a Custom Action in a MSI project, either by using Visual Studio 2010's installer project type, or a WiX project. I'll be writing up an article on the CodeProject on how to use the tool soon, until then you can download the tool and try it out now!&lt;/p></description><category>CodeProject</category></item><item><title>ConsoleControl and Happy Coders</title><link>https://dwmkerr.com/consolecontrol-and-happy-coders/</link><pubDate>Mon, 02 Sep 2013 13:27:47 +0000</pubDate><guid>https://dwmkerr.com/consolecontrol-and-happy-coders/</guid><description>&lt;p>Sometimes I write up an article and some code on the CodeProject and get a good response, other times it seems an article sinks beneath the waves without any notice. Looking over some emails the other day, I noticed that my ConsoleControl article had actually received a slow and steady response of extremely positive feedback - people are using it and suggesting improvements.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/09/screenshot.png">&lt;img src="images/screenshot.png" alt="screenshot" width="600" />&lt;/a>&lt;/p>
&lt;p>This is great, it's one of the things I love about the community of developers that I'm part of. So I decided to try and put a bit more back with ConsoleControl. I've moved the source code to GitHub, so that anyone can fork it and work on it easily:&lt;/p>
&lt;p>&lt;a title="ConsoleControl on GitHub" href="https://github.com/dwmkerr/consolecontrol" target="_blank">&lt;a href="https://github.com/dwmkerr/consolecontrol">https://github.com/dwmkerr/consolecontrol&lt;/a>&lt;/a>&lt;/p>
&lt;p>I've bulked out the readme.md file with some more information and am working in the documentation. I've also added ConsoleControl to Nuget - you can install it for WinForms or WPF with the commands below:&lt;/p>
&lt;pre>&lt;code>PM&amp;gt; Install-Package ConsoleControl
&lt;/code>
&lt;code>PM&amp;gt; Install-Package ConsoleControl.WPF
&lt;/code>&lt;/pre>
&lt;p>Finally, I'm blogging about it here. It's great to see people using a project like this, it's rare for me to share comments like the ones below, but I must say I was touched by:&lt;/p>
&lt;p>&lt;em>This is just about borderline genius. - &lt;/em>Gerben Rampaart
&lt;em>Brilliant. So easy to use and works flawlessly. &lt;/em>- Sukar
&lt;em>I saw similar controls - but yours is outstanding - I love it! BTW: Very nice coding (style, comments) - 5ed! - &lt;/em>johannesnestler&lt;/p>
&lt;p>To finish off this post, I'd like to say thanks to everyone who's commented, suggested improvements and shared their experiences with the code, it's a great feeling when you share something and it seems that people benefit from it. If you've used the code and want to share ideas for improvements or feedback, email, comment or hit the GitHub page or CodeProject article.&lt;/p></description><category>CodeProject</category></item><item><title>Space Invaders in JavaScript</title><link>https://dwmkerr.com/space-invaders-in-javascript/</link><pubDate>Sun, 25 Aug 2013 12:04:17 +0000</pubDate><guid>https://dwmkerr.com/space-invaders-in-javascript/</guid><description>&lt;p>If you take a look at the&lt;a title="Introducing Experiments" href="http://www.dwmkerr.com/2013/08/introducing-experiments/"> Experiments Page&lt;/a> you'll see that there's a new entry - &lt;a title="Space Invaders" href="http://www.dwmkerr.com/experiments/spaceinvaders" target="_blank">Space Invaders&lt;/a>.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/experiments/spaceinvaders" target="_blank">&lt;img src="images/spaceinvaders.jpg" alt="spaceinvaders" width="640" />&lt;/a>&lt;/p>
&lt;p>Space Invaders is a great little game to code if you're learning a new language or technology (and JavaScript is still very much in that category for me). I'll be writing up how I made the game on the CodeProject soon enough (if you're interested you can &lt;a href="http://www.codeproject.com/Articles/642499/Learn-JavaScript-Part-1-Create-a-Starfield" target="_blank">see how I made the starfield background in JavaScript&lt;/a>).&lt;/p>
&lt;p>You can check back periodically - the game is nearly done and more than ready to play with. The code is available as well, either just get it from the browser or check &lt;a title="Space Invaders on GitHub" href="http://github.com/dwmkerr/spaceinvaders" target="_blank">Space Invaders on GitHub&lt;/a>. I'll post when it's done and the next experiment starts!&lt;/p></description><category>CodeProject</category></item><item><title>Introducing Experiments</title><link>https://dwmkerr.com/introducing-experiments/</link><pubDate>Sat, 24 Aug 2013 06:00:16 +0000</pubDate><guid>https://dwmkerr.com/introducing-experiments/</guid><description>&lt;p>I'm staring a series of articles on learning Javascript (the first is available at &lt;a href="http://www.codeproject.com/Articles/642499/Learn-JavaScript-Part-1-Create-a-Starfield">&lt;a href="http://www.codeproject.com/Articles/642499/Learn-JavaScript-Part-1-Create-a-Starfield">http://www.codeproject.com/Articles/642499/Learn-JavaScript-Part-1-Create-a-Starfield&lt;/a>&lt;/a>). To help with this, I've created the &lt;a title="Experiments" href="http://www.dwmkerr.com/experiments">Experiments&lt;/a> page. This page will host each of the things I've been playing with in the process of learning JavaScript and coming up with good topics for tutorials.&lt;/p>
&lt;p>You can see the &lt;a title="Experiments" href="http://www.dwmkerr.com/experiments">Experiments&lt;/a> page here, there's also a link at the top of the site. If you like it, please feel free to comment on this post or get in touch.&lt;/p></description><category>CodeProject</category></item><item><title>Node.js and Express - Strange Http Status Codes</title><link>https://dwmkerr.com/node-js-and-express-strange-http-status-codes/</link><pubDate>Tue, 16 Jul 2013 16:23:43 +0000</pubDate><guid>https://dwmkerr.com/node-js-and-express-strange-http-status-codes/</guid><description>&lt;h3>In a Nutshell&lt;/h3>
Sending a response in Express with a call like &lt;em>res.send(status, body)&lt;/em> will send &lt;em>body&lt;/em> as the status code if it is numeric - ignoring &lt;em>status&lt;/em>. This is due to a fudge for backwards compatibility.
&lt;h3>The Details&lt;/h3>
&lt;span style="line-height: 1.714285714; font-size: 1rem;">&lt;strong>&lt;/strong>As part of a project I'm working on, I'm writing a service using &lt;/span>&lt;a style="line-height: 1.714285714; font-size: 1rem;" title="node.js" href="http://nodejs.org/" target="_blank">node.js&lt;/a>&lt;span style="line-height: 1.714285714; font-size: 1rem;"> and &lt;/span>&lt;a style="line-height: 1.714285714; font-size: 1rem;" title="Express" href="http://expressjs.com/" target="_blank">Express&lt;/a>&lt;span style="line-height: 1.714285714; font-size: 1rem;">. This service exposes some entities in a MongoDB database through a REST API. Typically I hit this API through client-side Javascript, but in some places I want to hit the same API from some C# code - and I don't want to have to create classes for everything. I've got a funky library for this which I'll be publishing soon, but it helped me find a problem.&lt;/span>
&lt;p>Testing the C# code showed me something that was a bit odd - GETs and POSTSs were working fine, but PUTs and DELETEs were showing an HTTP Status code of &amp;lsquo;1&amp;rsquo; (which isn't a valid code). Here's the what I was seeing:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/07/requests.png">&lt;img src="images/requests.png" alt="requests" width="600" />&lt;/a>&lt;/p>
&lt;p>Checking the node server showed the same thing - DELETEs were returning status 1.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/07/console.png">&lt;img src="images/console.png" alt="console" width="600" />&lt;/a>&lt;/p>
&lt;p>The server code is very lightweight so it's quick to see what's going on:&lt;/p>
&lt;p>[code lang=&amp;quot;js&amp;rdquo;]exports.deleteUser = function(request, response) {&lt;/p>
&lt;pre>&lt;code>// Get the id.
var id = request.params.id;
// Log the user id.
console.log('Deleting user: ' + id);
// Get the users collection, delete the object.
db.collection(collectionName, function(err, collection) {
collection.remove({'_id':new BSON.ObjectID(id)}, {safe:true}, function(err, result) {
if (err) {
console.log('Error deleting user: ' + err);
response.send(400, {'error':'An error has occurred'});
} else {
console.log('' + result + ' document(s) deleted');
response.send(result);
}
});
});
&lt;/code>&lt;/pre>
&lt;p>}[/code]&lt;/p>
&lt;p>The function is called successfully, so we hit &amp;lsquo;response.send&amp;rsquo;. This looks like the problem - the result object is simply the number one, checking the &lt;a title="Express API Documentation" href="http://expressjs.com/api.html" target="_blank">Express Api Documentation&lt;/a> for send shows some examples like this:&lt;/p>
&lt;pre>&lt;code>res.send(new Buffer('whoop'));
res.send({ some: 'json' });
res.send('some html');
res.send(404, 'Sorry, we cannot find that!');
res.send(500, { error: 'something blew up' });
res.send(200);&lt;/code>&lt;/pre>
&lt;p>So just like the final example, we're sending the code 1, which is not valid. What surprised me was what happened when I changed the send call to the below:&lt;/p>
&lt;p>[code lang=&amp;quot;js&amp;rdquo;]response.send(200, result)[/code]&lt;/p>
&lt;p>I was &lt;em>still &lt;/em>getting the code 1 returned. It turns out that this is a kind of undocumented oddity of Express - if you pass a numeric code and &lt;b>the second argument is also numeric&lt;/b> it sends the&lt;b> second argument as the status&lt;/b>.&lt;/p>
&lt;p>In response.js of Express we find:&lt;/p>
&lt;p>[code lang=&amp;quot;js&amp;rdquo;]res.send = function(body){
var req = this.req;
var head = &amp;lsquo;HEAD&amp;rsquo; == req.method;
var len;&lt;/p>
&lt;p>// allow status / body
if (2 == arguments.length) {
// res.send(body, status) backwards compat
if (&amp;lsquo;number&amp;rsquo; != typeof body &amp;amp;&amp;amp; &amp;lsquo;number&amp;rsquo; == typeof arguments[1]) {
this.statusCode = arguments[1];
} else {
this.statusCode = body;
body = arguments[1];
}
}[/code]&lt;/p>
&lt;p>So it seems the Express used to support a call like res.send({body}, 200) - and checks for a numeric second argument for backwards compatibility.&lt;/p>
&lt;p>The workaround - don't send numbers as any part of the response, unless it's most definitely the status code - if you want to return the number of documents deleted, format it as json first, otherwise Express will get confused and mess with your status codes.&lt;/p></description><category>CodeProject</category></item><item><title>Recursive read lock acquisitions not allowed in this mode</title><link>https://dwmkerr.com/recursive-read-lock-acquisitions-not-allowed-in-this-mode/</link><pubDate>Wed, 10 Jul 2013 02:17:09 +0000</pubDate><guid>https://dwmkerr.com/recursive-read-lock-acquisitions-not-allowed-in-this-mode/</guid><description>&lt;p>If you are using the following combination of tools:&lt;/p>
&lt;ul>
&lt;li>&lt;span style="line-height: 14px;">Visual Studio 2012&lt;/span>&lt;/li>
&lt;li>Visual Studio Tools for Git&lt;/li>
&lt;li>Nuget&lt;/li>
&lt;/ul>
Then you may encounter some weird problems when trying to update Nuget packages. For me, updates regularly fail with:
&lt;p>&lt;strong>Recursive read lock acquisitions not allowed in this mode.&lt;/strong>&lt;/p>
&lt;p>I'm lost on the root cause of this, but it does seem that the project I'm working on has files set to read-only by something regularly, perhaps Visual Studio is trying to make Git more TFS-y by locking things all over the place. Whatever the cause, I've found that the following usually helps:&lt;/p>
&lt;ol>
&lt;li>&lt;span style="line-height: 14px;">Don't use Update-Package - use Install-Package instead.&lt;/span>&lt;/li>
&lt;li>Make sure the solution has all of its files read+write, not read only.&lt;/li>
&lt;li>Open the team explorer and go to 'Commits' - making sure that the Git tools have loaded various components.&lt;/li>
&lt;/ol>
&lt;span style="line-height: 20px;">This combination of tricks seems to solve the problem. If anyone has any other ideas or suggestions, just comment.&lt;/span></description><category>CodeProject</category></item><item><title>Context Menu for Trello</title><link>https://dwmkerr.com/context-menu-for-trello/</link><pubDate>Thu, 27 Jun 2013 05:40:58 +0000</pubDate><guid>https://dwmkerr.com/context-menu-for-trello/</guid><description>&lt;p>I'm on holiday at the moment, back in sunny England. Holiday may not be the right term really, I'm mostly working through charity stuff (for my charity &lt;a title="Namaste - Children's Homes Nepal" href="http://www.childrenshomesnepal.org/" target="_blank">Namaste - Children's Homes Nepal&lt;/a>) and company administration. I'm also starting working on a big new project, which is pretty exciting.&lt;/p>
&lt;p>Anyway, I got a nice message from a fellow coder &lt;a title="Goerge Hahn on Twitter" href="https://twitter.com/George_Hahn" target="_blank">George Hahn&lt;/a> who has put together a pretty cool project that lets you send files directly to &lt;a title="Trello" href="https://trello.com/" target="_blank">Trello&lt;/a> as an attachment to a card, or even as a new card. Here's a screenshot of it in action:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/TrelloContextMenuExample.png">&lt;img src="images/TrelloContextMenuExample.png" alt="TrelloContextMenuExample" width="503" />&lt;/a>&lt;/p>
&lt;p>It's a nice project, you can check it out on GitHub:&lt;/p>
&lt;table>
&lt;tbody>
&lt;tr>
&lt;td>&lt;iframe style="width: 170px; height: 30px;" src="http://ghbtns.com/github-btn.html?user=GeorgeHahn&amp;amp;repo=TrelloContextMenu&amp;amp;type=watch&amp;amp;count=true&amp;amp;size=large" height="30" width="170" frameborder="0" scrolling="0">&lt;/iframe>&lt;/td>
&lt;td>&lt;iframe style="width: 170px; height: 30px;" src="http://ghbtns.com/github-btn.html?user=GeorgeHahn&amp;amp;repo=TrelloContextMenu&amp;amp;type=fork&amp;amp;count=true&amp;amp;size=large" height="30" width="170" frameborder="0" scrolling="0">&lt;/iframe>&lt;/td>
&lt;td>&lt;iframe style="width: 240px; height: 30px;" src="http://ghbtns.com/github-btn.html?user=GeorgeHahn&amp;amp;type=follow&amp;amp;count=true&amp;amp;size=large" height="30" width="240" frameborder="0" scrolling="0">&lt;/iframe>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
What's also cool about this project is that it's the first project that someone's told me about that uses &lt;a title="SharpShell" href="https://sharpshell.codeplex.com/" target="_blank">SharpShell&lt;/a>. Many people have got in touch with me about SharpShell (in fact, &lt;a title="SharpShell Context Menus on the CodeProject" href="http://www.codeproject.com/Articles/512956/NET-Shell-Extensions-Shell-Context-Menus" target="_blank">the SharpShell Context Menus article on the CodeProject&lt;/a> is very popular), but so far this is the first real-world project where the writer got in touch after the project is completed.
&lt;p>Thanks George, I look forward to seeing what else you're working on!&lt;/p></description><category>CodeProject</category></item><item><title>Visual Studio Deployment Projects - an Update</title><link>https://dwmkerr.com/visual-studio-deployment-projects-an-update/</link><pubDate>Mon, 24 Jun 2013 12:18:18 +0000</pubDate><guid>https://dwmkerr.com/visual-studio-deployment-projects-an-update/</guid><description>&lt;p>I received the following message in my inbox the other day:&lt;/p>
&lt;p>&amp;lsquo;[Uservoice declined - Bring back the basic setup and deployment project type Visual Studio Installer.&amp;rsquo;&lt;/p>
&lt;p>Some readers may recall my post on the frustrating &lt;a title="Deployment Projects in Visual Studio 2012" href="http://www.dwmkerr.com/2012/12/deployment-projects-in-visual-studio-2012/">removal of the simple deployment project from Visual Studio&lt;/a>. Unfortunately, with this message, they have closed the Uservoice request to bring back the basic setup projects (the request is at &lt;a href="http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-">&lt;a href="http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-">http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-&lt;/a>&lt;/a>).&lt;/p>
&lt;p>It's rare for me to blog or comment on products like visual studio, to complain or evangelise about features and so on, but in this case as the previous post had received some interest I thought I'd write an update.&lt;/p>
&lt;p>It's extremely frustrating for developers to have features like this removed from our toolkit. Is it fair to call it our toolkit? Perhaps not, but this is an extremely expensive product, we pay a lot of money for it and it's a product that evolves in a sense based on what &lt;strong>we &lt;/strong>do. As we start developing more and more web based applications, the product evolves in that area. As we develop less in other areas, features are no longer invested in. This is all fair enough.&lt;/p>
&lt;p>However, it is difficult to keep your customers happy when a simple and extremely useful feature is removed, and replaced with essentially a cross sell link to another product. In fact, let's look at this and really state what the problem is.&lt;/p>
&lt;p>&lt;strong>We've paid a hell of a lot of money for a feature rich toolkit, that can cope with diverse development requirements. An element we've used for years has been removed without explanation and replaced with an advert for an expensive alternative.&lt;/strong>&lt;/p>
&lt;p>I doubt very much the deployment project was a difficult or expensive one to maintain. In fact, its simplicity is one of the reasons it was popular. So most of us are thinking that a working, heavily used feature has been &lt;strong>deliberately &lt;/strong>removed. Why? To sell another product. This sort of mercenary behaviour is not appealing to us as customers.&lt;/p>
&lt;p>I would end this post by saying that us computer nerds are fickle and highly strung about things like this. If we feel we're getting screwed over, we're likely to move to alternative products.&lt;/p>
&lt;p>This indifference to customer opinion is rather worrying. (This was the &lt;strong>second highest voted item in Visual Studio Uservoice&lt;/strong>). It also seems to not be isolated. Many customers seem deeply disenchanted with decisions taken in Windows 8, these concerns have been raised and roundly ignored.&lt;/p>
&lt;p>I'm not going to go on any more about this, the comments and posts have been made, the requests ignored.&lt;/p>
&lt;p>But I will say that if you have a online system to collect user feedback and requests for features for a product as expensive as Visual Studio, a request in the top three is for you to &lt;em>bring back something you've removed&lt;/em> to get a kickback from Flexera, and you ignore the request, then don't bother asking for feedback, because it feels like a middle finger to your customers.&lt;/p></description><category>CodeProject</category></item><item><title>Web Deploy - Could not connect to the remote computer</title><link>https://dwmkerr.com/publish-web-web-deploy/</link><pubDate>Wed, 19 Jun 2013 09:22:06 +0000</pubDate><guid>https://dwmkerr.com/publish-web-web-deploy/</guid><description>&lt;p>Using Web Deploy is a nice and easy way to publish websites and web applications with Visual Studio. However, I found one thing that can be a bit of a blocker, that didn't seem to be explained anywhere very well.&lt;/p>
&lt;p>Let's imagine I administer a webserver that hosts the site &lt;a href="http://www.something.com">www.something.com&lt;/a>. I've installed the Remote Management tools for IIS and the Web Deploy stuff, and have also configured the site to allow Web Deploy. I now try and deploy using Visual Studio, with the settings below:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/somesite.jpg">&lt;img src="images/somesite.jpg" alt="somesite" width="600" />&lt;/a>&lt;/p>
&lt;p>Validating the connection fails with the message:&lt;/p>
&lt;p>&lt;em>'Could not connect to the remote computer &amp;ldquo;somesite.com&amp;rdquo;. On the remote computer, make sure that Web Deploy is installed and that the required process (&amp;ldquo;Web Management Process&amp;rdquo;) is started. [more stuff] ERROR_DESTINATION_NOT_REACHABLE.&lt;/em>&lt;/p>
&lt;p>So what do we try first?&lt;/p>
&lt;ul>
&lt;li>&lt;span style="line-height: 14px;">Check the Web Deploy feature is installed on the server, it is.&lt;/span>&lt;/li>
&lt;li>Check the Web Management Process is running, it is.&lt;/li>
&lt;li>Check port 8172 is open, it is.&lt;/li>
&lt;li>Read up on similar issues, they say the same as the above.&lt;/li>
&lt;/ul>
I spent quite some time pulling my hair out over this - is it because I'm on a different domain? Is there some other port that needs to be open too?
&lt;p>Now the error says &amp;lsquo;could not connect to the remote computer &amp;ldquo;somesite.com&amp;rdquo;&amp;rsquo; - so maybe the issue is here. I try the IP address, &lt;a href="http://www.somesite.com">www.somesite.com&lt;/a> and the IP address with the port 8172 specified - no joy.&lt;/p>
&lt;p>It turns out, that even though it says &amp;lsquo;Server&amp;rsquo; in the first box (leading us to think it would be the address of a server we need), it's actually the server &lt;strong>with http &lt;/strong>specified. Change the Server from &lt;strong>somesite.com &lt;/strong>to &lt;b>&lt;a href="http://www.somesite.com">http://www.somesite.com&lt;/a> &lt;/b>and it works a charm.&lt;/p>
&lt;p>Not the most exciting post ever, but hopefully this'll save someone else wasting the same amount of time that I did.&lt;/p></description><category>CodeProject</category></item><item><title>Build Buttons for Facebook, Twitter, LinkedIn, GitHub and More!</title><link>https://dwmkerr.com/build-buttons-for-facebook-twitter-linkedin-github-and-more/</link><pubDate>Tue, 18 Jun 2013 02:34:59 +0000</pubDate><guid>https://dwmkerr.com/build-buttons-for-facebook-twitter-linkedin-github-and-more/</guid><description>&lt;p>Recently I've been working on a small project called &lt;a title="Build Buttons" href="http://www.buildbuttons.com" target="_blank">Build Buttons&lt;/a>. &lt;a title="Build Buttons" href="http://www.buildbuttons.com" target="_blank">Build Buttons&lt;/a> is a website that let's you quickly create buttons for sharing and promoting content. You can use Build Buttons to create Facebook &amp;lsquo;Like&amp;rsquo; or &amp;lsquo;Follow&amp;rsquo; buttons, LinkedIn &amp;lsquo;Share&amp;rsquo; buttons, Google +1 buttons, GitHub Star, Fork and Follow buttons and more. Here's how it works.&lt;/p>
&lt;p>First, go to &lt;a title="Build Buttons" href="http://www.buildbuttons.com" target="_blank">&lt;a href="http://www.buildbuttons.com">www.buildbuttons.com&lt;/a>&lt;/a>:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/buildbuttons.jpg">&lt;img src="images/buildbuttons.jpg" alt="Build Buttons" width="800" />&lt;/a>&lt;/p>
&lt;p>Now choose the kind of buttons you want, in this example we'll select &amp;lsquo;Social Media&amp;rsquo; from the top menu:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/socialmedia.jpg">&lt;img src="images/socialmedia.jpg" alt="Social Media Buttons" width="800" />&lt;/a>&lt;/p>
&lt;p>On each category page, there's a list of the different types of buttons that can be built. Social Media includes the &amp;lsquo;Share&amp;rsquo; button set. Click &amp;lsquo;Build It!':&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/sharebuttons.jpg">&lt;img src="images/sharebuttons.jpg" alt="Social Media Button Settings" width="733" />&lt;/a>&lt;/p>
&lt;p>Now just fill in the details to customise your buttons, enter a URL and select the sort of buttons you want to include. When you're ready to see how your buttons look, choose &amp;lsquo;Build it!':&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/results.jpg">&lt;img src="images/results.jpg" alt="Build Buttons Results" width="597" />&lt;/a>&lt;/p>
&lt;p>You get a working preview of how your buttons look, and a text box that includes the HTML you need to drop into your webpage or blog, easy!&lt;/p>
&lt;p>Build Buttons has quite a few different types of buttons you can create. You can:&lt;/p>
&lt;ul>
&lt;li>&lt;span style="line-height: 14px;">Create a set of social media buttons&lt;/span>&lt;/li>
&lt;li>Create Facebook Like and Follow buttons&lt;/li>
&lt;li>Create Google +1 buttons&lt;/li>
&lt;li>Create LinkedIn Share buttons&lt;/li>
&lt;li>Create GitHub Star, Follow and Fork buttons&lt;/li>
&lt;/ul></description><category>CodeProject</category></item><item><title>WPF and Visual Studio Addins</title><link>https://dwmkerr.com/wpf-and-visual-studio-addins/</link><pubDate>Wed, 12 Jun 2013 01:36:18 +0000</pubDate><guid>https://dwmkerr.com/wpf-and-visual-studio-addins/</guid><description>&lt;p>If at all possible nowadays, I write all my Windows UI code in WPF, it's just quicker and easier than WinForms. Recently however, I came across a situation that you should just avoid.&lt;/p>
&lt;p>If you're developing addins for multiple versions of Visual Studio - don't use WPF for the Tools &amp;gt; Options windows. It's just noit going to place nice out of the box. This is because there's a lot of property page Win32 stuff going on in the host window that makes it hard to route messages properly - keyboard entry won't work correctly, tab order will be messed up and more, it's just not worth the pain.&lt;/p>
&lt;p>If you're developing addins for later versions of Visual Studio, you can actually use the VSPackage functionality to build options pages with WPF with ease, just check &lt;a href="http://msdn.microsoft.com/en-us/library/microsoft.visualstudio.shell.uielementdialogpage.aspx" target="_blank">UIElementDialogPage&lt;/a>. In fact, read the article here:&lt;/p>
&lt;p>&lt;a title="Creating Option Pages by using MPF" href="http://msdn.microsoft.com/en-us/library/bb165039.aspx" target="_blank">Creating Options Pages by using MPF &lt;/a>&lt;/p>
&lt;p>Final thoughts on this - if you want the functionality above in VS2010, you can get it (as long as you use MPF) by checking this page:&lt;/p>
&lt;p>&lt;a href="http://social.msdn.microsoft.com/Forums/en-US/vsx/thread/6af9718e-8778-4233-875d-b38c03e9f4ba" target="_blank">Unable to access WPF User Control in Options Dialog&lt;/a>&lt;/p>
&lt;p>You'll see that about halfway down, Ryan Moulden has posted some code from Microsoft for the UIElementDialogPage, you can use that you get the functionality in VS2010.&lt;/p>
&lt;p>Any other versions, or for a addin installed by an MSI, it's probably best to stick with WinForms.&lt;/p>
&lt;p> &lt;/p></description><category>CodeProject</category></item><item><title>Introducing Sil</title><link>https://dwmkerr.com/introducing-sil/</link><pubDate>Wed, 05 Jun 2013 15:35:39 +0000</pubDate><guid>https://dwmkerr.com/introducing-sil/</guid><description>&lt;p>For the last few weeks I've been trying to tie up a project I've been working on for a while called Sil. With lots of other things on my plate at the moment I haven't had much of a chance to work on it, but finally tonight I'm able to release the first version.&lt;/p>
&lt;p>Sil is short for &amp;lsquo;See IL&amp;rsquo;, or &amp;lsquo;See Intermediate Language&amp;rsquo;. It's primarily an addin for Visual Studio (2010 and 2012) that lets you right click on some code and disassemble it.&lt;/p>
&lt;p>I think it can be very useful sometimes to see what's going on in the code your writing, and searching for ildasm (which Sil actually uses itself) slows me down - I want to disassembly right from Visual Studio, and I want the results side-by-side with my original code.&lt;/p>
&lt;p>Here's a screenshot of how the code editor looks after I've just right clicked on a method and chosen &amp;lsquo;Disassemble&amp;rsquo;:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/06/ResultSized.png">&lt;img src="images/ResultSized.png" alt="ResultSized" width="640" />&lt;/a>&lt;/p>
&lt;p>It's not too shabby - syntax highlighting and a few options to see more detail. As I've disassembled a method, from the bottom of the window I can also expand the scope to the parent class or the whole assembly.&lt;/p>
&lt;p>Under the hood, Sil uses ildasm to disassemble the entire assembly, then parses it into a set of &amp;lsquo;DisassembledEntity&amp;rsquo; objects (which can be DisassembedClass, DisassembedEnumeration and so on). A little bit of WPF for the UI and the great AvalonEdit control and that's all there is too it. As you might expect, the bulk of the complexity is in the code to parse the disassembly into logical entities.&lt;/p>
&lt;p>You can get the Sil installer from the &lt;a title="Sil" href="http://www.dwmkerr.com/sil/">Sil page&lt;/a> on this site. You can also head to the CodeProject and take a look at the article I've just written &amp;lsquo;&lt;a title="See the Intermediate Language for C# Code" href="http://www.codeproject.com/Articles/602648/See-the-Intermediate-Language-for-Csharp-Code">See the Intermediate Language for C# Code'&lt;/a>.&lt;/p>
&lt;p>I think with this project, rather than using CodePlex (as I've done for Apex, SharpGL and some others) I'm going to go for GitHub to mix things up a bit. Watch this space for news on the source code going online - if you're keen for a look, it's also in the CodeProject article.&lt;/p></description><category>CodeProject</category></item><item><title>Creating Addins - 'An error occurred, and the wizard could not generate the project.'</title><link>https://dwmkerr.com/creating-addins-an-error-occurred-and-the-wizard-could-not-generate-the-project/</link><pubDate>Mon, 13 May 2013 02:38:34 +0000</pubDate><guid>https://dwmkerr.com/creating-addins-an-error-occurred-and-the-wizard-could-not-generate-the-project/</guid><description>&lt;p>When doing a little bit of work on a solution that contains a Visual Studio Addin the other day, I noticed that there's a little bit of an issue with Visual Studio. If you create an addin project and you get the message:&lt;/p>
&lt;p>&lt;em>An error occurred, and the wizard could not generate the project. Verify that the programming language is properly installed.&lt;/em>&lt;/p>
&lt;p>Then double check &lt;em>where &lt;/em>you are creating your addin. If it is in a child folder of the solution, then this error can occur. The solution - add the addin project to the solution root. Then if you need to, you can move it afterwards.&lt;/p>
&lt;p>This issue occurs in Visual Studio 2012, but a bit of googling suggests that it may also be an issue in 2010.&lt;/p></description><category>CodeProject</category></item><item><title>Getting Paths for Files in NUnit Tests</title><link>https://dwmkerr.com/getting-paths-for-files-in-nunit-tests/</link><pubDate>Thu, 02 May 2013 05:22:45 +0000</pubDate><guid>https://dwmkerr.com/getting-paths-for-files-in-nunit-tests/</guid><description>&lt;p>When using NUnit, sometimes you will want to access files in the test project. These might be xml files with data, assembly references or whatever. Now typically, NUnit will actually copy the files it thinks it needs into a temporary location. This causes the problem that you can then do things like use a relative path to get files in the project. You can use manifest resource streams but sometimes this just isn't suitable.&lt;/p>
&lt;p>To get the path of the root of your test project, you can use the snippet below. Make sure you call it in a unit test fixture that's actually in your test project, not from a class referenced in another project!&lt;/p>
&lt;p>This class, &amp;lsquo;TestHelper&amp;rsquo; can be included in a Unit Test project to let you quickly get the path to the test project.&lt;/p>
&lt;p>[code lang=&amp;quot;csharp&amp;rdquo;]public static class TestHelper
{
public static string GetTestsPath()
{
return Path.GetDirectoryName(Assembly.GetExecutingAssembly().CodeBase).Replace(@&amp;quot;file:&amp;amp;quot;, string.Empty);
}
}[/code]&lt;/p></description><category>CodeProject</category></item><item><title>Introducing FireKeys</title><link>https://dwmkerr.com/introducing-firekeys/</link><pubDate>Mon, 11 Mar 2013 11:11:29 +0000</pubDate><guid>https://dwmkerr.com/introducing-firekeys/</guid><description>&lt;p>I don't know when I learnt that Windows + E opened up Windows Explorer. It must have been a while ago. But it's imprinted in my muscle memory, the number of times I hit that combo every day is probably quite high. But how many other hotkeys do I use? Asides from a few other functional ones, like Win + D, I don't use hotkeys so much. And I got to thinking, I'd love to open Google Chrome with a hotkey just like I do with explorer.&lt;/p>
&lt;p>So I wrote FireKeys - a lightweight application that lets you assign hotkeys to actions. These actions could be opening program, a folder or a URL, but the underlying model is designed to be extensible.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/wp-content/uploads/2013/03/FireKeysMain.jpg">&lt;img src="images/FireKeysMain.jpg" alt="FireKeysMain" width="600" />&lt;/a>&lt;/p>
&lt;p>You can get the tool from the &lt;a title="FireKeys" href="http://www.dwmkerr.com/firekeys/">FireKeys&lt;/a> page. There's an article on how it was developed on the CodeProject, &lt;a href="http://www.codeproject.com/Articles/559500/FireKeys-Open-Programs-Folders-or-URLs-with-Hot-Ke">FireKeys - Open Programs, Folders and URLs with Hot Keys&lt;/a>.&lt;/p></description><category>CodeProject</category></item><item><title>Spider Solitaire and Augmented Reality</title><link>https://dwmkerr.com/spider-solitaire-and-augmented-reality/</link><pubDate>Mon, 25 Feb 2013 16:16:20 +0000</pubDate><guid>https://dwmkerr.com/spider-solitaire-and-augmented-reality/</guid><description>&lt;p>A while ago, I made an implementation of Solitaire and Spider Solitaire using WPF and my Apex MVVM library. I wrote about it on the CodeProject, in an article called &lt;a title="Solitaire and Spider Solitaire for WPF" href="http://www.codeproject.com/Articles/252152/Solitaire-and-Spider-Solitaire-for-WPF">Solitaire and Spider Solitaire for WPF&lt;/a> (imaginative title indeed).&lt;/p>
&lt;p>Anyway, just recently I got a very interesting message from rupam rupam, who has made an augmented reality version of the project! In his application, you use your webcam to play the game physically by picking up cards with gestures. Other gestures, like thumbs up and thumbs down are bound to commands in the game - here's a screenshot:&lt;/p>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=wCOjuPdBooI">&lt;img src="images/SpiderAugmented.jpg" alt="SpiderAugmented" />&lt;/a>&lt;/p>
&lt;p>The project is called GesCard and as far as I know there isn't a page showing the code - but there are more links on the YouTube video for the page. Check out the YouTube video with the link here &lt;a href="https://www.youtube.com/watch?v=wCOjuPdBooI">&lt;a href="https://www.youtube.com/watch?v=wCOjuPdBooI">https://www.youtube.com/watch?v=wCOjuPdBooI&lt;/a>&lt;/a>. Thanks to rupam for getting in touch and sharing this very cool code!&lt;/p>
&lt;p> &lt;/p></description><category>CodeProject</category></item><item><title>Switch Updated</title><link>https://dwmkerr.com/switch-updated/</link><pubDate>Sat, 16 Feb 2013 14:43:08 +0000</pubDate><guid>https://dwmkerr.com/switch-updated/</guid><description>&lt;p>There have been some problems with the version of Switch uploaded to the Visual Studio Gallery. I've created a new version of Switch (1.4) and uploaded this - it works fine now, for Visual Studio 2008, 2010 and 2012.&lt;/p>
&lt;p>You can find out more about this extension on the &lt;a title="Switch" href="http://www.dwmkerr.com/switch/">Switch Page&lt;/a>.&lt;/p></description><category>CodeProject</category></item><item><title>The Visual Studio Experimental Instance</title><link>https://dwmkerr.com/the-visual-studio-experimental-instance/</link><pubDate>Sat, 16 Feb 2013 14:41:27 +0000</pubDate><guid>https://dwmkerr.com/the-visual-studio-experimental-instance/</guid><description>&lt;p>Working on some addins lately has taught me a few really useful tricks about debugging in Visual Studio. I'll update this post over time.&lt;/p>
&lt;p>&lt;strong>The Experimental Instance&lt;/strong>&lt;/p>
&lt;p>Very useful to know - the experimental instance loads its extensions from a special folder, and debugging extensions drops them there. The location is:&lt;/p>
&lt;p>%UserProfile%\AppData\Local\Microsoft\VisualStudio\10.0Exp\Extensions\&lt;/p></description><category>CodeProject</category></item><item><title>Creating Info Tip Handlers with .NET</title><link>https://dwmkerr.com/creating-info-tip-handlers-with-net/</link><pubDate>Mon, 14 Jan 2013 03:47:44 +0000</pubDate><guid>https://dwmkerr.com/creating-info-tip-handlers-with-net/</guid><description>&lt;p>I have just added an article to the CodeProject that discusses how to create Info Tip shell extensions in .NET. These extensions are used by the shell to customise the tooltips shown over shell items.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/2013/01/creating-info-tip-handlers-with-net/shellinfotiphandler/" rel="attachment wp-att-210">&lt;img src="images/ShellInfoTipHandler.png" alt="ShellInfoTipHandler" width="385" />&lt;/a>&lt;/p>
&lt;p>The article shows how you can use &lt;a title="SharpShell on CodePlex" href="http://sharpshell.codeplex.com">SharpShell &lt;/a>to very quickly create these extensions, you can find it at: &lt;a title="Shell Info Tip Handlers" href="http://www.codeproject.com/Articles/527058/NET-Shell-Extensions-Shell-Info-Tip-Handlers">&lt;a href="http://www.codeproject.com/Articles/527058/NET-Shell-Extensions-Shell-Info-Tip-Handlers">http://www.codeproject.com/Articles/527058/NET-Shell-Extensions-Shell-Info-Tip-Handlers&lt;/a>&lt;/a>.&lt;/p>
&lt;p>So just how easy does SharpShell make creating Shell Info Tip Handlers? The answer is pretty easy indeed. The code below shows the &lt;strong>full &lt;/strong>implementation of a Shell Info Tip Handler that changes the tooltips for folders to show the name of the folder and the number of items it contains:&lt;/p>
&lt;p>[csharp]/// &amp;lt;summary&amp;gt;
/// The FolderInfoTip handler is an example SharpInfoTipHandler that provides an info tip
/// for folders that shows the number of items in the folder.
/// &amp;lt;/summary&amp;gt;
[ComVisible(true)]
[COMServerAssociation(AssociationType.Directory)]
public class FolderInfoTipHandler : SharpInfoTipHandler
{
/// &amp;lt;summary&amp;gt;
/// Gets info for the selected item (SelectedItemPath).
/// &amp;lt;/summary&amp;gt;
/// &amp;lt;param name=&amp;quot;infoType&amp;quot;&amp;gt;Type of info to return.&amp;lt;/param&amp;gt;
/// &amp;lt;param name=&amp;quot;singleLine&amp;quot;&amp;gt;if set to &amp;lt;c&amp;gt;true&amp;lt;/c&amp;gt;, put the info in a single line.&amp;lt;/param&amp;gt;
/// &amp;lt;returns&amp;gt;
/// Specified info for the selected file.
/// &amp;lt;/returns&amp;gt;
protected override string GetInfo(RequestedInfoType infoType, bool singleLine)
{
// Switch on the tip of info we need to provide.
switch (infoType)
{
case RequestedInfoType.InfoTip:&lt;/p>
&lt;pre>&lt;code> // Format the formatted info tip.
return string.Format(singleLine
? &amp;amp;quot;{0} - {1} Items&amp;amp;quot;
: &amp;amp;quot;{0}&amp;amp;quot; + Environment.NewLine + &amp;amp;quot;Contains {1} Items&amp;amp;quot;,
Path.GetFileName(SelectedItemPath), Directory.GetFiles(SelectedItemPath).Length);
case RequestedInfoType.Name:
// Return the name of the folder.
return string.Format(&amp;amp;quot;Folder '{0}'&amp;amp;quot;, Path.GetFileName(SelectedItemPath));
default:
// We won't be asked for anything else, like shortcut paths, for folders, so we
// can return an empty string in the default case.
return string.Empty;
}
}
&lt;/code>&lt;/pre>
&lt;p>} [/csharp]&lt;/p>
&lt;p>As you can see, all of the COM interfaces are hidden away and handled for you, there is no ugly pinvoke code and no use of strange structures imported from Win32. SharpShell handles all of the plumbing for you.&lt;/p></description><category>CodeProject</category></item><item><title>SharpShell</title><link>https://dwmkerr.com/sharpshell/</link><pubDate>Tue, 08 Jan 2013 16:28:05 +0000</pubDate><guid>https://dwmkerr.com/sharpshell/</guid><description>&lt;p>SharpShell is a project that I have recently uploaded to CodePlex. This class library, and set of tools and samples, is designed to be a framework to enable rapid development of Shell Extensions using the .NET Framework. In time it may grow to contain some functionality for using Shell entities within managed applications (for example, allowing an Explorer context menu to be built dynamically for a given path).&lt;/p>
&lt;p>Anyway, the code is all at &lt;a title="SharpShell on CodePlex" href="http://sharpshell.codeplex.com" target="_blank">sharpshell.codeplex.com&lt;/a>. You can also see a nice article on the CodeProject that show's how to create a Shell Context Menu Extension using C#, the article is at: &lt;a title=".NET Shell Extensions - Shell Context Menus" href="http://www.codeproject.com/Articles/512956/NET-Shell-Extensions-Shell-Context-Menus" target="_blank">.NET Shell Extensions - Shell Context Menus&lt;/a>.&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/2013/01/sharpshell/screenshot1_exampleiconhandler/" rel="attachment wp-att-200">&lt;img src="images/Screenshot1_ExampleIconHandler.png" alt="Screenshot1_ExampleIconHandler" width="515" />&lt;/a>&lt;/p>
&lt;p>&lt;em>Above: An example of a Managed Shell Extension. This sample colours the icons for dlls differently, depending on whether they are native dlls or assemblies.&lt;/em>&lt;/p>
&lt;p>So far, in the repo on CodePlex there are also samples for Shell Icon Handlers (which customise icons in Explorer) and Shell Info Tip Handlers (which customise tooltips). Both of these extension types are fully supported in the current dev version and will be released in the next few days. There's also a partially functioning Shell Property Sheet implementation which will be delivered in the subsequent version. The Shell Property Sheet introduces some particularly strange code - 32 and 64 bit C++ dlls are embedded as manifest resource streams and extracted as needed to provide access to C++ function pointers - ouch.&lt;/p>
&lt;p>More to follow - check out the project and the article.&lt;/p></description><category>CodeProject</category></item><item><title>SharpGL 2.1</title><link>https://dwmkerr.com/sharpgl-2-1/</link><pubDate>Sun, 30 Dec 2012 08:06:32 +0000</pubDate><guid>https://dwmkerr.com/sharpgl-2-1/</guid><description>&lt;p>For those who are interested, I'm now starting development of SharpGL 2.1. SharpGL 2.1 will primarily be a release to implement features and fix bugs that users have added to the Codeplex site. The actual features and bugs that'll be sorted are on the CodePlex site - just search for release &amp;lsquo;SharpGL 2.1&amp;rsquo;.&lt;/p>
&lt;p>This will also be the first release of SharpGL that will be published on Nuget.&lt;/p></description><category>CodeProject</category></item><item><title>Visual Studio Extensions and Menu Subitems</title><link>https://dwmkerr.com/visual-studio-extensions-and-menu-subitems/</link><pubDate>Sat, 15 Dec 2012 00:21:48 +0000</pubDate><guid>https://dwmkerr.com/visual-studio-extensions-and-menu-subitems/</guid><description>&lt;p>Recently I was working on a Visual Studio Extension for VS2010, instead of a single item in the the tools menu, what I wanted was a single item with a set of child items.&lt;/p>
&lt;p>Strangely enough, documentation on this is quite lacking. So if you need to know how to do it, here's the gist. First, create a standard Visual Studio 2010 extension with the wizard, we'll have some code like the below to start off with, in the OnConnection function:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#66d9ef">object&lt;/span> []contextGUIDS = &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#66d9ef">object&lt;/span>[] { };
Commands2 commands = (Commands2)_applicationObject.Commands;
&lt;span style="color:#66d9ef">string&lt;/span> toolsMenuName = &amp;amp;quot;Tools&amp;amp;quot;;
&lt;span style="color:#75715e">//Place the command on the tools menu.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//Find the MenuBar command bar, which is the top-level command bar holding all the main menu items:
&lt;/span>&lt;span style="color:#75715e">&lt;/span>Microsoft.VisualStudio.CommandBars.CommandBar menuBarCommandBar = ((Microsoft.VisualStudio.CommandBars.CommandBars)_applicationObject.CommandBars)[&amp;amp;quot;MenuBar&amp;amp;quot;];
&lt;span style="color:#75715e">//Find the Tools command bar on the MenuBar command bar:
&lt;/span>&lt;span style="color:#75715e">&lt;/span>CommandBarControl toolsControl = menuBarCommandBar.Controls[toolsMenuName];
CommandBarPopup toolsPopup = (CommandBarPopup)toolsControl;
&lt;span style="color:#75715e">//This try/catch block can be duplicated if you wish to add multiple commands to be handled by your Add-in,
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// just make sure you also update the QueryStatus/Exec method to include the new command names.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">try&lt;/span>
{
&lt;span style="color:#75715e">//Add a command to the Commands collection:
&lt;/span>&lt;span style="color:#75715e">&lt;/span> Command command = commands.AddNamedCommand2(_addInInstance, &amp;amp;quot;MyCommand&amp;amp;quot;, &amp;amp;quot;MyCommand&amp;amp;quot;,
&amp;amp;quot;Executes the command &lt;span style="color:#66d9ef">for&lt;/span> MyCommand&amp;amp;quot;, &lt;span style="color:#66d9ef">true&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#66d9ef">ref&lt;/span> contextGUIDS,
(&lt;span style="color:#66d9ef">int&lt;/span>)vsCommandStatus.vsCommandStatusSupported + (&lt;span style="color:#66d9ef">int&lt;/span>)vsCommandStatus.vsCommandStatusEnabled,
(&lt;span style="color:#66d9ef">int&lt;/span>)vsCommandStyle.vsCommandStylePictAndText, vsCommandControlType.vsCommandControlTypeButton);
&lt;span style="color:#75715e">//Add a control for the command to the tools menu:
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>((command != &lt;span style="color:#66d9ef">null&lt;/span>) &amp;amp;amp;&amp;amp;amp; (toolsPopup != &lt;span style="color:#66d9ef">null&lt;/span>))
{
command.AddControl(toolsPopup.CommandBar, &lt;span style="color:#ae81ff">1&lt;/span>);
}
}
&lt;span style="color:#66d9ef">catch&lt;/span>(System.ArgumentException)
{
&lt;span style="color:#75715e">//If we are here, then the exception is probably because a command with that name
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// already exists. If so there is no need to recreate the command and we can
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// safely ignore the exception.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now what we're going to do first, is change the code so that we don't actually add a Command named MyCommand, but instead a popup:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#75715e">//This try/catch block can be duplicated if you wish to add multiple commands to be handled by your Add-in,
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">// just make sure you also update the QueryStatus/Exec method to include the new command names.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">try&lt;/span>
{
&lt;span style="color:#75715e">// Have we got the tools popup?
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span>(toolsPopup != &lt;span style="color:#66d9ef">null&lt;/span>)
{
&lt;span style="color:#75715e">// Create &amp;#39;MyCommand&amp;#39; as a popup.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> popup = (CommandBarPopup)toolsPopup.Controls.Add(MsoControlType.msoControlPopup);
popup.Caption = &amp;amp;quot;MyCommand&amp;amp;quot;;
}
}
&lt;span style="color:#66d9ef">catch&lt;/span>(System.ArgumentException)
{
&lt;span style="color:#75715e">//If we are here, then the exception is probably because a command with that name&amp;amp;lt;br /&amp;amp;gt;
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// already exists. If so there is no need to recreate the command and we can&amp;amp;lt;br /&amp;amp;gt;
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// safely ignore the exception.
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now that we have the popup object, we can create commands and add them to the popup instead:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#75715e">// Have we got the tools popup?
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">if&lt;/span>(toolsPopup != &lt;span style="color:#66d9ef">null&lt;/span>)
{
&lt;span style="color:#75715e">// Create &amp;#39;MyCommand&amp;#39; as a popup.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> popup = (CommandBarPopup)toolsPopup.Controls.Add(MsoControlType.msoControlPopup);
popup.Caption = &amp;amp;quot;MyCommand&amp;amp;quot;;
&lt;span style="color:#75715e">// Create sub item 1.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> subItem1Command = commands.AddNamedCommand2(_addInInstance, &amp;amp;quot;MyCommand1&amp;amp;quot;, &amp;amp;quot;My Command Subitem &lt;span style="color:#ae81ff">1&lt;/span>&amp;amp;quot;, &amp;amp;quot;My Command Subitem &lt;span style="color:#ae81ff">1&lt;/span>&amp;amp;quot;,
&lt;span style="color:#66d9ef">true&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#66d9ef">ref&lt;/span> contextGUIDS);
&lt;span style="color:#75715e">// Add it.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> subItem1Command.AddControl(popup.CommandBar, &lt;span style="color:#ae81ff">1&lt;/span>);
&lt;span style="color:#75715e">// Create sub item 2.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> subItem2Command = commands.AddNamedCommand2(_addInInstance, &amp;amp;quot;MyCommand2&amp;amp;quot;, &amp;amp;quot;My Command Subitem &lt;span style="color:#ae81ff">2&lt;/span>&amp;amp;quot;, &amp;amp;quot;My Command Subitem &lt;span style="color:#ae81ff">2&lt;/span>&amp;amp;quot;,
&lt;span style="color:#66d9ef">true&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>&lt;span style="color:#ae81ff">9&lt;/span>, &lt;span style="color:#66d9ef">ref&lt;/span> contextGUIDS);
&lt;span style="color:#75715e">// Add it.
&lt;/span>&lt;span style="color:#75715e">&lt;/span> subItem2Command.AddControl(popup.CommandBar, &lt;span style="color:#ae81ff">2&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now that we have made these changes, if we run the addin, we get a menu structure like this:&lt;/p>
&lt;img src="images/CommandSubitems.jpg" width="511" /></description><category>CodeProject</category></item><item><title>XPath Studio - First Cut</title><link>https://dwmkerr.com/xpath-studio-first-cut/</link><pubDate>Sun, 09 Dec 2012 16:11:27 +0000</pubDate><guid>https://dwmkerr.com/xpath-studio-first-cut/</guid><description>&lt;p>I have just uploaded the first cut of my mini-project &amp;lsquo;XPath Studio&amp;rsquo;. This project is a small site that lets you choose a URL to a source webpage, and run any XPath query against it - showing the data that is returned from the query.&lt;/p>
&lt;p>At the moment this blog has an issue with images so I cannot upload screenshots, but in the next few days they'll be there. Until then, you can try out XPath Studio by visiting:&lt;/p>
&lt;p>&lt;a title="XPath Studio" href="http://www.xpathstudio.com" target="_blank">&lt;a href="http://www.xpathstudio.com">www.xpathstudio.com&lt;/a>&lt;/a>&lt;/p>
&lt;p>The project is ASP .NET MVC 4, with Razor. I've stripped out the bulk of the styling that's provided by default, and layed it out with &lt;a title="Twitter Bootstrap" href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap&lt;/a>.&lt;/p>
&lt;p>This is the first time that I've used Bootstrap and already have decided that it'll be my first choice for web applications, at least those in the proof of concept phase. The library is lightweight, easy to use, clean and simple.&lt;/p>
&lt;p>More updates on XPath Studio will come over the next few days, as I tweak the core functionality based on feedback.&lt;/p></description><category>CodeProject</category></item><item><title>Deployment Projects in Visual Studio 2012</title><link>https://dwmkerr.com/deployment-projects-in-visual-studio-2012/</link><pubDate>Sun, 02 Dec 2012 05:40:28 +0000</pubDate><guid>https://dwmkerr.com/deployment-projects-in-visual-studio-2012/</guid><description>&lt;p>[Note: They aren't bringing setup projects back, see &lt;a href="http://www.dwmkerr.com/2013/06/visual-studio-deployment-projects-an-update/">&lt;a href="http://www.dwmkerr.com/2013/06/visual-studio-deployment-projects-an-update/">http://www.dwmkerr.com/2013/06/visual-studio-deployment-projects-an-update/&lt;/a>&lt;/a>]&lt;/p>
&lt;p>As part of Microsoft's ongoing campaign to reduce the usability of their tools for anyone who isn't working in exactly the way they want, Visual Studio 2012 no longer comes with the ability to create setup and deployment projects.&lt;/p>
&lt;p>This is a pretty serious change. For anyone who is developing client applications, then an installer is pretty critical. Now the feature set in the VS deployment projects was fairly small - they were aimed towards making pretty basic, lean installers. And that was &lt;em>fine&lt;/em>. That was what we needed it for. Installers for utility apps, installers for basic client applications, installers for testing out projects on other machines before we went to more advanced systems.&lt;/p>
&lt;p>What's truly disappointing is the lack of alternatives. Rather suspiciously there are links to InstallShield projects in Visual Studio now.&lt;/p>
&lt;p>If you've never worked with InstallShield before then I envy you. It is truly awful - a maintainance nightmare combined with a user interface that makes creating basic installers baffling.&lt;/p>
&lt;p>So Visual Studio now has no deployment projects. You can try using the free edition of InstallShield, but be ready for a world of pain. Also, considering the vast complexity of the UI, the free edition is &lt;em>incredibly &lt;/em>limited in functionality - for example you cannot create &amp;lsquo;features&amp;rsquo; (i.e. the chunks of functionality that you offer as an optional feature for an installation).&lt;/p>
&lt;p>&lt;strong>Example of Time Wasted&lt;/strong>&lt;/p>
&lt;p>My Switch addin for Visual Studio adds a button to the UI that lets you switch between related files (cpp/h, aspx/aspx.cs etc etc).&lt;/p>
&lt;p>I need to update it to work in Visual Studio 2012. I cannot develop VS 2012 addin projects in Visual Studio 2010. With a sigh I move the solution into 2012. I write the 2012 addin. The deployment project doesn't load (as expected). I build the binaries into specific locations. I open the project in 2010. The 2012 addin doesn't load (as expected). However, the setup project will not build due to an error when &amp;lsquo;updating dependencies&amp;rsquo;. This project has no dependencies - it builds from specific locations.&lt;/p>
&lt;p>So now to release a version of Switch that supports VS2012, I need to use InstallShield. InstallShield's free edition doesn't support features - therefore I have to install Switch for 2008, 2010 and 2012 for everyone, always, regardless of whether they have it. A two hour update is not looking possible now. I don't have the time to waste trying to &lt;strong>bring back functionality I already had&lt;/strong> and have to move onto other work.&lt;/p>
&lt;p>&lt;strong>Conclusion&lt;/strong>&lt;/p>
&lt;p>Thanks MS for removing this critical feature, and replacing it with an essentially useless and overly complicated alternative.&lt;/p>
&lt;p>Please remember, we've paid for Visual Studio - not for a vessel to host adverts to other products. We had the functionality before, now its gone - replaced by links to an expensive (and frankly crap) suite of tools that aren't suitable. Why has this happened? The cynical part of me thinks there's some kind of deal going on between MS and InstallShield (well of course there is), and we're suffering from it.&lt;/p>
&lt;p>Hit the uservoice page here: &lt;a href="http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-" target="_blank">&lt;a href="http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-">http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/3041773-bring-back-the-basic-setup-and-deployment-project-&lt;/a>&lt;/a> to try and vote for it to go back in.&lt;/p></description><category>CodeProject</category></item><item><title>Goodbye BlogEngine.NET, Hello WordPress</title><link>https://dwmkerr.com/goodbye-blogengine-net-hello-wordpress/</link><pubDate>Mon, 26 Nov 2012 09:04:10 +0000</pubDate><guid>https://dwmkerr.com/goodbye-blogengine-net-hello-wordpress/</guid><description>&lt;p>I run my websites on a Windows Server. Years ago, when I started web development, I ran almost exclusively on LAMP (Linux, Apache, MySQL, PHP) setups, which worked great for the sites I was building.&lt;/p>
&lt;p>As I got more involved in commercial development, most of the sites and services I was working on were C#, ASP, IIS and MSSQL Server focused. This is great for web development too.&lt;/p>
&lt;p>When I moved onto a new, Windows based server, I decided that as I was running MSSQL Server and IIS on it, I would move my personal blog onto an ASP based platform - for this I chose BlogEngine.NET.&lt;/p>
&lt;p>More than one year later, I've moved to WordPress if you're running sites that need some kind of content management system, it really is one of the best. With lots of support online, regular updates, plugins and themes, a WordPress site generally is easier to maintain and keep looking good than, for example, a BlogEngine .NET site.&lt;/p>
&lt;p>I've also been very impressed with how easy it is to integrate WordPress into existing sites I'm updating my site &lt;a href="http://www.childrenshomesnepal.org">http://www.childrenshomesnepal.org&lt;/a> to have a news section driven by WordPress and it's a breeze - just a little bit of PHP and the posts are there.&lt;/p>
&lt;p>The short message, so far I'm yet to see a better CMS than WordPress for day-to-day use. And that includes Drupal, which is powerful, but a bit of a nightmare to set up (and requires too much IT expertise from contributors to a site).&lt;/p></description><category>CodeProject</category></item><item><title>The GAC Manager</title><link>https://dwmkerr.com/the-gac-manager/</link><pubDate>Sun, 29 Jul 2012 08:44:00 +0000</pubDate><guid>https://dwmkerr.com/the-gac-manager/</guid><description>&lt;p>I have started a new project on CodePlex called 'GAC Manager'. This is a project that is in two parts, the first is a simple tool to allow users to manipulate their local global assembly cache, the second is an API that provides the core functionality.&lt;/p>
&lt;p>Here's a screenshot of the tool in its current state:&lt;/p>
&lt;p>&lt;img src="images/1_TheGacManagerTool.png" />&lt;/p>
&lt;p>An article on the project is available on the CodeProject at:&amp;nbsp;&lt;a href="http://www.codeproject.com/Articles/430568/A-GAC-Manager-Utility-and-API">http://www.codeproject.com/Articles/430568/A-GAC-Manager-Utility-and-API&lt;/a>&lt;/p>
&lt;p>The project itself is at:&amp;nbsp;&lt;a href="https://github.com/dwmkerr/gacmanager">https://github.com/dwmkerr/gacmanager&lt;/a>&lt;/p>
&lt;p>As always, comments, feature requests and so on are welcome!&lt;/p></description><category>CodeProject</category></item><item><title>Changing Merge/Compare Tools in TFS</title><link>https://dwmkerr.com/changing-mergecompare-tools-in-tfs/</link><pubDate>Thu, 21 Jun 2012 07:56:00 +0000</pubDate><guid>https://dwmkerr.com/changing-mergecompare-tools-in-tfs/</guid><description>&lt;p>Moving from SVN to TFS has been an interesting experience. The integration of source control directly into Visual Studio seems like a good thing, but even on a well set up network it can occasionally bring Visual Studio to its knees. And I still don't trust its automerge.&lt;/p>
&lt;p>Anyway, if you find that the TFS diff and merge tools are just too ugly and odd to work with, there's a great page on the MSDN blogs that describes how to set Visual Studio to use your preferred tool:&lt;/p>
&lt;p>&lt;a href="http://blogs.msdn.com/b/jmanning/archive/2006/02/20/diff-merge-configuration-in-team-foundation-common-command-and-argument-values.aspx">http://blogs.msdn.com/b/jmanning/archive/2006/02/20/diff-merge-configuration-in-team-foundation-common-command-and-argument-values.aspx&lt;/a>&lt;/p>
&lt;p>Welcome back TortoiseMerge, I've missed you.&lt;/p></description><category>CodeProject</category></item><item><title>Go Offline Extension for Visual Studio 2010</title><link>https://dwmkerr.com/go-offline-extension-for-visual-studio-2010/</link><pubDate>Mon, 18 Jun 2012 10:54:00 +0000</pubDate><guid>https://dwmkerr.com/go-offline-extension-for-visual-studio-2010/</guid><description>&lt;p>Such a useful extension that I just had to big it up - the Go Offline extension adds the following menu item:&lt;/p>
&lt;p>File&amp;gt;Source Control&amp;gt;Go Offline&lt;/p>
&lt;p>&lt;a href="http://visualstudiogallery.msdn.microsoft.com/425f09d8-d070-4ab1-84c1-68fa326190f4?SRC=Home">http://visualstudiogallery.msdn.microsoft.com/425f09d8-d070-4ab1-84c1-68fa326190f4?SRC=Home&lt;/a>&lt;/p>
&lt;p>If you use TFS in a big environment, sometimes this can save a stack of time. Thanks to Bernhard Tschirren for taking the time to write this and share it!&lt;/p></description><category>CodeProject</category></item><item><title>Apex Part 2 - Adding Commands to an MVVM Application</title><link>https://dwmkerr.com/apex-part-2-adding-commands-to-an-mvvm-application/</link><pubDate>Tue, 15 May 2012 07:43:00 +0000</pubDate><guid>https://dwmkerr.com/apex-part-2-adding-commands-to-an-mvvm-application/</guid><description>&lt;p>In Part 2 of my video tutorial series on using Apex I show you how you can add commands to an MVVM application. Commands let you rapidly add functionality to a ViewModel, whilst still maintaining separation from UI.&lt;/p>
&lt;p>&lt;iframe src="http://www.youtube.com/embed/wt7nncMNRG8" frameborder="0" width="420" height="315">&lt;/iframe>&lt;/p>
&lt;p>A CodeProject article to accompany this video will be published shortly.&lt;/p></description><category>CodeProject</category></item><item><title>Apex Part 1 - Getting Started with the Apex SDK</title><link>https://dwmkerr.com/apex-part-1-getting-started-with-the-apex-sdk/</link><pubDate>Mon, 23 Apr 2012 05:35:00 +0000</pubDate><guid>https://dwmkerr.com/apex-part-1-getting-started-with-the-apex-sdk/</guid><description>&lt;p>Create an MVVM application in minutes with the new Apex SDK!&lt;/p>
&lt;p>The video below shows this in action, see what you think.&lt;/p>
&lt;p>&lt;iframe src="http://www.youtube.com/embed/m4cx9w5fiwk" frameborder="0" width="420" height="315">&lt;/iframe>&lt;/p>
&lt;p>There is also an accompanying article that describes what's going on. As always, would love to hear feedback!&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/Articles/371217/Apex-Part-1-Create-Your-First-MVVM-Application">http://www.codeproject.com/Articles/371217/Apex-Part-1-Create-Your-First-MVVM-Application&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Come on MS - Improve MFC</title><link>https://dwmkerr.com/come-on-ms-improve-mfc/</link><pubDate>Thu, 19 Apr 2012 09:02:00 +0000</pubDate><guid>https://dwmkerr.com/come-on-ms-improve-mfc/</guid><description>&lt;p>Loads of developers still use MFC. OK - if you're writing a new project, MFC would not be a great choice. But what if you're maintaining a 1.5 million line MFC app?&amp;nbsp;&lt;/p>
&lt;p>MFC support in Visual Studio has barely improved since VC++ 6.0 - in fact its got worse. Their cursory attempt to show an effort by adding support for the Ribbon Control with the MFC feature pack was not enough. Why can we still not properly use tab controls in the dialog editor?&lt;/p>
&lt;p>Those who use MFC are probably supporting big enterprise applications - for a long time now we've been neglected. Please vote for more MFC support in Visual Studio Uservoice below:&lt;/p>
&lt;p>&lt;a href="http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2782934-improve-mfc">http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2782934-improve-mfc&lt;/a>&lt;/p>
&lt;p>Will they listen? Chances are not - unless lots of people vote. But I'd really like to see some effort on this, it's a technology still used by many.&lt;/p>
&lt;p>It would be interesting to see a survey of enterprise applications - and what they're written in. It'd be interesting to then compare this to how well MS support that platform. MS will put lots of efforts into what they &lt;em>think &lt;/em>that developers &lt;em>should &lt;/em>be using - but how well are they supporting their real customers who are creating real products?&lt;/p></description><category>CodeProject</category></item><item><title>Could not load file or assembly 'System.Windows, Version=2.0.5.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e' or one of its dependencies.</title><link>https://dwmkerr.com/could-not-load-file-or-assembly-system-windows-version2-0-5-0-cultureneutral-publickeytoken7cec85d7bea7798e-or-one-of-its-dependencies/</link><pubDate>Mon, 16 Apr 2012 07:55:00 +0000</pubDate><guid>https://dwmkerr.com/could-not-load-file-or-assembly-system-windows-version2-0-5-0-cultureneutral-publickeytoken7cec85d7bea7798e-or-one-of-its-dependencies/</guid><description>&lt;p>Are you getting the error below when working with Silverlight projects?&lt;/p>
&lt;pre>Could not load file or assembly 'System.Windows, Version=2.0.5.0, &lt;br />Culture=neutral, PublicKeyToken=7cec85d7bea7798e' or&lt;br /> one of its dependencies.&lt;/pre>
&lt;p>It's a bit of an odd one. The solution that works for me is to re-register System.Core and System.Windows in the GAC. Use the commands below.&lt;/p>
&lt;p>&lt;strong>32 Bit System&lt;/strong>&lt;/p>
&lt;p>"C:\Program Files\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools\gacutil" /i "C:\Program Files\Microsoft Silverlight\4.1.10111.0\System.Core.dll"&lt;br />"C:\Program Files\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools\gacutil" /i "C:\Program Files\Microsoft Silverlight\4.1.10111.0\System.Windows.dll"&amp;nbsp;&amp;nbsp;&lt;/p>
&lt;p>&lt;strong>64 Bit System&lt;/strong>&lt;/p>
&lt;p>"C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools\gacutil" /i "C:\Program Files\Microsoft Silverlight\4.1.10111.0\System.Core.dll"&lt;br />"C:\Program Files&amp;nbsp;(x86)\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools\gacutil" /i "C:\Program Files\Microsoft Silverlight\4.1.10111.0\System.Windows.dll"&amp;nbsp;&amp;nbsp;&lt;/p>
&lt;p>So far I am yet to understand why this happens - if anyone can shed any light please comment!&lt;/p></description><category>CodeProject</category></item><item><title>Create Item Templates in Visual Studio</title><link>https://dwmkerr.com/create-item-templates-in-visual-studio/</link><pubDate>Fri, 13 Apr 2012 06:29:00 +0000</pubDate><guid>https://dwmkerr.com/create-item-templates-in-visual-studio/</guid><description>&lt;p>Part 3 of my series on extending Visual Studio is now available on the CodeProject:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/Articles/365680/Extending-Visual-Studio-Part-3-Item-Templates">http://www.codeproject.com/Articles/365680/Extending-Visual-Studio-Part-3-Item-Templates&lt;/a>&lt;/p>
&lt;p>In this article we look at how to create new Item Templates in Visual Studio.&lt;/p></description><category>CodeProject</category></item><item><title>Embedding a Console in a C# application</title><link>https://dwmkerr.com/embedding-a-console-in-a-c-application/</link><pubDate>Tue, 28 Feb 2012 05:29:00 +0000</pubDate><guid>https://dwmkerr.com/embedding-a-console-in-a-c-application/</guid><description>&lt;p>I have uploaded a new article on the CodeProject - embedding a Console in a C# Application. Here's a screenshot of the control in use:&lt;/p>
&lt;p>&lt;img src="images/Screenshot_ConsoleControlSample.png" />&lt;/p>
&lt;p>As always, comments and suggestions are more than welcome - you can find the article here:&amp;nbsp;&lt;a href="http://www.codeproject.com/Articles/335909/Embedding-a-Console-in-a-C-Application?msg=4169170#xx4168613xx">http://www.codeproject.com/Articles/335909/Embedding-a-Console-in-a-C-Application&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Disabling Constraints with a Stored Procedure in Oracle</title><link>https://dwmkerr.com/disabling-constraints-with-a-stored-procedure-in-oracle/</link><pubDate>Fri, 24 Feb 2012 06:20:00 +0000</pubDate><guid>https://dwmkerr.com/disabling-constraints-with-a-stored-procedure-in-oracle/</guid><description>&lt;p>Sometimes you need to disable constraints on a Oracle Database. Why might this be? Well image the situation that you are exporting data into an intermediate schema, you only want to import data from a certain date range and due to this you have only a subset of the records. You need this subset for analysis but you don't care about referential integrity - in fact if it is on then constraints will be violated. How can we do this?&lt;/p>
&lt;p>Here's a stored procedure that disables constraints for tables owned by 'UserName1' or 'UserName2':&lt;/p>
&lt;pre>CREATE OR REPLACE PROCEDURE extraction.sp_PrepExtractionDatabase&amp;nbsp;&lt;/pre>
&lt;pre>AUTHID CURRENT_USER&lt;/pre>
&lt;pre>IS&amp;nbsp;&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; v_Statement VARCHAR(5000);&lt;/pre>
&lt;pre>BEGIN &amp;nbsp;&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; FOR const in (CURSOR c_Constraints IS&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; &amp;nbsp; SELECT constraint_name, table_name, owner&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; &amp;nbsp; FROM ALL_CONSTRAINTS&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; &amp;nbsp; WHERE owner IN ('UserName1', 'UserName2')) LOOP&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; &amp;nbsp; v_Statement := 'ALTER TABLE ' || const.owner &lt;br />|| '.' || const.table_name || ' DISABLE CONSTRAINT '&lt;br /> || const.constraint_name;&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; &amp;nbsp; EXECUTE IMMEDIATE v_Statement;&lt;/pre>
&lt;pre>&amp;nbsp; &amp;nbsp; END LOOP;&lt;/pre>
&lt;pre>END;&lt;/pre>
&lt;pre>/&lt;/pre>
&lt;p>What's the key thing here? 'AUTHID CURRENT_USER'. Without this, running the query itself will work fine, but the stored procedure will find NOTHING in the ALL_CONSTRAINTS view. Run in the context of the current user and then the stored procedure will work fine.&lt;/p></description><category>CodeProject</category></item><item><title>SharpGL 2.0</title><link>https://dwmkerr.com/sharpgl-2-0/</link><pubDate>Wed, 22 Feb 2012 03:42:00 +0000</pubDate><guid>https://dwmkerr.com/sharpgl-2-0/</guid><description>&lt;p>SharpGL 2.0 has been released - hit the GitHub site to get it:&amp;nbsp;&lt;a href="https://github.com/dwmkerr/sharpgl">https://github.com/dwmkerr/sharpgl&lt;/a>&lt;/p>
&lt;p>Some new features:&lt;/p>
&lt;ul>
&lt;li>Full support for all OpenGL functions up to OpenGL 4.2&lt;/li>
&lt;li>Full support for all commonly used OpenGL extensions&lt;/li>
&lt;li>Support for WinForms applications&lt;/li>
&lt;li>Support for WPF applications (without resorting to WinForms hosts)&lt;/li>
&lt;li>A powerful scene graph including polygons, shaders, NURBs and more&lt;/li>
&lt;li>Many sample applications as starting points for your own projects.&lt;/li>
&lt;li>Visual Studio Extension with SharpGL project templates for WPF and WinForms.&lt;/li>
&lt;/ul>
&lt;div>And a few screenshots:&lt;/div>
&lt;div>&amp;nbsp;&lt;/div>
&lt;div>&amp;nbsp;The Radial Blur Sample&lt;/div>
&lt;p>&lt;img src="images/RadialBlurSample.png" />&lt;/p>
&lt;p>The New Project Types&lt;/p>
&lt;p>&lt;img src="images/NewWpfApplication.png" />&lt;/p>
&lt;p>WPF Support&lt;/p>
&lt;p>&lt;img src="images/TeapotSample.png" />&lt;/p>
&lt;p>Text Rendering&lt;/p>
&lt;p>&lt;img src="images/TextRenderingSample.png" />&lt;/p></description><category>CodeProject</category></item><item><title>Using imp or exp as a SYSDBA</title><link>https://dwmkerr.com/using-imp-or-exp-as-a-sysdba/</link><pubDate>Tue, 21 Feb 2012 07:21:00 +0000</pubDate><guid>https://dwmkerr.com/using-imp-or-exp-as-a-sysdba/</guid><description>&lt;p>One of the things that I regularly forget is the syntax for running imp or exp for Oracle and specifying a SYSDBA user. As a quick hint, here's the syntax:&lt;/p>
&lt;pre class="brush: c-sharp;">imp '"sys/pass@TNS as sysdba"' FILE=file.exp&lt;/pre>
&lt;p>An easy thing to forget!&lt;/p></description><category>CodeProject</category></item><item><title>Debugger:: An unhandled non-continuable exception was thrown during process load</title><link>https://dwmkerr.com/debugger-an-unhandled-non-continuable-exception-was-thrown-during-process-load/</link><pubDate>Wed, 08 Feb 2012 06:54:00 +0000</pubDate><guid>https://dwmkerr.com/debugger-an-unhandled-non-continuable-exception-was-thrown-during-process-load/</guid><description>&lt;p>The following exception can be a very tricky one to deal with:&lt;/p>
&lt;pre>Debugger:: An unhandled non-continuable exception was thrown during process load&lt;/pre>
&lt;p>here's some tips if you get it.&lt;/p>
&lt;ol>
&lt;li>Are you linking to winmm.lib? If so avoid it - it can cause these problems.&lt;/li>
&lt;li>Are you delay-loading the module? If not, try it - this can often resolve this issue if other modules like winmm.lib are interfering with the module that causes this exception.&lt;/li>
&lt;li>Are you using C++/CLI for the excepting module? If so, try using #pragma pack around exported class definitions.&lt;/li>
&lt;/ol>
&lt;div>If you haven't specified packing - do so. This is good practice anyway. I've used libraries that change the packing (which is very bad behaviour) before and this has caused all sorts of problems, so try and do the following:&lt;/div>
&lt;div>
&lt;pre class="brush: c-sharp;">// Push packing options, specify the packing.
#pragma pack(push, 1)
&lt;p>// Exported class
class MY_API MyClass
{
public:&lt;/p>
&lt;pre>&lt;code>// ...etc
&lt;/code>&lt;/pre>
&lt;p>};&lt;/pre>&lt;/p>
&lt;pre class="brush: c-sharp;">// Restore packing options.
#pragma pack(pop)&lt;/pre>
&lt;/div></description><category>CodeProject</category></item><item><title>Switch</title><link>https://dwmkerr.com/switch/</link><pubDate>Sat, 04 Feb 2012 03:53:00 +0000</pubDate><guid>https://dwmkerr.com/switch/</guid><description>&lt;p>&lt;img src="images/Title.jpg" />&lt;/p>
&lt;p>I have written the second article in my series on Extending Visual Studio. In this article I describe how to create a Visual Studio Addin that allows you to switch between cpp/h files, WinForms code and designer, XAML and codebehind and so on. You can find the article on the CodeProject here:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/Articles/324611/Extending-Visual-Studio-Part-2-Creating-Addins">http://www.codeproject.com/Articles/324611/Extending-Visual-Studio-Part-2-Creating-Addins&lt;/a>&amp;nbsp;&lt;/p>
&lt;p>There is also a direct download page on this blog, you can get Switch from dwmkerr.com by going here:&lt;/p>
&lt;p>&lt;a href="http://www.dwmkerr.com/page/Switch.aspx">http://www.dwmkerr.com/page/Switch.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>New Namaste Website</title><link>https://dwmkerr.com/new-namaste-website/</link><pubDate>Tue, 31 Jan 2012 14:18:00 +0000</pubDate><guid>https://dwmkerr.com/new-namaste-website/</guid><description>&lt;p>Today I uploaded the new version of the Namaste - Children's Homes Nepal website, please have a look!&lt;/p>
&lt;p>&lt;a title="Children's Homes Nepal" href="http://www.childrenshomesnepal.org" target="_blank">http://www.childrenshomesnepal.org&lt;/a>&lt;/p>
&lt;p>&amp;nbsp;&lt;img src="images/temp.jpg" />&lt;/p>
&lt;p>Any comments or suggestions would be most welcome :)&lt;/p></description><category>CodeProject</category></item><item><title>Funky WPF - Enumerations and the Combo Box</title><link>https://dwmkerr.com/funky-wpf-enumerations-and-the-combo-box/</link><pubDate>Wed, 18 Jan 2012 03:11:00 +0000</pubDate><guid>https://dwmkerr.com/funky-wpf-enumerations-and-the-combo-box/</guid><description>&lt;p class="MsoNormal">Binding a combo box to an enumeration in WPF is more work than it should be, creating an object data provider etc etc:&lt;/p>
&lt;pre class="brush: xml;">&amp;lt;Window.Resources&amp;gt;
&amp;lt;ObjectDataProvider MethodName="GetValues"
ObjectType="{x:Type sys:Enum}"
x:Key="CharacterEnumValues"&amp;gt;
&amp;lt;ObjectDataProvider.MethodParameters&amp;gt;
&amp;lt;x:Type TypeName="Character" /&amp;gt;
&amp;lt;/ObjectDataProvider.MethodParameters&amp;gt;
&amp;lt;/ObjectDataProvider&amp;gt;
&amp;lt;/Window.Resources&amp;gt;&lt;/pre>
&lt;p class="MsoNormal">Followed by&lt;/p>
&lt;pre class="brush: xml;">&amp;lt;ComboBox SelectedItem="{Binding Character}"&lt;br /> ItemsSource="{Binding &lt;br />Source={StaticResource CharacterValues}} "/&amp;gt;&lt;/pre>
&lt;p class="brush: xml;">What a pain! I have just added 'EnumerationComboBox' to my Apex library - so now you can do this:&lt;/p>
&lt;pre class="brush: xml;">&amp;lt;!-- The combo box, bound to an enumeration. --&amp;gt;
&amp;lt;apexControls:EnumerationComboBox &lt;br />SelectedEnumeration="{Binding Character}" /&amp;gt;&lt;/pre>
&lt;p class="MsoNormal">&lt;span lang="EN-US">No need for an ObjectDataProvider, an items source or anything &amp;ndash; and if you decorate enum&amp;rsquo;s with the &amp;lsquo;[Description]&amp;rsquo; attribute, it&amp;rsquo;ll use the description in the combo.&lt;/span>&lt;/p>
&lt;p class="MsoNormal">&lt;span lang="EN-US">There&amp;rsquo;s an article/download here for anyone who's interested:&lt;/span>&lt;/p>
&lt;p class="MsoNormal">&lt;a href="http://www.codeproject.com/KB/WPF/enumcombobox.aspx">http://www.codeproject.com/KB/WPF/enumcombobox.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>CodeProject MVP</title><link>https://dwmkerr.com/codeproject-mvp/</link><pubDate>Tue, 17 Jan 2012 07:25:00 +0000</pubDate><guid>https://dwmkerr.com/codeproject-mvp/</guid><description>&lt;p>As a great start to the new year I have been made a CodeProject MVP!&lt;/p>
&lt;p>Have a look at my index of articles below:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528">&lt;a href="http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528">http://www.codeproject.com/script/Articles/MemberArticles.aspx?amid=4259528&lt;/a>&lt;/a>&lt;/p>
&lt;p>Any suggestions for future articles are more than appreciated.&lt;/p></description><category>CodeProject</category></item><item><title>Downtime</title><link>https://dwmkerr.com/downtime/</link><pubDate>Wed, 04 Jan 2012 02:57:00 +0000</pubDate><guid>https://dwmkerr.com/downtime/</guid><description>&lt;p>Hi All,&lt;/p>
&lt;p>There will be some downtime on dwmkerr.com for the next 48 hours as I transfer the site and domain to another service.&lt;/p></description><category>CodeProject</category></item><item><title>Extending Visual Studio Part 1 - Code Snippets</title><link>https://dwmkerr.com/extending-visual-studio-part-1-code-snippets/</link><pubDate>Wed, 30 Nov 2011 05:20:00 +0000</pubDate><guid>https://dwmkerr.com/extending-visual-studio-part-1-code-snippets/</guid><description>&lt;p>I have published the first of a series of articles on extending Visual Studio on the CodeProject. Part 1 deals with Code Snippets, the article link is below, enjoy!&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/KB/dotnet/extendingvisualstudio1.aspx">http://www.codeproject.com/KB/dotnet/extendingvisualstudio1.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>How to Debug a Visual Studio Extension</title><link>https://dwmkerr.com/how-to-debug-a-visual-studio-extension/</link><pubDate>Mon, 28 Nov 2011 11:11:00 +0000</pubDate><guid>https://dwmkerr.com/how-to-debug-a-visual-studio-extension/</guid><description>&lt;p>Here are a few tips for debugging Visual Studio Extensions.&lt;/p>
&lt;p>&lt;strong>Visual Studio 2008/2010&lt;/strong>&lt;/p>
&lt;p>If you need to debug your Visual Studio extension, you may find that Visual Studio itself locks it. This is a real drag - to resolve this issue, add the following as a pre-build step:&lt;/p>
&lt;pre>if exist "$(TargetPath).locked" del "$(TargetPath).locked"&lt;/pre>
&lt;pre>if not exist "$(TargetPath).locked" if exist "$(TargetPath)" &lt;br />move "$(TargetPath)" "$(TargetPath).locked"&lt;/pre>
&lt;p>This will ensure the locked file is moved out of the way first - very useful!&lt;/p>
&lt;p>&lt;strong>Visual Studio 2010&lt;/strong>&lt;/p>
&lt;p>Every time I do a clean checkout of one of my projects, it seems to lose the ability to be run in the Experimental mode of visual studio. Here's a quick tip - if you lose the ability to debug your visual studio extension, make sure you have the 'Debug' tab of your project set up as below:&lt;/p>
&lt;p>&lt;img src="images/screenshot.png" />&lt;/p>
&lt;p>Specifically with the external program set as visual studio and the command line arguments as &lt;strong>/rootsuffix exp&lt;/strong>. This will run your extension in the Experimental Instance of Visual Studio.&lt;/p></description><category>CodeProject</category></item><item><title>Composite Data Service Framework on CodeProject</title><link>https://dwmkerr.com/composite-data-service-framework-on-codeproject/</link><pubDate>Sun, 27 Nov 2011 11:12:00 +0000</pubDate><guid>https://dwmkerr.com/composite-data-service-framework-on-codeproject/</guid><description>&lt;p>I have written an article on the CodeProject describing the Composite Data Service Framework project, the article is at:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/KB/WCF/compdataserviceframework1.aspx">http://www.codeproject.com/KB/WCF/compdataserviceframework1.aspx&lt;/a>&lt;/p>
&lt;p>Please have a look and get involved with suggestions via the 'Discuss' page of the CDSF homepage,&amp;nbsp;&lt;a href="http://cdsf.codeplex.com/">http://cdsf.codeplex.com/&lt;/a>.&lt;/p>
&lt;p>&lt;img src="images/CDSF-CodePlex-Banner-Logo.png" />&lt;/p></description><category>CodeProject</category></item><item><title>Getting Source Code Metrics from SVN</title><link>https://dwmkerr.com/getting-source-code-metrics-from-svn/</link><pubDate>Mon, 14 Nov 2011 07:55:00 +0000</pubDate><guid>https://dwmkerr.com/getting-source-code-metrics-from-svn/</guid><description>&lt;p>Lets say that we need to find out how many lines of code exist in a branch, or how many lines are checked in by a specific user. Let's ignore the usefulness of these metrics, just assume that they're needed (realistically, lines of code isn't a very useful metric, but perhaps you want to have a quick idea of how much has gone into a release). How do we do this?&lt;/p>
&lt;p>TortoiseSVN statistics aren't really enough. Here's some alternatives:&lt;/p>
&lt;ul>
&lt;li>SVNPlot&lt;br />Theoretically should give us graphs. Runs in python. Couldn't get it to work in five minutes so moved on.&lt;br />&lt;a href="http://code.google.com/p/svnplot/">http://code.google.com/p/svnplot/&lt;/a>&lt;/li>
&lt;li>StatSVN&lt;br />Much more respected than the above, runs through Java. Again, didn't have results in five minutes to moved on.&lt;br />&lt;a href="http://www.statsvn.org/">http://www.statsvn.org/&lt;/a>&lt;/li>
&lt;li>FishEye&lt;br />Very powerful but it's not free. Generates a lot of information that you can use to analyse your repositories.&lt;br />&lt;a href="http://www.atlassian.com/software/fisheye/overview?gclid=CN6cw4WptqwCFQRP4QodnCtcGg">http://www.atlassian.com/software/fisheye/overview?gclid=CN6cw4WptqwCFQRP4QodnCtcGg&lt;/a>&amp;nbsp;&lt;/li>
&lt;/ul>
&lt;p>I'd recommend taking a look at FishEye if you're going to go to the effort of getting these statistics. Any comments on alternatives would be welcome!&lt;/p></description><category>CodeProject</category></item><item><title>IDataServiceMetadataProvider Entities Missing in $metadata</title><link>https://dwmkerr.com/idataservicemetadataprovider-entities-missing-in-metadata/</link><pubDate>Wed, 09 Nov 2011 15:49:00 +0000</pubDate><guid>https://dwmkerr.com/idataservicemetadataprovider-entities-missing-in-metadata/</guid><description>&lt;p>If you are following through the example on creating custom data service providers as on this blog:&lt;/p>
&lt;p>&lt;a href="http://blogs.msdn.com/b/alexj/archive/2010/01/08/creating-a-data-service-provider-part-3-metadata.aspx">http://blogs.msdn.com/b/alexj/archive/2010/01/08/creating-a-data-service-provider-part-3-metadata.aspx&lt;/a>&lt;/p>
&lt;p>And you notice that your entities are not showing up in the $metadata file, double check that you have added this:&lt;/p>
&lt;pre class="brush: c-sharp;">public class service : MyNewDataService
{
// This method is called only once to initialize service-wide policies.
public static void InitializeService(DataServiceConfiguration config)
{
config.SetEntitySetAccessRule("*", EntitySetRights.AllRead);
config.DataServiceBehavior.MaxProtocolVersion = DataServiceProtocolVersion.V2;
}
}&lt;/pre>
&lt;pre class="brush: c-sharp;">Just remember to set the entity set access rules for all entities - other they won't show up!&lt;/pre></description><category>CodeProject</category></item><item><title>Composite Data Service Framework</title><link>https://dwmkerr.com/composite-data-service-framework/</link><pubDate>Wed, 09 Nov 2011 11:02:00 +0000</pubDate><guid>https://dwmkerr.com/composite-data-service-framework/</guid><description>&lt;p>Today I start a new project - the Composite Data Service Framework.&amp;nbsp;The Composite Data Service Framework is a project that aims to obviate some of the limitations of WCF Data Services, specifically:&lt;/p>
&lt;ul>
&lt;li>Allowing multiple data services to be aggregated in a single data service.&lt;/li>
&lt;li>Providing more support for Service Operations (such as auto-generation of proxies client-side).&lt;/li>
&lt;li>Aggregating different service types (entity framework, CLR types etc)&lt;/li>
&lt;li>Complementing OData services with traditional WCF services with a single definition of proxies client-side.&lt;/li>
&lt;/ul>
&lt;p>The project is in its early stages and is hosted at:&lt;/p>
&lt;p>&lt;a href="http://cdsf.codeplex.com/">http://cdsf.codeplex.com/&lt;/a>&lt;/p>
&lt;p>More updates will follow.&lt;/p></description><category>CodeProject</category></item><item><title>Data Service Exception "Unauthorised" when connecting to Sharepoint OData</title><link>https://dwmkerr.com/data-service-exception-unauthorised-when-connecting-to-sharepoint-odata/</link><pubDate>Wed, 02 Nov 2011 10:28:00 +0000</pubDate><guid>https://dwmkerr.com/data-service-exception-unauthorised-when-connecting-to-sharepoint-odata/</guid><description>&lt;p>If you are struggling to fetch data from a Sharepoint OData service and getting an error as below:&lt;/p>
&lt;pre> [DataServiceClientException: Unauthorized]
System.Data.Services.Client.QueryResult.Execute() +436914
System.Data.Services.Client.DataServiceRequest.Execute(DataServiceContext context, QueryComponents queryComponents) +133&amp;nbsp;&lt;/pre>
&lt;p>Then ensure you are setting the Credentials property of your Data Service Context, as below:&lt;/p>
&lt;pre class="brush: c-sharp;">// Create the data context.
SharepointDataContext dc = new SharepointDataContext(new Uri("http://dksp/_vti_bin/listdata.svc"));
&lt;p>// Provide default credentials, without this authorisation will fail!
dc.Credentials = System.Net.CredentialCache.DefaultCredentials;&lt;/p>
&lt;p>// Etc&amp;hellip;
var accounts = from a in dc.Accounts select a;&lt;/pre>&lt;/p>
&lt;p class="brush: c-sharp;">Just another issue you may come across when using Sharepoint OData services!&lt;/p></description><category>CodeProject</category></item><item><title>The "Name attribute is invalid" when adding a Service Reference to a Sharepoint OData Service</title><link>https://dwmkerr.com/the-name-attribute-is-invalid-when-adding-a-service-reference-to-a-sharepoint-odata-service/</link><pubDate>Wed, 02 Nov 2011 10:19:00 +0000</pubDate><guid>https://dwmkerr.com/the-name-attribute-is-invalid-when-adding-a-service-reference-to-a-sharepoint-odata-service/</guid><description>&lt;p>Well this little issue took me a while to investigate, but the skinny is this:&lt;/p>
&lt;p>If you are going to add a service reference to a Sharepoint OData service (e.g.&amp;nbsp;http://sharepoint/_vti_bin/listdata.svc) then make sure your Sharepoint site name does NOT begin with a number - otherwise Visual Studio will fail to add the reference.&lt;/p>
&lt;p>Quick and easy, but this took quite a while for me to find, hope it helps anyone in the same situation!&lt;/p></description><category>CodeProject</category></item><item><title>Apex 1.2 Released</title><link>https://dwmkerr.com/apex-1-2-released/</link><pubDate>Tue, 01 Nov 2011 07:31:00 +0000</pubDate><guid>https://dwmkerr.com/apex-1-2-released/</guid><description>&lt;p>Apex 1.2 has been released, with some new features:&lt;/p>
&lt;ul>
&lt;li>The &amp;lsquo;Compatibility&amp;rsquo; namespace, which contains classes to address compatibility issues between WPF, Silverlight and WP7.&lt;/li>
&lt;li>The &amp;lsquo;Asynchronous Command&amp;rsquo; object, which provides a powerful way to use Asynchronous Commands in MVVM.&lt;/li>
&lt;/ul>
&lt;p>The release is at: &lt;a href="https://github.com/dwmkerr/apex">https://github.com/dwmkerr/apex&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>MVVM Commanding</title><link>https://dwmkerr.com/mvvm-commanding/</link><pubDate>Sat, 29 Oct 2011 08:31:00 +0000</pubDate><guid>https://dwmkerr.com/mvvm-commanding/</guid><description>&lt;p>I have written an article that describes commanding in WPF, Silverlight and WP7 in detail. It is on the CodeProject at:&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/KB/WPF/consistentmvvmcommands.aspx">http://www.codeproject.com/KB/WPF/consistentmvvmcommands.aspx&lt;/a>&lt;/p>
&lt;p>It uses the latest version of Apex (version 1.2) which will be released formally shortly. Enjoy!&lt;/p></description><category>CodeProject</category></item><item><title>MVVM: Asynchronous Commands</title><link>https://dwmkerr.com/mvvm-asynchronous-commands/</link><pubDate>Mon, 24 Oct 2011 03:51:00 +0000</pubDate><guid>https://dwmkerr.com/mvvm-asynchronous-commands/</guid><description>&lt;p>The latest cut of the Apex Code (&lt;a href="http://apex.codeplex.com/SourceControl/changeset/changes/6701">http://apex.codeplex.com/SourceControl/changeset/changes/6701&lt;/a>) contains a very cool new feature - Asynchronous Command Objects.&lt;/p>
&lt;p>An Asynchronous Command is a ViewModelCommand - the standard object used in Apex for commanding. However, what is different about this function is that it runs Asynchronously.&lt;/p>
&lt;p>One of the problems with running a view model command asynchronously is that generally the view model properties cannot be accessed - as they're created on a different dispatcher. This problem is resolved by using the 'ReportProgress' function. Here's an example:&lt;/p>
&lt;pre class="brush: c-sharp;">public class SomeViewModel : ViewModel
{
public SomeViewModel()
{
// Create the command.
asyncCommand = new AsynchronousCommand(DoAsyncCommand, true);
}
&lt;p>private void DoAsyncCommand()
{
for(int i = 0; i &amp;lt; 100; i++)
{
// Perform some long operation.
string message = DoSomeLongOperation();&lt;/p>
&lt;pre>&lt;code> // Add the message to the View Model - safely!
asyncCommand.ReportProgress(
() =&amp;amp;gt;
{
messages.Add(message);
}
);
}
&lt;/code>&lt;/pre>
&lt;p>}&lt;/p>
&lt;p>private ObservableCollection&amp;lt;string&amp;gt; messages =
new ObservableCollection&amp;lt;string&amp;gt;();&lt;/p>
&lt;p>public ObservableCollection&amp;lt;string&amp;gt; Messages
{
get { return messages; }
}&lt;/p>
&lt;p>private AsynchronousCommand asyncCommand;&lt;/p>
&lt;p>public AsynchronousCommand AsyncCommand
{
get { return asyncCommand; }
}
}&lt;/pre>&lt;/p>
&lt;p class="brush: c-sharp;">In this basic mock-up we have a command called 'AsyncCommand' (which we could bind a button to for example) which invokes DoAsyncCommand. However, it invokes it Asynchronously. We can also update the ViewModel properties by using ReportProgress - meaning AsyncCommands can seamlessly provide live feedback while they're working - and we're keeping well locked in with the MVVM commanding model!&lt;/p>
&lt;p class="brush: c-sharp;">Expect a full article soon on the CodeProject, until then the source is at:&lt;/p>
&lt;p class="brush: c-sharp;">&lt;a href="http://apex.codeplex.com/SourceControl/changeset/changes/6701">http://apex.codeplex.com/SourceControl/changeset/changes/6701&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>SharpGL 2.0 Beta 1 Released</title><link>https://dwmkerr.com/sharpgl-2-0-beta-1-released/</link><pubDate>Mon, 10 Oct 2011 04:38:00 +0000</pubDate><guid>https://dwmkerr.com/sharpgl-2-0-beta-1-released/</guid><description>&lt;p>It's been a long time coming, but the first Beta of SharpGL 2.0 is finally here!&lt;/p>
&lt;p>The Beta is on CodePlex at:&amp;nbsp;&lt;a href="http://sharpgl.codeplex.com/releases/view/74704">http://sharpgl.codeplex.com/releases/view/74704&lt;/a>&lt;/p>
&lt;p>This includes the binaries, example applications and full source code.&lt;/p>
&lt;p>Some of the more exciting features are:&lt;/p>
&lt;ul>
&lt;li>Full hardware acceleration&lt;/li>
&lt;li>OpenGL Extensions&lt;/li>
&lt;li>Full core functionality up to OpenGL 4.2&lt;/li>
&lt;li>Native WPF Control&lt;/li>
&lt;/ul>
&lt;div>Below is a screenshot of SharpGL in a WPF application:&lt;/div>
&lt;div>&amp;nbsp;&lt;/div>
&lt;div>&amp;nbsp;&lt;img src="images/MainWindow-Final.png" />&lt;/div>
&lt;div>&amp;nbsp;&lt;/div>
&lt;div>And here's a link to a new CodeProject article describing how to use SharpGL in a WPF application:&lt;/div>
&lt;div>&amp;nbsp;&lt;/div>
&lt;div>&lt;a href="http://www.codeproject.com/KB/WPF/openglinwpf.aspx">http://www.codeproject.com/KB/WPF/openglinwpf.aspx&lt;/a>&lt;/div>
&lt;div>&amp;nbsp;&lt;/div>
&lt;div>Please try out SharpGL 2.0 Beta 1 and let me know what you think!&lt;/div></description><category>CodeProject</category></item><item><title>CodeProject Competition</title><link>https://dwmkerr.com/codeproject-competition/</link><pubDate>Thu, 06 Oct 2011 07:30:00 +0000</pubDate><guid>https://dwmkerr.com/codeproject-competition/</guid><description>&lt;p>My Solitaire and Spider Solitaire in WPF article is in two CodeProject competitions this month. The article is at:&lt;/p>
&lt;p>&lt;a href="https://www.codeproject.com/Articles/252152/Solitaire-and-Spider-Solitaire-for-WPF">https://www.codeproject.com/Articles/252152/Solitaire-and-Spider-Solitaire-for-WPF&lt;/a>&lt;/p>
&lt;p>If you think the article is worthy of a vote, then please go to the voting page for either of the two competitions!&lt;/p>
&lt;p>Best C# Article: &lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209">&lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209">http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1209&lt;/a>&lt;/a>&lt;/p>
&lt;p>Best Overall Article: &lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212">&lt;a href="http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212">http://www.codeproject.com/script/Surveys/VoteForm.aspx?srvid=1212&lt;/a>&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Drawing a DIB Section in WPF</title><link>https://dwmkerr.com/drawing-a-dib-section-in-wpf/</link><pubDate>Fri, 30 Sep 2011 05:09:00 +0000</pubDate><guid>https://dwmkerr.com/drawing-a-dib-section-in-wpf/</guid><description>&lt;p>One of the most exciting new features in the forthcoming SharpGL 2.0 (which was actually planned for 2.1 but has been moved to 2.0) is the facility to do OpenGL drawing in a WPF control. This isn't done via a WinFormsHost (which has unpleasant side-effects due to Airspace, see&amp;nbsp;&lt;a href="http://msdn.microsoft.com/en-us/library/aa970688(v=VS.100).aspx">http://msdn.microsoft.com/en-us/library/aa970688(v=VS.100).aspx&lt;/a>) but actually via an Image in a WPF UserControl.&lt;/p>
&lt;p>What does this mean? Well it means that when you use the SharpGL.WPF libraries OpenGLControl you get what is essentially a genuine WPF control - you can overlay other controls on top of it, with transparency and bitmap effects and do everything you'd normally be able to do with a WPF control.&lt;/p>
&lt;p>How this works is an interesting bit of code so here are the details.&lt;/p>
&lt;p>When using a WPF OpenGL control we render either using a DIBSectionRenderContextProvider, or a FBORenderContextProvider. Here's the difference:&lt;/p>
&lt;p>&lt;strong>DIBSectionRenderContextProvider&lt;/strong>&amp;nbsp;- Renders directly to a DIB Section. Supported with any version of OpenGL but never hardware accelerated.&lt;/p>
&lt;p>&lt;strong>FBORenderContextProvider&lt;/strong>&amp;nbsp;- Renders to a Framebuffer object, via the GL_EXT_framebuffer_object extension. This is fully hardware accelerated but only supported in OpenGL 1.3 and upwards. The resultant framebuffer is copied into a DIB section also.&lt;/p>
&lt;p>With either render context provider we end up with a DIB section that contains the frame - here's how we can render it:&lt;/p>
&lt;pre class="brush: c-sharp;">/// &amp;lt;summary&amp;gt;
/// Converts a &amp;lt;see cref="System.Drawing.Bitmap"/&amp;gt; into a WPF &amp;lt;see cref="BitmapSource"/&amp;gt;.
/// &amp;lt;/summary&amp;gt;
/// &amp;lt;remarks&amp;gt;Uses GDI to do the conversion. Hence the call to the marshalled DeleteObject.
/// &amp;lt;/remarks&amp;gt;
/// &amp;lt;param name="source"&amp;gt;The source bitmap.&amp;lt;/param&amp;gt;
/// &amp;lt;returns&amp;gt;A BitmapSource&amp;lt;/returns&amp;gt;
public static BitmapSource HBitmapToBitmapSource(IntPtr hBitmap)
{
BitmapSource bitSrc = null;
&lt;pre>&lt;code>try
{
bitSrc = System.Windows.Interop.Imaging.CreateBitmapSourceFromHBitmap(
hBitmap,
IntPtr.Zero,
Int32Rect.Empty,
BitmapSizeOptions.FromEmptyOptions());
}
catch (Win32Exception)
{
bitSrc = null;
}
finally
{
Win32.DeleteObject(hBitmap);
}
return bitSrc;
&lt;/code>&lt;/pre>
&lt;p>}&lt;/pre>&lt;/p>
&lt;p>This function allows us to turn a handle to a DIB section into a BitmapSource. The OpenGLControl is essentially just an image, and with each frame we simply set the BitmapSource to the newly rendered DIBSection.&lt;/p>
&lt;p>The version of the code this post relates to is:&amp;nbsp;&lt;a href="http://sharpgl.codeplex.com/SourceControl/changeset/view/4805">http://sharpgl.codeplex.com/SourceControl/changeset/view/4805&lt;/a>&lt;/p>
&lt;p>The WPF example renders the Utah Teapot (&lt;a href="http://en.wikipedia.org/wiki/Utah_teapot">http://en.wikipedia.org/wiki/Utah_teapot&lt;/a>) directly in a WPF application. We're still pre-beta but grab the code if you want to try OpenGL in WPF.&lt;/p></description><category>CodeProject</category></item><item><title>Importing OpenGL Extensions Functions with wglGetProcAddress</title><link>https://dwmkerr.com/importing-opengl-extensions-functions-with-wglgetprocaddress/</link><pubDate>Sat, 24 Sep 2011 06:57:00 +0000</pubDate><guid>https://dwmkerr.com/importing-opengl-extensions-functions-with-wglgetprocaddress/</guid><description>&lt;p>There are only a small set of the core OpenGL functions that can be imported via p/invoke - the majority of OpenGL functions are actually extension functions which are supported only on specific video cards. OpenGL offers a function called&amp;nbsp;wglGetProcAddress which can return the address of a named function - but how do we deal with this in the managed world?&lt;/p>
&lt;p>Here's a brief description of how it's handled in SharpGL. As of this morning, SharpGL's latest version contains &lt;strong>all &lt;/strong>core functions up to OpenGL 4.2 and &lt;strong>all &lt;/strong>standard extensions up to OpenGL 4.2. This takes the support for OpenGL to the latest version - August 2011.&lt;/p>
&lt;p>First we must import the wglGetProcAddress function:&lt;/p>
&lt;pre class="brush: c-sharp;">[DllImport("opengl32.dll")]
public static extern IntPtr wglGetProcAddress(string name);&lt;/pre>
&lt;p>This is the correect p/invoke method of importing this function, however it returns an IntPtr, which we cannot call as a function. We could change the return type to a delegate but this function can return essentially any type of delegate - so where do we go from here?&lt;/p>
&lt;p>Well the next step is to define the delegates we want to use - they must have exactly the same name as the OpenGL functions and use the correct parameters for marshalling. Here are a couple of delegates for OpenGL 1.4:&lt;/p>
&lt;pre class="brush: c-sharp;">private delegate void glBlendFuncSeparate (uint sfactorRGB, uint dfactorRGB, uint sfactorAlpha, uint dfactorAlpha);
&lt;p>private delegate void glMultiDrawArrays (uint mode, int[] first, int[] count, int primcount);&lt;/pre>&lt;/p>
&lt;p>Now we must create a function which will turn an IntPtr into a delegate and invoke it:&lt;/p>
&lt;pre class="brush: c-sharp;">/// &amp;lt;summary&amp;gt;
/// The set of extension functions.
/// &amp;lt;/summary&amp;gt;
private Dictionary&amp;lt;string, Delegate&amp;gt; extensionFunctions = new Dictionary&amp;lt;string, Delegate&amp;gt;();
&lt;p>/// &amp;lt;summary&amp;gt;
/// Invokes an extension function.
/// &amp;lt;/summary&amp;gt;
/// &amp;lt;typeparam name=&amp;quot;T&amp;rdquo;&amp;gt;The extension delegate type.&amp;lt;/typeparam&amp;gt;
/// &amp;lt;param name=&amp;quot;args&amp;rdquo;&amp;gt;The arguments to the pass to the function.&amp;lt;/param&amp;gt;
/// &amp;lt;returns&amp;gt;The return value of the extension function.&amp;lt;/returns&amp;gt;
private object InvokeExtensionFunction&amp;lt;T&amp;gt;(params object[] args)
{
// Get the type of the extension function.
Type delegateType = typeof(T);&lt;/p>
&lt;pre>&lt;code>// Get the name of the extension function.
string name = delegateType.Name;
// Does the dictionary contain our extension function?
Delegate del = null;
if (extensionFunctions.ContainsKey(name) == false)
{
// We haven't loaded it yet. Load it now.
IntPtr proc = Win32.wglGetProcAddress(name);
if (proc == IntPtr.Zero)
throw new Exception(&amp;quot;Extension function &amp;quot; + name + &amp;quot; not supported&amp;quot;);
// Get the delegate for the function pointer.
del = Marshal.GetDelegateForFunctionPointer(proc, delegateType);
if (del == null)
throw new Exception(&amp;quot;Extension function &amp;quot; + name + &amp;quot; not supported&amp;quot;);
// Add to the dictionary.
extensionFunctions.Add(name, del);
}
// Get the delegate.
del = extensionFunctions[name];
// Try and invoke it.
object result = null;
try
{
result = del.DynamicInvoke(args);
}
catch
{
throw new Exception(&amp;quot;Cannot invoke extension function &amp;quot; + name);
}
return result;
&lt;/code>&lt;/pre>
&lt;p>}&lt;/pre>&lt;/p>
&lt;p>We now have a generalised way to invoke an extension function. The loaded functions are stored in a dictionary keyed by name so that the heavy lifting is only done the first time we try to invoke the function. &amp;nbsp;We can finally add the functions to the class as below:&lt;/p>
&lt;pre class="brush: c-sharp;">public void BlendFuncSeparate(uint sfactorRGB, uint dfactorRGB, uint sfactorAlpha, uint dfactorAlpha)
{
InvokeExtensionFunction&amp;lt;glBlendFuncSeparate&amp;gt;(sfactorRGB, dfactorRGB, sfactorAlpha, dfactorAlpha);
}
&lt;p>public void MultiDrawArrays(uint mode, int[] first, int[] count, int primcount)
{
InvokeExtensionFunction&amp;lt;glMultiDrawArrays&amp;gt;(mode, first, count, primcount);
}&lt;/pre>&lt;/p>
&lt;p>This is pretty cool - we can invoke any extension function as long as we have defined a delegate for it. What's more, by making the InvokeExtensionFunction function public we can allow other developers to provide their own delegates and invoke other extension functions.&lt;/p>
&lt;p>This is the technique used in SharpGL 2.0 to import extension functions - the Core/OpenGLExtensions.cs file contains thousands of lines of functions defined like this, however knowing how to invoke any kind of delegate is a useful skill in the managed world, so this trick could be used in other places.&lt;/p>
&lt;p>The version of SharpGL this post relates to is at:&lt;/p>
&lt;p>&lt;a href="http://sharpgl.codeplex.com/SourceControl/changeset/view/4474">http://sharpgl.codeplex.com/SourceControl/changeset/view/4474&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Visual Studio Code Analysis - Buffer Overruns</title><link>https://dwmkerr.com/visual-studio-code-analysis-buffer-overruns/</link><pubDate>Tue, 20 Sep 2011 13:55:00 +0000</pubDate><guid>https://dwmkerr.com/visual-studio-code-analysis-buffer-overruns/</guid><description>&lt;p>Today I was looking through some fairly old source code in a large solution, large in this case is ~300 projects and about 1 million lines of code. Parts of the code base are very old - at some stage a decision was made to disable warning C4996. The problem I came across is reduced to its most simple form below:&lt;/p>
&lt;pre class="brush: c-sharp;">// AnalysisExample.cpp : An example of how static analysis can help.
//
&lt;p>#include &amp;ldquo;stdafx.h&amp;rdquo;&lt;/p>
&lt;p>int _tmain(int argc, _TCHAR* argv[])
{
// Create two buffers, one small, one large.
TCHAR storageSmall[13];
TCHAR storageLarge[128];&lt;/p>
&lt;pre>&lt;code>// Get a pointer to a string literal.
TCHAR* str = _T(&amp;quot;Here is a string that is too long.&amp;quot;);
// Now do something very dangerous.
::_tcscpy(storageLarge, str);
::_tcscpy(storageSmall, storageLarge);
return 0;
&lt;/code>&lt;/pre>
&lt;p>}&lt;/pre>&lt;/p>
&lt;p>Now in a sensible world with this warning enabled, we would get the following when compiling:&lt;/p>
&lt;pre>analysisexample.cpp(14): warning C4996: 'wcscpy':
This function or variable may be unsafe. Consider using
wcscpy_s instead. To disable deprecation, use
_CRT_SECURE_NO_WARNINGS. See online help for details.&lt;/pre>
&lt;pre>analysisexample.cpp(15): warning C4996: 'wcscpy':
This function or variable may be unsafe. Consider using
wcscpy_s instead. To disable deprecation, use
_CRT_SECURE_NO_WARNINGS. See online help for details.&lt;/pre>
&lt;p>The warning is telling us that wcscpy (which is what _tcscpy translates to in a Unicode build) is unsafe, which indeed it is as it does no buffer checking. However, when you migrate a Visual Studio 2005 solution to 2008 or straight to 2010 then suddenly you'll get lots of warnings like this. If there are thousands of warnings and they're masking other more important ones then you can see why maybe you'd consider disabling them.&lt;/p>
&lt;p>Why is this a bug?&lt;/p>
&lt;p>In case you didn't see it, a string literal that is 34 characters long (68 bytes) is copied to a buffer 128 characters long. OK so far. Then we copy the 34 characters into a smaller 13 character buffer - this causes a buffer overrun on the stack. In reality what happens is variables used subsequently in the function get overwritten unexpectedly. Or don't. Generally the worst case is that nothing odd happens during testing, but then the code blows up on-site with the customer, typically on something business critical like a database server - something it's hard to debug on.&lt;/p>
&lt;p>Visual Studio's Code Analysis tool is a life-saver. If you haven't used it before, get used to running it on &lt;em>all&lt;/em>&amp;nbsp;of your projects. Here's what happens when we run it (Analyze &amp;gt; Run Code Analysis On Solution):&lt;/p>
&lt;pre>1&amp;gt;analysisexample.cpp(18): warning C6202:
Buffer overrun for 'storageSmall', which is possibly
stack allocated, in call to 'wcscpy': length '256'
exceeds buffer size '26'&lt;/pre>
&lt;p>Code analysis has shown us &lt;em>exactly&lt;/em>&amp;nbsp;the problem, even with the warning disabled.&lt;/p>
&lt;p>So why is this important? Imagine we have the following four lines spread across four files:&lt;/p>
&lt;pre class="brush: c-sharp;">// Defined in Header1.h
static const int LENGTH1 = 13;
&lt;p>// Defined in Header2.h
static const int LENGTH2 = 128;&lt;/p>
&lt;p>// Defined in Header3.h
typedef TCHAR LineOne[LENGTH1];&lt;/p>
&lt;p>// Defined in Header4.h
typedef TCHAR LineTwo[LENGTH2];&lt;/pre>&lt;/p>
&lt;p>Our code could now look like this:&lt;/p>
&lt;pre class="brush: c-sharp;">// Create two buffers, one small, one large.
LineOne storageSmall;
LineTwo storageLarge;
&lt;p>// Get a pointer to a string literal.
TCHAR* str = _T(&amp;ldquo;Here is a string that is too long.&amp;quot;);&lt;/p>
&lt;p>// Now do something very dangerous.
::_tcscpy(storageLarge, str);
::_tcscpy(storageSmall, storageLarge);&lt;/pre>&lt;/p>
&lt;p>Suddenly things aren't looking quite so obviously wrong - now imagine the different lines that make up this bug are spread across more files - or even more projects. Static analysis takes only a few seconds to run, unfortunately it's only available in the more expensive versions of visual studio.&lt;/p>
&lt;p>An even better solution - don't run the risk, use &lt;strong>_tcscpy_s&lt;/strong>&amp;nbsp;rather than &lt;strong>_tcscpy &lt;/strong>- it checks the buffer length without even requiring a single extra parameter in the example above.&lt;/p></description><category>CodeProject</category></item><item><title>How ISupportInitialize Can Help</title><link>https://dwmkerr.com/how-isupportinitialize-can-help/</link><pubDate>Sun, 18 Sep 2011 14:49:00 +0000</pubDate><guid>https://dwmkerr.com/how-isupportinitialize-can-help/</guid><description>&lt;p>I have recently come to discover the &lt;a href="http://msdn.microsoft.com/en-us/library/system.componentmodel.isupportinitialize.aspx">ISupportInitialize&lt;/a> interface and found that it is extremely useful when developing more complicated WinForms controls.&lt;/p>
&lt;p>Here's the link to the interface on MSDN: &lt;a href="http://msdn.microsoft.com/en-us/library/system.componentmodel.isupportinitialize.aspx">ISupportInitialize&lt;/a> - here I'll describe how it can be useful.&lt;/p>
&lt;h3 id="the-problem">The Problem&lt;/h3>
&lt;p>I have a fairly complicated WinForms usercontrol called 'OpenGLControl', which allows OpenGL commands to be used to render 3D scenes in a C# WinForms application. The control has properties which are interdependent to each other. If these properties are set in the designer, code like this is generated:
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#75715e">// openGLControl1
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.Anchor = ((System.Windows.Forms.AnchorStyles)((((System.Windows.Forms.AnchorStyles.Top | System.Windows.Forms.AnchorStyles.Bottom)
| System.Windows.Forms.AnchorStyles.Left)
| System.Windows.Forms.AnchorStyles.Right)));
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.BitDepth = &lt;span style="color:#ae81ff">3&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.DrawRenderTime = &lt;span style="color:#66d9ef">true&lt;/span>;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.FrameRate = &lt;span style="color:#ae81ff">2&lt;/span>&lt;span style="color:#ae81ff">9.41176F&lt;/span>;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.Location = &lt;span style="color:#66d9ef">new&lt;/span> System.Drawing.Point(&lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>);
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.Name = &lt;span style="color:#e6db74">&amp;#34;openGLControl1&amp;#34;&lt;/span>;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.RenderContextType = SharpGL.RenderContextType.NativeWindow;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.Size = &lt;span style="color:#66d9ef">new&lt;/span> System.Drawing.Size(&lt;span style="color:#ae81ff">7&lt;/span>&lt;span style="color:#ae81ff">6&lt;/span>&lt;span style="color:#ae81ff">8&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>&lt;span style="color:#ae81ff">7&lt;/span>&lt;span style="color:#ae81ff">9&lt;/span>);
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.TabIndex = &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1.OpenGLDraw += &lt;span style="color:#66d9ef">new&lt;/span> System.Windows.Forms.PaintEventHandler(&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1_OpenGLDraw);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now this leads to a problem - BitDepth, OpenGLDraw, FrameRate etc must all be declared BEFORE the Size property is set - but how can we control this? Or how can we deal with this situation in general?&lt;/p>
&lt;p>This is where the ISupportInitialize interface comes in. If a control is added to the design surface with this interface, we'll get the following code wrapped around the designer code:&lt;/p>
&lt;div class="highlight">&lt;pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-cs" data-lang="cs">&lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> InitializeComponent()
{
System.ComponentModel.ComponentResourceManager resources = &lt;span style="color:#66d9ef">new&lt;/span> System.ComponentModel.ComponentResourceManager(&lt;span style="color:#66d9ef">typeof&lt;/span>(FormExample1));
&lt;span style="color:#66d9ef">this&lt;/span>.label1 = &lt;span style="color:#66d9ef">new&lt;/span> System.Windows.Forms.Label();
&lt;span style="color:#66d9ef">this&lt;/span>.linkLabel1 = &lt;span style="color:#66d9ef">new&lt;/span> System.Windows.Forms.LinkLabel();
&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1 = &lt;span style="color:#66d9ef">new&lt;/span> SharpGL.OpenGLControl();
((System.ComponentModel.ISupportInitialize)(&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1)).BeginInit();
&lt;span style="color:#66d9ef">this&lt;/span>.SuspendLayout();
&lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// ...ordianry designer code...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">//
&lt;/span>&lt;span style="color:#75715e">&lt;/span> ((System.ComponentModel.ISupportInitialize)(&lt;span style="color:#66d9ef">this&lt;/span>.openGLControl1)).EndInit();
&lt;span style="color:#66d9ef">this&lt;/span>.ResumeLayout(&lt;span style="color:#66d9ef">false&lt;/span>);
&lt;span style="color:#66d9ef">this&lt;/span>.PerformLayout();
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now just implement the ISupportInitialize interface in your control - in the &amp;lsquo;EndInit&amp;rsquo; function do any processing that depends on the interdependent properties. This is the earliest point that we can do processing like this. In certain circumstances, knowing about this interface can save you a lot of trouble.&lt;/p></description><category>CodeProject</category></item><item><title>SharpGL 2.0: Hardware Acceleration</title><link>https://dwmkerr.com/sharpgl-2-0-hardware-acceleration/</link><pubDate>Tue, 13 Sep 2011 07:33:00 +0000</pubDate><guid>https://dwmkerr.com/sharpgl-2-0-hardware-acceleration/</guid><description>&lt;p>It took a bit of working out, but finally SharpGL can support hardware acceleration. Previously, all rendering in SharpGL was done to a DIB Section, the result of this would be blitted to the screen. Much playing around has shown that in fact this is problematic - rendering to DIB sections can &lt;em>never&lt;/em> be hardware accelerated.&lt;/p>
&lt;p>To hardware accelerate rendering, the rendering must be to a window or a pixel buffer. This has introduced an architectural change to SharpGL - the handling of a render context and any supporting objects (DIB sections, windows etc) is handled by a class that implements the IRenderContextProvider interface. This interface specifies that render context providers must be able to Create, Destroy, Resize and Blit.&lt;/p>
&lt;p>SharpGL 2.0 now has two render context providers, DIBSectionRenderContext provider which uses a DIB Section as previously and HiddenWindowRenderContextProvider which renders to a hidden window. The hidden window render context provider allows full hardware acceleration.&lt;/p>
&lt;p>I will be adding a new example application to the solution which shows rendering with the two providers side by side.&lt;/p>
&lt;p>So don't forget: DIB Sections can't be accelerated.&lt;/p></description><category>CodeProject</category></item><item><title>P/Invoke Performance</title><link>https://dwmkerr.com/pinvoke-performance/</link><pubDate>Mon, 12 Sep 2011 13:09:00 +0000</pubDate><guid>https://dwmkerr.com/pinvoke-performance/</guid><description>&lt;p>SharpGL 2.0 has no P/Invoke - all native functions are called by a C++/CLI class library (OpenGLWrapper if you're getting the code from CodePlex) which calls functions directly. This means there's no more importing of PIXELFORMAT structures and so on.&lt;/p>
&lt;p>The thinking behind this was that a C++/CLI wrapper is faster than P/Invoke for a talkative API like OpenGL - but is this actually the case? In my new article on the CodeProject I investigate the performance differences between these two methods.&lt;/p>
&lt;p>&lt;a href="http://www.codeproject.com/KB/dotnet/pinvokeperformance.aspx">http://www.codeproject.com/KB/dotnet/pinvokeperformance.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item><item><title>Trials and Tribulations with SharpGL 2.0</title><link>https://dwmkerr.com/trials-and-tribulations-with-sharpgl-2-0/</link><pubDate>Mon, 12 Sep 2011 06:03:00 +0000</pubDate><guid>https://dwmkerr.com/trials-and-tribulations-with-sharpgl-2-0/</guid><description>&lt;p>SharpGL has not been updated for a while, the original CoreProject article is at: &lt;a href="http://www.codeproject.com/KB/openGL/sharpgl.aspx">http://www.codeproject.com/KB/openGL/sharpgl.aspx&lt;/a>&lt;/p>
&lt;p>Recently I have begun work on SharpGL 2.0, with plans to address some of the issues people have had with SharpGL 1.83. In preparation there is a public accessible repository on CodePlex: &lt;a href="http://sharpgl.codeplex.com/">http://sharpgl.codeplex.com/&lt;/a>&amp;nbsp;check it soon, it will shortly be online.&lt;/p>
&lt;p>Trying to squeeze acceptible performance from SharpGL has so far been an interesting task, I have found out many interesting things on the way, I'll be posting small snippets as I work on SharpGL 2.0 describing how I'm improving the performance and structure of the library.&lt;/p></description><category>CodeProject</category></item><item><title>Solitaire and Spider Solitaire on the CodeProject</title><link>https://dwmkerr.com/solitaire-and-spider-solitaire-on-the-codeproject/</link><pubDate>Mon, 12 Sep 2011 06:01:00 +0000</pubDate><guid>https://dwmkerr.com/solitaire-and-spider-solitaire-on-the-codeproject/</guid><description>&lt;p>I have uploaded a new article on the CodeProject, a step by step tutorial showing how to create Solitaire and Spider Solitaire for WPF with the help of Apex.&lt;/p>
&lt;p>The article is available at: &lt;a href="http://www.codeproject.com/KB/WPF/solitaire.aspx">http://www.codeproject.com/KB/WPF/solitaire.aspx&lt;/a>&lt;/p></description><category>CodeProject</category></item></channel></rss>